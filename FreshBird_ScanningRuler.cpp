///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 18.05
///////////////////////////////////////////////////////////////////////////////




#ifndef __APPLE__
#  include "HalconCpp.h"
#  include "HDevThread.h"
#else
#  ifndef HC_LARGE_IMAGES
#    include <HALCONCpp/HalconCpp.h>
#    include <HALCONCpp/HDevThread.h>
#  else
#    include <HALCONCppxl/HalconCpp.h>
#    include <HALCONCppxl/HDevThread.h>
#  endif
#endif



using namespace HalconCpp;

HTuple  gIsSinglePose;
HTuple  gTerminationButtonLabel;
HTuple  gInfoDecor;
HTuple  gInfoPos;
HTuple  gTitlePos;
HTuple  gTitleDecor;
HTuple  gAlphaDeselected;
HTuple  gDispObjOffset;
HTuple  gLabelsDecor;
HTuple  gUsesOpenGL;
HTuple ExpGetGlobalVar_gIsSinglePose(void)
{
  return gIsSinglePose;
}
void ExpSetGlobalVar_gIsSinglePose(HTuple val)
{
  gIsSinglePose = val;
}

HTuple ExpGetGlobalVar_gTerminationButtonLabel(void)
{
  return gTerminationButtonLabel;
}
void ExpSetGlobalVar_gTerminationButtonLabel(HTuple val)
{
  gTerminationButtonLabel = val;
}

HTuple ExpGetGlobalVar_gInfoDecor(void)
{
  return gInfoDecor;
}
void ExpSetGlobalVar_gInfoDecor(HTuple val)
{
  gInfoDecor = val;
}

HTuple ExpGetGlobalVar_gInfoPos(void)
{
  return gInfoPos;
}
void ExpSetGlobalVar_gInfoPos(HTuple val)
{
  gInfoPos = val;
}

HTuple ExpGetGlobalVar_gTitlePos(void)
{
  return gTitlePos;
}
void ExpSetGlobalVar_gTitlePos(HTuple val)
{
  gTitlePos = val;
}

HTuple ExpGetGlobalVar_gTitleDecor(void)
{
  return gTitleDecor;
}
void ExpSetGlobalVar_gTitleDecor(HTuple val)
{
  gTitleDecor = val;
}

HTuple ExpGetGlobalVar_gAlphaDeselected(void)
{
  return gAlphaDeselected;
}
void ExpSetGlobalVar_gAlphaDeselected(HTuple val)
{
  gAlphaDeselected = val;
}

HTuple ExpGetGlobalVar_gDispObjOffset(void)
{
  return gDispObjOffset;
}
void ExpSetGlobalVar_gDispObjOffset(HTuple val)
{
  gDispObjOffset = val;
}

HTuple ExpGetGlobalVar_gLabelsDecor(void)
{
  return gLabelsDecor;
}
void ExpSetGlobalVar_gLabelsDecor(HTuple val)
{
  gLabelsDecor = val;
}

HTuple ExpGetGlobalVar_gUsesOpenGL(void)
{
  return gUsesOpenGL;
}
void ExpSetGlobalVar_gUsesOpenGL(HTuple val)
{
  gUsesOpenGL = val;
}

// Procedure declarations 
// Chapter: Graphics / Output
// Short Description: Reflect the pose change that was introduced by the user by moving the mouse 
void analyze_graph_event (HObject ho_BackgroundImage, HTuple hv_Parameters, HTuple hv_MouseMapping, 
    HTuple hv_Button, HTuple hv_Row, HTuple hv_Column, HTuple hv_WindowHandle, HTuple hv_WindowHandleBuffer, 
    HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple hv_SelectedObjectIn, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_Labels, HTuple hv_Title, HTuple hv_Information, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_PosesIn, HTuple hv_ButtonHoldIn, HTuple hv_TBCenter, 
    HTuple hv_TBSize, HTuple hv_WindowCenteredRotationlIn, HTuple hv_MaxNumModels, 
    HTuple hv_MessageQueue, HTuple *hv_PosesOut, HTuple *hv_SelectedObjectOut, HTuple *hv_ButtonHoldOut, 
    HTuple *hv_WindowCenteredRotationOut);
// Chapter: Graphics / Output
// Short Description: Reflect the pose change that was introduced by the user by moving the mouse 
void analyze_graph_event_visualize_object_model_3d (HObject ho_BackgroundImage, HTuple hv_MouseMapping, 
    HTuple hv_Button, HTuple hv_Row, HTuple hv_Column, HTuple hv_WindowHandle, HTuple hv_WindowHandleBuffer, 
    HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple hv_SelectedObjectIn, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_Labels, HTuple hv_Title, HTuple hv_Information, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_PosesIn, HTuple hv_ButtonHoldIn, HTuple hv_TBCenter, 
    HTuple hv_TBSize, HTuple hv_WindowCenteredRotationlIn, HTuple hv_MaxNumModels, 
    HTuple *hv_PosesOut, HTuple *hv_SelectedObjectOut, HTuple *hv_ButtonHoldOut, 
    HTuple *hv_WindowCenteredRotationOut);
// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_custom_features and get_features. 
void append_length_or_values (HTuple hv_Mode, HTuple hv_Feature, HTuple hv_AccumulatedResults, 
    HTuple *hv_ExtendedResults);
// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_custom_features and get_features. 
void append_names_or_groups (HTuple hv_Mode, HTuple hv_Name, HTuple hv_Groups, HTuple hv_CurrentName, 
    HTuple hv_AccumulatedResults, HTuple *hv_ExtendedResults);
// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_features. 
void append_names_or_groups_pyramid (HTuple hv_Mode, HTuple hv_Groups, HTuple hv_CurrentName, 
    HTuple hv_Names, HTuple hv_NameRegExp, HTuple hv_AccumulatedResults, HTuple *hv_ExtendedResults);
// Chapter: Image / Manipulation
void apply_brightness_variation_spot (HObject ho_Image, HObject *ho_ImageSpot, HTuple hv_SpotSize, 
    HTuple hv_SpotRow, HTuple hv_SpotColumn, HTuple hv_BrightnessVariation);
// Chapter: Deep Learning / Classification
// Short Description: Return the classification results for the given images. 
void apply_dl_classifier_batchwise (HTuple hv_ImageFiles, HTuple hv_DLClassifierHandle, 
    HTuple *hv_DLClassifierResultIDs, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_PredictedClasses, 
    HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_Confidences);
// Chapter: Image / Manipulation
// Short Description: Augment/distort the given images. 
void augment_images (HObject ho_Images, HObject *ho_ImagesAugmented, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue);
// Chapter: Classification / Misc
// Short Description: Calculate color intensity features. 
void calc_feature_color_intensity (HObject ho_Region, HObject ho_Image, HTuple hv_ColorSpace, 
    HTuple hv_Mode, HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate edge density. 
void calc_feature_edge_density (HObject ho_Region, HObject ho_Image, HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate edge density histogram feature. 
void calc_feature_edge_density_histogram (HObject ho_Region, HObject ho_Image, HTuple hv_NumBins, 
    HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate the gradient direction histogram. 
void calc_feature_grad_dir_histo (HObject ho_Region, HObject ho_Image, HTuple hv_NumBins, 
    HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate gray-value projections and their histograms. 
void calc_feature_gray_proj (HObject ho_Region, HObject ho_Image, HTuple hv_Mode, 
    HTuple hv_Size, HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate gray-value projections of polar-transformed image regions. 
void calc_feature_polar_gray_proj (HObject ho_Region, HObject ho_Image, HTuple hv_Mode, 
    HTuple hv_Width, HTuple hv_Height, HTuple *hv_Features);
// Chapter: Classification / Misc
// Short Description: Calculate a feature on different image pyramid levels. 
void calc_feature_pyramid (HObject ho_Region, HObject ho_Image, HTuple hv_FeatureName, 
    HTuple hv_NumLevels, HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate one or more features of a given image and/or region. 
void calculate_features (HObject ho_Region, HObject ho_Image, HTuple hv_FeatureNames, 
    HTuple *hv_Features);
// Chapter: Filters / Lines
// Short Description: Calculates the parameters Sigma, Low, and High for lines_gauss from the maximum width and the contrast of the lines to be extracted. 
void calculate_lines_gauss_parameters (HTuple hv_MaxLineWidth, HTuple hv_Contrast, 
    HTuple *hv_Sigma, HTuple *hv_Low, HTuple *hv_High);
// Chapter: Transformations / Poses
// Short Description: Calculate the poses to grasp an object. 
void calculate_tool_in_base_robot_path_poses (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInModelRobotPathPoses, 
    HTuple hv_ModelInBasePose, HTuple hv_Poses, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_ToolInBaseRobotPathPoses);
// Chapter: Calibration / Monocular
// Short Description: Calibrate a camera with a single image. 
void calibrate_camera_and_plane_single_image (HTuple hv_CalibObjectData);
// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTuple hv_RowsTouchingPointInPlane, HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_CalibObjectData, HTuple *hv_HandEyeCalibData);
// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx_without_calib_plate (HTuple hv_RowsTouchingPointInPlane, 
    HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple hv_DistanceObjectTouchingPointToPlane, 
    HTuple hv_DistancePlaneToCamera, HTuple hv_Width, HTuple hv_Height, HTuple *hv_HandEyeCalibData);
// Chapter: Calibration / Hand-Eye
// Short Description: Calibrate the X, Y, Z coordinates of a touching point of a robot. 
void calibrate_robot_touching_point (HTuple hv_DataDir, HTuple *hv_RobotTouchingPointInToolCoordinates);
void check_find_surface_model_params (HTuple hv_WindowHandle, HTuple hv_SurfaceModel, 
    HTuple hv_ObjectModel3DScene, HTuple hv_GenParamNames, HTuple hv_GenParamValues);
// Chapter: Calibration / Hand-Eye
// Short Description: Check the input poses of the hand-eye calibration for consistency. 
void check_hand_eye_calibration_input_poses (HTuple hv_CalibDataID, HTuple hv_RotationTolerance, 
    HTuple hv_TranslationTolerance, HTuple *hv_Warnings);
void check_model_edges (HTuple hv_SurfaceModelID, HTuple hv_ObjectModel3D, HTuple hv_WindowHandleViewpoint, 
    HTuple hv_WindowHandleVisualization);
void check_mouse_over_button (HTuple hv_Parameters, HTuple hv_GraphButtonRow, HTuple hv_GraphButtonColumn, 
    HTuple *hv_FoundButton);
// Chapter: Calibration / Monocular
// Short Description: Collect the data to calibrate a camera with a single image. 
void collect_single_image_calibration_data (HTuple hv_ImageCaltabFileName, HTuple hv_CalPlateDescr, 
    HTuple hv_CalPlateThickness, HTuple hv_StartCamParam, HTuple *hv_CalibObjectData);
// Chapter: Graphics / Parameters
void color_string_to_rgb (HTuple hv_Color, HTuple *hv_RGB);
// Chapter: Graphics / Parameters
void color_string_to_rgb_visualize_object_model_3d (HTuple hv_Color, HTuple *hv_RGB);
// Chapter: Deep Learning / Classification
// Short Description: Compute the TopK error. 
void compute_top_k_error (HTuple hv_DLClassifierHandle, HTuple hv_DLClassifierResultID, 
    HTuple hv_GroundTruthLabels, HTuple hv_Indices, HTuple hv_K, HTuple *hv_TopKError);
// Chapter: Identification / Bar Code
// Short Description: Convert a decoded string of a bar code of type 'Code 39' to the type 'Code 32'. 
void convert_decoded_string_code39_to_code32 (HTuple hv_DecodedDataStringCode39, 
    HTuple *hv_ConvertedDataStringCode32);
void create_visualization_message_queues (HTuple *hv_MessageQueues);
// Chapter: 3D Matching / Surface-Based
// Short Description: Inspect the parameters for surface-based matching. 
void debug_find_surface_model (HTuple hv_SurfaceModelID, HTuple hv_ObjectModel3DModel, 
    HTuple hv_ObjectModel3DScene, HTuple hv_SurfaceMatchingResultID, HTuple *hv_CreateSurfaceModelParamName, 
    HTuple *hv_CreateSurfaceModelParamValue, HTuple *hv_FindSurfaceModelParamName, 
    HTuple *hv_FindSurfaceModelParamValue);
// Chapter: Graphics / Output
// Short Description: Determine the optimum distance of the object to obtain a reasonable visualization 
void determine_optimum_pose_distance (HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_ImageCoverage, HTuple hv_PoseIn, HTuple *hv_PoseOut);
// Chapter: Graphics / Output
// Short Description: Determine the optimum distance of the object to obtain a reasonable visualization 
void determine_optimum_pose_distance_visualize_object_model_3d (HTuple hv_ObjectModel3DID, 
    HTuple hv_CamParam, HTuple hv_ImageCoverage, HTuple hv_PoseIn, HTuple *hv_PoseOut);
void determine_visualization_pose_distance_aligned_with_y_axis (HTuple hv_ObjectModel3DRigidTrans5Tmp, 
    HTuple hv_WindowHandle1, HTuple *hv_PoseEstimatedDistance, HTuple *hv_Center);
// Short Description: Closes the window if it is still open. 
void dev_close_window_if_open (HTuple hv_WindowHandle);
// Chapter: Graphics / Text
void dev_disp_approach_pose_touching_point_instructions (HTuple hv_WindowHandle, 
    HTuple hv_WindowHandleGraphics, HTuple hv_Index);
// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions (HObject ho_Image);
// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions2 (HObject ho_Image);
// Chapter: Graphics / Text
// Short Description: Display the introduction for the procedure calibrate_robot_touching_point. 
void dev_disp_introduction (HTuple hv_WindowHandle, HTuple hv_WindowHandleGraphics);
// Chapter: Identification / Data Code
// Short Description: Display print quality information for individual data code modules. 
void dev_display_data_code_2d_print_quality_results (HTuple hv_DataCodeHandle, HTuple hv_ResultHandle, 
    HTuple hv_Mode, HTuple hv_QualityStandard, HTuple hv_Color, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue);
// Chapter: Deep Learning / Classification
// Short Description: Visualize and return the heatmap of a deep learning classification. 
void dev_display_dl_classifier_heatmap (HObject ho_Image, HTuple hv_DLClassifierHandle, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle);
// Chapter: Matching / Correlation-Based
// Short Description: Display the results of Correlation-Based Matching. 
void dev_display_ncc_matching_results (HTuple hv_ModelID, HTuple hv_Color, HTuple hv_Row, 
    HTuple hv_Column, HTuple hv_Angle, HTuple hv_Model);
// Chapter: Matching / Shape-Based
// Short Description: Display the results of Shape-Based Matching. 
void dev_display_shape_matching_results (HTuple hv_ModelID, HTuple hv_Color, HTuple hv_Row, 
    HTuple hv_Column, HTuple hv_Angle, HTuple hv_ScaleR, HTuple hv_ScaleC, HTuple hv_Model);
void dev_display_surface_matching_results (HTuple hv_WindowHandle1, HTuple hv_SurfaceMatchingResultID, 
    HTuple hv_ObjectModel3DModel, HTuple hv_ObjectModel3DScene, HTuple hv_Score, 
    HTuple hv_Pose, HTuple hv_EdgesTrained);
// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image. 
void dev_open_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle);
// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image size. 
void dev_open_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle);
// Chapter: Develop
// Short Description: Changes the size of a graphics window with a given maximum and minimum extent such that it preserves the aspect ratio of the given image 
void dev_resize_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit);
// Chapter: Develop
// Short Description: Resizes a graphics window with a given maximum extent such that it preserves the aspect ratio of a given width and height 
void dev_resize_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit);
// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'off'. 
void dev_update_off ();
// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'on'. 
void dev_update_on ();
// Chapter: Graphics / Output
// Short Description: Display the axes of a 3d coordinate system 
void disp_3d_coord_system (HTuple hv_WindowHandle, HTuple hv_CamParam, HTuple hv_Pose, 
    HTuple hv_CoordAxesLength);
// Chapter: Graphics / Output
// Short Description: Displays a continue button. 
void disp_buttons (HTuple hv_Parameters, HTuple hv_WindowHandle);
// Chapter: Graphics / Output
// Short Description: Displays a continue button. 
void disp_continue_button (HTuple hv_WindowHandle);
// Chapter: Graphics / Text
// Short Description: This procedure displays 'Click 'Run' to continue' in the lower right corner of the screen. 
void disp_continue_message (HTuple hv_WindowHandle, HTuple hv_Color, HTuple hv_Box);
// Chapter: Graphics / Text
// Short Description: This procedure displays 'End of program' in the lower right corner of the screen. 
void disp_end_of_program_message (HTuple hv_WindowHandle, HTuple hv_Color, HTuple hv_Box);
void disp_menu_ext (HObject ho_MenuRegions, HTuple hv_WindowHandleMenu, HTuple hv_MenuText, 
    HTuple hv_CasesDone, HTuple hv_CurrentCase);
// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_message (HTuple hv_WindowHandle, HTuple hv_String, HTuple hv_CoordSystem, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_Color, HTuple hv_Box);
// Chapter: Graphics / Output
// Short Description: This procedure calls disp_object_model_3d and a fallback solution if there is no OpenGL Available. 
void disp_object_model_3d_safe (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_Pose, HTuple hv_GenParamName, HTuple hv_GenParamValue);
// Chapter: Graphics / Output
// Short Description: This procedure calls disp_object_model_3d and a fallback solution if there is no OpenGL Available. 
void disp_object_model_3d_safe_visualize_object_model_3d (HTuple hv_WindowHandle, 
    HTuple hv_ObjectModel3D, HTuple hv_CamParam, HTuple hv_Pose, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue);
// Chapter: Graphics / Output
// Short Description: Can replace disp_object_model_3d if there is no OpenGL available. 
void disp_object_model_no_opengl (HObject *ho_ModelContours, HTuple hv_ObjectModel3DID, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandleBuffer, 
    HTuple hv_CamParam, HTuple hv_PosesOut);
// Chapter: Graphics / Output
// Short Description: Can replace disp_object_model_3d if there is no OpenGL available. 
void disp_object_model_no_opengl_visualize_object_model_3d (HObject *ho_ModelContours, 
    HTuple hv_ObjectModel3DID, HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandleBuffer, 
    HTuple hv_CamParam, HTuple hv_PosesOut);
void disp_slider (HTuple hv_WindowHandle, HTuple hv_Row, HTuple hv_TotalHeight, HTuple hv_ColLabel, 
    HTuple hv_ColValue, HTuple hv_ColSliderStart, HTuple hv_ColSliderEnd, HTuple hv_Label, 
    HTuple hv_ValueStart, HTuple hv_ValueEnd, HTuple hv_ValueCurr, HTuple hv_FormatString);
// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_text_button (HTuple hv_WindowHandle, HTuple hv_String, HTuple hv_CoordSystem, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_TextColor, HTuple hv_ButtonColor);
// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_text_button_visualize_object_model_3d (HTuple hv_WindowHandle, HTuple hv_String, 
    HTuple hv_CoordSystem, HTuple hv_Row, HTuple hv_Column, HTuple hv_TextColor, 
    HTuple hv_ButtonColor);
// Chapter: Graphics / Output
void disp_title_and_information (HTuple hv_Parameters, HTuple hv_WindowHandle, HTuple hv_Title, 
    HTuple hv_Information);
// Chapter: Graphics / Output
void disp_title_and_information_visualize_object_model_3d (HTuple hv_WindowHandle, 
    HTuple hv_Title, HTuple hv_Information);
// Chapter: Graphics / Output
// Short Description: Renders 3D object models in a buffer window. 
void dump_image_output (HObject ho_BackgroundImage, HTuple hv_Parameters, HTuple hv_WindowHandleBuffer, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_CamParam, HTuple hv_Poses, HTuple hv_ColorImage, 
    HTuple hv_Title, HTuple hv_Information, HTuple hv_Labels, HTuple hv_VisualizeTrackball, 
    HTuple hv_DisplayButtons, HTuple hv_TrackballCenterRow, HTuple hv_TrackballCenterCol, 
    HTuple hv_TrackballRadiusPixel, HTuple hv_SelectedObject, HTuple hv_VisualizeRotationCenter, 
    HTuple hv_RotationCenter, HTuple hv_Type, HTuple hv_Message, HTuple hv_DispViewPoint, 
    HTuple hv_ViewPoint);
// Chapter: Graphics / Output
// Short Description: Renders 3D object models in a buffer window. 
void dump_image_output_visualize_object_model_3d (HObject ho_BackgroundImage, HTuple hv_WindowHandleBuffer, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_CamParam, HTuple hv_Poses, HTuple hv_ColorImage, 
    HTuple hv_Title, HTuple hv_Information, HTuple hv_Labels, HTuple hv_VisualizeTrackball, 
    HTuple hv_DisplayContinueButton, HTuple hv_TrackballCenterRow, HTuple hv_TrackballCenterCol, 
    HTuple hv_TrackballRadiusPixel, HTuple hv_SelectedObject, HTuple hv_VisualizeRotationCenter, 
    HTuple hv_RotationCenter);
// Chapter: 3D Reconstruction / Multi-View Stereo
// Short Description: Estimate a bounding box for 3D reconstruction based on a stereo setup. 
void estimate_bounding_box_3d_reconstruction (HTuple hv_StereoModelID, HTuple hv_ObjectHeight, 
    HTuple *hv_BoundingBox);
void estimate_noise_real (HObject ho_Image, HTuple hv_OutlierRemovalAmount, HTuple *hv_Sigma);
void estimate_visualization_pose (HTuple hv_SampledModel, HTuple hv_WindowHandleModel, 
    HTuple *hv_PoseEstimated);
void estimate_visualization_pose_simple (HTuple hv_SampledModel, HTuple hv_WindowHandleModel, 
    HTuple *hv_PoseEstimated);
// Chapter: Deep Learning / Classification
// Short Description: Evaluate the performance of a deep-learning-based classifier. 
void evaluate_dl_classifier (HTuple hv_GroundTruthLabels, HTuple hv_DLClassifierHandle, 
    HTuple hv_DLClassifierResultID, HTuple hv_EvaluationMeasureType, HTuple hv_ClassesToEvaluate, 
    HTuple *hv_EvaluationMeasure);
// Chapter: XLD / Creation
// Short Description: Creates an arrow shaped XLD contour. 
void gen_arrow_contour_xld (HObject *ho_Arrow, HTuple hv_Row1, HTuple hv_Column1, 
    HTuple hv_Row2, HTuple hv_Column2, HTuple hv_HeadLength, HTuple hv_HeadWidth);
// Chapter: 3D Object Model / Creation
void gen_arrow_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowStart, HTuple hv_ArrowEnd, 
    HTuple *hv_OM3DArrow);
// Chapter: 3D Object Model / Creation
void gen_arrow_object_model_3d_visualize_object_model_3d (HTuple hv_ArrowThickness, 
    HTuple hv_ArrowStart, HTuple hv_ArrowEnd, HTuple *hv_OM3DArrow);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model which visualizes the bounding box of a stereo model. 
void gen_bounding_box_object_model_3d (HTuple hv_StereoModelID, HTuple *hv_ObjectModel3DBoundingBox);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the division model. 
void gen_cam_par_area_scan_division (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_Sx, 
    HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the division model. 
void gen_cam_par_area_scan_hypercentric_division (HTuple hv_Focus, HTuple hv_Kappa, 
    HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a hypercentric lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_hypercentric_polynomial (HTuple hv_Focus, HTuple hv_K1, 
    HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_polynomial (HTuple hv_Focus, HTuple hv_K1, HTuple hv_K2, 
    HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a telecentric lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_telecentric_division (HTuple hv_Magnification, HTuple hv_Kappa, 
    HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a telecentric lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_telecentric_polynomial (HTuple hv_Magnification, HTuple hv_K1, 
    HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a bilateral telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_bilateral_telecentric_division (HTuple hv_Magnification, 
    HTuple hv_Kappa, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a bilateral telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_bilateral_telecentric_polynomial (HTuple hv_Magnification, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_division (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_ImagePlaneDist, 
    HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, 
    HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an image-side telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_image_side_telecentric_division (HTuple hv_Focus, 
    HTuple hv_Kappa, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an image-side telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_image_side_telecentric_polynomial (HTuple hv_Focus, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an object-side telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_object_side_telecentric_division (HTuple hv_Magnification, 
    HTuple hv_Kappa, HTuple hv_ImagePlaneDist, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, 
    HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an object-side telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_object_side_telecentric_polynomial (HTuple hv_Magnification, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_ImagePlaneDist, 
    HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, 
    HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_polynomial (HTuple hv_Focus, HTuple hv_K1, HTuple hv_K2, 
    HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_ImagePlaneDist, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for a line scan camera. 
void gen_cam_par_line_scan (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple hv_Vx, 
    HTuple hv_Vy, HTuple hv_Vz, HTuple *hv_CameraParam);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera and the robot's tool. 
void gen_camera_and_tool_moving_cam_object_model_3d (HTuple hv_ToolInCamPose, HTuple hv_ToolInBasePose, 
    HTuple hv_CameraSize, HTuple hv_ConeLength, HTuple hv_OM3DToolOrig, HTuple hv_CamParam, 
    HTuple *hv_OM3DCamera, HTuple *hv_OM3DTool);
void gen_camera_facing_scene (HTuple hv_Viewpoint, HTuple hv_Center, HTuple hv_DiameterModel, 
    HTuple *hv_OM3DCamera);
// Short Description: Create a 3D object model that resembles a camera 
void gen_camera_object_model_3d (HTuple hv_Pose, HTuple hv_Size, HTuple *hv_OM3DCamera);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a symbolic 3D object model of a camera. 
void gen_camera_object_model_3d_reconstruction_3d (HTuple hv_CameraSetupModel, HTuple hv_CamIndex, 
    HTuple hv_CameraSize, HTuple *hv_OM3DCam);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models which visualize the cameras of a stereo model. 
void gen_camera_setup_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraSize, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3DCamera, HTuple *hv_ObjectModel3DCone);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model representing the view cone of a perspective camera. 
void gen_cone_perspective_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraIndex, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3D);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model representing the view cone of a telecentric camera. 
void gen_cone_telecentric_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraIndex, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3D);
// Chapter: Deep Learning / Classification
// Short Description: Visualize and return the confusion matrix for the given labels.  
void gen_confusion_matrix (HTuple hv_GroundTruthLabels, HTuple hv_PredictedClasses, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, robot's tool and plane. 
void gen_current_setup_moving_cam_object_model_3d (HTuple hv_CameraSize, HTuple hv_ToolInBasePose, 
    HTuple hv_HandEyeCalibData, HTuple hv_OM3DToolOrigin, HTuple hv_OM3DBase, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DTool, HTuple *hv_OM3DPlane);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, the plane, the robot's base and the robot's tool in a stationary camera setup. 
void gen_current_setup_stationary_cam_object_model_3d (HTuple hv_ArrowThickness, 
    HTuple hv_ArrowLength, HTuple hv_CameraSize, HTuple hv_HandEyeCalibData, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DPlane, HTuple *hv_OM3DBase, HTuple *hv_OM3DToolOrigin);
// Chapter: Deep Learning / Classification
// Short Description: Do not use this procedure, use dev_display_dl_classifier_heatmap.  
void gen_dl_classifier_heatmap (HObject ho_Image, HObject *ho_HeatmapRegions, HTuple hv_DLClassifierHandle, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle);
// Chapter: Classification / Misc
// Short Description: Generate a dummy image and region that are, e.g., used to determine the lengths of the feature vectors in get_feature_lengths. 
void gen_dummy_objects (HObject *ho_Region, HObject *ho_Image);
// Chapter: 3D Object Model / Creation
// Short Description: Generate the 3D object model of the plane. 
void gen_ground_plane_object_model_3d (HTuple hv_OM3DTool, HTuple hv_OM3DCamera, 
    HTuple hv_OM3DBase, HTuple hv_FactorBorder, HTuple hv_PlaneInBasePose, HTuple *hv_OM3DPlane);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object of the matched model, in the case of rectification. 
void gen_matching_object_model_3d (HTuple hv_ModelID, HTuple hv_ObjectHeight, HTuple hv_Poses, 
    HTuple hv_HandEyeCalibData, HTuple hv_RectificationData, HTuple *hv_OM3DModel);
void gen_menu_regions_ext (HObject *ho_MenuRegions, HTuple hv_TopBottom, HTuple hv_WindowHandleMenu, 
    HTuple hv_PercentageHeight, HTuple hv_NumRows, HTuple hv_NumCols);
// Chapter: 3D Object Model / Creation
// Short Description: Generate base and tool 3D models of the robot. 
void gen_robot_tool_and_base_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowLength, 
    HTuple *hv_OM3DToolOrigin, HTuple *hv_OM3DBase);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models which visualize a sheet of light setup. 
void gen_sheet_of_light_object_model_3d (HTuple hv_SheetOfLightModelID, HTuple hv_PlaneAndMovementSize, 
    HTuple hv_CameraSize, HTuple hv_ConeLength, HTuple *hv_OM3DLightPlane, HTuple *hv_OM3DMovement, 
    HTuple *hv_OM3DCamera, HTuple *hv_OM3DCone);
// Chapter: 3D Object Model / Creation
void gen_tool_to_touching_point_object_model_3d (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple *hv_OM3DToolTouchingPoint);
// Chapter: 3D Object Model / Features
void get_bounding_box_points_from_min_max (HTuple hv_BoundingBox, HTuple *hv_PX, 
    HTuple *hv_PY, HTuple *hv_PZ);
// Chapter: Calibration / Camera Parameters
// Short Description: Get the value of a specified camera parameter from the camera parameter tuple. 
void get_cam_par_data (HTuple hv_CameraParam, HTuple hv_ParamName, HTuple *hv_ParamValue);
// Chapter: Calibration / Camera Parameters
// Short Description: Get the names of the parameters in a camera parameter tuple. 
void get_cam_par_names (HTuple hv_CameraParam, HTuple *hv_CameraType, HTuple *hv_ParamNames);
// Chapter: Classification / Misc
// Short Description: Describe and calculate user-defined features to be used in conjunction with the calculate_feature_set procedure library. 
void get_custom_features (HObject ho_Region, HObject ho_Image, HTuple hv_CurrentName, 
    HTuple hv_Mode, HTuple *hv_Output);
// Chapter: Deep Learning / Classification
// Short Description: Display and return the classified images. 
void get_dl_classifier_image_results (HObject *ho_Images, HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_PredictedClasses, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_WindowHandle);
// Chapter: 3D Object Model / Transformations
void get_extent_by_axis (HTuple hv_OM3D, HTuple hv_XExtent, HTuple hv_YExtent, HTuple hv_ZExtent, 
    HTuple *hv_XExtentOut, HTuple *hv_YExtentOut, HTuple *hv_ZExtentOut);
// Chapter: Classification / Misc
// Short Description: Returns the length of the feature vector for each feature name. 
void get_feature_lengths (HTuple hv_FeatureNames, HTuple *hv_Lengths);
// Chapter: Classification / Misc
// Short Description: Returns a list of feature names that belong to the feature groups given in GroupNames. 
void get_feature_names (HTuple hv_GroupNames, HTuple *hv_Names);
// Chapter: Classification / Misc
// Short Description: This procedure contains all relevant information about the supported features. 
void get_features (HObject ho_Region, HObject ho_Image, HTuple hv_Namelist, HTuple hv_Mode, 
    HTuple *hv_Output);
void get_find_parameter (HTuple hv_GenParamNames, HTuple hv_GenParamValues, HTuple hv_ParamName, 
    HTuple hv_DefaultValue, HTuple *hv_ParamValue);
void get_find_surface_model_param (HTuple hv_ParamName, HTuple hv_DefaultValue, HTuple hv_GenParamNames, 
    HTuple hv_GenParamValues, HTuple hv_ConvertBoolToInt, HTuple *hv_ParamValue);
void get_image_direction (HObject ho_Image, HTuple *hv_MedianDirection);
void get_mouse_info (HTuple hv_WindowHandle, HTuple hv_MessageQueue, HTuple hv_Timeout, 
    HTuple *hv_Row, HTuple *hv_Column, HTuple *hv_Button);
// Chapter: Calibration / Hand-Eye
// Short Description: Get the coordinates of the central mark of the closest finder pattern. 
void get_nearest_finder_pattern_coordinates (HObject ho_CalibPlateImage, HTuple hv_RowNearFinderPattern, 
    HTuple hv_ColumNearFinderPattern, HTuple hv_CalibObjectData, HTuple *hv_RowFinderPattern, 
    HTuple *hv_ColumnFinderPattern);
// Chapter: Graphics / Output
// Short Description: Compute the center of all given 3D object models. 
void get_object_models_center (HTuple hv_ObjectModel3DID, HTuple *hv_Center);
// Chapter: Graphics / Output
// Short Description: Compute the center of all given 3D object models. 
void get_object_models_center_visualize_object_model_3d (HTuple hv_ObjectModel3DID, 
    HTuple *hv_Center);
// Chapter: Transformations / Misc
// Short Description: Calculate the touching point in tool coordinates. 
void get_robot_touching_point_in_tool_coordinates (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple *hv_RobotTouchingPointInToolCoordinates);
// Chapter: Matrix / Arithmetic
void get_rotation_axis (HTuple hv_MatRot, HTuple hv_MatRot0, HTuple *hv_RotationAxis, 
    HTuple *hv_DiffToIdentity);
// Chapter: 3D Reconstruction / Sheet of Light
// Short Description: Calculate the dimensions of a sheet-of-light calibration object. 
void get_sheet_of_light_calib_object_dimensions (HTuple hv_Width, HTuple hv_Length, 
    HTuple hv_HeightMin, HTuple hv_HeightMax, HTuple *hv_DiameterCircle, HTuple *hv_PyramidHeight, 
    HTuple *hv_PyramidDistanceFromFront, HTuple *hv_PyramidBottomDiagonal, HTuple *hv_PyramidTopDiagonal, 
    HTuple *hv_Angle);
// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera. 
void get_trackball_center (HTuple hv_SelectedObject, HTuple hv_TrackballRadiusPixel, 
    HTuple hv_ObjectModel3D, HTuple hv_Poses, HTuple *hv_TBCenter, HTuple *hv_TBSize);
// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera. 
void get_trackball_center_visualize_object_model_3d (HTuple hv_SelectedObject, HTuple hv_TrackballRadiusPixel, 
    HTuple hv_ObjectModel3D, HTuple hv_Poses, HTuple *hv_TBCenter, HTuple *hv_TBSize);
// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera (version for inspection_mode = 'surface'). 
void get_trackball_center_fixed (HTuple hv_SelectedObject, HTuple hv_TrackballCenterRow, 
    HTuple hv_TrackballCenterCol, HTuple hv_TrackballRadiusPixel, HTuple hv_Scene3D, 
    HTuple hv_ObjectModel3DID, HTuple hv_Poses, HTuple hv_WindowHandleBuffer, HTuple hv_CamParam, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple *hv_TBCenter, HTuple *hv_TBSize);
// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera (version for inspection_mode = 'surface'). 
void get_trackball_center_fixed_visualize_object_model_3d (HTuple hv_SelectedObject, 
    HTuple hv_TrackballCenterRow, HTuple hv_TrackballCenterCol, HTuple hv_TrackballRadiusPixel, 
    HTuple hv_Scene3D, HTuple hv_ObjectModel3DID, HTuple hv_Poses, HTuple hv_WindowHandleBuffer, 
    HTuple hv_CamParam, HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple *hv_TBCenter, 
    HTuple *hv_TBSize);
void inspect_normal_direction (HObject ho_MenuRegions, HTuple hv_WindowHandle1, HTuple hv_WindowHandle2, 
    HTuple hv_WindowHandleMenu, HTuple hv_SurfaceModelID, HTuple hv_Scene, HTuple hv_RelSamplingDistance, 
    HTuple hv_KeyPointFraction, HTuple hv_MinScore, HTuple hv_GenParamNames, HTuple hv_GenParamValues, 
    HTuple hv_SurfaceMatchingResultID, HTuple hv_MenuText, HTuple hv_CurrentCase, 
    HTuple hv_CasesDone, HTuple hv_FontSize, HTuple *hv_CreateNames, HTuple *hv_CreateValues, 
    HTuple *hv_FindNames, HTuple *hv_FindValues);
void inspect_scene_edge_directions (HTuple hv_WindowHandle1, HTuple hv_WindowHandle2, 
    HTuple hv_SurfaceModelID, HTuple hv_ObjectModel3DScene, HTuple hv_SurfaceMatchingResultID, 
    HTuple hv_MaxGapIn, HTuple hv_MinAmplitudeIn, HTuple hv_ViewpointIn, HTuple *hv_Viewpoint);
void inspect_scene_edge_parameters (HTuple hv_WindowHandle1, HTuple hv_WindowHandle2, 
    HTuple hv_SurfaceModelID, HTuple hv_ObjectModel3DScene, HTuple hv_SurfaceMatchingResultID, 
    HTuple hv_MaxGapIn, HTuple hv_MinAmplitudeAbsIn, HTuple hv_ViewpointIn, HTuple *hv_MaxGap, 
    HTuple *hv_MinAmplitudeAbs);
// Chapter: File / Misc
// Short Description: Get all image files under the given path 
void list_image_files (HTuple hv_ImageDirectory, HTuple hv_Extensions, HTuple hv_Options, 
    HTuple *hv_ImageFiles);
// Chapter: Graphics / Output
// Short Description: Get string extends of several lines. 
void max_line_width (HTuple hv_WindowHandle, HTuple hv_Lines, HTuple *hv_MaxWidth);
// Chapter: Graphics / Output
// Short Description: Get string extends of several lines. 
void max_line_width_visualize_object_model_3d (HTuple hv_WindowHandle, HTuple hv_Lines, 
    HTuple *hv_MaxWidth);
// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system. 
void obtain_3d_pose_of_match_moving_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, 
    HTuple *hv_ModelInBasePose);
// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system in a stationary camera setup. 
void obtain_3d_pose_of_match_stationary_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, HTuple *hv_ModelInBasePose);
// Chapter: Graphics / Window
// Short Description: Open a new window next to an existing one. 
void open_new_window (HTuple *hv_WindowHandle, HTuple *hv_WindowHandleGraphics);
// Chapter: File / Misc
// Short Description: Parse a filename into directory, base filename, and extension 
void parse_filename (HTuple hv_FileName, HTuple *hv_BaseName, HTuple *hv_Extension, 
    HTuple *hv_Directory);
// Chapter: Deep Learning / Classification
// Short Description: Plot the training error, validation error and learning rate during deep learning classifier training. 
void plot_dl_classifier_training_progress (HTuple hv_TrainingErrors, HTuple hv_ValidationErrors, 
    HTuple hv_LearningRates, HTuple hv_Epochs, HTuple hv_NumEpochs, HTuple hv_WindowHandle);
// Chapter: Graphics / Output
// Short Description:  This procedure plots tuples representing functions or curves in a coordinate system. 
void plot_funct_1d (HTuple hv_WindowHandle, HTuple hv_Function, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName, HTuple hv_GenParamValue);
// Chapter: Graphics / Output
// Short Description:  This procedure plots tuples representing functions or curves in a coordinate system. 
void plot_tuple (HTuple hv_WindowHandle, HTuple hv_XValues, HTuple hv_YValues, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName, HTuple hv_GenParamValue);
// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp. 
void prepare_poses_and_rectification_data_moving_cam (HTuple hv_ToolInBasePose, HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData);
// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp in a stationary camera setup. 
void prepare_poses_and_rectification_data_stationary_cam (HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData);
// Chapter: Deep Learning / Classification
// Short Description: Preprocess images for deep-learning-based classification training and inference. 
void preprocess_dl_classifier_images (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_DLClassifierHandle);
void process_slider_events (HTuple hv_WindowHandle, HTuple hv_MessageQueues, HTuple hv_PreviousState, 
    HTuple *hv_CurrentState, HTuple *hv_DidFinish);
// Short Description: Generic processor for events of visualize_object_model_3d_ext 
void process_visualize_events_generic (HTuple hv_WindowHandle, HTuple hv_MessageQueues, 
    HTuple hv_PreviousState, HTuple *hv_DidFinish, HTuple *hv_NewState, HTuple *hv_ButtonPressed, 
    HTuple *hv_Poses);
// Chapter: Graphics / Output
// Short Description: Project an image point onto the trackball 
void project_point_on_trackball (HTuple hv_X, HTuple hv_Y, HTuple hv_VirtualTrackball, 
    HTuple hv_TrackballSize, HTuple *hv_V);
// Chapter: Graphics / Output
// Short Description: Project an image point onto the trackball 
void project_point_on_trackball_visualize_object_model_3d (HTuple hv_X, HTuple hv_Y, 
    HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple *hv_V);
// Chapter: Classification / Misc
// Short Description: List all available feature group names. 
void query_feature_group_names (HTuple *hv_GroupNames);
// Chapter: Classification / Misc
// Short Description: Returns a table of feature names sorted by groups. 
void query_feature_names_by_group (HTuple hv_GroupNames, HTuple *hv_FeatureNames, 
    HTuple *hv_Groups);
// Chapter: Deep Learning / Classification
// Short Description: Read the data set containing the images and their respective ground truth labels.  
void read_dl_classifier_data_set (HTuple hv_ImageDirectory, HTuple hv_LabelSource, 
    HTuple *hv_ImageFiles, HTuple *hv_GroundTruthLabels, HTuple *hv_LabelIndices, 
    HTuple *hv_UniqueClasses);
// Chapter: System / Multithreading
void read_message_obj (HObject *ho_ObjectData, HTuple hv_MessageHandle, HTuple hv_Key);
// Chapter: System / Multithreading
void read_message_tuple (HTuple hv_MessageHandle, HTuple hv_Key, HTuple *hv_TupleData);
// Chapter: Calibration / Hand-Eye
// Short Description: Prepare the input image for matching and compute the needed pose. 
void rectify_image_and_compute_matching_plane_moving_cam (HObject ho_Image, HObject *ho_ImageRectified, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData);
// Chapter: File / Misc
// Short Description: This procedure removes a directory recursively. 
void remove_dir_recursively (HTuple hv_DirName);
// Chapter: Filters / Arithmetic
// Short Description: Scale the gray values of an image from the interval [Min,Max] to [0,255] 
void scale_image_range (HObject ho_Image, HObject *ho_ImageScaled, HTuple hv_Min, 
    HTuple hv_Max);
void ScanningRuler_ReadBuffer (HObject *ho_ImageCirX, HObject *ho_ImageCirY, HObject *ho_ImageCirZ, 
    HObject *ho_Intensity, HTuple hv_Width, HTuple hv_Height, HTuple hv_File);
void select_case (HObject ho_MenuRegions, HTuple hv_WindowHandleMenu, HTuple hv_MenuTexts, 
    HTuple *hv_SelectedCase);
// Chapter: Object / Manipulation
// Short Description: Select elements from object arrays using a mask. 
void select_mask_obj (HObject ho_Objects, HObject *ho_SelectedObjects, HTuple hv_Mask);
// Chapter: Deep Learning / Classification
// Short Description: Select a percentage of the given data. 
void select_percentage_dl_classifier_data (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_SelectPercentage, HTuple *hv_ImageFilesOut, HTuple *hv_LabelsOut);
void send_pose_update (HTuple hv_Parameters, HTuple hv_Poses);
// Chapter: Calibration / Camera Parameters
// Short Description: Set the value of a specified camera parameter in the camera parameter tuple. 
void set_cam_par_data (HTuple hv_CameraParamIn, HTuple hv_ParamName, HTuple hv_ParamValue, 
    HTuple *hv_CameraParamOut);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, HTuple hv_Bold, 
    HTuple hv_Slant);
void set_edge_parameter_sliders (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_MesageQueues, HTuple hv_MessageQueueOut, HTuple hv_ModelDiameter, HTuple hv_AmplitudeRange, 
    HTuple hv_MaxGapRange, HTuple hv_Viewpoint, HTuple *hv_MinAmplitude, HTuple *hv_MaxGap);
// Chapter: Tools / Geometry
// Short Description: Sort tuple pairs. 
void sort_pairs (HTuple hv_T1, HTuple hv_T2, HTuple hv_SortMode, HTuple *hv_Sorted1, 
    HTuple *hv_Sorted2);
// Chapter: Deep Learning / Classification
// Short Description: Split and shuffle the images and ground truth labels into training, validation and test subsets. 
void split_dl_classifier_data_set (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_TrainingPercent, HTuple hv_ValidationPercent, HTuple *hv_TrainingImages, 
    HTuple *hv_TrainingLabels, HTuple *hv_ValidationImages, HTuple *hv_ValidationLabels, 
    HTuple *hv_TestImages, HTuple *hv_TestLabels);
// Chapter: Inspection / Structured Light
// Short Description: Acquire images for the synchronization between the screen and the camera in a structured light setup. 
void structured_light_camera_screen_sync (HObject *ho_CameraImages, HTuple hv_AcqHandle, 
    HTuple hv_WindowHandle, HTuple hv_WindowWidth, HTuple hv_WindowHeight, HTuple hv_WaitSeconds, 
    HTuple *hv_ImagesPerSecond);
// Chapter: Inspection / Structured Light
// Short Description: Visually inspect the Gray code images of a structured light model. 
void structured_light_inspect_segmentation (HObject ho_CameraImages, HObject ho_BinarizedImages, 
    HTuple hv_WindowHandle);
// Chapter: Classification / Misc
// Short Description: Test procedure for custom features. 
void test_features (HTuple hv_FeatureNames);
// Chapter: Graphics / Output
// Short Description: Compute the 3D rotation from the mouse movement 
void trackball (HTuple hv_MX1, HTuple hv_MY1, HTuple hv_MX2, HTuple hv_MY2, HTuple hv_VirtualTrackball, 
    HTuple hv_TrackballSize, HTuple hv_SensFactor, HTuple *hv_QuatRotation);
// Chapter: Graphics / Output
// Short Description: Compute the 3D rotation from the mouse movement 
void trackball_visualize_object_model_3d (HTuple hv_MX1, HTuple hv_MY1, HTuple hv_MX2, 
    HTuple hv_MY2, HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple hv_SensFactor, 
    HTuple *hv_QuatRotation);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Tuple / Arithmetic
// Short Description: Calculates the cross product of two vectors of length 3. 
void tuple_vector_cross_product (HTuple hv_V1, HTuple hv_V2, HTuple *hv_VC);
// Chapter: Tuple / Arithmetic
// Short Description: Calculates the cross product of two vectors of length 3. 
void tuple_vector_cross_product_visualize_object_model_3d (HTuple hv_V1, HTuple hv_V2, 
    HTuple *hv_VC);
// Chapter: Graphics / 3D Scene
// Short Description: Visualize the poses that were used to calculate the touching point, and the result. 
void visualize_calibrated_touching_point (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, HTuple hv_WindowHandle);
// Chapter: Graphics / Output
// Short Description: Interactively display 3D object models 
void visualize_object_model_3d (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_PoseIn, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_Title, HTuple hv_Label, HTuple hv_Information, HTuple *hv_PoseOut);
// Chapter: Graphics / Output
// Short Description: Interactively display 3D object models 
void visualize_object_model_3d_ext (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_PoseIn, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_Title, HTuple hv_Label, HTuple hv_Information, HTuple hv_MessageQueue, 
    HTuple hv_Buttons, HTuple hv_Type, HTuple hv_Message, HTuple hv_DispViewPoint, 
    HTuple hv_ViewPoint);
// Short Description: Display continue button and wait for user to click it 
void wait_continue_button (HTuple hv_WindowHandle);
void write_note (HTuple hv_WindowHandle, HTuple hv_Type, HTuple hv_String);
// Chapter: 3D Object Model / Transformations
// Short Description: Transform 3D points from images to a 3D object model, and add extended attributes to the points of the object model. 
void xyz_attrib_to_object_model_3d (HObject ho_X, HObject ho_Y, HObject ho_Z, HObject ho_AttribImage, 
    HTuple hv_AttribName, HTuple *hv_ObjectModel3D);

// Generated stubs for parallel procedure calls. Wrapped in name
// space to avoid name conflicts with actual procedure names
namespace HDevExportCpp
{
// Parallel execution wrapper for visualize_object_model_3d_ext(...) 
static void* _hcppthread_visualize_object_model_3d_ext(void *hcthread);
// Parallel execution wrapper for set_edge_parameter_sliders(...) 
static void* _hcppthread_set_edge_parameter_sliders(void *hcthread);
}

// Procedures 
// Chapter: Graphics / Output
// Short Description: Reflect the pose change that was introduced by the user by moving the mouse 
void analyze_graph_event (HObject ho_BackgroundImage, HTuple hv_Parameters, HTuple hv_MouseMapping, 
    HTuple hv_Button, HTuple hv_Row, HTuple hv_Column, HTuple hv_WindowHandle, HTuple hv_WindowHandleBuffer, 
    HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple hv_SelectedObjectIn, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_Labels, HTuple hv_Title, HTuple hv_Information, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_PosesIn, HTuple hv_ButtonHoldIn, HTuple hv_TBCenter, 
    HTuple hv_TBSize, HTuple hv_WindowCenteredRotationlIn, HTuple hv_MaxNumModels, 
    HTuple hv_MessageQueue, HTuple *hv_PosesOut, HTuple *hv_SelectedObjectOut, HTuple *hv_ButtonHoldOut, 
    HTuple *hv_WindowCenteredRotationOut)
{

  // Local iconic variables
  HObject  ho_ImageDump;

  // Local control variables
  HTuple  hv_VisualizeTB, hv_InvLog2, hv_Seconds;
  HTuple  hv_ModelIndex, hv_Exception1, hv_HomMat3DIdentity;
  HTuple  hv_NumModels, hv_Width, hv_Height, hv_MinImageSize;
  HTuple  hv_TrackballRadiusPixel, hv_TrackballCenterRow;
  HTuple  hv_TrackballCenterCol, hv_gIsSinglePose, hv_NumChannels;
  HTuple  hv_ColorImage, hv_BAnd, hv_SensFactor, hv_IsButtonTrans;
  HTuple  hv_IsButtonRot, hv_IsButtonDist, hv_MRow1, hv_MCol1;
  HTuple  hv_ButtonLoop, hv_MRow2, hv_MCol2, hv_PX, hv_PY;
  HTuple  hv_PZ, hv_QX1, hv_QY1, hv_QZ1, hv_QX2, hv_QY2, hv_QZ2;
  HTuple  hv_Len, hv_Dist, hv_Translate, hv_Index, hv_PoseIn;
  HTuple  hv_HomMat3DIn, hv_HomMat3DOut, hv_PoseOut, hv_Indices;
  HTuple  hv_Sequence, hv_Mod, hv_SequenceReal, hv_Sequence2Int;
  HTuple  hv_Selected, hv_InvSelected, hv_Exception, hv_DRow;
  HTuple  hv_TranslateZ, hv_MX1, hv_MY1, hv_MX2, hv_MY2, hv_RelQuaternion;
  HTuple  hv_HomMat3DRotRel, hv_HomMat3DInTmp1, hv_HomMat3DInTmp;
  HTuple  hv_PosesOut2;

  //This procedure reflects
  //- the pose change that was introduced by the user by
  //  moving the mouse
  //- the selection of a single object
  //
  (*hv_ButtonHoldOut) = hv_ButtonHoldIn;
  (*hv_PosesOut) = hv_PosesIn;
  (*hv_SelectedObjectOut) = hv_SelectedObjectIn;
  (*hv_WindowCenteredRotationOut) = hv_WindowCenteredRotationlIn;
  hv_VisualizeTB = ((*hv_SelectedObjectOut).TupleMax())!=0;
  hv_InvLog2 = 1.0/(HTuple(2).TupleLog());
  //
  if (0 != (hv_Button==HTuple(hv_MouseMapping[6])))
  {
    if (0 != (*hv_ButtonHoldOut))
    {
      return;
    }
    //Ctrl (16) + Alt (32) + left mouse button (1) => Toggle rotation center position
    //If WindowCenteredRotation is not 1, set it to 1, otherwise, set it to 2
    CountSeconds(&hv_Seconds);
    if (0 != ((*hv_WindowCenteredRotationOut)==1))
    {
      (*hv_WindowCenteredRotationOut) = 2;
    }
    else
    {
      (*hv_WindowCenteredRotationOut) = 1;
    }
    (*hv_ButtonHoldOut) = 1;
    return;
  }
  if (0 != (HTuple(hv_Button==HTuple(hv_MouseMapping[5])).TupleAnd((hv_ObjectModel3DID.TupleLength())<=hv_MaxNumModels)))
  {
    if (0 != (*hv_ButtonHoldOut))
    {
      return;
    }
    //Ctrl (16) + left mouse button (1) => Select an object
    try
    {
      SetScene3dParam(hv_Scene3D, "object_index_persistence", "true");
      DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
      GetDisplayScene3dInfo(hv_WindowHandleBuffer, hv_Scene3D, hv_Row, hv_Column, 
          "object_index", &hv_ModelIndex);
      SetScene3dParam(hv_Scene3D, "object_index_persistence", "false");
    }
    // catch (Exception1) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception1);
      //* NO OpenGL, no selection possible
      return;
    }
    if (0 != (hv_ModelIndex==-1))
    {
      //Background click:
      if (0 != (((*hv_SelectedObjectOut).TupleSum())==((*hv_SelectedObjectOut).TupleLength())))
      {
        //If all objects are already selected, deselect all
        (*hv_SelectedObjectOut) = HTuple(hv_ObjectModel3DID.TupleLength(),0);
      }
      else
      {
        //Otherwise select all
        (*hv_SelectedObjectOut) = HTuple(hv_ObjectModel3DID.TupleLength(),1);
      }
    }
    else
    {
      //Object click:
      (*hv_SelectedObjectOut)[hv_ModelIndex] = HTuple((*hv_SelectedObjectOut)[hv_ModelIndex]).TupleNot();
    }
    (*hv_ButtonHoldOut) = 1;
  }
  else
  {
    //Change the pose
    HomMat3dIdentity(&hv_HomMat3DIdentity);
    hv_NumModels = hv_ObjectModel3DID.TupleLength();
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    hv_MinImageSize = (hv_Width.TupleConcat(hv_Height)).TupleMin();
    hv_TrackballRadiusPixel = (hv_TrackballSize*hv_MinImageSize)/2.0;
    //Set trackball fixed in the center of the window
    hv_TrackballCenterRow = hv_Height/2;
    hv_TrackballCenterCol = hv_Width/2;
    if (0 != ((hv_ObjectModel3DID.TupleLength())<hv_MaxNumModels))
    {
      if (0 != ((*hv_WindowCenteredRotationOut)==1))
      {
        get_trackball_center_fixed(hv_SelectedObjectIn, hv_TrackballCenterRow, hv_TrackballCenterCol, 
            hv_TrackballRadiusPixel, hv_Scene3D, hv_ObjectModel3DID, hv_PosesIn, 
            hv_WindowHandleBuffer, hv_CamParam, hv_GenParamName, hv_GenParamValue, 
            &hv_TBCenter, &hv_TBSize);
      }
      else
      {
        get_trackball_center(hv_SelectedObjectIn, hv_TrackballRadiusPixel, hv_ObjectModel3DID, 
            hv_PosesIn, &hv_TBCenter, &hv_TBSize);
      }
    }
    if (0 != (HTuple(((*hv_SelectedObjectOut).TupleMin())==0).TupleAnd(((*hv_SelectedObjectOut).TupleMax())==1)))
    {
      //At this point, multiple objects do not necessary have the same
      //pose any more. Consequently, we have to return a tuple of poses
      //as output of visualize_object_model_3d
      hv_gIsSinglePose = 0;
      SetMessageTuple(hv_Parameters, "gIsSinglePose", hv_gIsSinglePose);
    }
    CountChannels(ho_BackgroundImage, &hv_NumChannels);
    hv_ColorImage = hv_NumChannels==3;
    //Alt (32) => lower sensitivity
    TupleRsh(hv_Button, 5, &hv_BAnd);
    if (0 != (hv_BAnd%2))
    {
      hv_SensFactor = 0.1;
    }
    else
    {
      hv_SensFactor = 1.0;
    }
    hv_IsButtonTrans = HTuple(HTuple(hv_MouseMapping[0])==hv_Button).TupleOr((32+HTuple(hv_MouseMapping[0]))==hv_Button);
    hv_IsButtonRot = HTuple(HTuple(hv_MouseMapping[1])==hv_Button).TupleOr((32+HTuple(hv_MouseMapping[1]))==hv_Button);
    hv_IsButtonDist = HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(hv_MouseMapping[2])==hv_Button).TupleOr((32+HTuple(hv_MouseMapping[2]))==hv_Button)).TupleOr(HTuple(hv_MouseMapping[3])==hv_Button)).TupleOr((32+HTuple(hv_MouseMapping[3]))==hv_Button)).TupleOr(HTuple(hv_MouseMapping[4])==hv_Button)).TupleOr((32+HTuple(hv_MouseMapping[4]))==hv_Button);
    if (0 != hv_IsButtonTrans)
    {
      //Translate in XY-direction
      hv_MRow1 = hv_Row;
      hv_MCol1 = hv_Column;
      while (0 != hv_IsButtonTrans)
      {
        try
        {
          get_mouse_info(hv_WindowHandle, hv_MessageQueue, HTuple(), &hv_Row, &hv_Column, 
              &hv_ButtonLoop);
          hv_IsButtonTrans = hv_ButtonLoop==hv_Button;
          hv_MRow2 = hv_MRow1+((hv_Row-hv_MRow1)*hv_SensFactor);
          hv_MCol2 = hv_MCol1+((hv_Column-hv_MCol1)*hv_SensFactor);
          GetLineOfSight(hv_MRow1, hv_MCol1, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, 
              &hv_QX1, &hv_QY1, &hv_QZ1);
          GetLineOfSight(hv_MRow2, hv_MCol2, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, 
              &hv_QX2, &hv_QY2, &hv_QZ2);
          hv_Len = (((hv_QX1*hv_QX1)+(hv_QY1*hv_QY1))+(hv_QZ1*hv_QZ1)).TupleSqrt();
          hv_Dist = (((HTuple(hv_TBCenter[0])*HTuple(hv_TBCenter[0]))+(HTuple(hv_TBCenter[1])*HTuple(hv_TBCenter[1])))+(HTuple(hv_TBCenter[2])*HTuple(hv_TBCenter[2]))).TupleSqrt();
          hv_Translate = ((((hv_QX2-hv_QX1).TupleConcat(hv_QY2-hv_QY1)).TupleConcat(hv_QZ2-hv_QZ1))*hv_Dist)/hv_Len;
          (*hv_PosesOut) = HTuple();
          if (0 != (hv_NumModels<=hv_MaxNumModels))
          {
            {
            HTuple end_val109 = hv_NumModels-1;
            HTuple step_val109 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val109, step_val109); hv_Index += step_val109)
            {
              hv_PoseIn = hv_PosesIn.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
              if (0 != (HTuple((*hv_SelectedObjectOut)[hv_Index])))
              {
                PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, HTuple(hv_Translate[0]), HTuple(hv_Translate[1]), 
                    HTuple(hv_Translate[2]), &hv_HomMat3DOut);
                HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
                SetScene3dInstancePose(hv_Scene3D, hv_Index, hv_PoseOut);
              }
              else
              {
                hv_PoseOut = hv_PoseIn;
              }
              (*hv_PosesOut) = (*hv_PosesOut).TupleConcat(hv_PoseOut);
            }
            }
          }
          else
          {
            TupleFind((*hv_SelectedObjectOut), 1, &hv_Indices);
            hv_PoseIn = hv_PosesIn.TupleSelectRange(HTuple(hv_Indices[0])*7,(HTuple(hv_Indices[0])*7)+6);
            PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
            HomMat3dTranslate(hv_HomMat3DIn, HTuple(hv_Translate[0]), HTuple(hv_Translate[1]), 
                HTuple(hv_Translate[2]), &hv_HomMat3DOut);
            HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
            hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
            TupleMod(hv_Sequence, 7, &hv_Mod);
            hv_SequenceReal = HTuple::TupleGenSequence(0,hv_NumModels-(1.0/7.0),1.0/7.0);
            hv_Sequence2Int = hv_SequenceReal.TupleInt();
            TupleSelect((*hv_SelectedObjectOut), hv_Sequence2Int, &hv_Selected);
            hv_InvSelected = 1-hv_Selected;
            TupleSelect(hv_PoseOut, hv_Mod, &(*hv_PosesOut));
            (*hv_PosesOut) = ((*hv_PosesOut)*hv_Selected)+(hv_PosesIn*hv_InvSelected);
            SetScene3dInstancePose(hv_Scene3D, HTuple::TupleGenSequence(0,hv_NumModels-1,1), 
                (*hv_PosesOut));
          }
          dump_image_output(ho_BackgroundImage, hv_Parameters, hv_WindowHandleBuffer, 
              hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3DID, hv_GenParamName, hv_GenParamValue, 
              hv_CamParam, (*hv_PosesOut), hv_ColorImage, hv_Title, hv_Information, 
              hv_Labels, hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, 
              hv_TBSize, (*hv_SelectedObjectOut), (*hv_WindowCenteredRotationOut)==1, 
              hv_TBCenter, HTuple(), HTuple(), HTuple(), HTuple());
          DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
          //dev_set_window (WindowHandle)
          //dev_display (ImageDump)
          DispObj(ho_ImageDump, hv_WindowHandle);
          send_pose_update(hv_Parameters, (*hv_PosesOut));
          //
          hv_MRow1 = hv_Row;
          hv_MCol1 = hv_Column;
          hv_PosesIn = (*hv_PosesOut);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
    }
    else if (0 != hv_IsButtonDist)
    {
      //Change the Z distance
      hv_MRow1 = hv_Row;
      while (0 != hv_IsButtonDist)
      {
        try
        {
          get_mouse_info(hv_WindowHandle, hv_MessageQueue, HTuple(), &hv_Row, &hv_Column, 
              &hv_ButtonLoop);
          hv_IsButtonDist = hv_ButtonLoop==hv_Button;
          hv_MRow2 = hv_Row;
          hv_DRow = hv_MRow2-hv_MRow1;
          hv_Dist = (((HTuple(hv_TBCenter[0])*HTuple(hv_TBCenter[0]))+(HTuple(hv_TBCenter[1])*HTuple(hv_TBCenter[1])))+(HTuple(hv_TBCenter[2])*HTuple(hv_TBCenter[2]))).TupleSqrt();
          hv_TranslateZ = (((-hv_Dist)*hv_DRow)*0.003)*hv_SensFactor;
          hv_TBCenter[2] = HTuple(hv_TBCenter[2])+hv_TranslateZ;
          (*hv_PosesOut) = HTuple();
          if (0 != (hv_NumModels<=hv_MaxNumModels))
          {
            {
            HTuple end_val165 = hv_NumModels-1;
            HTuple step_val165 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val165, step_val165); hv_Index += step_val165)
            {
              hv_PoseIn = hv_PosesIn.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
              if (0 != (HTuple((*hv_SelectedObjectOut)[hv_Index])))
              {
                //Transform the whole scene or selected object only
                PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, 0, 0, hv_TranslateZ, &hv_HomMat3DOut);
                HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
                SetScene3dInstancePose(hv_Scene3D, hv_Index, hv_PoseOut);
              }
              else
              {
                hv_PoseOut = hv_PoseIn;
              }
              (*hv_PosesOut) = (*hv_PosesOut).TupleConcat(hv_PoseOut);
            }
            }
          }
          else
          {
            TupleFind((*hv_SelectedObjectOut), 1, &hv_Indices);
            hv_PoseIn = hv_PosesIn.TupleSelectRange(HTuple(hv_Indices[0])*7,(HTuple(hv_Indices[0])*7)+6);
            PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
            HomMat3dTranslate(hv_HomMat3DIn, 0, 0, hv_TranslateZ, &hv_HomMat3DOut);
            HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
            hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
            TupleMod(hv_Sequence, 7, &hv_Mod);
            hv_SequenceReal = HTuple::TupleGenSequence(0,hv_NumModels-(1.0/7.0),1.0/7.0);
            hv_Sequence2Int = hv_SequenceReal.TupleInt();
            TupleSelect((*hv_SelectedObjectOut), hv_Sequence2Int, &hv_Selected);
            hv_InvSelected = 1-hv_Selected;
            TupleSelect(hv_PoseOut, hv_Mod, &(*hv_PosesOut));
            (*hv_PosesOut) = ((*hv_PosesOut)*hv_Selected)+(hv_PosesIn*hv_InvSelected);
            SetScene3dInstancePose(hv_Scene3D, HTuple::TupleGenSequence(0,hv_NumModels-1,1), 
                (*hv_PosesOut));
          }
          dump_image_output(ho_BackgroundImage, hv_Parameters, hv_WindowHandleBuffer, 
              hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3DID, hv_GenParamName, hv_GenParamValue, 
              hv_CamParam, (*hv_PosesOut), hv_ColorImage, hv_Title, hv_Information, 
              hv_Labels, hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, 
              hv_TBSize, (*hv_SelectedObjectOut), (*hv_WindowCenteredRotationOut), 
              hv_TBCenter, HTuple(), HTuple(), HTuple(), HTuple());
          DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
          //dev_set_window (WindowHandle)
          //dev_display (ImageDump)
          DispObj(ho_ImageDump, hv_WindowHandle);
          send_pose_update(hv_Parameters, (*hv_PosesOut));
          //
          hv_MRow1 = hv_Row;
          hv_PosesIn = (*hv_PosesOut);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
    }
    else if (0 != hv_IsButtonRot)
    {
      //Rotate the object
      hv_MRow1 = hv_Row;
      hv_MCol1 = hv_Column;
      while (0 != hv_IsButtonRot)
      {
        try
        {
          get_mouse_info(hv_WindowHandle, hv_MessageQueue, HTuple(), &hv_Row, &hv_Column, 
              &hv_ButtonLoop);
          hv_IsButtonRot = hv_ButtonLoop==hv_Button;
          hv_MRow2 = hv_Row;
          hv_MCol2 = hv_Column;
          //Transform the pixel coordinates to relative image coordinates
          hv_MX1 = (hv_TrackballCenterCol-hv_MCol1)/(0.5*hv_MinImageSize);
          hv_MY1 = (hv_TrackballCenterRow-hv_MRow1)/(0.5*hv_MinImageSize);
          hv_MX2 = (hv_TrackballCenterCol-hv_MCol2)/(0.5*hv_MinImageSize);
          hv_MY2 = (hv_TrackballCenterRow-hv_MRow2)/(0.5*hv_MinImageSize);
          //Compute the quaternion rotation that corresponds to the mouse
          //movement
          trackball(hv_MX1, hv_MY1, hv_MX2, hv_MY2, hv_VirtualTrackball, hv_TrackballSize, 
              hv_SensFactor, &hv_RelQuaternion);
          //Transform the quaternion to a rotation matrix
          QuatToHomMat3d(hv_RelQuaternion, &hv_HomMat3DRotRel);
          (*hv_PosesOut) = HTuple();
          if (0 != (hv_NumModels<=hv_MaxNumModels))
          {
            {
            HTuple end_val229 = hv_NumModels-1;
            HTuple step_val229 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val229, step_val229); hv_Index += step_val229)
            {
              hv_PoseIn = hv_PosesIn.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
              if (0 != (HTuple((*hv_SelectedObjectOut)[hv_Index])))
              {
                //Transform the whole scene or selected object only
                PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, -HTuple(hv_TBCenter[0]), -HTuple(hv_TBCenter[1]), 
                    -HTuple(hv_TBCenter[2]), &hv_HomMat3DIn);
                HomMat3dCompose(hv_HomMat3DRotRel, hv_HomMat3DIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, HTuple(hv_TBCenter[0]), HTuple(hv_TBCenter[1]), 
                    HTuple(hv_TBCenter[2]), &hv_HomMat3DOut);
                HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
                SetScene3dInstancePose(hv_Scene3D, hv_Index, hv_PoseOut);
              }
              else
              {
                hv_PoseOut = hv_PoseIn;
              }
              (*hv_PosesOut) = (*hv_PosesOut).TupleConcat(hv_PoseOut);
            }
            }
          }
          else
          {
            TupleFind((*hv_SelectedObjectOut), 1, &hv_Indices);
            hv_PoseIn = hv_PosesIn.TupleSelectRange(HTuple(hv_Indices[0])*7,(HTuple(hv_Indices[0])*7)+6);
            PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
            HomMat3dTranslate(hv_HomMat3DIn, -HTuple(hv_TBCenter[0]), -HTuple(hv_TBCenter[1]), 
                -HTuple(hv_TBCenter[2]), &hv_HomMat3DInTmp1);
            HomMat3dCompose(hv_HomMat3DRotRel, hv_HomMat3DInTmp1, &hv_HomMat3DInTmp);
            HomMat3dTranslate(hv_HomMat3DInTmp, HTuple(hv_TBCenter[0]), HTuple(hv_TBCenter[1]), 
                HTuple(hv_TBCenter[2]), &hv_HomMat3DOut);
            HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
            hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
            TupleMod(hv_Sequence, 7, &hv_Mod);
            hv_SequenceReal = HTuple::TupleGenSequence(0,hv_NumModels-(1.0/7.0),1.0/7.0);
            hv_Sequence2Int = hv_SequenceReal.TupleInt();
            TupleSelect((*hv_SelectedObjectOut), hv_Sequence2Int, &hv_Selected);
            hv_InvSelected = 1-hv_Selected;
            TupleSelect(hv_PoseOut, hv_Mod, &(*hv_PosesOut));
            hv_PosesOut2 = ((*hv_PosesOut)*hv_Selected)+(hv_PosesIn*hv_InvSelected);
            (*hv_PosesOut) = hv_PosesOut2;
            SetScene3dInstancePose(hv_Scene3D, HTuple::TupleGenSequence(0,hv_NumModels-1,1), 
                (*hv_PosesOut));
          }
          dump_image_output(ho_BackgroundImage, hv_Parameters, hv_WindowHandleBuffer, 
              hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3DID, hv_GenParamName, hv_GenParamValue, 
              hv_CamParam, (*hv_PosesOut), hv_ColorImage, hv_Title, hv_Information, 
              hv_Labels, hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, 
              hv_TBSize, (*hv_SelectedObjectOut), (*hv_WindowCenteredRotationOut), 
              hv_TBCenter, HTuple(), HTuple(), HTuple(), HTuple());
          DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
          //dev_set_window (WindowHandle)
          //dev_display (ImageDump)
          DispObj(ho_ImageDump, hv_WindowHandle);
          send_pose_update(hv_Parameters, (*hv_PosesOut));
          //
          hv_MRow1 = hv_Row;
          hv_MCol1 = hv_Column;
          hv_PosesIn = (*hv_PosesOut);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
    }
    (*hv_PosesOut) = hv_PosesIn;
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Reflect the pose change that was introduced by the user by moving the mouse 
void analyze_graph_event_visualize_object_model_3d (HObject ho_BackgroundImage, HTuple hv_MouseMapping, 
    HTuple hv_Button, HTuple hv_Row, HTuple hv_Column, HTuple hv_WindowHandle, HTuple hv_WindowHandleBuffer, 
    HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple hv_SelectedObjectIn, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_Labels, HTuple hv_Title, HTuple hv_Information, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_PosesIn, HTuple hv_ButtonHoldIn, HTuple hv_TBCenter, 
    HTuple hv_TBSize, HTuple hv_WindowCenteredRotationlIn, HTuple hv_MaxNumModels, 
    HTuple *hv_PosesOut, HTuple *hv_SelectedObjectOut, HTuple *hv_ButtonHoldOut, 
    HTuple *hv_WindowCenteredRotationOut)
{

  // Local iconic variables
  HObject  ho_ImageDump;

  // Local control variables
  HTuple  ExpTmpLocalVar_gIsSinglePose, hv_VisualizeTB;
  HTuple  hv_InvLog2, hv_Seconds, hv_ModelIndex, hv_Exception1;
  HTuple  hv_HomMat3DIdentity, hv_NumModels, hv_Width, hv_Height;
  HTuple  hv_MinImageSize, hv_TrackballRadiusPixel, hv_TrackballCenterRow;
  HTuple  hv_TrackballCenterCol, hv_NumChannels, hv_ColorImage;
  HTuple  hv_BAnd, hv_SensFactor, hv_IsButtonTrans, hv_IsButtonRot;
  HTuple  hv_IsButtonDist, hv_MRow1, hv_MCol1, hv_ButtonLoop;
  HTuple  hv_MRow2, hv_MCol2, hv_PX, hv_PY, hv_PZ, hv_QX1;
  HTuple  hv_QY1, hv_QZ1, hv_QX2, hv_QY2, hv_QZ2, hv_Len;
  HTuple  hv_Dist, hv_Translate, hv_Index, hv_PoseIn, hv_HomMat3DIn;
  HTuple  hv_HomMat3DOut, hv_PoseOut, hv_Indices, hv_Sequence;
  HTuple  hv_Mod, hv_SequenceReal, hv_Sequence2Int, hv_Selected;
  HTuple  hv_InvSelected, hv_Exception, hv_DRow, hv_TranslateZ;
  HTuple  hv_MX1, hv_MY1, hv_MX2, hv_MY2, hv_RelQuaternion;
  HTuple  hv_HomMat3DRotRel, hv_HomMat3DInTmp1, hv_HomMat3DInTmp;
  HTuple  hv_PosesOut2;

  //This procedure reflects
  //- the pose change that was introduced by the user by
  //  moving the mouse
  //- the selection of a single object
  //
  //global tuple gIsSinglePose
  //
  (*hv_ButtonHoldOut) = hv_ButtonHoldIn;
  (*hv_PosesOut) = hv_PosesIn;
  (*hv_SelectedObjectOut) = hv_SelectedObjectIn;
  (*hv_WindowCenteredRotationOut) = hv_WindowCenteredRotationlIn;
  hv_VisualizeTB = ((*hv_SelectedObjectOut).TupleMax())!=0;
  hv_InvLog2 = 1.0/(HTuple(2).TupleLog());
  //
  if (0 != (hv_Button==HTuple(hv_MouseMapping[6])))
  {
    if (0 != (*hv_ButtonHoldOut))
    {
      return;
    }
    //Ctrl (16) + Alt (32) + left mouse button (1) => Toggle rotation center position
    //If WindowCenteredRotation is not 1, set it to 1, otherwise, set it to 2
    CountSeconds(&hv_Seconds);
    if (0 != ((*hv_WindowCenteredRotationOut)==1))
    {
      (*hv_WindowCenteredRotationOut) = 2;
    }
    else
    {
      (*hv_WindowCenteredRotationOut) = 1;
    }
    (*hv_ButtonHoldOut) = 1;
    return;
  }
  if (0 != (HTuple(hv_Button==HTuple(hv_MouseMapping[5])).TupleAnd((hv_ObjectModel3DID.TupleLength())<=hv_MaxNumModels)))
  {
    if (0 != (*hv_ButtonHoldOut))
    {
      return;
    }
    //Ctrl (16) + left mouse button (1) => Select an object
    try
    {
      SetScene3dParam(hv_Scene3D, "object_index_persistence", "true");
      DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
      GetDisplayScene3dInfo(hv_WindowHandleBuffer, hv_Scene3D, hv_Row, hv_Column, 
          "object_index", &hv_ModelIndex);
      SetScene3dParam(hv_Scene3D, "object_index_persistence", "false");
    }
    // catch (Exception1) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception1);
      //* NO OpenGL, no selection possible
      return;
    }
    if (0 != (hv_ModelIndex==-1))
    {
      //Background click:
      if (0 != (((*hv_SelectedObjectOut).TupleSum())==((*hv_SelectedObjectOut).TupleLength())))
      {
        //If all objects are already selected, deselect all
        (*hv_SelectedObjectOut) = HTuple(hv_ObjectModel3DID.TupleLength(),0);
      }
      else
      {
        //Otherwise select all
        (*hv_SelectedObjectOut) = HTuple(hv_ObjectModel3DID.TupleLength(),1);
      }
    }
    else
    {
      //Object click:
      (*hv_SelectedObjectOut)[hv_ModelIndex] = HTuple((*hv_SelectedObjectOut)[hv_ModelIndex]).TupleNot();
    }
    (*hv_ButtonHoldOut) = 1;
  }
  else
  {
    //Change the pose
    HomMat3dIdentity(&hv_HomMat3DIdentity);
    hv_NumModels = hv_ObjectModel3DID.TupleLength();
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    hv_MinImageSize = (hv_Width.TupleConcat(hv_Height)).TupleMin();
    hv_TrackballRadiusPixel = (hv_TrackballSize*hv_MinImageSize)/2.0;
    //Set trackball fixed in the center of the window
    hv_TrackballCenterRow = hv_Height/2;
    hv_TrackballCenterCol = hv_Width/2;
    if (0 != ((hv_ObjectModel3DID.TupleLength())<hv_MaxNumModels))
    {
      if (0 != ((*hv_WindowCenteredRotationOut)==1))
      {
        get_trackball_center_fixed_visualize_object_model_3d(hv_SelectedObjectIn, 
            hv_TrackballCenterRow, hv_TrackballCenterCol, hv_TrackballRadiusPixel, 
            hv_Scene3D, hv_ObjectModel3DID, hv_PosesIn, hv_WindowHandleBuffer, hv_CamParam, 
            hv_GenParamName, hv_GenParamValue, &hv_TBCenter, &hv_TBSize);
      }
      else
      {
        get_trackball_center_visualize_object_model_3d(hv_SelectedObjectIn, hv_TrackballRadiusPixel, 
            hv_ObjectModel3DID, hv_PosesIn, &hv_TBCenter, &hv_TBSize);
      }
    }
    if (0 != (HTuple(((*hv_SelectedObjectOut).TupleMin())==0).TupleAnd(((*hv_SelectedObjectOut).TupleMax())==1)))
    {
      //At this point, multiple objects do not necessary have the same
      //pose any more. Consequently, we have to return a tuple of poses
      //as output of visualize_object_model_3d
      ExpTmpLocalVar_gIsSinglePose = 0;
      ExpSetGlobalVar_gIsSinglePose(ExpTmpLocalVar_gIsSinglePose);
    }
    CountChannels(ho_BackgroundImage, &hv_NumChannels);
    hv_ColorImage = hv_NumChannels==3;
    //Alt (32) => lower sensitivity
    TupleRsh(hv_Button, 5, &hv_BAnd);
    if (0 != (hv_BAnd%2))
    {
      hv_SensFactor = 0.1;
    }
    else
    {
      hv_SensFactor = 1.0;
    }
    hv_IsButtonTrans = HTuple(HTuple(hv_MouseMapping[0])==hv_Button).TupleOr((32+HTuple(hv_MouseMapping[0]))==hv_Button);
    hv_IsButtonRot = HTuple(HTuple(hv_MouseMapping[1])==hv_Button).TupleOr((32+HTuple(hv_MouseMapping[1]))==hv_Button);
    hv_IsButtonDist = HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(hv_MouseMapping[2])==hv_Button).TupleOr((32+HTuple(hv_MouseMapping[2]))==hv_Button)).TupleOr(HTuple(hv_MouseMapping[3])==hv_Button)).TupleOr((32+HTuple(hv_MouseMapping[3]))==hv_Button)).TupleOr(HTuple(hv_MouseMapping[4])==hv_Button)).TupleOr((32+HTuple(hv_MouseMapping[4]))==hv_Button);
    if (0 != hv_IsButtonTrans)
    {
      //Translate in XY-direction
      hv_MRow1 = hv_Row;
      hv_MCol1 = hv_Column;
      while (0 != hv_IsButtonTrans)
      {
        try
        {
          GetMpositionSubPix(hv_WindowHandle, &hv_Row, &hv_Column, &hv_ButtonLoop);
          hv_IsButtonTrans = hv_ButtonLoop==hv_Button;
          hv_MRow2 = hv_MRow1+((hv_Row-hv_MRow1)*hv_SensFactor);
          hv_MCol2 = hv_MCol1+((hv_Column-hv_MCol1)*hv_SensFactor);
          GetLineOfSight(hv_MRow1, hv_MCol1, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, 
              &hv_QX1, &hv_QY1, &hv_QZ1);
          GetLineOfSight(hv_MRow2, hv_MCol2, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, 
              &hv_QX2, &hv_QY2, &hv_QZ2);
          hv_Len = (((hv_QX1*hv_QX1)+(hv_QY1*hv_QY1))+(hv_QZ1*hv_QZ1)).TupleSqrt();
          hv_Dist = (((HTuple(hv_TBCenter[0])*HTuple(hv_TBCenter[0]))+(HTuple(hv_TBCenter[1])*HTuple(hv_TBCenter[1])))+(HTuple(hv_TBCenter[2])*HTuple(hv_TBCenter[2]))).TupleSqrt();
          hv_Translate = ((((hv_QX2-hv_QX1).TupleConcat(hv_QY2-hv_QY1)).TupleConcat(hv_QZ2-hv_QZ1))*hv_Dist)/hv_Len;
          (*hv_PosesOut) = HTuple();
          if (0 != (hv_NumModels<=hv_MaxNumModels))
          {
            {
            HTuple end_val110 = hv_NumModels-1;
            HTuple step_val110 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val110, step_val110); hv_Index += step_val110)
            {
              hv_PoseIn = hv_PosesIn.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
              if (0 != (HTuple((*hv_SelectedObjectOut)[hv_Index])))
              {
                PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, HTuple(hv_Translate[0]), HTuple(hv_Translate[1]), 
                    HTuple(hv_Translate[2]), &hv_HomMat3DOut);
                HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
                SetScene3dInstancePose(hv_Scene3D, hv_Index, hv_PoseOut);
              }
              else
              {
                hv_PoseOut = hv_PoseIn;
              }
              (*hv_PosesOut) = (*hv_PosesOut).TupleConcat(hv_PoseOut);
            }
            }
          }
          else
          {
            TupleFind((*hv_SelectedObjectOut), 1, &hv_Indices);
            hv_PoseIn = hv_PosesIn.TupleSelectRange(HTuple(hv_Indices[0])*7,(HTuple(hv_Indices[0])*7)+6);
            PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
            HomMat3dTranslate(hv_HomMat3DIn, HTuple(hv_Translate[0]), HTuple(hv_Translate[1]), 
                HTuple(hv_Translate[2]), &hv_HomMat3DOut);
            HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
            hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
            TupleMod(hv_Sequence, 7, &hv_Mod);
            hv_SequenceReal = HTuple::TupleGenSequence(0,hv_NumModels-(1.0/7.0),1.0/7.0);
            hv_Sequence2Int = hv_SequenceReal.TupleInt();
            TupleSelect((*hv_SelectedObjectOut), hv_Sequence2Int, &hv_Selected);
            hv_InvSelected = 1-hv_Selected;
            TupleSelect(hv_PoseOut, hv_Mod, &(*hv_PosesOut));
            (*hv_PosesOut) = ((*hv_PosesOut)*hv_Selected)+(hv_PosesIn*hv_InvSelected);
            SetScene3dInstancePose(hv_Scene3D, HTuple::TupleGenSequence(0,hv_NumModels-1,1), 
                (*hv_PosesOut));
          }
          dump_image_output_visualize_object_model_3d(ho_BackgroundImage, hv_WindowHandleBuffer, 
              hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3DID, hv_GenParamName, hv_GenParamValue, 
              hv_CamParam, (*hv_PosesOut), hv_ColorImage, hv_Title, hv_Information, 
              hv_Labels, hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, 
              hv_TBSize, (*hv_SelectedObjectOut), (*hv_WindowCenteredRotationOut)==1, 
              hv_TBCenter);
          DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
          HDevWindowStack::SetActive(hv_WindowHandle);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ImageDump, HDevWindowStack::GetActive());
          //
          hv_MRow1 = hv_Row;
          hv_MCol1 = hv_Column;
          hv_PosesIn = (*hv_PosesOut);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
    }
    else if (0 != hv_IsButtonDist)
    {
      //Change the Z distance
      hv_MRow1 = hv_Row;
      while (0 != hv_IsButtonDist)
      {
        try
        {
          GetMpositionSubPix(hv_WindowHandle, &hv_Row, &hv_Column, &hv_ButtonLoop);
          hv_IsButtonDist = hv_ButtonLoop==hv_Button;
          hv_MRow2 = hv_Row;
          hv_DRow = hv_MRow2-hv_MRow1;
          hv_Dist = (((HTuple(hv_TBCenter[0])*HTuple(hv_TBCenter[0]))+(HTuple(hv_TBCenter[1])*HTuple(hv_TBCenter[1])))+(HTuple(hv_TBCenter[2])*HTuple(hv_TBCenter[2]))).TupleSqrt();
          hv_TranslateZ = (((-hv_Dist)*hv_DRow)*0.003)*hv_SensFactor;
          hv_TBCenter[2] = HTuple(hv_TBCenter[2])+hv_TranslateZ;
          (*hv_PosesOut) = HTuple();
          if (0 != (hv_NumModels<=hv_MaxNumModels))
          {
            {
            HTuple end_val164 = hv_NumModels-1;
            HTuple step_val164 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val164, step_val164); hv_Index += step_val164)
            {
              hv_PoseIn = hv_PosesIn.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
              if (0 != (HTuple((*hv_SelectedObjectOut)[hv_Index])))
              {
                //Transform the whole scene or selected object only
                PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, 0, 0, hv_TranslateZ, &hv_HomMat3DOut);
                HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
                SetScene3dInstancePose(hv_Scene3D, hv_Index, hv_PoseOut);
              }
              else
              {
                hv_PoseOut = hv_PoseIn;
              }
              (*hv_PosesOut) = (*hv_PosesOut).TupleConcat(hv_PoseOut);
            }
            }
          }
          else
          {
            TupleFind((*hv_SelectedObjectOut), 1, &hv_Indices);
            hv_PoseIn = hv_PosesIn.TupleSelectRange(HTuple(hv_Indices[0])*7,(HTuple(hv_Indices[0])*7)+6);
            PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
            HomMat3dTranslate(hv_HomMat3DIn, 0, 0, hv_TranslateZ, &hv_HomMat3DOut);
            HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
            hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
            TupleMod(hv_Sequence, 7, &hv_Mod);
            hv_SequenceReal = HTuple::TupleGenSequence(0,hv_NumModels-(1.0/7.0),1.0/7.0);
            hv_Sequence2Int = hv_SequenceReal.TupleInt();
            TupleSelect((*hv_SelectedObjectOut), hv_Sequence2Int, &hv_Selected);
            hv_InvSelected = 1-hv_Selected;
            TupleSelect(hv_PoseOut, hv_Mod, &(*hv_PosesOut));
            (*hv_PosesOut) = ((*hv_PosesOut)*hv_Selected)+(hv_PosesIn*hv_InvSelected);
            SetScene3dInstancePose(hv_Scene3D, HTuple::TupleGenSequence(0,hv_NumModels-1,1), 
                (*hv_PosesOut));
          }
          dump_image_output_visualize_object_model_3d(ho_BackgroundImage, hv_WindowHandleBuffer, 
              hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3DID, hv_GenParamName, hv_GenParamValue, 
              hv_CamParam, (*hv_PosesOut), hv_ColorImage, hv_Title, hv_Information, 
              hv_Labels, hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, 
              hv_TBSize, (*hv_SelectedObjectOut), (*hv_WindowCenteredRotationOut), 
              hv_TBCenter);
          DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
          HDevWindowStack::SetActive(hv_WindowHandle);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ImageDump, HDevWindowStack::GetActive());
          //
          hv_MRow1 = hv_Row;
          hv_PosesIn = (*hv_PosesOut);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
    }
    else if (0 != hv_IsButtonRot)
    {
      //Rotate the object
      hv_MRow1 = hv_Row;
      hv_MCol1 = hv_Column;
      while (0 != hv_IsButtonRot)
      {
        try
        {
          GetMpositionSubPix(hv_WindowHandle, &hv_Row, &hv_Column, &hv_ButtonLoop);
          hv_IsButtonRot = hv_ButtonLoop==hv_Button;
          hv_MRow2 = hv_Row;
          hv_MCol2 = hv_Column;
          //Transform the pixel coordinates to relative image coordinates
          hv_MX1 = (hv_TrackballCenterCol-hv_MCol1)/(0.5*hv_MinImageSize);
          hv_MY1 = (hv_TrackballCenterRow-hv_MRow1)/(0.5*hv_MinImageSize);
          hv_MX2 = (hv_TrackballCenterCol-hv_MCol2)/(0.5*hv_MinImageSize);
          hv_MY2 = (hv_TrackballCenterRow-hv_MRow2)/(0.5*hv_MinImageSize);
          //Compute the quaternion rotation that corresponds to the mouse
          //movement
          trackball_visualize_object_model_3d(hv_MX1, hv_MY1, hv_MX2, hv_MY2, hv_VirtualTrackball, 
              hv_TrackballSize, hv_SensFactor, &hv_RelQuaternion);
          //Transform the quaternion to a rotation matrix
          QuatToHomMat3d(hv_RelQuaternion, &hv_HomMat3DRotRel);
          (*hv_PosesOut) = HTuple();
          if (0 != (hv_NumModels<=hv_MaxNumModels))
          {
            {
            HTuple end_val226 = hv_NumModels-1;
            HTuple step_val226 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val226, step_val226); hv_Index += step_val226)
            {
              hv_PoseIn = hv_PosesIn.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
              if (0 != (HTuple((*hv_SelectedObjectOut)[hv_Index])))
              {
                //Transform the whole scene or selected object only
                PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, -HTuple(hv_TBCenter[0]), -HTuple(hv_TBCenter[1]), 
                    -HTuple(hv_TBCenter[2]), &hv_HomMat3DIn);
                HomMat3dCompose(hv_HomMat3DRotRel, hv_HomMat3DIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, HTuple(hv_TBCenter[0]), HTuple(hv_TBCenter[1]), 
                    HTuple(hv_TBCenter[2]), &hv_HomMat3DOut);
                HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
                SetScene3dInstancePose(hv_Scene3D, hv_Index, hv_PoseOut);
              }
              else
              {
                hv_PoseOut = hv_PoseIn;
              }
              (*hv_PosesOut) = (*hv_PosesOut).TupleConcat(hv_PoseOut);
            }
            }
          }
          else
          {
            TupleFind((*hv_SelectedObjectOut), 1, &hv_Indices);
            hv_PoseIn = hv_PosesIn.TupleSelectRange(HTuple(hv_Indices[0])*7,(HTuple(hv_Indices[0])*7)+6);
            PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
            HomMat3dTranslate(hv_HomMat3DIn, -HTuple(hv_TBCenter[0]), -HTuple(hv_TBCenter[1]), 
                -HTuple(hv_TBCenter[2]), &hv_HomMat3DInTmp1);
            HomMat3dCompose(hv_HomMat3DRotRel, hv_HomMat3DInTmp1, &hv_HomMat3DInTmp);
            HomMat3dTranslate(hv_HomMat3DInTmp, HTuple(hv_TBCenter[0]), HTuple(hv_TBCenter[1]), 
                HTuple(hv_TBCenter[2]), &hv_HomMat3DOut);
            HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
            hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
            TupleMod(hv_Sequence, 7, &hv_Mod);
            hv_SequenceReal = HTuple::TupleGenSequence(0,hv_NumModels-(1.0/7.0),1.0/7.0);
            hv_Sequence2Int = hv_SequenceReal.TupleInt();
            TupleSelect((*hv_SelectedObjectOut), hv_Sequence2Int, &hv_Selected);
            hv_InvSelected = 1-hv_Selected;
            TupleSelect(hv_PoseOut, hv_Mod, &(*hv_PosesOut));
            hv_PosesOut2 = ((*hv_PosesOut)*hv_Selected)+(hv_PosesIn*hv_InvSelected);
            (*hv_PosesOut) = hv_PosesOut2;
            SetScene3dInstancePose(hv_Scene3D, HTuple::TupleGenSequence(0,hv_NumModels-1,1), 
                (*hv_PosesOut));
          }
          dump_image_output_visualize_object_model_3d(ho_BackgroundImage, hv_WindowHandleBuffer, 
              hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3DID, hv_GenParamName, hv_GenParamValue, 
              hv_CamParam, (*hv_PosesOut), hv_ColorImage, hv_Title, hv_Information, 
              hv_Labels, hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, 
              hv_TBSize, (*hv_SelectedObjectOut), (*hv_WindowCenteredRotationOut), 
              hv_TBCenter);
          DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
          HDevWindowStack::SetActive(hv_WindowHandle);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ImageDump, HDevWindowStack::GetActive());
          //
          hv_MRow1 = hv_Row;
          hv_MCol1 = hv_Column;
          hv_PosesIn = (*hv_PosesOut);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
    }
    (*hv_PosesOut) = hv_PosesIn;
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_custom_features and get_features. 
void append_length_or_values (HTuple hv_Mode, HTuple hv_Feature, HTuple hv_AccumulatedResults, 
    HTuple *hv_ExtendedResults)
{

  // Local iconic variables

  //
  //Auxiliary procedure used only by get_features and get_custom_features
  //
  if (0 != (hv_Mode==HTuple("get_lengths")))
  {
    //Output in 'get_lengths' mode is the length of the feature
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_Feature.TupleLength());
  }
  else if (0 != (hv_Mode==HTuple("calculate")))
  {
    //Output in 'calculate' mode is the feature vector
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_Feature);
  }
  else
  {
    (*hv_ExtendedResults) = hv_AccumulatedResults;
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_custom_features and get_features. 
void append_names_or_groups (HTuple hv_Mode, HTuple hv_Name, HTuple hv_Groups, HTuple hv_CurrentName, 
    HTuple hv_AccumulatedResults, HTuple *hv_ExtendedResults)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_FirstOccurrence, hv_BelongsToGroup;

  //
  //Auxiliary procedure used only by get_features and get_custom_features
  //
  (*hv_ExtendedResults) = hv_AccumulatedResults;
  if (0 != (hv_Mode==HTuple("get_names")))
  {
    hv_FirstOccurrence = HTuple((hv_AccumulatedResults.TupleLength())==0).TupleOr((hv_AccumulatedResults.TupleFind(hv_Name))==-1);
    hv_BelongsToGroup = HTuple(((hv_Name.TupleConcat(hv_Groups)).TupleFind(hv_CurrentName))!=-1).TupleOr(hv_CurrentName==HTuple("all"));
    if (0 != (hv_FirstOccurrence.TupleAnd(hv_BelongsToGroup)))
    {
      //Output in 'get_names' mode is the name of the feature
      (*hv_ExtendedResults).Clear();
      (*hv_ExtendedResults).Append(hv_AccumulatedResults);
      (*hv_ExtendedResults).Append(hv_Name);
    }
  }
  else if (0 != (hv_Mode==HTuple("get_groups")))
  {
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_Groups);
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_features. 
void append_names_or_groups_pyramid (HTuple hv_Mode, HTuple hv_Groups, HTuple hv_CurrentName, 
    HTuple hv_Names, HTuple hv_NameRegExp, HTuple hv_AccumulatedResults, HTuple *hv_ExtendedResults)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_BelongsToGroup, hv_TmpNames, hv_J;
  HTuple  hv_FirstOccurrence;

  //
  //Auxiliary procedure used only by get_features and get_custom_features
  //
  (*hv_ExtendedResults) = hv_AccumulatedResults;
  if (0 != (hv_Mode==HTuple("get_names")))
  {
    hv_BelongsToGroup = HTuple((hv_Groups.TupleFind(hv_CurrentName))!=-1).TupleOr(hv_CurrentName==HTuple("all"));
    if (0 != (hv_CurrentName.TupleRegexpTest(hv_NameRegExp)))
    {
      hv_Names = hv_CurrentName;
    }
    else if (0 != (hv_BelongsToGroup.TupleNot()))
    {
      hv_Names = HTuple();
    }
    hv_TmpNames = HTuple();
    {
    HTuple end_val12 = (hv_Names.TupleLength())-1;
    HTuple step_val12 = 1;
    for (hv_J=0; hv_J.Continue(end_val12, step_val12); hv_J += step_val12)
    {
      hv_FirstOccurrence = HTuple((hv_AccumulatedResults.TupleLength())==0).TupleOr((hv_AccumulatedResults.TupleFind(HTuple(hv_Names[hv_J])))==-1);
      if (0 != hv_FirstOccurrence)
      {
        //Output in 'get_names' mode is the name of the feature
        hv_TmpNames = hv_TmpNames.TupleConcat(HTuple(hv_Names[hv_J]));
      }
    }
    }
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_TmpNames);
  }
  else if (0 != (hv_Mode==HTuple("get_groups")))
  {
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_Groups);
  }
  return;
}

// Chapter: Image / Manipulation
void apply_brightness_variation_spot (HObject ho_Image, HObject *ho_ImageSpot, HTuple hv_SpotSize, 
    HTuple hv_SpotRow, HTuple hv_SpotColumn, HTuple hv_BrightnessVariation)
{

  // Local iconic variables
  HObject  ho_Filter, ho_GaussImage, ho_GaussFilter;
  HObject  ho_Gauss, ho_GaussTargetType, ho_AddImage;

  // Local control variables
  HTuple  hv_Direction, hv_Width, hv_Height, hv_ShiftRow;
  HTuple  hv_ShiftCol, hv_Type, hv_NChannels, hv_Index1;

  //This procedure applies a brightness spot
  //of a given intensity and size at a given location
  //to the input image.
  //The modified image is returned in ImageSpot.
  //
  if (0 != (hv_BrightnessVariation<0))
  {
    hv_Direction = 0;
    hv_BrightnessVariation = -hv_BrightnessVariation;
  }
  else
  {
    hv_Direction = 1;
  }
  GetImageSize(ho_Image, &hv_Width, &hv_Height);
  //Generate Gauss filter that simulates an illumination spot of size 'SpotSize'.
  GenGaussFilter(&ho_Filter, 1, 1, 0, "none", "dc_center", hv_SpotSize, hv_SpotSize);
  //Shift the filter image to the given position.
  hv_ShiftRow = -((hv_SpotSize/2)-hv_SpotRow);
  hv_ShiftCol = -((hv_SpotSize/2)-hv_SpotColumn);
  TileImagesOffset(ho_Filter, &ho_GaussImage, hv_ShiftRow, hv_ShiftCol, -1, -1, -1, 
      -1, hv_Width, hv_Height);
  FullDomain(ho_GaussImage, &ho_GaussFilter);
  //Convert Gauss filter to target image type and apply brightness variation.
  GetImageType(ho_Image, &hv_Type);
  ScaleImage(ho_GaussFilter, &ho_Gauss, hv_BrightnessVariation, 0);
  ConvertImageType(ho_Gauss, &ho_GaussTargetType, hv_Type);
  //Add channels to fit input image.
  CountChannels(ho_Image, &hv_NChannels);
  CopyObj(ho_GaussTargetType, &ho_AddImage, 1, 1);
  {
  HTuple end_val26 = hv_NChannels-1;
  HTuple step_val26 = 1;
  for (hv_Index1=1; hv_Index1.Continue(end_val26, step_val26); hv_Index1 += step_val26)
  {
    AppendChannel(ho_AddImage, ho_GaussTargetType, &ho_AddImage);
  }
  }
  //Apply on image.
  if (0 != hv_Direction)
  {
    AddImage(ho_Image, ho_AddImage, &(*ho_ImageSpot), 1, 0);
  }
  else
  {
    SubImage(ho_Image, ho_AddImage, &(*ho_ImageSpot), 1, 0);
  }
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Return the classification results for the given images. 
void apply_dl_classifier_batchwise (HTuple hv_ImageFiles, HTuple hv_DLClassifierHandle, 
    HTuple *hv_DLClassifierResultIDs, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_PredictedClasses, 
    HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_Confidences)
{

  // Local iconic variables
  HObject  ho_BatchImages;

  // Local control variables
  HTuple  hv_BatchSize, hv_NumImages, hv_Sequence;
  HTuple  hv_BatchStartIndex, hv_BatchIndices, hv_BatchImageFiles;
  HTuple  hv_DLClassifierResultID, hv_Exception, hv_NumImagesInBatch;
  HTuple  hv_Index, hv_PredictedClass, hv_ClassConfidence;
  HTuple  hv_VectorIndex;

  //This procedure classifies the images given as paths
  //by ImageFiles using the operator apply_dl_classifier.
  //To avoid that the main memory is overloaded, the images
  //are classified batchwise, according to the hyperparameter 'batch_size',
  //which is stored in the DLClassifierHandle.
  //As result, the classification result handles for every batch
  //are returned in DLClassifierResultIDs.
  //Additionally, for every image the descending sorted
  //Confidences and corresponding PredictedClasses
  //are returned as vectors.
  //
  //Get batch size from handle.
  GetDlClassifierParam(hv_DLClassifierHandle, "batch_size", &hv_BatchSize);
  //
  //Check the input parameters.
  if (0 != ((hv_ImageFiles.TupleLength())<1))
  {
    throw HException("ImageFiles must not be empty.");
  }
  //
  //Sequence is used for easier indexing of the images.
  hv_NumImages = hv_ImageFiles.TupleLength();
  hv_Sequence = HTuple::TupleGenSequence(0,hv_NumImages-1,1);
  //
  //Loop through all selected images.
  (*hvec_PredictedClasses) = HTupleVector(1);
  (*hvec_Confidences) = HTupleVector(1);
  (*hv_DLClassifierResultIDs) = HTuple();
  {
  HTuple end_val27 = hv_NumImages-1;
  HTuple step_val27 = hv_BatchSize;
  for (hv_BatchStartIndex=0; hv_BatchStartIndex.Continue(end_val27, step_val27); hv_BatchStartIndex += step_val27)
  {
    //Select the data for the current batch.
    hv_BatchIndices = hv_Sequence.TupleSelectRange(hv_BatchStartIndex,((hv_BatchStartIndex+hv_BatchSize)-1).TupleMin2(hv_NumImages-1));
    hv_BatchImageFiles = HTuple(hv_ImageFiles[hv_BatchIndices]);
    //Read the current batch images.
    ReadImage(&ho_BatchImages, hv_BatchImageFiles);
    //Apply the classifier for this batch.
    try
    {
      ApplyDlClassifier(ho_BatchImages, hv_DLClassifierHandle, &hv_DLClassifierResultID);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      if (0 != ((HTuple(hv_Exception[0]).TupleEqualElem(((((HTuple(2106).Append(2107)).Append(3122)).Append(9001)).Append(9003)))).TupleSum()))
      {
        throw HException(HTuple("Images need to fulfill the network requirements, please provide preprocessed images."));
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    //Get results from result handle.
    hv_NumImagesInBatch = hv_BatchImageFiles.TupleLength();
    {
    HTuple end_val45 = hv_NumImagesInBatch-1;
    HTuple step_val45 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val45, step_val45); hv_Index += step_val45)
    {
      GetDlClassifierResult(hv_DLClassifierResultID, hv_Index, "predicted_classes", 
          &hv_PredictedClass);
      GetDlClassifierResult(hv_DLClassifierResultID, hv_Index, "confidences", &hv_ClassConfidence);
      //Store the classification results.
      hv_VectorIndex = hv_BatchStartIndex+hv_Index;
      (*hvec_PredictedClasses)[hv_VectorIndex] = HTupleVector(hv_PredictedClass);
      (*hvec_Confidences)[hv_VectorIndex] = HTupleVector(hv_ClassConfidence);
    }
    }
    (*hv_DLClassifierResultIDs) = (*hv_DLClassifierResultIDs).TupleConcat(hv_DLClassifierResultID);
  }
  }
  return;
}

// Chapter: Image / Manipulation
// Short Description: Augment/distort the given images. 
void augment_images (HObject ho_Images, HObject *ho_ImagesAugmented, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue)
{

  // Local iconic variables
  HObject  ho_ImageSelected, ho_ImagePart, ho_ImageRotated;
  HObject  ho_DomainRotated, ho_ImageScaled, ho_ImageSpot;

  // Local control variables
  HTuple  hv_AugmentationPercentage, hv_CropPercentage;
  HTuple  hv_CropPixel, hv_Rotation, hv_RotationRange, hv_Mirror;
  HTuple  hv_BrightnessVariation, hv_BrightnessVariationSpot;
  HTuple  hv_GenParamIndex, hv_CurrentParamName, hv_CurrentParamValue;
  HTuple  hv_NumAvailableDistortions, hv_NumImages, hv_AugmentationRate;
  HTuple  hv_NumAugmentations, hv_ImageIndices, hv_SelectedImages;
  HTuple  hv_SelectedDistortions, hv_IndexDistortion, hv_Index;
  HTuple  hv_ImageIndex, hv_CurrentDistortion, hv_Width, hv_Height;
  HTuple  hv_CropRate, hv_Row1, hv_Row2, hv_Column1, hv_Column2;
  HTuple  hv_Length, hv_RotationStep, hv_NumPossibleRotations;
  HTuple  hv_CurrentRotation, hv_HomMat2DIdentity, hv_HomMat2DRotate;
  HTuple  hv_NumMirrorMethods, hv_PropabilityMethods, hv_StrMirror;
  HTuple  hv_StrIdx, hv_SelectedChar, hv_BrightnessVariationValue;
  HTuple  hv_SpotSize, hv_SpotRow, hv_SpotColumn;
  HTupleVector  hvec_AvailableDistortions(1), hvec_Distortions(1);

  //This procedure can be used to augment given input Images
  //using different methods, which can be specified using
  //GenParamName and GenParamValue. The augmented images are returned
  //in ImagesAugmented.
  //
  //Set default parameters.
  //
  //The percentages of the images that are to be augmented.
  hv_AugmentationPercentage.Clear();
  hv_AugmentationPercentage[0] = "augmentation_percentage";
  hv_AugmentationPercentage[1] = 50;
  //Fraction of image length and width that remains after cropping (in %).
  hv_CropPercentage.Clear();
  hv_CropPercentage[0] = "crop_percentage";
  hv_CropPercentage[1] = "off";
  //Image length and width that remains after cropping (in pixel).
  hv_CropPixel.Clear();
  hv_CropPixel[0] = "crop_pixel";
  hv_CropPixel[1] = "off";
  //Step size for possible rotations.
  hv_Rotation.Clear();
  hv_Rotation[0] = "rotate";
  hv_Rotation[1] = 0;
  //Step range for rotations with step size 1.
  hv_RotationRange.Clear();
  hv_RotationRange[0] = "rotate_range";
  hv_RotationRange[1] = 0;
  //Allowed mirroring methods coded by 'r' (row), 'c' (column).
  hv_Mirror.Clear();
  hv_Mirror[0] = "mirror";
  hv_Mirror[1] = "off";
  //The absolute brightness change can vary in the range[-value, +value].
  hv_BrightnessVariation.Clear();
  hv_BrightnessVariation[0] = "brightness_variation";
  hv_BrightnessVariation[1] = 0;
  //The absolute brightness peak of a randomly positioned spot can vary in the range[-value, +value].
  hv_BrightnessVariationSpot.Clear();
  hv_BrightnessVariationSpot[0] = "brightness_variation_spot";
  hv_BrightnessVariationSpot[1] = 0;
  //
  //Parse the generic parameters.
  //
  //Check if GenParamName matches GenParamValue.
  if (0 != ((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength())))
  {
    throw HException("Number of generic parameters does not match number of generic parameter values");
  }
  //Check for generic parameter names and overwrite defaults.
  {
  HTuple end_val31 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val31 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val31, step_val31); hv_GenParamIndex += step_val31)
  {
    hv_CurrentParamName = HTuple(hv_GenParamName[hv_GenParamIndex]);
    hv_CurrentParamValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    //
    if (0 != (hv_CurrentParamName==HTuple(hv_AugmentationPercentage[0])))
    {
      //Set augmentation percentage.
      hv_AugmentationPercentage[1] = hv_CurrentParamValue;
      //Check if input value is in range of 1-100 %.
      if (0 != (hv_CurrentParamValue.TupleIsNumber()))
      {
        if (0 != (HTuple(hv_CurrentParamValue<1).TupleOr(hv_CurrentParamValue>100)))
        {
          throw HException("The given value for augmentation_percentage has to be in the range 1-100.");
        }
      }
      else
      {
        throw HException("The given value for augmentation_percentage has to be in the range 1-100.");
      }
    }
    else if (0 != (hv_CurrentParamName==HTuple(hv_Rotation[0])))
    {
      //Set rotation.
      hv_Rotation[1] = hv_CurrentParamValue;
      //Check if input value is in range of 0-180 deg.
      if (0 != (hv_CurrentParamValue.TupleIsNumber()))
      {
        if (0 != (HTuple(hv_CurrentParamValue<0).TupleOr(hv_CurrentParamValue>180)))
        {
          throw HException("The given value for rotate has to be in the range 0-180.");
        }
      }
      else
      {
        throw HException("The given value for rotate has to be in the range 0-180.");
      }
    }
    else if (0 != (hv_CurrentParamName==HTuple(hv_RotationRange[0])))
    {
      //Set rotation.
      hv_RotationRange[1] = hv_CurrentParamValue;
      //Check if input value is in range of 0-180 deg.
      if (0 != (hv_CurrentParamValue.TupleIsNumber()))
      {
        if (0 != (HTuple(hv_CurrentParamValue<0).TupleOr(hv_CurrentParamValue>180)))
        {
          throw HException("The given value for rotate_range has to be in the range 0-180.\"");
        }
      }
      else
      {
        throw HException("The given value for rotate_range has to be in the range 0-180.");
      }
    }
    else if (0 != (hv_CurrentParamName==HTuple(hv_Mirror[0])))
    {
      //Set mirroring.
      hv_Mirror[1] = hv_CurrentParamValue;
      //Check if input is string and is 'off' or contains the wanted strings.
      if (0 != ((hv_CurrentParamValue.TupleIsNumber()).TupleOr(HTuple(HTuple(HTuple(HTuple(HTuple(hv_CurrentParamValue==HTuple("off")).TupleOr(hv_CurrentParamValue==HTuple("c"))).TupleOr(hv_CurrentParamValue==HTuple("r"))).TupleOr(hv_CurrentParamValue==HTuple("cr"))).TupleOr(hv_CurrentParamValue==HTuple("rc"))).TupleNot())))
      {
        throw HException("Unknown mirror method.");
      }
    }
    else if (0 != (hv_CurrentParamName==HTuple(hv_CropPercentage[0])))
    {
      //Set cropping with percentage.
      hv_CropPercentage[1] = hv_CurrentParamValue;
      //Check if input value is in range of 1-100 %.
      if (0 != (hv_CurrentParamValue.TupleIsNumber()))
      {
        if (0 != (HTuple(hv_CurrentParamValue<1).TupleOr(hv_CurrentParamValue>100)))
        {
          throw HException("The given value for crop_percentage has to be in the range 1-100.");
        }
      }
      else
      {
        throw HException("The given value for crop_percentage has to be in the range 1-100.");
      }
    }
    else if (0 != (hv_CurrentParamName==HTuple(hv_CropPixel[0])))
    {
      //Set cropping with pixels.
      hv_CropPixel[1] = hv_CurrentParamValue;
      //Check if input value is greater 0.
      if (0 != (hv_CurrentParamValue.TupleIsNumber()))
      {
        if (0 != (hv_CurrentParamValue<1))
        {
          throw HException("The given value for crop_pixel has to be greater then or equal to 1.");
        }
      }
      else
      {
        throw HException("The given value for crop_pixel has to be a string.");
      }
    }
    else if (0 != (hv_CurrentParamName==HTuple(hv_BrightnessVariation[0])))
    {
      //Set brightness variation.
      hv_BrightnessVariation[1] = hv_CurrentParamValue;
      //Check if input value is in range of 0-255.
      if (0 != (hv_CurrentParamValue.TupleIsNumber()))
      {
        if (0 != (HTuple(hv_CurrentParamValue<0).TupleOr(hv_CurrentParamValue>255)))
        {
          throw HException("The given value for brightness_variation has to be in the range 0-255.");
        }
      }
      else
      {
        throw HException("The given value for brightness_variation has to be in the range 0-255.");
      }
    }
    else if (0 != (hv_CurrentParamName==HTuple(hv_BrightnessVariationSpot[0])))
    {
      //Set brightness variation of spot.
      hv_BrightnessVariationSpot[1] = hv_CurrentParamValue;
      //Check if input value is in range of 0-255.
      if (0 != (hv_CurrentParamValue.TupleIsNumber()))
      {
        if (0 != (HTuple(hv_CurrentParamValue<0).TupleOr(hv_CurrentParamValue>255)))
        {
          throw HException("The given value for brightness_variation_spot has to be in the range 0-255.");
        }
      }
      else
      {
        throw HException("The given value for brightness_variation_spot has to be in the range 0-255.");
      }
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //Aggregate all possible distortions and parameter values into a vector.
  //
  hvec_AvailableDistortions = HTupleVector(1);
  //Cropping percentage.
  if (0 != (HTuple(hv_CropPercentage[1]).TupleIsNumber()))
  {
    hvec_AvailableDistortions[HTuple(hvec_AvailableDistortions.Length())] = HTupleVector(hv_CropPercentage);
  }
  //Cropping pixel.
  if (0 != (HTuple(hv_CropPixel[1]).TupleIsNumber()))
  {
    hvec_AvailableDistortions[HTuple(hvec_AvailableDistortions.Length())] = HTupleVector(hv_CropPixel);
  }
  //Rotation with a given angular step size.
  if (0 != (HTuple(hv_Rotation[1])>0))
  {
    hvec_AvailableDistortions[HTuple(hvec_AvailableDistortions.Length())] = HTupleVector(hv_Rotation);
  }
  //Rotation within a given range (step size 1).
  if (0 != (HTuple(hv_RotationRange[1])>0))
  {
    hvec_AvailableDistortions[HTuple(hvec_AvailableDistortions.Length())] = HTupleVector(hv_RotationRange);
  }
  //Mirroring: in row and column direction are allowed.
  if (0 != (HTuple(HTuple(hv_Mirror[1]).TupleRegexpTest("r")).TupleOr(HTuple(hv_Mirror[1]).TupleRegexpTest("c"))))
  {
    hvec_AvailableDistortions[HTuple(hvec_AvailableDistortions.Length())] = HTupleVector(hv_Mirror);
  }
  //Brightness variation.
  if (0 != (HTuple(hv_BrightnessVariation[1])>0))
  {
    hvec_AvailableDistortions[HTuple(hvec_AvailableDistortions.Length())] = HTupleVector(hv_BrightnessVariation);
  }
  //Brightness variation spot.
  if (0 != (HTuple(hv_BrightnessVariationSpot[1])>0))
  {
    hvec_AvailableDistortions[HTuple(hvec_AvailableDistortions.Length())] = HTupleVector(hv_BrightnessVariationSpot);
  }
  //Check number of available distortions
  hv_NumAvailableDistortions = HTuple(hvec_AvailableDistortions.Length());
  if (0 != (hv_NumAvailableDistortions==0))
  {
    (*ho_ImagesAugmented) = ho_Images;
    return;
  }
  //
  //Randomly choose images and augmentation methods.
  //
  //Number of images to be augmented.
  CountObj(ho_Images, &hv_NumImages);
  if (0 != (hv_NumImages==0))
  {
    throw HException("There are no images to be processed.");
  }
  //Calculate how many images are to be augmented.
  hv_AugmentationRate = HTuple(hv_AugmentationPercentage[1])*0.01;
  hv_NumAugmentations = ((hv_AugmentationRate*hv_NumImages).TupleCeil()).TupleInt();
  //Select a random subset of images
  //that are to be augmented.
  tuple_shuffle(HTuple::TupleGenSequence(0,hv_NumImages-1,1), &hv_ImageIndices);
  hv_SelectedImages = hv_ImageIndices.TupleSelectRange(0,hv_NumAugmentations-1);
  //Select a random distortion method for each image.
  hv_SelectedDistortions = ((HTuple::TupleRand(hv_NumAugmentations)*hv_NumAvailableDistortions).TupleFloor()).TupleInt();
  //Fill up vector of distortions for all input images.
  hvec_Distortions = HTupleVector(1);
  hv_IndexDistortion = 0;
  {
  HTuple end_val181 = hv_NumImages-1;
  HTuple step_val181 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val181, step_val181); hv_Index += step_val181)
  {
    //Check if Index corresponds to a selected image.
    if (0 != (((hv_SelectedImages.TupleEqualElem(hv_Index)).TupleSum())>0))
    {
      //Add a distortion method.
      hvec_Distortions[hv_Index] = hvec_AvailableDistortions[HTuple(hv_SelectedDistortions[hv_IndexDistortion])];
      hv_IndexDistortion += 1;
    }
    else
    {
      //Image will not be distorted.
      hvec_Distortions[hv_Index] = HTupleVector((HTuple("none").Append(0)));
    }
  }
  }
  //
  //Augment (distort) the images.
  //
  //Generate output image array.
  GenEmptyObj(&(*ho_ImagesAugmented));
  //Loop over all images and apply distortions.
  {
  HTuple end_val198 = hv_NumImages-1;
  HTuple step_val198 = 1;
  for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val198, step_val198); hv_ImageIndex += step_val198)
  {
    //Get distortion method.
    hv_CurrentDistortion = hvec_Distortions[hv_ImageIndex].T();
    //Get image to be processed.
    SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex+1);
    GetImageSize(ho_ImageSelected, &hv_Width, &hv_Height);
    if (0 != (HTuple(hv_CurrentDistortion[0])==HTuple(hv_CropPercentage[0])))
    {
      //Cropping:
      //Define cropping rectangle.
      hv_CropRate = HTuple(hv_CurrentDistortion[1])*0.01;
      hv_Row1 = (((1-hv_CropRate)*hv_Height)*HTuple::TupleRand(1)).TupleFloor();
      hv_Row2 = hv_Row1+(hv_CropRate*hv_Height);
      hv_Column1 = (((1-hv_CropRate)*hv_Width)*HTuple::TupleRand(1)).TupleFloor();
      hv_Column2 = hv_Column1+(hv_CropRate*hv_Width);
      //Crop the image and add to output.
      CropRectangle1(ho_ImageSelected, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, 
          hv_Column2);
      ConcatObj((*ho_ImagesAugmented), ho_ImagePart, &(*ho_ImagesAugmented));
    }
    else if (0 != (HTuple(hv_CurrentDistortion[0])==HTuple(hv_CropPixel[0])))
    {
      //Cropping:
      //Define cropping rectangle.
      hv_Length = ((const HTuple&)hv_CurrentDistortion)[1];
      hv_Row1 = HTuple::TupleRand(1)*(hv_Height-hv_Length);
      hv_Row2 = (hv_Row1+hv_Length)-1;
      hv_Column1 = HTuple::TupleRand(1)*(hv_Width-hv_Length);
      hv_Column2 = (hv_Column1+hv_Length)-1;
      //Crop the image and add to output.
      CropRectangle1(ho_ImageSelected, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, 
          hv_Column2);
      ConcatObj((*ho_ImagesAugmented), ho_ImagePart, &(*ho_ImagesAugmented));
    }
    else if (0 != (HTuple(HTuple(hv_CurrentDistortion[0])==HTuple(hv_Rotation[0])).TupleOr(HTuple(hv_CurrentDistortion[0])==HTuple(hv_RotationRange[0]))))
    {
      //Rotation:
      if (0 != (HTuple(hv_CurrentDistortion[0])==HTuple(hv_Rotation[0])))
      {
        //Determine rotation angle for method 'rotate' (angle in range [0:CurrentDistortion[1]:360)).
        hv_RotationStep = ((const HTuple&)hv_CurrentDistortion)[1];
        hv_NumPossibleRotations = 360.0/hv_RotationStep;
        hv_CurrentRotation = hv_RotationStep*(((hv_NumPossibleRotations*HTuple::TupleRand(1)).TupleInt())+1);
      }
      else
      {
        //Determine rotation angle for method 'rotate_range' (angle in range [0:1:CurrentDistortion[1])).
        hv_RotationStep = 1;
        hv_NumPossibleRotations = ((const HTuple&)hv_CurrentDistortion)[1];
        hv_CurrentRotation = hv_RotationStep*(((hv_NumPossibleRotations*HTuple::TupleRand(1)).TupleInt())+1);
        //Select direction of rotation randomly.
        if (0 != ((HTuple::TupleRand(1).TupleRound())>0.5))
        {
          hv_CurrentRotation = 360.0-hv_CurrentRotation;
        }
      }
      if (0 != (HTuple((hv_CurrentRotation.TupleInt())==hv_CurrentRotation).TupleAnd(((hv_CurrentRotation.TupleInt())%90)==0)))
      {
        //Rotations around 90 degrees are faster with rotate_image
        RotateImage(ho_ImageSelected, &ho_ImagePart, hv_CurrentRotation.TupleInt(), 
            "constant");
      }
      else
      {
        //Create rotation matrix.
        HomMat2dIdentity(&hv_HomMat2DIdentity);
        HomMat2dRotate(hv_HomMat2DIdentity, hv_CurrentRotation.TupleRad(), hv_Height/2.0, 
            hv_Width/2.0, &hv_HomMat2DRotate);
        //Apply rotation.
        AffineTransImage(ho_ImageSelected, &ho_ImageRotated, hv_HomMat2DRotate, "constant", 
            "false");
        //Remove potential undefined domain.
        GetDomain(ho_ImageRotated, &ho_DomainRotated);
        InnerRectangle1(ho_DomainRotated, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
        CropRectangle1(ho_ImageRotated, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, 
            hv_Column2);
      }
      //Add the image to the output.
      ConcatObj((*ho_ImagesAugmented), ho_ImagePart, &(*ho_ImagesAugmented));
    }
    else if (0 != (HTuple(hv_CurrentDistortion[0])==HTuple(hv_Mirror[0])))
    {
      //Mirroring:
      //If more than one method is allowed, chose mirroring method(s) to be applied.
      hv_NumMirrorMethods = HTuple(hv_CurrentDistortion[1]).TupleStrlen();
      hv_PropabilityMethods = 1.0/hv_NumMirrorMethods;
      hv_StrMirror = "";
      while (0 != (hv_StrMirror==HTuple("")))
      {
        {
        HTuple end_val266 = hv_NumMirrorMethods-1;
        HTuple step_val266 = 1;
        for (hv_StrIdx=0; hv_StrIdx.Continue(end_val266, step_val266); hv_StrIdx += step_val266)
        {
          hv_SelectedChar = HTuple(hv_CurrentDistortion[1]).TupleStrBitSelect(hv_StrIdx);
          if (0 != (HTuple::TupleRand(1)<hv_PropabilityMethods))
          {
            hv_StrMirror += hv_SelectedChar;
          }
        }
        }
      }
      //Apply the chosen mirroring method(s).
      if (0 != (hv_StrMirror.TupleRegexpTest("c")))
      {
        MirrorImage(ho_ImageSelected, &ho_ImageSelected, "column");
      }
      if (0 != (hv_StrMirror.TupleRegexpTest("r")))
      {
        MirrorImage(ho_ImageSelected, &ho_ImageSelected, "row");
      }
      //Add the image to the output.
      ConcatObj((*ho_ImagesAugmented), ho_ImageSelected, &(*ho_ImagesAugmented));
    }
    else if (0 != (HTuple(hv_CurrentDistortion[0])==HTuple(hv_BrightnessVariation[0])))
    {
      //Brightness variation:
      //Add random brightness variation.
      hv_BrightnessVariationValue = ((HTuple::TupleRand(1)*2)-1)*HTuple(hv_CurrentDistortion[1]);
      ScaleImage(ho_ImageSelected, &ho_ImageScaled, 1.0, hv_BrightnessVariationValue);
      //Add the image to the output.
      ConcatObj((*ho_ImagesAugmented), ho_ImageScaled, &(*ho_ImagesAugmented));
    }
    else if (0 != (HTuple(hv_CurrentDistortion[0])==HTuple(hv_BrightnessVariationSpot[0])))
    {
      //Determine random brightness variation.
      hv_BrightnessVariationValue = ((HTuple::TupleRand(1)*2)-1)*HTuple(hv_CurrentDistortion[1]);
      //Determine random spot size between [0.5*Width, Width].
      hv_SpotSize = hv_Width*((HTuple::TupleRand(1)/2)+.5);
      //Determine random spot position.
      hv_SpotRow = HTuple::TupleRand(1)*hv_Height;
      hv_SpotColumn = HTuple::TupleRand(1)*hv_Width;
      apply_brightness_variation_spot(ho_ImageSelected, &ho_ImageSpot, hv_SpotSize, 
          hv_SpotRow, hv_SpotColumn, hv_BrightnessVariationValue);
      //Add the image to the output.
      ConcatObj((*ho_ImagesAugmented), ho_ImageSpot, &(*ho_ImagesAugmented));
    }
    else
    {
      //Add unchanged image to the output.
      ConcatObj((*ho_ImagesAugmented), ho_ImageSelected, &(*ho_ImagesAugmented));
    }
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate color intensity features. 
void calc_feature_color_intensity (HObject ho_Region, HObject ho_Image, HTuple hv_ColorSpace, 
    HTuple hv_Mode, HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_R, ho_G, ho_B, ho_I1, ho_I2, ho_I3;

  // Local control variables
  HTuple  hv_Channels, hv_Mean1, hv_Deviation1;
  HTuple  hv_Mean2, hv_Deviation2, hv_Mean3, hv_Deviation3;
  HTuple  hv_Tmp1, hv_Tmp2, hv_Tmp3, hv_NumRegions, hv_Index;

  //
  //Calculate color features
  //
  //Transform an RGB image into the given ColorSpace
  //and calculate the mean gray value and the deviation
  //for all three channels.
  //
  CountChannels(ho_Image, &hv_Channels);
  if (0 != (hv_Channels!=3))
  {
    throw HException(((("Error when calculating feature "+hv_ColorSpace)+"_")+hv_Mode).TupleConcat("Please use a 3-channel RGB image or remove color feature from the list."));
  }
  Decompose3(ho_Image, &ho_R, &ho_G, &ho_B);
  if (0 != (hv_ColorSpace==HTuple("rgb")))
  {
    Intensity(ho_Region, ho_R, &hv_Mean1, &hv_Deviation1);
    Intensity(ho_Region, ho_G, &hv_Mean2, &hv_Deviation2);
    Intensity(ho_Region, ho_B, &hv_Mean3, &hv_Deviation3);
  }
  else
  {
    TransFromRgb(ho_R, ho_G, ho_B, &ho_I1, &ho_I2, &ho_I3, hv_ColorSpace);
    Intensity(ho_Region, ho_I1, &hv_Mean1, &hv_Deviation1);
    Intensity(ho_Region, ho_I2, &hv_Mean2, &hv_Deviation2);
    Intensity(ho_Region, ho_I3, &hv_Mean3, &hv_Deviation3);
  }
  if (0 != (hv_Mode==HTuple("mean")))
  {
    hv_Tmp1 = hv_Mean1;
    hv_Tmp2 = hv_Mean2;
    hv_Tmp3 = hv_Mean3;
  }
  else if (0 != (hv_Mode==HTuple("deviation")))
  {
    hv_Tmp1 = hv_Deviation1;
    hv_Tmp2 = hv_Deviation2;
    hv_Tmp3 = hv_Deviation3;
  }
  CountObj(ho_Region, &hv_NumRegions);
  if (0 != (hv_NumRegions>0))
  {
    hv_Index = HTuple::TupleGenSequence(0,(3*hv_NumRegions)-1,3);
    (*hv_Feature)[hv_Index] = hv_Tmp1;
    (*hv_Feature)[1+hv_Index] = hv_Tmp2;
    (*hv_Feature)[2+hv_Index] = hv_Tmp3;
  }
  else
  {
    (*hv_Feature) = HTuple();
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate edge density. 
void calc_feature_edge_density (HObject ho_Region, HObject ho_Image, HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_RegionUnion, ho_ImageReduced, ho_EdgeAmplitude;

  // Local control variables
  HTuple  hv_Area, hv_Row, hv_Column, hv_Width;
  HTuple  hv_Height, hv_AreaGray, hv_ZeroIndex;

  //
  //Calculate the edge density, i.e.
  //the ratio of the edge amplitudes to the area of the region.
  //
  Union1(ho_Region, &ho_RegionUnion);
  ReduceDomain(ho_Image, ho_RegionUnion, &ho_ImageReduced);
  AreaCenter(ho_Region, &hv_Area, &hv_Row, &hv_Column);
  GetImageSize(ho_ImageReduced, &hv_Width, &hv_Height);
  if (0 != (HTuple(hv_Width>1).TupleAnd(hv_Height>1)))
  {
    SobelAmp(ho_ImageReduced, &ho_EdgeAmplitude, "sum_abs", 3);
    AreaCenterGray(ho_Region, ho_EdgeAmplitude, &hv_AreaGray, &hv_Row, &hv_Column);
    hv_ZeroIndex = hv_Area.TupleFind(0);
    if (0 != (hv_ZeroIndex!=-1))
    {
      hv_Area[hv_ZeroIndex] = 1;
      hv_AreaGray[hv_ZeroIndex] = 0;
    }
    (*hv_Feature) = hv_AreaGray/hv_Area;
  }
  else
  {
    (*hv_Feature) = HTuple(hv_Area.TupleLength(),0.0);
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate edge density histogram feature. 
void calc_feature_edge_density_histogram (HObject ho_Region, HObject ho_Image, HTuple hv_NumBins, 
    HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_Channel1, ho_EdgeAmplitude, ho_RegionSelected;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_NumRegions;
  HTuple  hv_J, hv_Area, hv_Row, hv_Column, hv_Histo, hv_BinSize;

  //
  //Calculate the edge density histogram, i.e.
  //the ratio of the edge amplitude histogram to the area of the region.
  //
  (*hv_Feature) = HTuple();
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  CountObj(ho_Region, &hv_NumRegions);
  if (0 != (HTuple(hv_ImageWidth>1).TupleAnd(hv_ImageHeight>1)))
  {
    AccessChannel(ho_Image, &ho_Channel1, 1);
    SobelAmp(ho_Channel1, &ho_EdgeAmplitude, "sum_abs", 3);
    {
    HTuple end_val10 = hv_NumRegions;
    HTuple step_val10 = 1;
    for (hv_J=1; hv_J.Continue(end_val10, step_val10); hv_J += step_val10)
    {
      SelectObj(ho_Region, &ho_RegionSelected, hv_J);
      AreaCenter(ho_RegionSelected, &hv_Area, &hv_Row, &hv_Column);
      if (0 != (hv_Area>0))
      {
        GrayHistoRange(ho_RegionSelected, ho_EdgeAmplitude, 0, 255, hv_NumBins, &hv_Histo, 
            &hv_BinSize);
        (*hv_Feature) = (*hv_Feature).TupleConcat((hv_Histo.TupleReal())/(hv_Histo.TupleSum()));
      }
      else
      {
        (*hv_Feature) = ((*hv_Feature).TupleConcat(1.0)).TupleConcat(HTuple(hv_NumBins-1,0.0));
      }
    }
    }
  }
  else
  {
    (*hv_Feature) = HTuple(hv_NumRegions*hv_NumBins,0.0);
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate the gradient direction histogram. 
void calc_feature_grad_dir_histo (HObject ho_Region, HObject ho_Image, HTuple hv_NumBins, 
    HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_Channel1, ho_RegionSelected, ho_ImageReduced;
  HObject  ho_EdgeAmplitude, ho_EdgeDirection;

  // Local control variables
  HTuple  hv_NumRegions, hv_Index, hv_Histo, hv_BinSize;
  HTuple  hv_Sum;

  //
  //Calculate gradient direction histogram
  //
  AccessChannel(ho_Image, &ho_Channel1, 1);
  CountObj(ho_Region, &hv_NumRegions);
  (*hv_Feature) = HTuple();
  {
  HTuple end_val6 = hv_NumRegions;
  HTuple step_val6 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val6, step_val6); hv_Index += step_val6)
  {
    SelectObj(ho_Region, &ho_RegionSelected, hv_Index);
    ReduceDomain(ho_Channel1, ho_RegionSelected, &ho_ImageReduced);
    SobelDir(ho_ImageReduced, &ho_EdgeAmplitude, &ho_EdgeDirection, "sum_abs_binomial", 
        3);
    GrayHistoRange(ho_RegionSelected, ho_EdgeDirection, 0, 179, hv_NumBins, &hv_Histo, 
        &hv_BinSize);
    hv_Sum = hv_Histo.TupleSum();
    if (0 != (hv_Sum!=0))
    {
      (*hv_Feature) = (*hv_Feature).TupleConcat((hv_Histo.TupleReal())/hv_Sum);
    }
    else
    {
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_Histo);
    }
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate gray-value projections and their histograms. 
void calc_feature_gray_proj (HObject ho_Region, HObject ho_Image, HTuple hv_Mode, 
    HTuple hv_Size, HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_RegionTmp, ho_RegionMoved, ho_ImageTmp;

  // Local control variables
  HTuple  hv_NumRegions, hv_Index, hv_RowsTmp, hv_ColumnsTmp;
  HTuple  hv_HorProjectionFilledUp, hv_VertProjectionFilledUp;
  HTuple  hv_Row1, hv_Column1, hv_Row2, hv_Column2, hv_ScaleHeight;
  HTuple  hv_ScaleWidth, hv_HorProjection, hv_VertProjection;
  HTuple  hv_HorProjectionFilledUpFront, hv_VertProjectionFilledUpFront;
  HTuple  hv_Histo, hv_BinSize;

  //
  //Calculate gray-value projections and their histograms
  //
  CountObj(ho_Region, &hv_NumRegions);
  (*hv_Feature) = HTuple();
  //
  {
  HTuple end_val6 = hv_NumRegions;
  HTuple step_val6 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val6, step_val6); hv_Index += step_val6)
  {
    SelectObj(ho_Region, &ho_RegionTmp, hv_Index);
    //Test empty region
    GetRegionPoints(ho_RegionTmp, &hv_RowsTmp, &hv_ColumnsTmp);
    if (0 != ((hv_RowsTmp.TupleLength())==0))
    {
      hv_HorProjectionFilledUp = HTuple(hv_Size,-1.0);
      hv_VertProjectionFilledUp = HTuple(hv_Size,-1.0);
    }
    else
    {
      //Zoom image and region to Size x Size pixels
      SmallestRectangle1(ho_RegionTmp, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      MoveRegion(ho_RegionTmp, &ho_RegionMoved, -hv_Row1, -hv_Column1);
      CropRectangle1(ho_Image, &ho_ImageTmp, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
      hv_ScaleHeight = (hv_Size.TupleReal())/((hv_Row2-hv_Row1)+1);
      hv_ScaleWidth = (hv_Size.TupleReal())/((hv_Column2-hv_Column1)+1);
      ZoomImageFactor(ho_ImageTmp, &ho_ImageTmp, hv_ScaleWidth, hv_ScaleHeight, "constant");
      ZoomRegion(ho_RegionMoved, &ho_RegionTmp, hv_ScaleWidth, hv_ScaleHeight);
      //Calculate gray value projection
      GrayProjections(ho_RegionTmp, ho_ImageTmp, "simple", &hv_HorProjection, &hv_VertProjection);
      //Fill up projection in case the zoomed region is smaller than
      //Size x Size pixels due to interpolation effects
      SmallestRectangle1(ho_RegionTmp, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_HorProjectionFilledUpFront.Clear();
      hv_HorProjectionFilledUpFront.Append(HTuple(HTuple(0).TupleMax2(hv_Row1),-1.0));
      hv_HorProjectionFilledUpFront.Append(hv_HorProjection);
      hv_HorProjectionFilledUp.Clear();
      hv_HorProjectionFilledUp.Append(hv_HorProjectionFilledUpFront);
      hv_HorProjectionFilledUp.Append(HTuple(hv_Size-(hv_HorProjectionFilledUpFront.TupleLength()),-1.0));
      hv_VertProjectionFilledUpFront.Clear();
      hv_VertProjectionFilledUpFront.Append(HTuple(HTuple(0).TupleMax2(hv_Column1),-1.0));
      hv_VertProjectionFilledUpFront.Append(hv_VertProjection);
      hv_VertProjectionFilledUp.Clear();
      hv_VertProjectionFilledUp.Append(hv_VertProjectionFilledUpFront);
      hv_VertProjectionFilledUp.Append(HTuple(hv_Size-(hv_VertProjectionFilledUpFront.TupleLength()),-1.0));
    }
    if (0 != (hv_Mode==HTuple("hor")))
    {
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_HorProjectionFilledUp);
    }
    else if (0 != (hv_Mode==HTuple("vert")))
    {
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_VertProjectionFilledUp);
    }
    else if (0 != (hv_Mode==HTuple("hor_histo")))
    {
      TupleHistoRange(hv_HorProjectionFilledUp, 0, 255, hv_Size, &hv_Histo, &hv_BinSize);
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_Histo);
    }
    else if (0 != (hv_Mode==HTuple("vert_histo")))
    {
      TupleHistoRange(hv_VertProjectionFilledUp, 0, 255, hv_Size, &hv_Histo, &hv_BinSize);
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_Histo);
    }
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate gray-value projections of polar-transformed image regions. 
void calc_feature_polar_gray_proj (HObject ho_Region, HObject ho_Image, HTuple hv_Mode, 
    HTuple hv_Width, HTuple hv_Height, HTuple *hv_Features)
{

  // Local iconic variables
  HObject  ho_RegionSelected, ho_PolarTransImage;
  HObject  ho_EdgeAmplitude, ho_ImageAbs;

  // Local control variables
  HTuple  hv_NumRegions, hv_Index, hv_Row, hv_Column;
  HTuple  hv_Radius, hv_HorProjection, hv_VertProjection;

  //
  //Calculate gray-value projections of
  //polar-transformed image regions.
  //
  CountObj(ho_Region, &hv_NumRegions);
  (*hv_Features) = HTuple();
  {
  HTuple end_val6 = hv_NumRegions;
  HTuple step_val6 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val6, step_val6); hv_Index += step_val6)
  {
    SelectObj(ho_Region, &ho_RegionSelected, hv_Index);
    SmallestCircle(ho_RegionSelected, &hv_Row, &hv_Column, &hv_Radius);
    PolarTransImageExt(ho_Image, &ho_PolarTransImage, hv_Row, hv_Column, 0, HTuple(360).TupleRad(), 
        0, (hv_Radius.TupleConcat(1)).TupleMax(), hv_Width, hv_Height, "bilinear");
    //
    if (0 != (hv_Mode==HTuple("hor_gray")))
    {
      GrayProjections(ho_PolarTransImage, ho_PolarTransImage, "simple", &hv_HorProjection, 
          &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_HorProjection);
    }
    else if (0 != (hv_Mode==HTuple("vert_gray")))
    {
      GrayProjections(ho_PolarTransImage, ho_PolarTransImage, "simple", &hv_HorProjection, 
          &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_VertProjection);
    }
    else if (0 != (hv_Mode==HTuple("hor_sobel_amp")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "sum_abs", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_HorProjection);
    }
    else if (0 != (hv_Mode==HTuple("vert_sobel_amp")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "sum_abs", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_VertProjection);
    }
    else if (0 != (hv_Mode==HTuple("hor_sobel_x")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "x_binomial", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_HorProjection);
    }
    else if (0 != (hv_Mode==HTuple("vert_sobel_x")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "x_binomial", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_VertProjection);
    }
    else if (0 != (hv_Mode==HTuple("hor_sobel_y")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "y_binomial", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_HorProjection);
    }
    else if (0 != (hv_Mode==HTuple("vert_sobel_y")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "y_binomial", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_VertProjection);
    }
    else
    {
      throw HException(("Unknown Mode: "+hv_Mode)+" in calc_feature_polar_proj");
    }
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate a feature on different image pyramid levels. 
void calc_feature_pyramid (HObject ho_Region, HObject ho_Image, HTuple hv_FeatureName, 
    HTuple hv_NumLevels, HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_ImageZoom, ho_RegionZoom;

  // Local control variables
  HTuple  hv_Zoom, hv_NumRegions, hv_I, hv_Features;
  HTuple  hv_FeatureLength, hv_Step, hv_Indices, hv_J, hv_Start;
  HTuple  hv_End;

  //
  //Calculate a feature for different pyramid levels
  //
  hv_Zoom = 0.5;
  (*hv_Feature) = HTuple();
  CountObj(ho_Region, &hv_NumRegions);
  if (0 != (hv_NumRegions>0))
  {
    {
    HTuple end_val7 = hv_NumLevels;
    HTuple step_val7 = 1;
    for (hv_I=1; hv_I.Continue(end_val7, step_val7); hv_I += step_val7)
    {
      if (0 != (hv_I>1))
      {
        ZoomImageFactor(ho_ImageZoom, &ho_ImageZoom, hv_Zoom, hv_Zoom, "constant");
        ZoomRegion(ho_RegionZoom, &ho_RegionZoom, hv_Zoom, hv_Zoom);
        calculate_features(ho_RegionZoom, ho_ImageZoom, hv_FeatureName, &hv_Features);
      }
      else
      {
        CopyObj(ho_Image, &ho_ImageZoom, 1, 1);
        CopyObj(ho_Region, &ho_RegionZoom, 1, hv_NumRegions);
        calculate_features(ho_RegionZoom, ho_ImageZoom, hv_FeatureName, &hv_Features);
        hv_FeatureLength = (hv_Features.TupleLength())/hv_NumRegions;
        hv_Step = hv_NumLevels*hv_FeatureLength;
      }
      hv_Indices = HTuple();
      {
      HTuple end_val20 = hv_NumRegions-1;
      HTuple step_val20 = 1;
      for (hv_J=0; hv_J.Continue(end_val20, step_val20); hv_J += step_val20)
      {
        hv_Start = (hv_J*hv_Step)+((hv_I-1)*hv_FeatureLength);
        hv_End = (hv_Start+hv_FeatureLength)-1;
        hv_Indices = hv_Indices.TupleConcat(HTuple::TupleGenSequence(hv_Start,hv_End,1));
      }
      }
      (*hv_Feature)[hv_Indices] = hv_Features;
    }
    }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate one or more features of a given image and/or region. 
void calculate_features (HObject ho_Region, HObject ho_Image, HTuple hv_FeatureNames, 
    HTuple *hv_Features)
{

  //
  //Calculate features given in FeatureNames
  //for the input regions in Region
  //(if needed supported by the underlying
  //gray-value or color image Image).
  //
  get_features(ho_Region, ho_Image, hv_FeatureNames, "calculate", &(*hv_Features));
  return;
}

// Chapter: Filters / Lines
// Short Description: Calculates the parameters Sigma, Low, and High for lines_gauss from the maximum width and the contrast of the lines to be extracted. 
void calculate_lines_gauss_parameters (HTuple hv_MaxLineWidth, HTuple hv_Contrast, 
    HTuple *hv_Sigma, HTuple *hv_Low, HTuple *hv_High)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ContrastHigh, hv_ContrastLow, hv_HalfWidth;
  HTuple  hv_Help;

  //Check control parameters
  if (0 != ((hv_MaxLineWidth.TupleLength())!=1))
  {
    throw HException("Wrong number of values of control parameter: 1");
  }
  if (0 != ((hv_MaxLineWidth.TupleIsNumber()).TupleNot()))
  {
    throw HException("Wrong type of control parameter: 1");
  }
  if (0 != (hv_MaxLineWidth<=0))
  {
    throw HException("Wrong value of control parameter: 1");
  }
  if (0 != (HTuple((hv_Contrast.TupleLength())!=1).TupleAnd((hv_Contrast.TupleLength())!=2)))
  {
    throw HException("Wrong number of values of control parameter: 2");
  }
  if (0 != (((hv_Contrast.TupleIsNumber()).TupleMin())==0))
  {
    throw HException("Wrong type of control parameter: 2");
  }
  //Set and check ContrastHigh
  hv_ContrastHigh = ((const HTuple&)hv_Contrast)[0];
  if (0 != (hv_ContrastHigh<0))
  {
    throw HException("Wrong value of control parameter: 2");
  }
  //Set or derive ContrastLow
  if (0 != ((hv_Contrast.TupleLength())==2))
  {
    hv_ContrastLow = ((const HTuple&)hv_Contrast)[1];
  }
  else
  {
    hv_ContrastLow = hv_ContrastHigh/3.0;
  }
  //Check ContrastLow
  if (0 != (hv_ContrastLow<0))
  {
    throw HException("Wrong value of control parameter: 2");
  }
  if (0 != (hv_ContrastLow>hv_ContrastHigh))
  {
    throw HException("Wrong value of control parameter: 2");
  }
  //
  //Calculate the parameters Sigma, Low, and High for lines_gauss
  if (0 != (hv_MaxLineWidth<(HTuple(3.0).TupleSqrt())))
  {
    //Note that LineWidthMax < sqrt(3.0) would result in a Sigma < 0.5,
    //which does not make any sense, because the corresponding smoothing
    //filter mask would be of size 1x1.
    //To avoid this, LineWidthMax is restricted to values greater or equal
    //to sqrt(3.0) and the contrast values are adapted to reflect the fact
    //that lines that are thinner than sqrt(3.0) pixels have a lower contrast
    //in the smoothed image (compared to lines that are sqrt(3.0) pixels wide).
    hv_ContrastLow = (hv_ContrastLow*hv_MaxLineWidth)/(HTuple(3.0).TupleSqrt());
    hv_ContrastHigh = (hv_ContrastHigh*hv_MaxLineWidth)/(HTuple(3.0).TupleSqrt());
    hv_MaxLineWidth = HTuple(3.0).TupleSqrt();
  }
  //Convert LineWidthMax and the given contrast values into the input parameters
  //Sigma, Low, and High required by lines_gauss
  hv_HalfWidth = hv_MaxLineWidth/2.0;
  (*hv_Sigma) = hv_HalfWidth/(HTuple(3.0).TupleSqrt());
  hv_Help = ((-2.0*hv_HalfWidth)/((HTuple(6.283185307178).TupleSqrt())*((*hv_Sigma).TuplePow(3.0))))*((-0.5*((hv_HalfWidth/(*hv_Sigma)).TuplePow(2.0))).TupleExp());
  (*hv_High) = (hv_ContrastHigh*hv_Help).TupleFabs();
  (*hv_Low) = (hv_ContrastLow*hv_Help).TupleFabs();
  return;
}

// Chapter: Transformations / Poses
// Short Description: Calculate the poses to grasp an object. 
void calculate_tool_in_base_robot_path_poses (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInModelRobotPathPoses, 
    HTuple hv_ModelInBasePose, HTuple hv_Poses, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_ToolInBaseRobotPathPoses)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation;
  HTuple  hv_ViewOfTransform, hv_Index1, hv_ToolInBaseRobotPathPose;

  //
  read_message_tuple(hv_Poses, "OrderOfTransform", &hv_OrderOfTransform);
  read_message_tuple(hv_Poses, "OrderOfRotation", &hv_OrderOfRotation);
  read_message_tuple(hv_Poses, "ViewOfTransform", &hv_ViewOfTransform);
  //
  {
  HTuple end_val5 = HTuple(hvec_ToolInModelRobotPathPoses.Length())-1;
  HTuple step_val5 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val5, step_val5); hv_Index1 += step_val5)
  {
    PoseCompose(hv_ModelInBasePose, hvec_ToolInModelRobotPathPoses[hv_Index1].T(), 
        &hv_ToolInBaseRobotPathPose);
    ConvertPoseType(hv_ToolInBaseRobotPathPose, hv_OrderOfTransform, hv_OrderOfRotation, 
        hv_ViewOfTransform, &hv_ToolInBaseRobotPathPose);
    (*hvec_ToolInBaseRobotPathPoses)[hv_Index1] = HTupleVector(hv_ToolInBaseRobotPathPose);
  }
  }
  return;
}

// Chapter: Calibration / Monocular
// Short Description: Calibrate a camera with a single image. 
void calibrate_camera_and_plane_single_image (HTuple hv_CalibObjectData)
{

  // Local iconic variables
  HObject  ho_ImageCaltab;

  // Local control variables
  HTuple  hv_CalPlateDescr, hv_CalPlateThickness;
  HTuple  hv_StartCamParam, hv_CalibDataID, hv_ErrorCamCalibInPixel;
  HTuple  hv_CamParam, hv_PlaneInCamPose0, hv_PlaneInCamPose;

  read_message_obj(&ho_ImageCaltab, hv_CalibObjectData, "ImageCaltab");
  read_message_tuple(hv_CalibObjectData, "CalPlateDescr", &hv_CalPlateDescr);
  read_message_tuple(hv_CalibObjectData, "CalPlateThickness", &hv_CalPlateThickness);
  read_message_tuple(hv_CalibObjectData, "StartCamParam", &hv_StartCamParam);
  //
  //Check input
  if (0 != (HTuple(hv_StartCamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //
  //Create a HALCON calibration data model.
  CreateCalibData("calibration_object", 1, 1, &hv_CalibDataID);
  //Set the needed calibration information.
  SetCalibDataCamParam(hv_CalibDataID, 0, HTuple(), hv_StartCamParam);
  SetCalibDataCalibObject(hv_CalibDataID, 0, hv_CalPlateDescr);
  //Find the calibration plate.
  FindCalibObject(ho_ImageCaltab, hv_CalibDataID, 0, 0, 0, HTuple(), HTuple());
  //Calibrating from only one view requires some parameter to be excluded
  //from the optimization.
  SetCalibData(hv_CalibDataID, "camera", 0, "excluded_settings", "focus");
  //Calibrate the camera.
  CalibrateCameras(hv_CalibDataID, &hv_ErrorCamCalibInPixel);
  //Get the calibration results.
  GetCalibData(hv_CalibDataID, "camera", 0, "params", &hv_CamParam);
  GetCalibData(hv_CalibDataID, "calib_obj_pose", (HTuple(0).Append(0)), "pose", &hv_PlaneInCamPose0);
  SetOriginPose(hv_PlaneInCamPose0, 0, 0, hv_CalPlateThickness, &hv_PlaneInCamPose);
  //Convert pose to standard pose type.
  ConvertPoseType(hv_PlaneInCamPose, "Rp+T", "gba", "point", &hv_PlaneInCamPose);
  //
  //Add data to output message.
  SetMessageTuple(hv_CalibObjectData, "ErrorCamCalibInPixel", hv_ErrorCamCalibInPixel);
  SetMessageTuple(hv_CalibObjectData, "CamParam", hv_CamParam);
  SetMessageTuple(hv_CalibObjectData, "PlaneInCamPose", hv_PlaneInCamPose);
  //Clean up.
  ClearCalibData(hv_CalibDataID);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTuple hv_RowsTouchingPointInPlane, HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_CalibObjectData, HTuple *hv_HandEyeCalibData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_CalPlateThickness, hv_PlaneInCamPose;
  HTuple  hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0;
  HTuple  hv_Index, hv_OrderOfTransform, hv_OrderOfRotation;
  HTuple  hv_ViewOfTransform, hv_TouchingPointInToolPose;
  HTuple  hv_XBase, hv_YBase, hv_ZBase, hv_TouchingPointInBasePose;
  HTuple  hv_XPlane, hv_YPlane, hv_ZPlane, hv_HomMat3DPlaneToBase;
  HTuple  hv_PlaneInBasePose, hv_BaseInPlanePose, hv_BaseInCamPose;
  HTuple  hv_XPlaneBase, hv_YPlaneBase, hv_ZPlaneBase, hv_DiffX;
  HTuple  hv_DiffY, hv_DiffZ, hv_SqrDiff, hv_PlanePointsRMS;
  HTuple  hv_PlanePointsMaxDiff;

  //
  read_message_tuple(hv_CalibObjectData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_CalibObjectData, "CalPlateThickness", &hv_CalPlateThickness);
  read_message_tuple(hv_CalibObjectData, "PlaneInCamPose", &hv_PlaneInCamPose);
  //
  //Check input
  if (0 != (HTuple(HTuple((hv_RowsTouchingPointInPlane.TupleLength())<3).TupleOr((hv_ColumnsTouchingPointInPlane.TupleLength())<3)).TupleOr(HTuple(hvec_ToolInBasePoses.Length())<3)))
  {
    throw HException("Please specify at least three image coordinates and robot poses.");
  }
  if (0 != (HTuple((hv_RowsTouchingPointInPlane.TupleLength())!=(hv_ColumnsTouchingPointInPlane.TupleLength())).TupleOr((hv_RowsTouchingPointInPlane.TupleLength())!=HTuple(hvec_ToolInBasePoses.Length()))))
  {
    throw HException("The number of image coordinates and robot poses have to be equal.");
  }
  if (0 != (HTuple(hv_CamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //
  //If points on top of the calibration plate are approached, we have to adapt the PlaneInCamPose accordingly.
  SetOriginPose(hv_PlaneInCamPose, 0, 0, -hv_CalPlateThickness, &hv_PlaneInCamPose);
  //Keep track of the pose type used by the robot.
  GetPoseType(hvec_ToolInBasePoses[0].T(), &hv_OrderOfTransform0, &hv_OrderOfRotation0, 
      &hv_ViewOfTransform0);
  {
  HTuple ExpTmpOutVar_0;
  ConvertPoseType(hvec_ToolInBasePoses[0].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
  hvec_ToolInBasePoses[0].T() = ExpTmpOutVar_0;
  }
  {
  HTuple end_val21 = HTuple(hvec_ToolInBasePoses.Length())-1;
  HTuple step_val21 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
  {
    GetPoseType(hvec_ToolInBasePoses[hv_Index].T(), &hv_OrderOfTransform, &hv_OrderOfRotation, 
        &hv_ViewOfTransform);
    if (0 != (HTuple(HTuple(hv_OrderOfTransform0!=hv_OrderOfTransform).TupleOr(hv_OrderOfRotation0!=hv_OrderOfRotation)).TupleOr(hv_ViewOfTransform0!=hv_ViewOfTransform)))
    {
      throw HException("ToolInBasePoses have different pose types.");
    }
    //Convert to default pose type.
    {
    HTuple ExpTmpOutVar_0;
    ConvertPoseType(hvec_ToolInBasePoses[hv_Index].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
    hvec_ToolInBasePoses[hv_Index].T() = ExpTmpOutVar_0;
    }
  }
  }
  //
  //Collect the robot translations.
  CreatePose(HTuple(hv_RobotTouchingPointInToolCoordinates[0]), HTuple(hv_RobotTouchingPointInToolCoordinates[1]), 
      HTuple(hv_RobotTouchingPointInToolCoordinates[2]), 0, 0, 0, "Rp+T", "gba", 
      "point", &hv_TouchingPointInToolPose);
  hv_XBase = HTuple();
  hv_YBase = HTuple();
  hv_ZBase = HTuple();
  {
  HTuple end_val35 = (hv_RowsTouchingPointInPlane.TupleLength())-1;
  HTuple step_val35 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val35, step_val35); hv_Index += step_val35)
  {
    PoseCompose(hvec_ToolInBasePoses[hv_Index].T(), hv_TouchingPointInToolPose, &hv_TouchingPointInBasePose);
    hv_XBase = hv_XBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[0]));
    hv_YBase = hv_YBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[1]));
    hv_ZBase = hv_ZBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[2]));
  }
  }
  //
  //Get the plane coordinates of the input image points.
  ImagePointsToWorldPlane(hv_CamParam, hv_PlaneInCamPose, hv_RowsTouchingPointInPlane, 
      hv_ColumnsTouchingPointInPlane, "m", &hv_XPlane, &hv_YPlane);
  TupleGenConst(hv_XPlane.TupleLength(), 0, &hv_ZPlane);
  VectorToHomMat3d("rigid", hv_XPlane, hv_YPlane, hv_ZPlane, hv_XBase, hv_YBase, 
      hv_ZBase, &hv_HomMat3DPlaneToBase);
  HomMat3dToPose(hv_HomMat3DPlaneToBase, &hv_PlaneInBasePose);
  //If points on top of the calibration plate are approached, we have to readapt the Plane accordingly.
  SetOriginPose(hv_PlaneInCamPose, 0, 0, hv_CalPlateThickness, &hv_PlaneInCamPose);
  SetOriginPose(hv_PlaneInBasePose, 0, 0, hv_CalPlateThickness, &hv_PlaneInBasePose);
  PoseInvert(hv_PlaneInBasePose, &hv_BaseInPlanePose);
  PoseCompose(hv_PlaneInCamPose, hv_BaseInPlanePose, &hv_BaseInCamPose);
  //
  //Get the BaseInCamPose.
  PoseInvert(hv_PlaneInBasePose, &hv_BaseInPlanePose);
  PoseCompose(hv_PlaneInCamPose, hv_BaseInPlanePose, &hv_BaseInCamPose);
  //Convert to output pose type.
  ConvertPoseType(hv_BaseInCamPose, hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0, 
      &hv_BaseInCamPose);
  ConvertPoseType(hv_PlaneInBasePose, hv_OrderOfTransform0, hv_OrderOfRotation0, 
      hv_ViewOfTransform0, &hv_PlaneInBasePose);

  //Get the difference of the points in the plane as seen by the camera
  //to the points in the plane as approached by the robot.
  AffineTransPoint3d(hv_HomMat3DPlaneToBase, hv_XPlane, hv_YPlane, hv_ZPlane, &hv_XPlaneBase, 
      &hv_YPlaneBase, &hv_ZPlaneBase);
  hv_DiffX = hv_XPlaneBase-hv_XBase;
  hv_DiffY = hv_YPlaneBase-hv_YBase;
  hv_DiffZ = hv_ZPlaneBase-hv_ZBase;
  hv_SqrDiff = ((hv_DiffX*hv_DiffX)+(hv_DiffY*hv_DiffY))+(hv_DiffZ*hv_DiffZ);
  hv_PlanePointsRMS = ((hv_SqrDiff.TupleSum())/(hv_DiffX.TupleLength())).TupleSqrt();
  hv_PlanePointsMaxDiff = (hv_SqrDiff.TupleSqrt()).TupleMax();
  //
  //Create output message.
  CreateMessage(&(*hv_HandEyeCalibData));
  SetMessageTuple((*hv_HandEyeCalibData), "CamParam", hv_CamParam);
  SetMessageTuple((*hv_HandEyeCalibData), "BaseInCamPose", hv_BaseInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInBasePose", hv_PlaneInBasePose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInCamPose0", hv_PlaneInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsRMS", hv_PlanePointsRMS);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsMaxDiff", hv_PlanePointsMaxDiff);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx_without_calib_plate (HTuple hv_RowsTouchingPointInPlane, 
    HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple hv_DistanceObjectTouchingPointToPlane, 
    HTuple hv_DistancePlaneToCamera, HTuple hv_Width, HTuple hv_Height, HTuple *hv_HandEyeCalibData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OrderOfTransform0, hv_OrderOfRotation0;
  HTuple  hv_ViewOfTransform0, hv_Index, hv_OrderOfTransform;
  HTuple  hv_OrderOfRotation, hv_ViewOfTransform, hv_RobotTouchingPointToToolXYZPose;
  HTuple  hv_XBase, hv_YBase, hv_ZBase, hv_TouchingPointInBasePose;
  HTuple  hv_OM3DPlanePoints, hv_OM3DPlane, hv_TouchingPointPlaneInBasePose;
  HTuple  hv_FocusOrig, hv_DiffRow, hv_DiffCol, hv_DistPixel;
  HTuple  hv_DiffX, hv_DiffY, hv_DiffZ, hv_DistWorld, hv_Quotient;
  HTuple  hv_SX, hv_SY, hv_FocusShift, hv_BestIndex, hv_ErrorBasePoseInPixel;
  HTuple  hv_NumFocus, hv_Focus, hv_CamParam0, hv_BaseInCamPose0;
  HTuple  hv_ErrorBasePoseInPixelTmp, hv_BaseInCamPose, hv_CamParam;
  HTuple  hv_TouchingPointPlaneInCamPose, hv_TouchingPointPlaneInCamPose0Rot;
  HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_CosAngleBetweenZAxis;
  HTuple  hv_SwitchZDirection, hv_TouchingPointPlaneInCamPose1;
  HTuple  hv_CamInBasePose, hv_TouchingPointPlanePointsCamX;
  HTuple  hv_TouchingPointPlanePointsCamY, hv_TouchingPointPlanePointsCamZ;
  HTuple  hv_BaseInTouchingPointPlanePose, hv_HomMat3D1, hv_TouchingPointPlanePointsToolX;
  HTuple  hv_TouchingPointPlanePointsToolY, hv_TouchingPointPlanePointsToolZ;
  HTuple  hv_SqrDiff, hv_PlanePointsRMS, hv_PlanePointsMaxDiff;
  HTuple  hv_PlaneInBasePose, hv_PlaneInCamPose;

  //Check input.
  if (0 != (HTuple(HTuple((hv_RowsTouchingPointInPlane.TupleLength())<4).TupleOr((hv_ColumnsTouchingPointInPlane.TupleLength())<4)).TupleOr(HTuple(hvec_ToolInBasePoses.Length())<4)))
  {
    throw HException("Please specify at least four image coordinates and robot poses.");
  }
  if (0 != (HTuple((hv_RowsTouchingPointInPlane.TupleLength())!=(hv_ColumnsTouchingPointInPlane.TupleLength())).TupleOr((hv_RowsTouchingPointInPlane.TupleLength())!=HTuple(hvec_ToolInBasePoses.Length()))))
  {
    throw HException("The number of image coordinates and robot poses have to be equal.");
  }
  if (0 != (HTuple(hv_Width<=0).TupleOr(hv_Height<=0)))
  {
    throw HException("Width or Height must be greater than 0.");
  }
  if (0 != (hv_DistancePlaneToCamera<=0))
  {
    throw HException("DistancePlaneToCamera must be greater than 0.");
  }
  if (0 != (hv_DistancePlaneToCamera<=0))
  {
    throw HException("DistanceObjectTouchingPointToPlane must be greater than 0.");
  }
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hvec_ToolInBasePoses[0].T(), &hv_OrderOfTransform0, &hv_OrderOfRotation0, 
      &hv_ViewOfTransform0);
  {
  HTuple ExpTmpOutVar_0;
  ConvertPoseType(hvec_ToolInBasePoses[0].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
  hvec_ToolInBasePoses[0].T() = ExpTmpOutVar_0;
  }
  {
  HTuple end_val20 = HTuple(hvec_ToolInBasePoses.Length())-1;
  HTuple step_val20 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val20, step_val20); hv_Index += step_val20)
  {
    GetPoseType(hvec_ToolInBasePoses[hv_Index].T(), &hv_OrderOfTransform, &hv_OrderOfRotation, 
        &hv_ViewOfTransform);
    if (0 != (HTuple(HTuple(hv_OrderOfTransform0!=hv_OrderOfTransform).TupleOr(hv_OrderOfRotation0!=hv_OrderOfRotation)).TupleOr(hv_ViewOfTransform0!=hv_ViewOfTransform)))
    {
      throw HException("ToolInBasePoses have different pose types.");
    }
    //Convert to default pose type.
    {
    HTuple ExpTmpOutVar_0;
    ConvertPoseType(hvec_ToolInBasePoses[hv_Index].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
    hvec_ToolInBasePoses[hv_Index].T() = ExpTmpOutVar_0;
    }
  }
  }
  //
  //Collect the robot translations.
  CreatePose(HTuple(hv_RobotTouchingPointInToolCoordinates[0]), HTuple(hv_RobotTouchingPointInToolCoordinates[1]), 
      HTuple(hv_RobotTouchingPointInToolCoordinates[2]), 0, 0, 0, "Rp+T", "gba", 
      "point", &hv_RobotTouchingPointToToolXYZPose);
  hv_XBase = HTuple();
  hv_YBase = HTuple();
  hv_ZBase = HTuple();
  {
  HTuple end_val34 = (hv_RowsTouchingPointInPlane.TupleLength())-1;
  HTuple step_val34 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val34, step_val34); hv_Index += step_val34)
  {
    PoseCompose(hvec_ToolInBasePoses[hv_Index].T(), hv_RobotTouchingPointToToolXYZPose, 
        &hv_TouchingPointInBasePose);
    hv_XBase = hv_XBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[0]));
    hv_YBase = hv_YBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[1]));
    hv_ZBase = hv_ZBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[2]));
  }
  }
  //
  // Use the specified robot translations to obtain the PlaneInBasePose.
  GenObjectModel3dFromPoints(hv_XBase, hv_YBase, hv_ZBase, &hv_OM3DPlanePoints);
  FitPrimitivesObjectModel3d(hv_OM3DPlanePoints, "primitive_type", "plane", &hv_OM3DPlane);
  GetObjectModel3dParams(hv_OM3DPlane, "primitive_pose", &hv_TouchingPointPlaneInBasePose);
  //
  //Obtain fictitious camera parameters.
  hv_FocusOrig = 0.008;
  hv_DiffRow = (hv_RowsTouchingPointInPlane.TupleSelectRange(0,(hv_RowsTouchingPointInPlane.TupleLength())-2))-(hv_RowsTouchingPointInPlane.TupleSelectRange(1,(hv_RowsTouchingPointInPlane.TupleLength())-1));
  hv_DiffCol = (hv_ColumnsTouchingPointInPlane.TupleSelectRange(0,(hv_ColumnsTouchingPointInPlane.TupleLength())-2))-(hv_ColumnsTouchingPointInPlane.TupleSelectRange(1,(hv_ColumnsTouchingPointInPlane.TupleLength())-1));
  hv_DistPixel = ((hv_DiffRow*hv_DiffRow)+(hv_DiffCol*hv_DiffCol)).TupleSqrt();
  hv_DiffX = (hv_XBase.TupleSelectRange(0,(hv_XBase.TupleLength())-2))-(hv_XBase.TupleSelectRange(1,(hv_XBase.TupleLength())-1));
  hv_DiffY = (hv_YBase.TupleSelectRange(0,(hv_YBase.TupleLength())-2))-(hv_YBase.TupleSelectRange(1,(hv_YBase.TupleLength())-1));
  hv_DiffZ = (hv_ZBase.TupleSelectRange(0,(hv_ZBase.TupleLength())-2))-(hv_ZBase.TupleSelectRange(1,(hv_ZBase.TupleLength())-1));
  hv_DistWorld = (((hv_DiffX*hv_DiffX)+(hv_DiffY*hv_DiffY))+(hv_DiffZ*hv_DiffZ)).TupleSqrt();
  hv_Quotient = (hv_DistWorld/hv_DistPixel).TupleMedian();
  //Camera parameter will be generated in the following form:
  //SX := Quotient * FocusOrig / DistancePlaneToCamera
  //SY := SX
  //gen_cam_par_area_scan_division (FocusOrig, 0, SX, SY, Width / 2.0, Height / 2.0, Width, Height, HandEyeCalibData)
  //
  //Use the specified image points and robot translations to obtain the BaseInCamPose.
  hv_FocusShift.Clear();
  hv_FocusShift[0] = 0.1;
  hv_FocusShift[1] = 0.2;
  hv_FocusShift[2] = 0.33;
  hv_FocusShift[3] = 0.5;
  hv_FocusShift[4] = 0.75;
  hv_FocusShift[5] = 1.0;
  hv_FocusShift[6] = 1.5;
  hv_FocusShift[7] = 2;
  hv_FocusShift[8] = 3;
  hv_FocusShift[9] = 3.125;
  hv_FocusShift[10] = 3.5;
  hv_FocusShift[11] = 4;
  hv_BestIndex = -1;
  //The value of focus should not have much influence when camera and plane are parallel,
  //but just in case, check different values.
  hv_ErrorBasePoseInPixel = 1e9;
  {
  HTuple end_val67 = (hv_FocusShift.TupleLength())-1;
  HTuple step_val67 = 1;
  for (hv_NumFocus=0; hv_NumFocus.Continue(end_val67, step_val67); hv_NumFocus += step_val67)
  {
    hv_Focus = hv_FocusOrig*HTuple(hv_FocusShift[hv_NumFocus]);
    hv_SX = (hv_Quotient*hv_Focus)/hv_DistancePlaneToCamera;
    hv_SY = hv_SX;
    gen_cam_par_area_scan_division(hv_Focus, 0, hv_SX, hv_SY, hv_Width/2.0, hv_Height/2.0, 
        hv_Width, hv_Height, &hv_CamParam0);
    VectorToPose(hv_XBase, hv_YBase, hv_ZBase, hv_RowsTouchingPointInPlane, hv_ColumnsTouchingPointInPlane, 
        hv_CamParam0, "iterative", "error", &hv_BaseInCamPose0, &hv_ErrorBasePoseInPixelTmp);
    if (0 != (hv_ErrorBasePoseInPixel>hv_ErrorBasePoseInPixelTmp))
    {
      hv_BaseInCamPose = hv_BaseInCamPose0;
      hv_ErrorBasePoseInPixel = hv_ErrorBasePoseInPixelTmp;
      hv_CamParam = hv_CamParam0;
    }
  }
  }
  //Get the PlaneInCamPose.
  PoseCompose(hv_BaseInCamPose, hv_TouchingPointPlaneInBasePose, &hv_TouchingPointPlaneInCamPose);
  //
  //The z-axis of the plane should point away from the camera.
  hv_TouchingPointPlaneInCamPose0Rot = hv_TouchingPointPlaneInCamPose;
  hv_TouchingPointPlaneInCamPose0Rot[HTuple::TupleGenSequence(0,2,1)] = ((HTuple(0).Append(0)).Append(0));
  PoseToHomMat3d(hv_TouchingPointPlaneInCamPose0Rot, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 1, &hv_Qx, &hv_Qy, &hv_CosAngleBetweenZAxis);
  if (0 != (hv_CosAngleBetweenZAxis<0))
  {
    CreatePose(0, 0, 0, 180, 0, 0, "Rp+T", "gba", "point", &hv_SwitchZDirection);
    PoseCompose(hv_TouchingPointPlaneInCamPose, hv_SwitchZDirection, &hv_TouchingPointPlaneInCamPose1);
    hv_TouchingPointPlaneInCamPose = hv_TouchingPointPlaneInCamPose1;
    PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
    PoseCompose(hv_CamInBasePose, hv_TouchingPointPlaneInCamPose, &hv_TouchingPointPlaneInBasePose);
  }
  //
  //Get the difference of the points in the plane as seen by the camera
  //to the points in the plane as approached by the robot.
  ImagePointsToWorldPlane(hv_CamParam, hv_TouchingPointPlaneInCamPose, hv_RowsTouchingPointInPlane, 
      hv_ColumnsTouchingPointInPlane, "m", &hv_TouchingPointPlanePointsCamX, &hv_TouchingPointPlanePointsCamY);
  TupleGenConst(hv_TouchingPointPlanePointsCamY.TupleLength(), 0.0, &hv_TouchingPointPlanePointsCamZ);
  PoseInvert(hv_TouchingPointPlaneInBasePose, &hv_BaseInTouchingPointPlanePose);
  PoseToHomMat3d(hv_BaseInTouchingPointPlanePose, &hv_HomMat3D1);
  AffineTransPoint3d(hv_HomMat3D1, hv_XBase, hv_YBase, hv_ZBase, &hv_TouchingPointPlanePointsToolX, 
      &hv_TouchingPointPlanePointsToolY, &hv_TouchingPointPlanePointsToolZ);
  hv_DiffX = hv_TouchingPointPlanePointsCamX-hv_TouchingPointPlanePointsToolX;
  hv_DiffY = hv_TouchingPointPlanePointsCamY-hv_TouchingPointPlanePointsToolY;
  hv_DiffZ = hv_TouchingPointPlanePointsCamZ-hv_TouchingPointPlanePointsToolZ;
  hv_SqrDiff = ((hv_DiffX*hv_DiffX)+(hv_DiffY*hv_DiffY))+(hv_DiffZ*hv_DiffZ);
  hv_PlanePointsRMS = ((hv_SqrDiff.TupleSum())/(hv_DiffX.TupleLength())).TupleSqrt();
  hv_PlanePointsMaxDiff = (hv_SqrDiff.TupleSqrt()).TupleMax();
  //
  SetOriginPose(hv_TouchingPointPlaneInBasePose, 0, 0, hv_DistanceObjectTouchingPointToPlane, 
      &hv_PlaneInBasePose);
  SetOriginPose(hv_TouchingPointPlaneInCamPose, 0, 0, hv_DistanceObjectTouchingPointToPlane, 
      &hv_PlaneInCamPose);
  //
  //Convert to output pose type.
  ConvertPoseType(hv_BaseInCamPose, hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0, 
      &hv_BaseInCamPose);
  ConvertPoseType(hv_PlaneInBasePose, hv_OrderOfTransform0, hv_OrderOfRotation0, 
      hv_ViewOfTransform0, &hv_PlaneInBasePose);
  ConvertPoseType(hv_PlaneInCamPose, hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0, 
      &hv_PlaneInCamPose);
  //
  //Create output message.
  CreateMessage(&(*hv_HandEyeCalibData));
  SetMessageTuple((*hv_HandEyeCalibData), "CamParam", hv_CamParam);
  SetMessageTuple((*hv_HandEyeCalibData), "BaseInCamPose", hv_BaseInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInBasePose", hv_PlaneInBasePose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInCamPose0", hv_PlaneInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsRMS", hv_PlanePointsRMS);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsMaxDiff", hv_PlanePointsMaxDiff);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Calibrate the X, Y, Z coordinates of a touching point of a robot. 
void calibrate_robot_touching_point (HTuple hv_DataDir, HTuple *hv_RobotTouchingPointInToolCoordinates)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WindowHandle, hv_WindowHandleGraphics;
  HTuple  hv_Index, hv_ToolInBasePoseTouchingPoint;
  HTupleVector  hvec_ToolInBasePosesTouchingPoint(1);

  //
  //Open a new window.
  open_new_window(&hv_WindowHandle, &hv_WindowHandleGraphics);
  //Display introduction.
  dev_disp_introduction(hv_WindowHandle, hv_WindowHandleGraphics);
  // stop(...); only in hdevelop
  //
  //Read three ToolInBasesPoses which are used
  //to calibrate the RobotTouchingPointInToolCoordinates.
  for (hv_Index=1; hv_Index<=3; hv_Index+=1)
  {
    ReadPose(((hv_DataDir+"tool_in_base_pose_touching_point_0")+hv_Index)+".dat", 
        &hv_ToolInBasePoseTouchingPoint);
    dev_disp_approach_pose_touching_point_instructions(hv_WindowHandle, hv_WindowHandleGraphics, 
        hv_Index);
    // stop(...); only in hdevelop
    //Collect poses in vector.
    hvec_ToolInBasePosesTouchingPoint[hv_Index-1] = HTupleVector(hv_ToolInBasePoseTouchingPoint);
  }
  HDevWindowStack::SetActive(hv_WindowHandleGraphics);
  if (HDevWindowStack::IsOpen())
    CloseWindow(HDevWindowStack::Pop());
  //
  //Calculate the coordinates of the touching point
  //of the robot with respect to the robot's tool.
  get_robot_touching_point_in_tool_coordinates(hvec_ToolInBasePosesTouchingPoint, 
      &(*hv_RobotTouchingPointInToolCoordinates));
  //
  //Visualize results.
  visualize_calibrated_touching_point((*hv_RobotTouchingPointInToolCoordinates), 
      hvec_ToolInBasePosesTouchingPoint, hv_WindowHandle);
  return;
}

void check_find_surface_model_params (HTuple hv_WindowHandle, HTuple hv_SurfaceModel, 
    HTuple hv_ObjectModel3DScene, HTuple hv_GenParamNames, HTuple hv_GenParamValues)
{

  // Local iconic variables
  HObject  ho_X, ho_Y, ho_Z;

  // Local control variables
  HTuple  hv_DiameterModel, hv_Exception, hv_NumScenePoints;
  HTuple  hv_HasTriangles, hv_HasPolygons, hv_HasMapping;
  HTuple  hv_HasPointNormals, hv_NumPointsScene, hv_PX, hv_PY;
  HTuple  hv_PZ, hv_BBox, hv_DiameterScene, hv_CenterScene;
  HTuple  hv_EdgesTrained, hv_CenterModel, hv_HasCamPar, hv_CamPar;
  HTuple  hv_SizesOK, hv_IsNaN, hv_LargeNum, hv_Inf, hv_IsInf;
  HTuple  hv_DistThreshold, hv_NumNeighbors, hv_MaxNumNeighbors;
  HTuple  hv_Pos, hv_MedianDensity, hv_NormalsGood, hv_MLSNormals;
  HTuple  hv_NormalPos, hv_CheckNormals, hv_NX, hv_NY, hv_NZ;
  HTuple  hv_Length, hv_LengthOne, hv_LengthNotOne, hv_Rows;
  HTuple  hv_Cols, hv_MappingAsString, hv_CenterFromOrigin;
  HTuple  hv_CenterToDiameter, hv_NumSparsePoints, hv_MedianDirectionX;
  HTuple  hv_MedianDirectionXNorm, hv_MedianDirectionY, hv_MedianDirectionYNorm;
  HTuple  hv_ErrorX, hv_ErrorY, hv_DistanceOriginRel, hv_OM3D3DEdges;
  HTuple  hv_ViewpointString, hv_Viewpoint, hv_ViewpointToCenter;
  HTuple  hv_ZSigmaAbs, hv_ZSigmaRel, hv_ZSigmaPct;

  write_note(hv_WindowHandle, "none", "Checking parameters for find_surface_model[_image]...");
  NewLine(hv_WindowHandle);

  //*****************************************************************
  //Basic Parameter Checks
  //*****************************************************************
  if (0 != (HTuple((hv_SurfaceModel.TupleLength())!=1).TupleOr((hv_ObjectModel3DScene.TupleLength())!=1)))
  {
    write_note(hv_WindowHandle, "error", "Invalid number of surface model or scenes");
  }
  else
  {
    try
    {
      GetSurfaceModelParam(hv_SurfaceModel, "diameter", &hv_DiameterModel);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      write_note(hv_WindowHandle, "error", "Invalid surface model (nor a valid surface model handle)");
    }
    try
    {
      GetObjectModel3dParams(hv_ObjectModel3DScene, "num_points", &hv_NumScenePoints);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      write_note(hv_WindowHandle, "error", "Invalid scene (not a valid 3D object model handle)");
    }
    write_note(hv_WindowHandle, "ok", "Semantic types of parameters are OK");
  }

  if (0 != (hv_NumScenePoints<20))
  {
    write_note(hv_WindowHandle, "warning", (("The scene contains only "+hv_NumScenePoints)+" point(s). ")+"Some tests might be disabled.");
  }
  else
  {
    write_note(hv_WindowHandle, "ok", ("Number of scene points OK (Total number: "+hv_NumScenePoints)+")");
  }


  GetObjectModel3dParams(hv_ObjectModel3DScene, "has_triangles", &hv_HasTriangles);
  GetObjectModel3dParams(hv_ObjectModel3DScene, "has_polygons", &hv_HasPolygons);
  GetObjectModel3dParams(hv_ObjectModel3DScene, "has_xyz_mapping", &hv_HasMapping);
  GetObjectModel3dParams(hv_ObjectModel3DScene, "has_point_normals", &hv_HasPointNormals);
  GetObjectModel3dParams(hv_ObjectModel3DScene, "num_points", &hv_NumPointsScene);
  try
  {
    GetObjectModel3dParams(hv_ObjectModel3DScene, "point_coord_x", &hv_PX);
    GetObjectModel3dParams(hv_ObjectModel3DScene, "point_coord_y", &hv_PY);
    GetObjectModel3dParams(hv_ObjectModel3DScene, "point_coord_z", &hv_PZ);
    GetObjectModel3dParams(hv_ObjectModel3DScene, "bounding_box1", &hv_BBox);
    GetObjectModel3dParams(hv_ObjectModel3DScene, "diameter", &hv_DiameterScene);
    GetObjectModel3dParams(hv_ObjectModel3DScene, "center", &hv_CenterScene);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    //No points
    hv_PX = HTuple();
    hv_PY = HTuple();
    hv_PZ = HTuple();
    hv_BBox.Clear();
    hv_BBox[0] = 0;
    hv_BBox[1] = 0;
    hv_BBox[2] = 0;
    hv_BBox[3] = 0;
    hv_BBox[4] = 0;
    hv_BBox[5] = 0;
    hv_DiameterScene = 0;
    hv_CenterScene.Clear();
    hv_CenterScene[0] = 0;
    hv_CenterScene[1] = 0;
    hv_CenterScene[2] = 0;
  }

  GetSurfaceModelParam(hv_SurfaceModel, "3d_edges_trained", &hv_EdgesTrained);
  GetSurfaceModelParam(hv_SurfaceModel, "center", &hv_CenterModel);

  hv_HasCamPar = 0;
  try
  {
    GetSurfaceModelParam(hv_SurfaceModel, "camera_parameter", &hv_CamPar);
    hv_HasCamPar = 1;
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }

  if (0 != hv_HasCamPar)
  {
    write_note(hv_WindowHandle, "warning", HTuple("find_surface_model_images was used. Note that the parameters for image-based refinement (camera parameters, camera pose) are not checked by this version of the procedure."));
  }


  //*****************************************************************
  //Diameters
  //*****************************************************************
  hv_SizesOK = 1;
  GetSurfaceModelParam(hv_SurfaceModel, "diameter", &hv_DiameterModel);

  if (0 != (hv_DiameterScene<(0.3*hv_DiameterModel)))
  {
    write_note(hv_WindowHandle, "warning", "The diameter of the scene is very small (<30 % of model diameter)");
    hv_SizesOK = 0;
  }
  if (0 != ((hv_DiameterModel*30)<hv_DiameterScene))
  {
    write_note(hv_WindowHandle, "warning", "The diameter of the scene is very large (more than 30 times the model diameter)");
    hv_SizesOK = 0;
  }
  if (0 != hv_SizesOK)
  {
    write_note(hv_WindowHandle, "ok", "Scene and model diameters seem to match");
  }


  //*****************************************************************
  //Check for NaN, INF in the 3D data
  //*****************************************************************
  if (0 != (hv_NumScenePoints>0))
  {
    //NaNs are the only "numbers" that are not equal to themself
    hv_IsNaN = HTuple((hv_PX.TupleNotEqualElem(hv_PX)).TupleOr(hv_PY.TupleNotEqualElem(hv_PY))).TupleOr(hv_PZ.TupleNotEqualElem(hv_PZ));
    //Inf is created by multiplying a large number a few times.
    //We cannot directly create it (with, for example, 1e500), since that
    //does not work in all language exports.
    hv_LargeNum = 1e50;
    TupleMult(hv_LargeNum, hv_LargeNum, &hv_LargeNum);
    TupleMult(hv_LargeNum, hv_LargeNum, &hv_LargeNum);
    TupleMult(hv_LargeNum, hv_LargeNum, &hv_Inf);
    hv_IsInf = HTuple(((hv_PX.TupleFabs()).TupleGreaterEqualElem(hv_Inf)).TupleOr((hv_PY.TupleFabs()).TupleGreaterEqualElem(hv_Inf))).TupleOr((hv_PZ.TupleFabs()).TupleGreaterEqualElem(hv_Inf));
    if (0 != ((HTuple(hv_IsNaN.TupleOr(hv_IsInf)).TupleSum())>0))
    {
      write_note(hv_WindowHandle, "warning", HTuple(HTuple("The scene contains ")+(HTuple(hv_IsNaN.TupleOr(hv_IsInf)).TupleSum()))+" point(s) with INF or NaN coordinates");
    }
    else
    {
      write_note(hv_WindowHandle, "ok", "No INF or NaN in data");
    }
  }


  //*****************************************************************
  //Check for other multiple points in the data
  //*****************************************************************
  hv_DistThreshold = hv_DiameterModel*1e-7;
  if (0 != (hv_NumScenePoints>0))
  {
    GetObjectModel3dParams(hv_ObjectModel3DScene, "num_neighbors_fast "+hv_DistThreshold, 
        &hv_NumNeighbors);
    hv_MaxNumNeighbors = hv_NumNeighbors.TupleMax();
    if (0 != (hv_MaxNumNeighbors>30))
    {
      hv_Pos = ((const HTuple&)HTuple(hv_NumNeighbors.TupleSortIndex()))[(hv_NumNeighbors.TupleLength())-1];
      write_note(hv_WindowHandle, "error", (((((((("The scene point with the following coordinates seems to be duplicated around "+hv_MaxNumNeighbors)+" times: ")+"(")+HTuple(hv_PX[hv_Pos]))+HTuple(","))+HTuple(hv_PY[hv_Pos]))+HTuple(","))+HTuple(hv_PZ[hv_Pos]))+")");
      write_note(hv_WindowHandle, "warning", HTuple(HTuple("Note that point duplication can generate several false positive ")+HTuple("warnings and errors! It is recommended to first fix this problem, "))+"then to re-run this procedure");
      write_note(hv_WindowHandle, "warning", HTuple("To remove duplicate points, consider reducing the domain of the XYZ images or using select_points_object_model_3d with 'num_neighbors_fast'"));
      wait_continue_button(hv_WindowHandle);
      return;
    }
    else
    {
      write_note(hv_WindowHandle, "ok", "No duplicate point(s) detected");
    }
  }



  //*****************************************************************
  //Density of scene points
  //*****************************************************************
  //Compute the approximate scene point density
  //ATTENTION: If a point is contained multiple times in the scene,
  //           the density can be reported to be very high
  hv_DistThreshold = hv_DiameterModel*0.05;
  GetObjectModel3dParams(hv_ObjectModel3DScene, "num_neighbors_fast "+hv_DistThreshold, 
      &hv_NumNeighbors);
  hv_MedianDensity = (hv_NumNeighbors*1.0).TupleMedian();

  if (0 != (hv_MedianDensity<1))
  {
    write_note(hv_WindowHandle, "warning", "The point density in the scene seems low");
  }
  else if (0 != (hv_MedianDensity>350))
  {
    write_note(hv_WindowHandle, "warning", HTuple(HTuple("The point density in the scene seems very high. ")+"This is not necessarily a problem if the sensor has a ")+"very high resolution");
  }
  else
  {
    write_note(hv_WindowHandle, "ok", "The point density in the scene looks good");
  }


  //*****************************************************************
  //Check for Scene Normals
  //
  //Normals can come from:
  //- Precomputed normal vectors (for example with surface_normals_object_model_3d)
  //- A XYZ-Mapping, used to compute the normals
  //- Setting 'scene_normal_computation' to 'mls', which is identical to using
  //  surface_normals_object_model_3d, but faster
  //*****************************************************************
  hv_NormalsGood = 0;
  hv_MLSNormals = 0;
  hv_NormalPos = hv_GenParamNames.TupleFind("scene_normal_computation");
  if (0 != (HTuple(hv_NormalPos!=-1).TupleAnd(hv_NormalPos!=HTuple())))
  {
    hv_MLSNormals = HTuple(hv_GenParamValues[hv_NormalPos])==HTuple("mls");
  }

  hv_CheckNormals = 0;
  if (0 != (hv_MLSNormals==HTuple("true")))
  {
    write_note(hv_WindowHandle, "ok", "Normals computed with MLS method");
  }
  else if (0 != (hv_HasPointNormals==HTuple("true")))
  {
    write_note(hv_WindowHandle, "ok", "Scene contains normals vectors");
    hv_CheckNormals = 1;
  }
  else if (0 != (hv_HasMapping==HTuple("true")))
  {
    write_note(hv_WindowHandle, "ok", HTuple("Scene contains XYZ-Mapping, used for normal computation"));
  }
  else
  {
    write_note(hv_WindowHandle, "error", HTuple("No suitable way for computing the scene normals found (no XYZ mapping and no precomputed normals found). ")+"Please see the documentation of find_surface_model.");
  }


  //*****************************************************************
  //Check Normal Correctness
  //*****************************************************************
  if (0 != hv_CheckNormals)
  {
    GetObjectModel3dParams(hv_ObjectModel3DScene, "point_normal_x", &hv_NX);
    GetObjectModel3dParams(hv_ObjectModel3DScene, "point_normal_y", &hv_NY);
    GetObjectModel3dParams(hv_ObjectModel3DScene, "point_normal_z", &hv_NZ);

    hv_Length = (((hv_NX*hv_NX)+(hv_NY*hv_NY))+(hv_NZ*hv_NZ)).TupleSqrt();
    hv_LengthOne = (((hv_Length-1).TupleFabs()).TupleLessElem(0.05)).TupleSum();
    hv_LengthNotOne = (hv_Length.TupleLength())-hv_LengthOne;
    if (0 != (HTuple(hv_LengthNotOne>((hv_Length.TupleLength())*0.05)).TupleOr(hv_LengthNotOne>10)))
    {
      write_note(hv_WindowHandle, "error", ((((HTuple("Scene normals do not have length 1. ")+"(")+hv_LengthOne)+HTuple(" have length ~ 1, "))+hv_LengthNotOne)+" have not.)");
    }
    else
    {
      write_note(hv_WindowHandle, "ok", ((((HTuple("Scene normals have length 1. ")+"(")+hv_LengthOne)+HTuple(" have length ~ 1, "))+hv_LengthNotOne)+" have not.)");
    }
  }


  //*****************************************************************
  //Check Mapping
  //
  //Avoid duplicates in the mapping, which can happen when merging
  //multiple scenes into one.
  //*****************************************************************
  if (0 != (hv_HasMapping==HTuple("true")))
  {
    GetObjectModel3dParams(hv_ObjectModel3DScene, "mapping_row", &hv_Rows);
    GetObjectModel3dParams(hv_ObjectModel3DScene, "mapping_col", &hv_Cols);
    if (0 != (HTuple(HTuple(HTuple(((hv_Rows.TupleLessElem(0)).TupleSum())>0).TupleOr(((hv_Cols.TupleLessElem(0)).TupleSum())>0)).TupleOr(((hv_Rows.TupleGreaterElem(100000)).TupleSum())>0)).TupleOr((hv_Cols.TupleGreaterElem(1000000)).TupleSum())))
    {
      write_note(hv_WindowHandle, "error", "Mapping contains invalid values (smaller zero or very large)");
    }
    else
    {
      //Search for duplicates
      hv_MappingAsString = (hv_Rows+"#")+hv_Cols;
      hv_MappingAsString = hv_MappingAsString.TupleUnion(HTuple());
      if (0 != ((hv_MappingAsString.TupleLength())!=(hv_Rows.TupleLength())))
      {
        write_note(hv_WindowHandle, "error", "Mapping contains duplicates. Maybe two scenes were merged into one?");
      }
    }
  }


  //*****************************************************************
  //Model Center
  //The model center should not be too far away from the origin.
  //Otherwise, numerical issues might worsen the result.
  //*****************************************************************
  hv_CenterFromOrigin = ((hv_CenterModel*hv_CenterModel).TupleSum()).TupleSqrt();
  hv_CenterToDiameter = hv_CenterFromOrigin/hv_DiameterModel;
  if (0 != (hv_CenterToDiameter>10))
  {
    write_note(hv_WindowHandle, "warning", ("The model center is far away from the origin (more than "+(hv_CenterToDiameter.TupleString(".0")))+" times the diameter).");
  }
  else
  {
    write_note(hv_WindowHandle, "ok", "Model center is close to origin");
  }


  //*****************************************************************
  //Scene contains a mesh?
  //*****************************************************************
  if (0 != (HTuple(hv_HasTriangles==HTuple("true")).TupleOr(hv_HasPolygons==HTuple("true"))))
  {
    write_note(hv_WindowHandle, "warning", HTuple("Scene contains a mesh (triangles or polygons). ")+HTuple("Meshes are ignored, and only the 3D points are used during matching"));
  }
  else
  {
    write_note(hv_WindowHandle, "ok", "Scene contains no mesh (triangles or polygons)");
  }


  //*****************************************************************
  //Scene contains sparse data / points?
  //A point is 'sparse' if it has very few neighbors
  //*****************************************************************
  hv_DistThreshold = hv_DiameterModel*0.05;
  GetObjectModel3dParams(hv_ObjectModel3DScene, "num_neighbors_fast "+hv_DistThreshold, 
      &hv_NumNeighbors);
  hv_NumSparsePoints = (hv_MaxNumNeighbors.TupleLessElem(3)).TupleSum();
  if (0 != (HTuple(hv_NumSparsePoints>20).TupleOr(hv_NumSparsePoints>(0.05*hv_NumScenePoints))))
  {
    write_note(hv_WindowHandle, "warning", (("Scene contains "+hv_NumSparsePoints)+" isolated point(s) that are far away from the other points. ")+"Consider removing them beforehand.");
  }
  else
  {
    write_note(hv_WindowHandle, "ok", ("Scene contains "+hv_NumSparsePoints)+" isolated point(s).");
  }


  //*****************************************************************
  //For edge-based matching, does the scene contain a mapping?
  //*****************************************************************
  if (0 != (hv_EdgesTrained==HTuple("false")))
  {
    write_note(hv_WindowHandle, "info", HTuple("Surface model was not created for edge-supported matching, ")+"skipping corresponding checks.");
  }
  else
  {
    write_note(hv_WindowHandle, "info", "Surface model was created for edge-supported matching");
  }

  if (0 != (hv_EdgesTrained==HTuple("true")))
  {
    if (0 != (hv_HasMapping==HTuple("false")))
    {
      write_note(hv_WindowHandle, "error", HTuple("Scene does not contain XYZ-Mapping, which is required for ")+"edge-supported matching.  Create the scene with xyz_to_object_model_3d instead.");
    }
    else
    {
      write_note(hv_WindowHandle, "ok", "Scene contains XYZ-Mapping");
    }
  }


  //*****************************************************************
  //For edge-based matching, is the mapping direction OK?
  //*****************************************************************
  if (0 != (HTuple(hv_EdgesTrained==HTuple("true")).TupleAnd(hv_HasMapping==HTuple("true"))))
  {
    ObjectModel3dToXyz(&ho_X, &ho_Y, &ho_Z, hv_ObjectModel3DScene, "from_xyz_map", 
        HTuple(), HTuple());
    //Try to find the approximate direction in X
    get_image_direction(ho_X, &hv_MedianDirectionX);
    if (0 != ((((hv_MedianDirectionX*hv_MedianDirectionX).TupleSum()).TupleSqrt())>1e-8))
    {
      hv_MedianDirectionXNorm = hv_MedianDirectionX/(((hv_MedianDirectionX*hv_MedianDirectionX).TupleSum()).TupleSqrt());
    }
    else
    {
      hv_MedianDirectionXNorm.Clear();
      hv_MedianDirectionXNorm[0] = 0;
      hv_MedianDirectionXNorm[1] = 0;
    }
    get_image_direction(ho_Y, &hv_MedianDirectionY);
    if (0 != ((((hv_MedianDirectionY*hv_MedianDirectionY).TupleSum()).TupleSqrt())>1e-8))
    {
      hv_MedianDirectionYNorm = hv_MedianDirectionY/(((hv_MedianDirectionY*hv_MedianDirectionY).TupleSum()).TupleSqrt());
    }
    else
    {
      hv_MedianDirectionYNorm.Clear();
      hv_MedianDirectionYNorm[0] = 0;
      hv_MedianDirectionYNorm[1] = 0;
    }

    hv_ErrorX = hv_MedianDirectionXNorm-(HTuple(1).Append(0));
    hv_ErrorY = hv_MedianDirectionYNorm-(HTuple(0).Append(1));

    if (0 != (HTuple((((hv_ErrorX*hv_ErrorX).TupleSum()).TupleSqrt())>0.2).TupleOr((((hv_ErrorY*hv_ErrorY).TupleSum()).TupleSqrt())>0.2)))
    {
      write_note(hv_WindowHandle, "error", HTuple(HTuple("X or Y image of scene is not aligned with coordinate axis. ")+"This leads to incorrect edge directions and must be corrected. ")+HTuple("The X image should have increasing coordinates from left to right, the Y image from top to bottom."));
    }
    else
    {
      write_note(hv_WindowHandle, "ok", "X- and Y-Directions of mapping seem good");
    }
  }




  //*****************************************************************
  //Check if the origin is inside the data AND we would compute
  //the normals from the mapping
  //*****************************************************************
  if (0 != (HTuple(hv_HasPointNormals==HTuple("false")).TupleAnd(hv_HasMapping==HTuple("true"))))
  {
    hv_DistanceOriginRel = (((hv_CenterScene*hv_CenterScene).TupleSum()).TupleSqrt())/hv_DiameterModel;
    if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(hv_BBox[0])<0).TupleAnd(HTuple(hv_BBox[1])<0)).TupleAnd(HTuple(hv_BBox[2])<0)).TupleAnd(HTuple(hv_BBox[3])>0)).TupleAnd(HTuple(hv_BBox[4])>0)).TupleAnd(HTuple(hv_BBox[5])>0)))
    {
      write_note(hv_WindowHandle, "warning", (((HTuple(HTuple("The scene origin is inside the scene data. This is problematic, since normals ")+"are computed from the mapping and oriented towards the origin. ")+"The distance from scene center to origin is ~")+(hv_DistanceOriginRel.TupleString(".1f")))+" times the model diameter. ")+"Consider moving the scene origin to the original viewpoint of the sensor.");
    }
    else
    {
      write_note(hv_WindowHandle, "ok", ("Origin is not inside scene data. The distance from scene center to origin is ~"+(hv_DistanceOriginRel.TupleString(".1f")))+" times the model diameter. ");
    }
  }


  //*****************************************************************
  //Check if the viewpoint is inside the data AND we compute edges internally
  //*****************************************************************
  get_find_parameter(hv_GenParamNames, hv_GenParamValues, "3d_edges", HTuple(), &hv_OM3D3DEdges);
  if (0 != (HTuple(hv_EdgesTrained==HTuple("true")).TupleAnd(hv_OM3D3DEdges==HTuple())))
  {
    //Obtain the viewpoint
    get_find_parameter(hv_GenParamNames, hv_GenParamValues, "viewpoint", "0 0 0", 
        &hv_ViewpointString);
    hv_Viewpoint = (hv_ViewpointString.TupleSplit(" ")).TupleNumber();
    hv_ViewpointToCenter = hv_Viewpoint-hv_CenterScene;
    hv_DistanceOriginRel = (((hv_ViewpointToCenter*hv_ViewpointToCenter).TupleSum()).TupleSqrt())/hv_DiameterModel;
    if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(hv_BBox[0])<0).TupleAnd(HTuple(hv_BBox[1])<0)).TupleAnd(HTuple(hv_BBox[2])<0)).TupleAnd(HTuple(hv_BBox[3])>0)).TupleAnd(HTuple(hv_BBox[4])>0)).TupleAnd(HTuple(hv_BBox[5])>0)))
    {
      write_note(hv_WindowHandle, "warning", ((HTuple("The viewpoint is inside the scene data. This is problematic, since the edge viewing directions will probably be incorrect. The distance from scene center to the viewpoint is ~")+(hv_DistanceOriginRel.TupleString(".1f")))+" times the model diameter. ")+"Consider moving the viewpoint origin to the original viewpoint of the sensor.");
    }
    else
    {
      write_note(hv_WindowHandle, "ok", ("Viewpoint is not inside scene data. The distance from scene center to origin is ~"+(hv_DistanceOriginRel.TupleString(".1f")))+" times the model diameter. ");
    }
  }


  //*****************************************************************
  //Check noise in Z-Direction
  //*****************************************************************
  if (0 != (hv_HasMapping==HTuple("true")))
  {
    ObjectModel3dToXyz(&ho_X, &ho_Y, &ho_Z, hv_ObjectModel3DScene, "from_xyz_map", 
        HTuple(), HTuple());
    estimate_noise_real(ho_Z, 0.05, &hv_ZSigmaAbs);
    hv_ZSigmaRel = hv_ZSigmaAbs/hv_DiameterModel;
    hv_ZSigmaPct = ((hv_ZSigmaRel*100).TupleString(".1"))+"%";
    if (0 != (hv_ZSigmaRel>0.2))
    {
      write_note(hv_WindowHandle, "error", ((("The noise in the data is very high (relative value: "+hv_ZSigmaPct)+"). ")+"Consider smoothing the Z-image with a median filter and using ")+"the mls normal estimation method.");
    }
    else if (0 != (hv_ZSigmaRel>0.1))
    {
      write_note(hv_WindowHandle, "warning", ((("The noise in the data seems rather high (relative value: "+hv_ZSigmaPct)+"). ")+"Consider smoothing the Z-image with a median filter and using ")+"the mls normal estimation method.");
    }
    else
    {
      write_note(hv_WindowHandle, "ok", ("The noise in the data looks good (relative value: "+hv_ZSigmaPct)+")");
    }
  }
  else
  {
    //No suitable way of checking the noise (yet)
    write_note(hv_WindowHandle, "info", "Noise was not checked (requires XYZ mapping)");
  }

  //*****************************************************************
  //DONE
  //Wait for user to click continue
  //*****************************************************************
  wait_continue_button(hv_WindowHandle);

  return;

}

// Chapter: Calibration / Hand-Eye
// Short Description: Check the input poses of the hand-eye calibration for consistency. 
void check_hand_eye_calibration_input_poses (HTuple hv_CalibDataID, HTuple hv_RotationTolerance, 
    HTuple hv_TranslationTolerance, HTuple *hv_Warnings)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinLargeRotationFraction, hv_MinLargeAnglesFraction;
  HTuple  hv_StdDevFactor, hv_Type, hv_Exception, hv_IsHandEyeScara;
  HTuple  hv_IsHandEyeArticulated, hv_NumCameras, hv_NumCalibObjs;
  HTuple  hv_I1, hv_PosesIdx, hv_RefCalibDataID, hv_UseTemporaryCopy;
  HTuple  hv_CamPoseCal, hv_SerializedItemHandle, hv_TmpCalibDataID;
  HTuple  hv_Error, hv_Index, hv_CamDualQuatCal, hv_BasePoseTool;
  HTuple  hv_BaseDualQuatTool, hv_NumCalibrationPoses, hv_LX2s;
  HTuple  hv_LY2s, hv_LZ2s, hv_TranslationToleranceSquared;
  HTuple  hv_RotationToleranceSquared, hv_Index1, hv_CamDualQuatCal1;
  HTuple  hv_Cal1DualQuatCam, hv_BaseDualQuatTool1, hv_Tool1DualQuatBase;
  HTuple  hv_Index2, hv_CamDualQuatCal2, hv_DualQuat1, hv_BaseDualQuatTool2;
  HTuple  hv_DualQuat2, hv_LX1, hv_LY1, hv_LZ1, hv_MX1, hv_MY1;
  HTuple  hv_MZ1, hv_Rot1, hv_Trans1, hv_LX2, hv_LY2, hv_LZ2;
  HTuple  hv_MX2, hv_MY2, hv_MZ2, hv_Rot2, hv_Trans2, hv_MeanRot;
  HTuple  hv_MeanTrans, hv_SinTheta2, hv_CosTheta2, hv_SinTheta2Squared;
  HTuple  hv_CosTheta2Squared, hv_ErrorRot, hv_StdDevQ0, hv_ToleranceDualQuat0;
  HTuple  hv_ErrorDualQuat0, hv_StdDevQ4, hv_ToleranceDualQuat4;
  HTuple  hv_ErrorDualQuat4, hv_Message, hv_NumPairs, hv_NumPairsMax;
  HTuple  hv_LargeRotationFraction, hv_NumPairPairs, hv_NumPairPairsMax;
  HTuple  hv_Angles, hv_Idx, hv_LXA, hv_LYA, hv_LZA, hv_LXB;
  HTuple  hv_LYB, hv_LZB, hv_ScalarProduct, hv_LargeAngles;
  HTuple  hv_LargeAnglesFraction;
  HTupleVector  hvec_CamDualQuatsCal(1), hvec_BaseDualQuatsTool(1);

  //This procedure checks the hand-eye calibration input poses that are stored in
  //the calibration data model CalibDataID for consistency.
  //
  //For this check, it is necessary to know the accuracy of the input poses.
  //Therefore, the RotationTolerance and TranslationTolerance must be
  //specified that approximately describe the error in the rotation and in the
  //translation part of the input poses, respectively. The rotation tolerance must
  //be passed in RotationTolerance in radians. The translation tolerance must be
  //passed in TranslationTolerance in the same unit in which the input poses were
  //given, i.e., typically in meters. Therefore, the more accurate the
  //input poses are, the lower the values for RotationTolerance and
  //TranslationTolerance should be chosen. If the accuracy of the robot's tool
  //poses is different from the accuracy of the calibration object poses, the
  //tolerance values of the poses with the lower accuracy (i.e., the higher
  //tolerance values) should be passed.
  //
  //Typically, check_hand_eye_calibration_input_poses is called after all
  //calibration poses have been set in the calibration data model and before the
  //hand eye calibration is performed. The procedure checks all pairs of robot
  //tool poses and compares them to the corresponding pair of calibration object
  //poses. For each inconsistent pose pair, a string is returned in Warnings that
  //indicates the inconsistent pose pair. For larger values for RotationTolerance
  //or TranslationTolerance, i.e., for less accurate input poses, fewer warnings
  //will be generated because the check is more tolerant, and vice versa. The
  //procedure is also helpful if the errors that are returned by the hand-eye
  //calibration are larger than expected to identify potentially erroneous poses.
  //Note that it is not possible to check the consistency of a single pose but
  //only of pose pairs. Nevertheless, if a certain pose occurs multiple times in
  //different warning messages, it is likely that the pose is erroneous.
  //Erroneous poses that result in inconsistent pose pairs should removed
  //from the calibration data model by using remove_calib_data_observ and
  //remove_calib_data before performing the hand-eye calibration.
  //
  //check_hand_eye_calibration_input_poses also checks whether enough calibration
  //pose pairs are passed with a significant relative rotation angle, which
  //is necessary for a robust hand-eye calibration.
  //
  //check_hand_eye_calibration_input_poses also verifies that the correct
  //calibration model was chosen in create_calib_data. If a model of type
  //'hand_eye_stationary_cam' or 'hand_eye_moving_cam' was chosen, the calibration
  //of an articulated robot is assumed. For 'hand_eye_scara_stationary_cam' or
  //'hand_eye_scara_moving_cam', the calibration of a SCARA robot is assumed.
  //Therefore, if all input poses for an articulated robot are parallel or if some
  //robot poses for a SCARA robot are tilted, a corresponding message is returned
  //in Warnings. Furthermore, if the number of tilted input poses for articulated
  //robots is below a certain value, a corresponding message in Warnings indicates
  //that the accuracy of the result of the hand-eye calibration might be low.
  //
  //If no problems have been detected in the input poses, an empty tuple is
  //returned in Warnings.
  //
  //
  //Define the minimum fraction of pose pairs with a rotation angle exceeding
  //2*RotationTolerance.
  hv_MinLargeRotationFraction = 0.1;
  //Define the minimum fraction of screw axes pairs with an angle exceeding
  //2*RotationTolerance for articulated robots.
  hv_MinLargeAnglesFraction = 0.1;
  //Factor that is used to multiply the standard deviations to obtain an error
  //threshold.
  hv_StdDevFactor = 3.0;
  //
  //Check input control parameters.
  if (0 != ((hv_CalibDataID.TupleLength())!=1))
  {
    throw HException("Wrong number of values of control parameter: 1");
  }
  if (0 != ((hv_RotationTolerance.TupleLength())!=1))
  {
    throw HException("Wrong number of values of control parameter: 2");
  }
  if (0 != ((hv_TranslationTolerance.TupleLength())!=1))
  {
    throw HException("Wrong number of values of control parameter: 3");
  }
  try
  {
    GetCalibData(hv_CalibDataID, "model", "general", "type", &hv_Type);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException("Wrong value of control parameter: 1");
  }
  if (0 != (hv_RotationTolerance<0))
  {
    throw HException("Wrong value of control parameter: 2");
  }
  if (0 != (hv_TranslationTolerance<0))
  {
    throw HException("Wrong value of control parameter: 3");
  }
  //
  //Read out the calibration data model.
  hv_IsHandEyeScara = HTuple(hv_Type==HTuple("hand_eye_scara_stationary_cam")).TupleOr(hv_Type==HTuple("hand_eye_scara_moving_cam"));
  hv_IsHandEyeArticulated = HTuple(hv_Type==HTuple("hand_eye_stationary_cam")).TupleOr(hv_Type==HTuple("hand_eye_moving_cam"));
  //This procedure only works for hand-eye calibration applications.
  if (0 != (HTuple(hv_IsHandEyeScara.TupleNot()).TupleAnd(hv_IsHandEyeArticulated.TupleNot())))
  {
    throw HException("check_hand_eye_calibration_input_poses only works for hand-eye calibrations");
  }
  GetCalibData(hv_CalibDataID, "model", "general", "num_cameras", &hv_NumCameras);
  GetCalibData(hv_CalibDataID, "model", "general", "num_calib_objs", &hv_NumCalibObjs);
  //
  //Get all valid calibration pose indices.
  QueryCalibDataObservIndices(hv_CalibDataID, "camera", 0, &hv_I1, &hv_PosesIdx);
  hv_RefCalibDataID = hv_CalibDataID;
  hv_UseTemporaryCopy = 0;
  //If necessary, calibrate the interior camera parameters.
  if (0 != hv_IsHandEyeArticulated)
  {
    //For articulated (non-SCARA) robots, we have to check whether the camera
    //is already calibrated. Otherwise, the queried poses might not be very
    //accurate.
    try
    {
      GetCalibData(hv_CalibDataID, "calib_obj_pose", HTuple(0).TupleConcat(HTuple(hv_PosesIdx[0])), 
          "pose", &hv_CamPoseCal);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      if (0 != (HTuple(hv_NumCameras!=0).TupleAnd(hv_NumCalibObjs!=0)))
      {
        //If the interior camera parameters are not calibrated yet, perform
        //the camera calibration by using a temporary copy of the calibration
        //data model.
        SerializeCalibData(hv_CalibDataID, &hv_SerializedItemHandle);
        DeserializeCalibData(hv_SerializedItemHandle, &hv_TmpCalibDataID);
        ClearSerializedItem(hv_SerializedItemHandle);
        hv_RefCalibDataID = hv_TmpCalibDataID;
        hv_UseTemporaryCopy = 1;
        CalibrateCameras(hv_TmpCalibDataID, &hv_Error);
      }
    }
  }
  //Query all robot tool and calibration object poses.
  {
  HTuple end_val120 = (hv_PosesIdx.TupleLength())-1;
  HTuple step_val120 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val120, step_val120); hv_Index += step_val120)
  {
    try
    {
      //For an articulated robot with a camera and a calibration object,
      //a calibrated poses should always be available.
      GetCalibData(hv_RefCalibDataID, "calib_obj_pose", HTuple(0).TupleConcat(HTuple(hv_PosesIdx[hv_Index])), 
          "pose", &hv_CamPoseCal);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      //For a SCARA robot or for an articulated robots with a general
      //sensor and no calibration object, directly use the observed poses.
      GetCalibDataObservPose(hv_RefCalibDataID, 0, 0, HTuple(hv_PosesIdx[hv_Index]), 
          &hv_CamPoseCal);
    }
    //Transform the calibration object poses to dual quaternions.
    PoseToDualQuat(hv_CamPoseCal, &hv_CamDualQuatCal);
    hvec_CamDualQuatsCal[hv_Index] = HTupleVector(hv_CamDualQuatCal);
    //Transform the robot tool pose to dual quaternions.
    GetCalibData(hv_RefCalibDataID, "tool", HTuple(hv_PosesIdx[hv_Index]), "tool_in_base_pose", 
        &hv_BasePoseTool);
    PoseToDualQuat(hv_BasePoseTool, &hv_BaseDualQuatTool);
    hvec_BaseDualQuatsTool[hv_Index] = HTupleVector(hv_BaseDualQuatTool);
  }
  }
  hv_NumCalibrationPoses = hv_PosesIdx.TupleLength();
  if (0 != hv_UseTemporaryCopy)
  {
    ClearCalibData(hv_TmpCalibDataID);
  }
  //
  //In the first test, check the poses for consistency. The principle of
  //the hand-eye calibration is that the movement of the robot from time
  //i to time j is represented by the relative pose of the calibration
  //object from i to j in the camera coordinate system and also by the
  //relative pose of the robot tool from i to j in the robot base
  //coordinate system. Because both relative poses represent the same 3D
  //rigid transformation, but only seen from two different coordinate
  //systems, their screw axes differ but their screw angle and their
  //screw translation should be identical. This knowledge can be used to
  //check the consistency of the input poses. Furthermore, remember the
  //screw axes for all robot movements to later check whether the
  //correct calibration model (SCARA or articulated) was selected by the
  //user.
  (*hv_Warnings) = HTuple();
  hv_LX2s = HTuple();
  hv_LY2s = HTuple();
  hv_LZ2s = HTuple();
  hv_TranslationToleranceSquared = hv_TranslationTolerance*hv_TranslationTolerance;
  hv_RotationToleranceSquared = hv_RotationTolerance*hv_RotationTolerance;
  {
  HTuple end_val162 = hv_NumCalibrationPoses-2;
  HTuple step_val162 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val162, step_val162); hv_Index1 += step_val162)
  {
    hv_CamDualQuatCal1 = hvec_CamDualQuatsCal[hv_Index1].T();
    DualQuatConjugate(hv_CamDualQuatCal1, &hv_Cal1DualQuatCam);
    hv_BaseDualQuatTool1 = hvec_BaseDualQuatsTool[hv_Index1].T();
    DualQuatConjugate(hv_BaseDualQuatTool1, &hv_Tool1DualQuatBase);
    {
    HTuple end_val167 = hv_NumCalibrationPoses-1;
    HTuple step_val167 = 1;
    for (hv_Index2=hv_Index1+1; hv_Index2.Continue(end_val167, step_val167); hv_Index2 += step_val167)
    {
      //For two robot poses, ...
      //... compute the movement of the calibration object in the
      //camera coordinate system.
      hv_CamDualQuatCal2 = hvec_CamDualQuatsCal[hv_Index2].T();
      DualQuatCompose(hv_Cal1DualQuatCam, hv_CamDualQuatCal2, &hv_DualQuat1);
      //
      //... compute the movement of the tool in the robot base
      //coordinate system.
      hv_BaseDualQuatTool2 = hvec_BaseDualQuatsTool[hv_Index2].T();
      DualQuatCompose(hv_Tool1DualQuatBase, hv_BaseDualQuatTool2, &hv_DualQuat2);
      //
      //Check whether the two movements are consistent. If the two
      //movements are consistent, the scalar parts of the corresponding
      //dual quaternions should be equal. For the equality check, we
      //have to take the accuracy of the input poses into account, which
      //are given by RotationTolerance and TranslationTolerance.
      DualQuatToScrew(hv_DualQuat1, "moment", &hv_LX1, &hv_LY1, &hv_LZ1, &hv_MX1, 
          &hv_MY1, &hv_MZ1, &hv_Rot1, &hv_Trans1);
      DualQuatToScrew(hv_DualQuat2, "moment", &hv_LX2, &hv_LY2, &hv_LZ2, &hv_MX2, 
          &hv_MY2, &hv_MZ2, &hv_Rot2, &hv_Trans2);
      while (0 != (hv_Rot1>(HTuple(180.0).TupleRad())))
      {
        hv_Rot1 = hv_Rot1-(HTuple(360.0).TupleRad());
      }
      while (0 != (hv_Rot2>(HTuple(180.0).TupleRad())))
      {
        hv_Rot2 = hv_Rot2-(HTuple(360.0).TupleRad());
      }
      //
      hv_Rot1 = hv_Rot1.TupleFabs();
      hv_Trans1 = hv_Trans1.TupleFabs();
      hv_Rot2 = hv_Rot2.TupleFabs();
      hv_Trans2 = hv_Trans2.TupleFabs();
      hv_MeanRot = 0.5*(hv_Rot1+hv_Rot2);
      hv_MeanTrans = 0.5*(hv_Trans1+hv_Trans2);
      hv_SinTheta2 = (0.5*hv_MeanRot).TupleSin();
      hv_CosTheta2 = (0.5*hv_MeanRot).TupleCos();
      hv_SinTheta2Squared = hv_SinTheta2*hv_SinTheta2;
      hv_CosTheta2Squared = hv_CosTheta2*hv_CosTheta2;
      //
      //1. Check the scalar part of the real part of the dual quaternion,
      //which encodes the rotation component of the screw:
      //  q[0] = cos(theta/2)
      //Here, theta is the screw rotation angle.
      hv_ErrorRot = (hv_Rot1-hv_Rot2).TupleFabs();
      while (0 != (hv_ErrorRot>(HTuple(180.0).TupleRad())))
      {
        hv_ErrorRot = hv_ErrorRot-(HTuple(360.0).TupleRad());
      }
      hv_ErrorRot = hv_ErrorRot.TupleFabs();
      //Compute the standard deviation of the scalar part of the real part
      //by applying the law of error propagation.
      hv_StdDevQ0 = (0.5*hv_SinTheta2)*hv_RotationTolerance;
      //Multiply the standard deviation by a factor to increase the certainty.
      hv_ToleranceDualQuat0 = hv_StdDevFactor*hv_StdDevQ0;
      hv_ErrorDualQuat0 = ((HTuple(hv_DualQuat2[0]).TupleFabs())-(HTuple(hv_DualQuat1[0]).TupleFabs())).TupleFabs();
      //
      //2. Check the scalar part of the dual part of the dual quaternion,
      //which encodes translation and rotation components of the screw:
      //  q[4] = -d/2*sin(theta/2)
      //Here, d is the screw translation.
      //
      //Compute the standard deviation of the scalar part of the dual part
      //by applying the law of error propagation.
      hv_StdDevQ4 = (((0.25*hv_SinTheta2Squared)*hv_TranslationToleranceSquared)+((((0.0625*hv_MeanTrans)*hv_MeanTrans)*hv_CosTheta2Squared)*hv_RotationToleranceSquared)).TupleSqrt();
      //Multiply the standard deviation by a factor to increase the certainty.
      hv_ToleranceDualQuat4 = hv_StdDevFactor*hv_StdDevQ4;
      hv_ErrorDualQuat4 = ((HTuple(hv_DualQuat2[4]).TupleFabs())-(HTuple(hv_DualQuat1[4]).TupleFabs())).TupleFabs();
      //If one of the two errors exceeds the computed thresholds, return
      //a warning for the current pose pair.
      if (0 != (HTuple(hv_ErrorDualQuat0>hv_ToleranceDualQuat0).TupleOr(hv_ErrorDualQuat4>hv_ToleranceDualQuat4)))
      {
        hv_Message = ((("Inconsistent pose pair ("+(HTuple(hv_PosesIdx[hv_Index1]).TupleString("2d")))+HTuple(","))+(HTuple(hv_PosesIdx[hv_Index2]).TupleString("2d")))+")";
        (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
      }
      //
      //Remember the screw axes (of the robot tool movements) for screws
      //with a significant rotation part. For movements without rotation
      //the direction of the screw axis is determined by the translation
      //part only. Hence, the direction of the screw axis cannot be used
      //to decide whether an articulated or a SCARA robot is used.
      if (0 != (hv_Rot2>(hv_StdDevFactor*hv_RotationTolerance)))
      {
        hv_LX2s = hv_LX2s.TupleConcat(hv_LX2);
        hv_LY2s = hv_LY2s.TupleConcat(hv_LY2);
        hv_LZ2s = hv_LZ2s.TupleConcat(hv_LZ2);
      }
    }
    }
  }
  }
  //
  //In the second test, we check whether enough calibration poses with a
  //significant rotation part are available for calibration.
  hv_NumPairs = hv_LX2s.TupleLength();
  hv_NumPairsMax = (hv_NumCalibrationPoses*(hv_NumCalibrationPoses-1))/2;
  if (0 != (hv_NumPairs<2))
  {
    hv_Message = "There are not enough rotated calibration poses available.";
    (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
    //In this case, we can skip further test.
    return;
  }
  hv_LargeRotationFraction = (hv_NumPairs.TupleReal())/hv_NumPairsMax;
  if (0 != (HTuple(hv_NumPairs<4).TupleOr(hv_LargeRotationFraction<hv_MinLargeRotationFraction)))
  {
    hv_Message = HTuple("Only few rotated robot poses available, which might result in a reduced accuracy of the calibration results.");
    (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
  }
  //
  //In the third test, we compute the angle between the screw axes with
  //a significant rotation part. For SCARA robots, this angle must be 0 in
  //all cases. For articulated robots, for a significant fraction of robot
  //poses, this angle should exceed a certain threshold. For this test, we
  //use the robot tool poses as they are assumed to be more accurate than the
  //calibration object poses.
  hv_NumPairPairs = (hv_NumPairs*(hv_NumPairs-1))/2;
  hv_NumPairPairsMax = (hv_NumPairsMax*(hv_NumPairsMax-1))/2;
  hv_Angles = HTuple(hv_NumPairPairs,0);
  hv_Idx = 0;
  {
  HTuple end_val277 = hv_NumPairs-2;
  HTuple step_val277 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val277, step_val277); hv_Index1 += step_val277)
  {
    hv_LXA = HTuple(hv_LX2s[hv_Index1]);
    hv_LYA = HTuple(hv_LY2s[hv_Index1]);
    hv_LZA = HTuple(hv_LZ2s[hv_Index1]);
    {
    HTuple end_val281 = hv_NumPairs-1;
    HTuple step_val281 = 1;
    for (hv_Index2=hv_Index1+1; hv_Index2.Continue(end_val281, step_val281); hv_Index2 += step_val281)
    {
      hv_LXB = HTuple(hv_LX2s[hv_Index2]);
      hv_LYB = HTuple(hv_LY2s[hv_Index2]);
      hv_LZB = HTuple(hv_LZ2s[hv_Index2]);
      //Compute the scalar product, i.e. the cosine of the screw
      //axes. To obtain valid values, crop the cosine to the
      //interval [-1,1].
      hv_ScalarProduct = ((((((hv_LXA*hv_LXB)+(hv_LYA*hv_LYB))+(hv_LZA*hv_LZB)).TupleConcat(1)).TupleMin()).TupleConcat(-1)).TupleMax();
      //Compute the angle between the axes in the range [0,pi/2].
      hv_Angles[hv_Idx] = (hv_ScalarProduct.TupleFabs()).TupleAcos();
      hv_Idx += 1;
    }
    }
  }
  }
  //Large angles should significantly exceed the RotationTolerance.
  hv_LargeAngles = (hv_Angles.TupleGreaterElem(hv_StdDevFactor*hv_RotationTolerance)).TupleSum();
  //Calculate the fraction of pairs of movements, i.e., pairs of pose
  //pairs, that have a large angle between their corresponding screw
  //axes.
  hv_LargeAnglesFraction = (hv_LargeAngles.TupleReal())/hv_NumPairPairsMax;
  //For SCARA robots, all screw axes should be parallel, i.e., no
  //two screw axes should have a large angle.
  if (0 != (hv_IsHandEyeScara.TupleAnd(hv_LargeAngles>0)))
  {
    hv_Message = HTuple("The robot poses indicate that this might be an articulated robot, although a SCARA robot was selected in the calibration data model.");
    (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
  }
  //For articulated robots, the screw axes should have a large
  //angles.
  if (0 != hv_IsHandEyeArticulated)
  {
    if (0 != (hv_LargeAngles==0))
    {
      //If there is no pair of movements with a large angle between
      //their corresponding screw axes, this might be a SCARA robot.
      hv_Message = HTuple("The robot poses indicate that this might be a SCARA robot (no tilted robot poses available), although an articulated robot was selected in the calibration data model.");
      (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
    }
    else if (0 != (hv_LargeAngles<3))
    {
      //If there are at most 2 movements with a large angle between
      //their corresponding screw axes, the calibration might be
      //unstable.
      hv_Message = "Not enough tilted robot poses available for an accurate calibration of an articulated robot.";
      (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
    }
    else if (0 != (hv_LargeAnglesFraction<hv_MinLargeAnglesFraction))
    {
      //If there is only a low fraction of pairs of movements with
      //a large angle between their corresponding screw axes, the
      //accuracy of the calibration might be low.
      hv_Message = HTuple("Only few tilted robot poses available, which might result in a reduced accuracy of the calibration results.");
      (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
    }
  }
  return;
}

void check_model_edges (HTuple hv_SurfaceModelID, HTuple hv_ObjectModel3D, HTuple hv_WindowHandleViewpoint, 
    HTuple hv_WindowHandleVisualization)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_GenParamValue, hv_Instructions, hv_MessageQueues1;
  HTuple  hv_Buttons, hv_Row, hv_Column, hv_Width, hv_Height;
  HTuple  hv_CameraParam, hv_CurrentState1, hv_DiameterModel;
  HTuple  hv_CenterModel, hv_Viewpoint, hv_OM3DCamera, hv_OM3DLineSphereToModel;
  HTuple  hv_Center, hv_PoseIn, hv_CamParamVis, hv_PoseEstimated;
  HTuple  hv_MessageQueues2, hv_DirectionsShown, hv_CurrentState2;
  HTuple  hv_DidFinish1, hv_ButtonPressed, hv_Pose, hv_PoseInvert;
  HTuple  hv_Direction, hv_Length, hv_OM3DSphere, hv_OM3DModelEdges;
  HTuple  hv_EdgeDirs, hv_MessageHandle, hv_DidFinish2, hv_TIT;
  HTupleVector  hvec_TI(1);

  // +++ Threading variables 
  HDevThread*         hcppthread_handle;
  HDevThreadContext   hcppthread_context; // <-signals begin of procedure

  GetSurfaceModelParam(hv_SurfaceModelID, "diameter", &hv_GenParamValue);
  //
  hv_Instructions[0] = "Rotate: Left button";
  hv_Instructions[1] = "Zoom:   Shift + left button";
  hv_Instructions[2] = "Move:   Ctrl  + left button";
  //
  create_visualization_message_queues(&hv_MessageQueues1);
  hv_Buttons.Clear();
  hv_Buttons[0] = "Continue";
  hv_Buttons[1] = "right";
  hv_Buttons[2] = "bottom";
  hv_Buttons[3] = -1;
  hv_Buttons[4] = -1;
  GetWindowExtents(hv_WindowHandleViewpoint, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  gen_cam_par_area_scan_division(0.008, 0, 5.2e-006, 5.2e-006, (hv_Width*0.5)+0.5, 
      (hv_Height*0.5)+0.5, hv_Width, hv_Height, &hv_CameraParam);
  // Create a thread instance
  hcppthread_handle = new HDevThread(hcppthread_context,
              (void*)HDevExportCpp::_hcppthread_visualize_object_model_3d_ext,15,0);
  // Set thread procedure call arguments 
  hcppthread_handle->SetInputCtrlParamTuple(0,hv_WindowHandleViewpoint);
  hcppthread_handle->SetInputCtrlParamTuple(1,hv_ObjectModel3D);
  hcppthread_handle->SetInputCtrlParamTuple(2,hv_CameraParam);
  hcppthread_handle->SetInputCtrlParamTuple(3,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(4,((HTuple("disp_pose").Append("color_0")).Append("alpha_0")));
  hcppthread_handle->SetInputCtrlParamTuple(5,((HTuple("true").Append("cyan")).Append(0.5)));
  hcppthread_handle->SetInputCtrlParamTuple(6,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(7,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(8,hv_Instructions);
  hcppthread_handle->SetInputCtrlParamTuple(9,hv_MessageQueues1);
  hcppthread_handle->SetInputCtrlParamTuple(10,hv_Buttons);
  hcppthread_handle->SetInputCtrlParamTuple(11,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(12,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(13,"false");
  hcppthread_handle->SetInputCtrlParamTuple(14,HTuple());

  // Start proc line in thread
  hcppthread_handle->ParStart(&hvec_TI[0].T());

  hv_CurrentState1 = HTuple();
  //
  GetSurfaceModelParam(hv_SurfaceModelID, "diameter", &hv_DiameterModel);
  GetSurfaceModelParam(hv_SurfaceModelID, "center", &hv_CenterModel);
  hv_Viewpoint = hv_CenterModel-(((HTuple(0).Append(0)).Append(1))*hv_DiameterModel);
  gen_camera_object_model_3d(hv_Viewpoint.TupleConcat((((HTuple(0).Append(0)).Append(0)).Append(0))), 
      hv_DiameterModel*0.05, &hv_OM3DCamera);
  GenObjectModel3dFromPoints(HTuple(hv_Viewpoint[0]).TupleConcat(HTuple(hv_CenterModel[0])), 
      HTuple(hv_Viewpoint[1]).TupleConcat(HTuple(hv_CenterModel[1])), HTuple(hv_Viewpoint[2]).TupleConcat(HTuple(hv_CenterModel[2])), 
      &hv_OM3DLineSphereToModel);
  SetObjectModel3dAttribMod(hv_OM3DLineSphereToModel, "lines", HTuple(), ((HTuple(2).Append(0)).Append(1)));
  //
  //Find a pose for the second window such that both the model and the camer are visible,
  //from the side.
  get_object_models_center((hv_ObjectModel3D.TupleConcat(hv_OM3DCamera)).TupleConcat(hv_OM3DLineSphereToModel), 
      &hv_Center);
  CreatePose(-HTuple(hv_Center[0]), -HTuple(hv_Center[1]), -HTuple(hv_Center[2]), 
      -90, 0, 0, "Rp+T", "gba", "point", &hv_PoseIn);
  GetWindowExtents(hv_WindowHandleVisualization, &hv_Row, &hv_Column, &hv_Width, 
      &hv_Height);
  gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
      hv_Width, hv_Height, &hv_CamParamVis);
  determine_optimum_pose_distance((hv_ObjectModel3D.TupleConcat(hv_OM3DCamera)).TupleConcat(hv_OM3DLineSphereToModel), 
      hv_CamParamVis, 0.5, hv_PoseIn, &hv_PoseEstimated);
  //
  create_visualization_message_queues(&hv_MessageQueues2);
  hv_Buttons.Clear();
  hv_Buttons[0] = "Hide Edge Directions";
  hv_Buttons[1] = "center";
  hv_Buttons[2] = "bottom";
  hv_Buttons[3] = -1;
  hv_Buttons[4] = -1;
  hv_DirectionsShown = 1;
  // Create a thread instance
  hcppthread_handle = new HDevThread(hcppthread_context,
              (void*)HDevExportCpp::_hcppthread_visualize_object_model_3d_ext,15,0);
  // Set thread procedure call arguments 
  hcppthread_handle->SetInputCtrlParamTuple(0,hv_WindowHandleVisualization);
  hcppthread_handle->SetInputCtrlParamTuple(1,((hv_ObjectModel3D.TupleConcat(hv_ObjectModel3D)).TupleConcat(hv_OM3DCamera)).TupleConcat(hv_OM3DLineSphereToModel));
  hcppthread_handle->SetInputCtrlParamTuple(2,hv_CamParamVis);
  hcppthread_handle->SetInputCtrlParamTuple(3,hv_PoseEstimated);
  hcppthread_handle->SetInputCtrlParamTuple(4,(((((HTuple("color_0").Append("color_1")).Append("color_2")).Append("color_3")).Append("alpha_0")).Append("disp_normals_1")));
  hcppthread_handle->SetInputCtrlParamTuple(5,(((((HTuple("cyan").Append("red")).Append("gray")).Append("white")).Append(0.5)).Append("true")));
  hcppthread_handle->SetInputCtrlParamTuple(6,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(7,(((HTuple("").Append("")).Append("Viewpoint")).Append("")));
  hcppthread_handle->SetInputCtrlParamTuple(8,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(9,hv_MessageQueues2);
  hcppthread_handle->SetInputCtrlParamTuple(10,hv_Buttons);
  hcppthread_handle->SetInputCtrlParamTuple(11,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(12,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(13,"false");
  hcppthread_handle->SetInputCtrlParamTuple(14,HTuple());

  // Start proc line in thread
  hcppthread_handle->ParStart(&hvec_TI[1].T());

  hv_CurrentState2 = HTuple();
  //
  do
  {
    process_visualize_events_generic(hv_WindowHandleViewpoint, hv_MessageQueues1, 
        hv_CurrentState1, &hv_DidFinish1, &hv_CurrentState1, &hv_ButtonPressed, &hv_Pose);
    if (0 != (hv_ButtonPressed==0))
    {
      //Exit button
      break;
    }
    if (0 != (hv_Pose!=HTuple()))
    {
      //The pose of view 1 was updated
      //-> Update the viewpoint in view 2
      PoseInvert(hv_Pose, &hv_PoseInvert);
      hv_Viewpoint = hv_PoseInvert.TupleSelectRange(0,2);
      //pose_to_hom_mat3d (Pose, HomMat3D)


      //hom_mat3d_invert (HomMat3D, HomMat3DInvert)
      //affine_trans_point_3d (HomMat3DInvert, 0, 0, 0, Qx, Qy, Qz)
      //Viewpoint := [Qx,Qy,Qz]
      //With this method, the viewpoint would be very far away in view 2, leading to not-so-nice
      //visualization. Adapt the distance to be always the same.
      hv_Direction = hv_Viewpoint-hv_CenterModel;
      hv_Length = ((hv_Direction*hv_Direction).TupleSum()).TupleSqrt();
      hv_Viewpoint = hv_CenterModel+(hv_Direction*(hv_DiameterModel/hv_Length));
      //
      hv_PoseInvert[HTuple::TupleGenSequence(0,2,1)] = hv_Viewpoint;
      //
      gen_camera_object_model_3d(hv_PoseInvert, hv_DiameterModel*0.05, &hv_OM3DSphere);
      GenObjectModel3dFromPoints(HTuple(hv_Viewpoint[0]).TupleConcat(HTuple(hv_CenterModel[0])), 
          HTuple(hv_Viewpoint[1]).TupleConcat(HTuple(hv_CenterModel[1])), HTuple(hv_Viewpoint[2]).TupleConcat(HTuple(hv_CenterModel[2])), 
          &hv_OM3DLineSphereToModel);
      SetObjectModel3dAttribMod(hv_OM3DLineSphereToModel, "lines", HTuple(), ((HTuple(2).Append(0)).Append(1)));
      GetSurfaceModelParam(hv_SurfaceModelID, "edges "+((hv_Viewpoint+" ").TupleSum()), 
          &hv_OM3DModelEdges);
      //
      GetObjectModel3dParams(hv_OM3DModelEdges, HTuple("edge_dir_")+((HTuple("x").Append("y")).Append("z")), 
          &hv_EdgeDirs);
      SetObjectModel3dAttribMod(hv_OM3DModelEdges, HTuple("point_normal_")+((HTuple("x").Append("y")).Append("z")), 
          HTuple(), hv_EdgeDirs);
      //
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "replace_object_model");
      SetMessageTuple(hv_MessageHandle, "index", ((HTuple(1).Append(2)).Append(3)));
      SetMessageTuple(hv_MessageHandle, "model", (hv_OM3DModelEdges.TupleConcat(hv_OM3DSphere)).TupleConcat(hv_OM3DLineSphereToModel));
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
    }

    process_visualize_events_generic(hv_WindowHandleVisualization, hv_MessageQueues2, 
        hv_CurrentState2, &hv_DidFinish2, &hv_CurrentState2, &hv_ButtonPressed, &hv_Pose);
    if (0 != (hv_ButtonPressed==0))
    {
      hv_DirectionsShown = hv_DirectionsShown.TupleNot();
      //Toggle edge direction, using the normal vectors of the edge
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "toggle_param");
      SetMessageTuple(hv_MessageHandle, "param", "disp_normals_1");
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "change_button_text");
      SetMessageTuple(hv_MessageHandle, "index", 0);
      if (0 != hv_DirectionsShown)
      {
        SetMessageTuple(hv_MessageHandle, "text", "Hide Edge Directions");
      }
      else
      {
        SetMessageTuple(hv_MessageHandle, "text", "Show Edge Directions");
      }
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
    }
  }
  while (0 == (hv_DidFinish1.TupleOr(hv_DidFinish2)));

  //Send termination message to all subthreads
  CreateMessage(&hv_MessageHandle);
  SetMessageTuple(hv_MessageHandle, "type", "exit");
  EnqueueMessage(HTuple(hv_MessageQueues1[1]), hv_MessageHandle, HTuple(), HTuple());
  CreateMessage(&hv_MessageHandle);
  SetMessageTuple(hv_MessageHandle, "type", "exit");
  EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());

  //Wait for all subthreads to finish
  hv_TIT = hvec_TI.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_TIT);
  return;
}

void check_mouse_over_button (HTuple hv_Parameters, HTuple hv_GraphButtonRow, HTuple hv_GraphButtonColumn, 
    HTuple *hv_FoundButton)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_gButtons, hv_idx;

  GetMessageTuple(hv_Parameters, "gButtons", &hv_gButtons);
  (*hv_FoundButton) = -1;
  {
  HTuple end_val2 = (hv_gButtons.TupleLength())-1;
  HTuple step_val2 = 5;
  for (hv_idx=0; hv_idx.Continue(end_val2, step_val2); hv_idx += step_val2)
  {
    if (0 != (HTuple(HTuple(HTuple(hv_GraphButtonRow>=(HTuple(hv_gButtons[hv_idx+2])-1)).TupleAnd(hv_GraphButtonRow<=(HTuple(hv_gButtons[hv_idx+4])+1))).TupleAnd(hv_GraphButtonColumn>=(HTuple(hv_gButtons[hv_idx+1])-1))).TupleAnd(hv_GraphButtonColumn<=(HTuple(hv_gButtons[hv_idx+3])+1))))
    {
      (*hv_FoundButton) = hv_idx;
    }
  }
  }
  return;
}

// Chapter: Calibration / Monocular
// Short Description: Collect the data to calibrate a camera with a single image. 
void collect_single_image_calibration_data (HTuple hv_ImageCaltabFileName, HTuple hv_CalPlateDescr, 
    HTuple hv_CalPlateThickness, HTuple hv_StartCamParam, HTuple *hv_CalibObjectData)
{

  // Local iconic variables
  HObject  ho_ImageCaltab;

  // Local control variables
  HTuple  hv_FinderRow, hv_FinderColumn, hv_MarksPerRow;

  //
  //Read an image of the calibration plate
  //that is placed in the measurement plane of the robot.
  ReadImage(&ho_ImageCaltab, hv_ImageCaltabFileName);
  dev_disp_calibration_data_instructions(ho_ImageCaltab);
  // stop(...); only in hdevelop
  //
  //Specify the finder pattern of the calibration plate you used.
  //The information can usually be found in the used description file.
  hv_FinderRow.Clear();
  hv_FinderRow[0] = 13;
  hv_FinderRow[1] = 6;
  hv_FinderRow[2] = 6;
  hv_FinderRow[3] = 20;
  hv_FinderRow[4] = 20;
  hv_FinderColumn.Clear();
  hv_FinderColumn[0] = 15;
  hv_FinderColumn[1] = 6;
  hv_FinderColumn[2] = 24;
  hv_FinderColumn[3] = 6;
  hv_FinderColumn[4] = 24;
  //Specify the number of marks per row.
  hv_MarksPerRow = 31;
  //
  //Create output message.
  CreateMessage(&(*hv_CalibObjectData));
  SetMessageObj(ho_ImageCaltab, (*hv_CalibObjectData), "ImageCaltab");
  SetMessageTuple((*hv_CalibObjectData), "CalPlateDescr", hv_CalPlateDescr);
  SetMessageTuple((*hv_CalibObjectData), "CalPlateThickness", hv_CalPlateThickness);
  SetMessageTuple((*hv_CalibObjectData), "StartCamParam", hv_StartCamParam);
  SetMessageTuple((*hv_CalibObjectData), "FinderRow", hv_FinderRow);
  SetMessageTuple((*hv_CalibObjectData), "FinderColumn", hv_FinderColumn);
  SetMessageTuple((*hv_CalibObjectData), "MarksPerRow", hv_MarksPerRow);
  return;
}

// Chapter: Graphics / Parameters
void color_string_to_rgb (HTuple hv_Color, HTuple *hv_RGB)
{

  // Local iconic variables
  HObject  ho_Rectangle, ho_Image;

  // Local control variables
  HTuple  hv_WindowHandleBuffer, hv_Exception;

  OpenWindow(0, 0, 1, 1, 0, "buffer", "", &hv_WindowHandleBuffer);
  SetPart(hv_WindowHandleBuffer, 0, 0, -1, -1);
  GenRectangle1(&ho_Rectangle, 0, 0, 0, 0);
  try
  {
    SetColor(hv_WindowHandleBuffer, hv_Color);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_Exception = "Wrong value of control parameter Color (must be a valid color string)";
    throw HException(hv_Exception);
  }
  DispObj(ho_Rectangle, hv_WindowHandleBuffer);
  DumpWindowImage(&ho_Image, hv_WindowHandleBuffer);
  CloseWindow(hv_WindowHandleBuffer);
  GetGrayval(ho_Image, 0, 0, &(*hv_RGB));
  (*hv_RGB) += ((HTuple(0).Append(0)).Append(0));
  return;
}

// Chapter: Graphics / Parameters
void color_string_to_rgb_visualize_object_model_3d (HTuple hv_Color, HTuple *hv_RGB)
{

  // Local iconic variables
  HObject  ho_Rectangle, ho_Image;

  // Local control variables
  HTuple  hv_WindowHandleBuffer, hv_Exception;

  OpenWindow(0, 0, 1, 1, 0, "buffer", "", &hv_WindowHandleBuffer);
  SetPart(hv_WindowHandleBuffer, 0, 0, -1, -1);
  GenRectangle1(&ho_Rectangle, 0, 0, 0, 0);
  try
  {
    SetColor(hv_WindowHandleBuffer, hv_Color);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_Exception = "Wrong value of control parameter Color (must be a valid color string)";
    throw HException(hv_Exception);
  }
  DispObj(ho_Rectangle, hv_WindowHandleBuffer);
  DumpWindowImage(&ho_Image, hv_WindowHandleBuffer);
  CloseWindow(hv_WindowHandleBuffer);
  GetGrayval(ho_Image, 0, 0, &(*hv_RGB));
  (*hv_RGB) += ((HTuple(0).Append(0)).Append(0));
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Compute the TopK error. 
void compute_top_k_error (HTuple hv_DLClassifierHandle, HTuple hv_DLClassifierResultID, 
    HTuple hv_GroundTruthLabels, HTuple hv_Indices, HTuple hv_K, HTuple *hv_TopKError)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumMatches, hv_GroundTruthLabelsSelected;
  HTuple  hv_BatchSize, hv_IndexLabel, hv_CurrentLabel, hv_ResultHandleIndex;
  HTuple  hv_ResultIndex, hv_PredictedClasses;

  //This procedure compares the GroundtruthLabels
  //with the K inferred classes of highest probability,
  //stored in DLClassifierResultID, and returns the TopKError.
  //Indices defines which images (and thus GroundTruthLabels
  //as well as inference results) are considered.
  hv_NumMatches = 0;
  //
  //Select the chosen GroundTruthLabels.
  hv_GroundTruthLabelsSelected = HTuple(hv_GroundTruthLabels[hv_Indices]);
  //
  //Get the batch size from the classifier handle.
  GetDlClassifierParam(hv_DLClassifierHandle, "batch_size", &hv_BatchSize);
  //
  //Loop through all selected ground truth labels.
  {
  HTuple end_val14 = (hv_GroundTruthLabelsSelected.TupleLength())-1;
  HTuple step_val14 = 1;
  for (hv_IndexLabel=0; hv_IndexLabel.Continue(end_val14, step_val14); hv_IndexLabel += step_val14)
  {
    //Get ground truth label.
    hv_CurrentLabel = HTuple(hv_GroundTruthLabelsSelected[hv_IndexLabel]);
    hv_ResultHandleIndex = ((HTuple(hv_Indices[hv_IndexLabel])/hv_BatchSize).TupleFloor()).TupleInt();
    hv_ResultIndex = HTuple(hv_Indices[hv_IndexLabel])%hv_BatchSize;
    GetDlClassifierResult(HTuple(hv_DLClassifierResultID[hv_ResultHandleIndex]), 
        hv_ResultIndex, "predicted_classes", &hv_PredictedClasses);
    //Get the K best results.
    hv_PredictedClasses = hv_PredictedClasses.TupleSelectRange(0,hv_K-1);
    //Count how often the ground truth label
    //and K predicted classes match.
    if (0 != ((hv_PredictedClasses.TupleFind(hv_CurrentLabel))!=-1))
    {
      hv_NumMatches += 1;
    }
  }
  }
  (*hv_TopKError) = 1.0-((hv_NumMatches.TupleReal())/(hv_GroundTruthLabelsSelected.TupleLength()));
  return;
}

// Chapter: Identification / Bar Code
// Short Description: Convert a decoded string of a bar code of type 'Code 39' to the type 'Code 32'. 
void convert_decoded_string_code39_to_code32 (HTuple hv_DecodedDataStringCode39, 
    HTuple *hv_ConvertedDataStringCode32)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Symbols, hv_Digit, hv_CheckDigit, hv_CheckSum;
  HTuple  hv_Value;

  //This procedure converts a decoded string of a 'Code 32'
  //barcode that was read with the bar code reader for 'Code 39'
  //to the 'Code 32' decoding.
  //
  //Basically a 'Code 32' bar code corresponds to a 'Code 39' with
  //8 digits and a checksum digit % 10 whereas even positions are
  //weighted twice.
  //The 9-digit number is represented to the base 32 and written
  //with chars (via the symbol table) analogous to a hexadecimal number.
  //
  //Initialize symbol table
  hv_Symbols.Clear();
  hv_Symbols[0] = "0";
  hv_Symbols[1] = "1";
  hv_Symbols[2] = "2";
  hv_Symbols[3] = "3";
  hv_Symbols[4] = "4";
  hv_Symbols[5] = "5";
  hv_Symbols[6] = "6";
  hv_Symbols[7] = "7";
  hv_Symbols[8] = "8";
  hv_Symbols[9] = "9";
  hv_Symbols[10] = "B";
  hv_Symbols[11] = "C";
  hv_Symbols[12] = "D";
  hv_Symbols[13] = "F";
  hv_Symbols[14] = "G";
  hv_Symbols[15] = "H";
  hv_Symbols[16] = "J";
  hv_Symbols[17] = "K";
  hv_Symbols[18] = "L";
  hv_Symbols[19] = "M";
  hv_Symbols[20] = "N";
  hv_Symbols[21] = "P";
  hv_Symbols[22] = "Q";
  hv_Symbols[23] = "R";
  hv_Symbols[24] = "S";
  hv_Symbols[25] = "T";
  hv_Symbols[26] = "U";
  hv_Symbols[27] = "V";
  hv_Symbols[28] = "W";
  hv_Symbols[29] = "X";
  hv_Symbols[30] = "Y";
  hv_Symbols[31] = "Z";
  //Check the chars in the decoded 'Code 39' string.
  //It must consist of exactly 6 chars and must not
  //contain any invalid chars. If these conditions are
  //fulfilled, convert the string to 'Code 32', else
  //return an empty string.
  if (0 != (hv_DecodedDataStringCode39.TupleRegexpTest(("^["+(hv_Symbols.TupleSum()))+"]{6}$")))
  {
    //
    //Convert the value of each digit in the decoded 'Code 39' string
    (*hv_ConvertedDataStringCode32) = 0;
    for (hv_Digit=0; hv_Digit<=5; hv_Digit+=1)
    {
      (*hv_ConvertedDataStringCode32) += hv_Symbols.TupleFind(hv_DecodedDataStringCode39.TupleStrBitSelect(hv_Digit));
      if (0 != (hv_Digit<5))
      {
        (*hv_ConvertedDataStringCode32) = (*hv_ConvertedDataStringCode32)*32;
      }
    }
    //Write the converted string as 9 digit string with leading zeros
    (*hv_ConvertedDataStringCode32) = (*hv_ConvertedDataStringCode32).TupleString("9.9d");
    //
    //Verify the checksum (last digit)
    hv_CheckDigit = ((*hv_ConvertedDataStringCode32).TupleStrBitSelect(8)).TupleNumber();
    hv_CheckSum = 0;
    for (hv_Digit=0; hv_Digit<=7; hv_Digit+=1)
    {
      //Sum first 8 digits, but even digits have weight 2
      hv_Value = (1+(hv_Digit%2))*(((*hv_ConvertedDataStringCode32).TupleStrBitSelect(hv_Digit)).TupleNumber());
      //But actually we only want the cross digit sum,
      //This 'formula' works for 0-19
      if (0 != (hv_Value>=10))
      {
        hv_Value = hv_Value-9;
      }
      hv_CheckSum += hv_Value;
    }
    hv_CheckSum = hv_CheckSum%10;
    //
    //If the checksum fits, return the converted 'Code 32' string,
    //else return an empty string
    if (0 != (hv_CheckDigit!=hv_CheckSum))
    {
      //Bad checksum
      (*hv_ConvertedDataStringCode32) = "";
    }
    else
    {
      //Always printed with leading A
      (*hv_ConvertedDataStringCode32) = "A"+(*hv_ConvertedDataStringCode32);
    }
  }
  else
  {
    //Wrong number of chars or invalid chars
    (*hv_ConvertedDataStringCode32) = "";
  }
  return;
  //
}

void create_visualization_message_queues (HTuple *hv_MessageQueues)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_QueueHandleInMouse, hv_QueueHandleInEvents;
  HTuple  hv_QueueHandleOut;

  CreateMessageQueue(&hv_QueueHandleInMouse);
  CreateMessageQueue(&hv_QueueHandleInEvents);
  CreateMessageQueue(&hv_QueueHandleOut);
  SetMessageQueueParam(hv_QueueHandleInMouse, "max_message_num", 1);
  (*hv_MessageQueues).Clear();
  (*hv_MessageQueues).Append(hv_QueueHandleInMouse);
  (*hv_MessageQueues).Append(hv_QueueHandleInEvents);
  (*hv_MessageQueues).Append(hv_QueueHandleOut);
  return;

}

// Chapter: 3D Matching / Surface-Based
// Short Description: Inspect the parameters for surface-based matching. 
void debug_find_surface_model (HTuple hv_SurfaceModelID, HTuple hv_ObjectModel3DModel, 
    HTuple hv_ObjectModel3DScene, HTuple hv_SurfaceMatchingResultID, HTuple *hv_CreateSurfaceModelParamName, 
    HTuple *hv_CreateSurfaceModelParamValue, HTuple *hv_FindSurfaceModelParamName, 
    HTuple *hv_FindSurfaceModelParamValue)
{

  // Local iconic variables
  HObject  ho_MenuRegions;

  // Local control variables
  HTuple  hv_WindowScaling, hv_WindowSize, hv_FontSize;
  HTuple  hv_WidthMenu, hv_HeightMenu, hv_WindowHandleMenu;
  HTuple  hv_Row, hv_Column, hv_Width, hv_Height, hv_HasEdges;
  HTuple  hv_MenuText, hv_MenuCode, hv_TopBottom, hv_NumCols;
  HTuple  hv_NumRows, hv_PercentageHeight, hv_CheckedCase;
  HTuple  hv_Case, hv_RowButtons0, hv_ColumnButtons0, hv_RowButtons1;
  HTuple  hv_ColumnButtons1, hv_MenuBottom, hv_RelSamplingDistance;
  HTuple  hv_KeyPointFraction, hv_MinScore, hv_GenParamNames;
  HTuple  hv_GenParamValues, hv_NumPoses, hv_Pose, hv_Score;
  HTuple  hv_Index, hv_CurrPose, hv_CurrScore, hv_Exception;
  HTuple  hv_CasesDone, hv_CurrentCase, hv_MaxGap, hv_MinAmplitudeAbs;
  HTuple  hv_Viewpoint, hv_UserProvidedEdges, hv_ModelDiameter;
  HTuple  hv_ViewpointStr, hv_MinAmplitudeRel, hv_OM3DProvidedEdges;
  HTuple  hv_NormalParamsSet, hv_Message, hv_WindowHandle1;
  HTuple  hv_WindowHandle2, hv_CreateName, hv_CreateValue;
  HTuple  hv_FindNames, hv_FindValues, hv_EdgeParamsSet;

  //Please adjust the WindowScaling parameter in order to zoom the window size as desired
  hv_WindowScaling = 1.2;
  //
  hv_WindowSize = (512*hv_WindowScaling).TupleInt();
  hv_FontSize = 13.5*hv_WindowScaling;
  //
  hv_WidthMenu = hv_WindowSize*2;
  hv_HeightMenu = hv_WindowSize/3;
  //
  SetWindowAttr("background_color","black");
  OpenWindow(0,0,hv_WidthMenu,hv_HeightMenu,0,"visible","",&hv_WindowHandleMenu);
  HDevWindowStack::Push(hv_WindowHandleMenu);
  //
  GetWindowExtents(hv_WindowHandleMenu, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  set_display_font(hv_WindowHandleMenu, hv_FontSize, "mono", "true", "false");
  //
  //Define the entries in the menu
  GetSurfaceModelParam(hv_SurfaceModelID, "3d_edges_trained", &hv_HasEdges);
  if (0 != ((hv_SurfaceMatchingResultID.TupleLength())==0))
  {
    if (0 != (hv_HasEdges==HTuple("true")))
    {
      hv_MenuText.Clear();
      hv_MenuText[0] = "Automatic Value Check";
      hv_MenuText[1] = "Inspect Model Edges";
      hv_MenuText[2] = "Exit";
      hv_MenuCode.Clear();
      hv_MenuCode[0] = "check";
      hv_MenuCode[1] = "model_edges";
      hv_MenuCode[2] = "exit";
    }
    else
    {
      hv_MenuText.Clear();
      hv_MenuText[0] = "Automatic Value Check";
      hv_MenuText[1] = "Normal Directions";
      hv_MenuText[2] = "Exit";
      hv_MenuCode.Clear();
      hv_MenuCode[0] = "check";
      hv_MenuCode[1] = "normals";
      hv_MenuCode[2] = "exit";
    }
  }
  else
  {
    if (0 != (hv_HasEdges==HTuple("true")))
    {
      hv_MenuText.Clear();
      hv_MenuText[0] = "Automatic Value Check";
      hv_MenuText[1] = "Inspect Model Edges";
      hv_MenuText[2] = "Normal Directions";
      hv_MenuText[3] = "3D Edge Extraction";
      hv_MenuText[4] = "3D Edge Directions";
      hv_MenuText[5] = "Matching Results";
      hv_MenuText[6] = "Exit";
      hv_MenuCode.Clear();
      hv_MenuCode[0] = "check";
      hv_MenuCode[1] = "model_edges";
      hv_MenuCode[2] = "normals";
      hv_MenuCode[3] = "scene_edge_params";
      hv_MenuCode[4] = "scene_edge_dirs";
      hv_MenuCode[5] = "results";
      hv_MenuCode[6] = "exit";
    }
    else
    {
      hv_MenuText.Clear();
      hv_MenuText[0] = "Automatic Value Check";
      hv_MenuText[1] = "Normal Directions";
      hv_MenuText[2] = "Matching Results";
      hv_MenuText[3] = "Exit";
      hv_MenuCode.Clear();
      hv_MenuCode[0] = "check";
      hv_MenuCode[1] = "normals";
      hv_MenuCode[2] = "results";
      hv_MenuCode[3] = "exit";
    }
  }
  //Generate the menu buttons
  hv_TopBottom = "top";
  hv_NumCols = 4;
  hv_NumRows = 1+(((hv_MenuText.TupleLength())-1)/hv_NumCols);
  hv_PercentageHeight = 20*hv_NumRows;
  hv_CheckedCase = hv_NumCols+1;
  hv_Case = hv_NumCols+1;
  gen_menu_regions_ext(&ho_MenuRegions, hv_TopBottom, hv_WindowHandleMenu, hv_PercentageHeight, 
      hv_NumRows, hv_NumCols);
  //
  SmallestRectangle1(ho_MenuRegions, &hv_RowButtons0, &hv_ColumnButtons0, &hv_RowButtons1, 
      &hv_ColumnButtons1);
  hv_MenuBottom = hv_RowButtons1.TupleMax();
  SetTposition(hv_WindowHandleMenu, hv_MenuBottom+6, 1);
  write_note(hv_WindowHandleMenu, "instruction", "Handlungsanweisung");
  //
  if (0 != ((hv_SurfaceMatchingResultID.TupleLength())>0))
  {
    try
    {
      GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "sampling_rate", 0, &hv_RelSamplingDistance);
      GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "refpt_rate", 0, &hv_KeyPointFraction);
      GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "min_score", 0, &hv_MinScore);
      GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "param_names", 0, &hv_GenParamNames);
      GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "param_values", 0, &hv_GenParamValues);
      GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "num_poses", 0, &hv_NumPoses);
      hv_Pose = HTuple();
      hv_Score = HTuple();
      {
      HTuple end_val57 = hv_NumPoses-1;
      HTuple step_val57 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val57, step_val57); hv_Index += step_val57)
      {
        GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "pose", hv_Index, &hv_CurrPose);
        hv_Pose = hv_Pose.TupleConcat(hv_CurrPose);
        GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "score", hv_Index, &hv_CurrScore);
        hv_Score = hv_Score.TupleConcat(hv_CurrScore);
      }
      }
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      //Result handle is invalid, or we are in an unsupported HALCON version
      HDevWindowStack::SetActive(hv_WindowHandleMenu);
      if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
      disp_message(hv_WindowHandleMenu, HTuple("Error: This version of HALCON is not supported by this procedure, or the given result handle\n was not created with find_surface_model"), 
          "window", 12, 12, "red", "false");
      wait_continue_button(hv_WindowHandleMenu);
      if (HDevWindowStack::IsOpen())
        CloseWindow(HDevWindowStack::Pop());
      return;
    }
    if (0 != (hv_RelSamplingDistance==0))
    {
      HDevWindowStack::SetActive(hv_WindowHandleMenu);
      if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
      disp_message(hv_WindowHandleMenu, "Error: The given result handle was not created with find_surface_model. Please pass a result handle\n created by find_surface_model.", 
          "window", 12, 12, "red", "false");
      wait_continue_button(hv_WindowHandleMenu);
      if (HDevWindowStack::IsOpen())
        CloseWindow(HDevWindowStack::Pop());
      return;
    }
  }
  else
  {
    hv_GenParamNames = HTuple();
    hv_GenParamValues = HTuple();
  }
  //
  hv_CasesDone = HTuple();
  hv_CurrentCase = HTuple();
  //
  //Find the parameters used for the edge extraction
  hv_MaxGap = HTuple();
  hv_MinAmplitudeAbs = HTuple();
  hv_Viewpoint = HTuple();
  hv_UserProvidedEdges = 0;
  if (0 != (HTuple(hv_HasEdges==HTuple("true")).TupleAnd((hv_SurfaceMatchingResultID.TupleLength())>0)))
  {
    GetSurfaceModelParam(hv_SurfaceModelID, "diameter", &hv_ModelDiameter);
    get_find_parameter(hv_GenParamNames, hv_GenParamValues, "viewpoint", "0 0 0", 
        &hv_ViewpointStr);
    hv_Viewpoint = (hv_ViewpointStr.TupleSplit(" ")).TupleNumber();
    get_find_parameter(hv_GenParamNames, hv_GenParamValues, "max_gap", 30, &hv_MaxGap);
    get_find_parameter(hv_GenParamNames, hv_GenParamValues, "3d_edge_min_amplitude_rel", 
        HTuple(), &hv_MinAmplitudeRel);
    if (0 != (hv_MinAmplitudeRel!=HTuple()))
    {
      hv_MinAmplitudeAbs = hv_MinAmplitudeRel*hv_ModelDiameter;
    }
    else
    {
      get_find_parameter(hv_GenParamNames, hv_GenParamValues, "3d_edge_min_amplitude_abs", 
          0.05*hv_ModelDiameter, &hv_MinAmplitudeAbs);
    }
    //
    get_find_parameter(hv_GenParamNames, hv_GenParamValues, "3d_edges", HTuple(), 
        &hv_OM3DProvidedEdges);
    hv_UserProvidedEdges = (hv_OM3DProvidedEdges.TupleLength())>0;
  }
  hv_NormalParamsSet = 0;
  //
  while (0 != 1)
  {
    ClearWindow(hv_WindowHandleMenu);
    disp_menu_ext(ho_MenuRegions, hv_WindowHandleMenu, hv_MenuText, hv_CasesDone, 
        HTuple());
    SetTposition(hv_WindowHandleMenu, hv_MenuBottom+6, 1);
    write_note(hv_WindowHandleMenu, "info", "Please consider the limitations of this procedure as described in its documentation.");
    write_note(hv_WindowHandleMenu, "instruction", "Select a test from above. It is recommended to start with the Automatic Value Check.");
    if (0 != ((hv_SurfaceMatchingResultID.TupleLength())==0))
    {
      write_note(hv_WindowHandleMenu, "warning", HTuple("No result handle was provided. To enable more tests, run find_surface_model() with 'ReturnResultHandle' set to 'true' beforehand and pass the result handle to this procedure."));
    }
    if (0 != hv_UserProvidedEdges)
    {
      write_note(hv_WindowHandleMenu, "warning", HTuple("Edges were passed to find_surface_model manually with the '3d_edges' parameter. Some checks of scene edges might be incorrect, since they assume that edges are extracted by find_surface_model."));
    }
    select_case(ho_MenuRegions, hv_WindowHandleMenu, hv_MenuText, &hv_CurrentCase);
    if (0 != (hv_CurrentCase==-1))
    {
      //Window was closed -> abort
      break;
    }
    if (0 != (HTuple(hv_MenuCode[hv_CurrentCase])==HTuple("exit")))
    {
      break;
    }
    TupleUnion(hv_CasesDone, hv_CurrentCase, &hv_CasesDone);
    disp_menu_ext(ho_MenuRegions, hv_WindowHandleMenu, hv_MenuText, hv_CasesDone, 
        hv_CurrentCase);
    //
    //****************************
    //Inspect Normal Directions *
    //****************************
    if (0 != (HTuple(hv_MenuCode[hv_CurrentCase])==HTuple("normals")))
    {
      HDevWindowStack::SetActive(hv_WindowHandleMenu);
      SetTposition(hv_WindowHandleMenu, hv_MenuBottom+6, 1);
      hv_Message = HTuple("Check visually, if the normals of the model point approximately in the same direction as the normals of the scene by moving the model and the scene accordingly");
      write_note(hv_WindowHandleMenu, "instruction", hv_Message);
      //
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,0,hv_WindowSize,hv_WindowSize,0,"visible","",&hv_WindowHandle1);
      HDevWindowStack::Push(hv_WindowHandle1);
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,hv_WindowSize,hv_WindowSize,hv_WindowSize,0,"visible","",&hv_WindowHandle2);
      HDevWindowStack::Push(hv_WindowHandle2);
      set_display_font(hv_WindowHandle1, hv_FontSize, "mono", "true", "false");
      set_display_font(hv_WindowHandle2, hv_FontSize, "mono", "true", "false");
      //
      inspect_normal_direction(ho_MenuRegions, hv_WindowHandle1, hv_WindowHandle2, 
          hv_WindowHandleMenu, hv_SurfaceModelID, hv_ObjectModel3DScene, hv_RelSamplingDistance, 
          hv_KeyPointFraction, hv_MinScore, hv_GenParamNames, hv_GenParamValues, 
          hv_SurfaceMatchingResultID, hv_MenuText, hv_CurrentCase, hv_CasesDone, 
          hv_FontSize, &hv_CreateName, &hv_CreateValue, &hv_FindNames, &hv_FindValues);
      hv_NormalParamsSet = 1;
      //
      dev_close_window_if_open(hv_WindowHandle1);
      dev_close_window_if_open(hv_WindowHandle2);
    }
    //
    //***************************
    //Check the data structure *
    //***************************
    //
    if (0 != (HTuple(hv_MenuCode[hv_CurrentCase])==HTuple("check")))
    {
      //Update the visualization of the menue
      HDevWindowStack::SetActive(hv_WindowHandleMenu);
      SetTposition(hv_WindowHandleMenu, hv_MenuBottom+6, 1);
      write_note(hv_WindowHandleMenu, "instruction", "Please wait while an automatic check of parameters and values is performed");
      //
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,0,hv_WindowSize*2,hv_WindowSize,0,"visible","",&hv_WindowHandle1);
      HDevWindowStack::Push(hv_WindowHandle1);
      set_display_font(hv_WindowHandle1, hv_FontSize, "mono", "true", "false");
      //
      check_find_surface_model_params(hv_WindowHandle1, hv_SurfaceModelID, hv_ObjectModel3DScene, 
          hv_GenParamNames, hv_GenParamValues);
      //
      dev_close_window_if_open(hv_WindowHandle1);
    }
    //
    //****************
    //Prepare edges *
    //****************
    //
    if (0 != (HTuple(hv_MenuCode[hv_CurrentCase])==HTuple("scene_edge_params")))
    {
      HDevWindowStack::SetActive(hv_WindowHandleMenu);
      SetTposition(hv_WindowHandleMenu, hv_MenuBottom+6, 1);
      hv_Message = "Find the 3D edges by adjusting the MinAmplitude and the MaxGap accordingly";
      write_note(hv_WindowHandleMenu, "instruction", hv_Message);
      //
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,0,hv_WindowSize,hv_WindowSize,0,"visible","",&hv_WindowHandle1);
      HDevWindowStack::Push(hv_WindowHandle1);
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,hv_WindowSize,hv_WindowSize,hv_WindowSize,0,"visible","",&hv_WindowHandle2);
      HDevWindowStack::Push(hv_WindowHandle2);
      set_display_font(hv_WindowHandle1, hv_FontSize, "mono", "true", "false");
      set_display_font(hv_WindowHandle2, hv_FontSize, "mono", "true", "false");
      //
      inspect_scene_edge_parameters(hv_WindowHandle1, hv_WindowHandle2, hv_SurfaceModelID, 
          hv_ObjectModel3DScene, hv_SurfaceMatchingResultID, hv_MaxGap, hv_MinAmplitudeAbs, 
          hv_Viewpoint, &hv_MaxGap, &hv_MinAmplitudeAbs);
      hv_EdgeParamsSet = 1;
      //
      dev_close_window_if_open(hv_WindowHandle1);
      dev_close_window_if_open(hv_WindowHandle2);
    }
    //
    //******************
    //Edge Directions *
    //******************
    //
    if (0 != (HTuple(hv_MenuCode[hv_CurrentCase])==HTuple("scene_edge_dirs")))
    {
      HDevWindowStack::SetActive(hv_WindowHandleMenu);
      SetTposition(hv_WindowHandleMenu, hv_MenuBottom+6, 1);
      hv_Message = HTuple(HTuple("Move the left view such that you see the scene from the direction of the sensor (viewpoint, default is [0,0,0]). ")+HTuple("The right view shows the extracted edges, viewing directions (green) and edge directions (red). The viewing directions show away from the viewpoint. "))+"The edge directions should be perpendicular to the edges and point outward.";
      write_note(hv_WindowHandleMenu, "instruction", hv_Message);
      //
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,0,hv_WindowSize,hv_WindowSize,0,"visible","",&hv_WindowHandle1);
      HDevWindowStack::Push(hv_WindowHandle1);
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,hv_WindowSize,hv_WindowSize,hv_WindowSize,0,"visible","",&hv_WindowHandle2);
      HDevWindowStack::Push(hv_WindowHandle2);
      set_display_font(hv_WindowHandle1, hv_FontSize, "mono", "true", "false");
      set_display_font(hv_WindowHandle2, hv_FontSize, "mono", "true", "false");
      //
      inspect_scene_edge_directions(hv_WindowHandle1, hv_WindowHandle2, hv_SurfaceModelID, 
          hv_ObjectModel3DScene, hv_SurfaceMatchingResultID, hv_MaxGap, hv_MinAmplitudeAbs, 
          hv_Viewpoint, &hv_Viewpoint);
      //
      dev_close_window_if_open(hv_WindowHandle1);
      dev_close_window_if_open(hv_WindowHandle2);
    }
    //
    //***************************
    //Inspect Model Edges      *
    //***************************
    //
    if (0 != (HTuple(hv_MenuCode[hv_CurrentCase])==HTuple("model_edges")))
    {
      //Update the visualization of the menue
      HDevWindowStack::SetActive(hv_WindowHandleMenu);
      SetTposition(hv_WindowHandleMenu, hv_MenuBottom+6, 1);
      write_note(hv_WindowHandleMenu, "info", "This tool allows to inspect the edges that create_surface_model found in the object.");
      write_note(hv_WindowHandleMenu, "instruction", "Use the left window to move the viewpoint and the right window to inspect the edges.");
      write_note(hv_WindowHandleMenu, "info", "The visualized \"edge directions\" should be perpendicular to the direction of the model edges and point outward.");
      //
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,0,hv_WindowSize,hv_WindowSize,0,"visible","",&hv_WindowHandle1);
      HDevWindowStack::Push(hv_WindowHandle1);
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,hv_WindowSize,hv_WindowSize,hv_WindowSize,0,"visible","",&hv_WindowHandle2);
      HDevWindowStack::Push(hv_WindowHandle2);
      set_display_font(hv_WindowHandle1, hv_FontSize, "mono", "true", "false");
      set_display_font(hv_WindowHandle2, hv_FontSize, "mono", "true", "false");
      //
      check_model_edges(hv_SurfaceModelID, hv_ObjectModel3DModel, hv_WindowHandle1, 
          hv_WindowHandle2);
      //
      dev_close_window_if_open(hv_WindowHandle1);
      dev_close_window_if_open(hv_WindowHandle2);
    }
    //
    //***************************
    //Inspect Matching Results *
    //***************************
    //
    if (0 != (HTuple(hv_MenuCode[hv_CurrentCase])==HTuple("results")))
    {
      //Update the visualization of the menue
      HDevWindowStack::SetActive(hv_WindowHandleMenu);
      SetTposition(hv_WindowHandleMenu, hv_MenuBottom+6, 1);
      write_note(hv_WindowHandleMenu, "instruction", "Inspect the matching results below.");
      //
      SetWindowAttr("background_color","black");
      OpenWindow(hv_HeightMenu+50,0,hv_WindowSize,hv_WindowSize,0,"visible","",&hv_WindowHandle1);
      HDevWindowStack::Push(hv_WindowHandle1);
      set_display_font(hv_WindowHandle1, hv_FontSize, "mono", "true", "false");
      //
      dev_display_surface_matching_results(hv_WindowHandle1, hv_SurfaceMatchingResultID, 
          hv_ObjectModel3DModel, hv_ObjectModel3DScene, hv_Score, hv_Pose, hv_HasEdges);
      //
      dev_close_window_if_open(hv_WindowHandle1);
    }
  }
  //
  dev_close_window_if_open(hv_WindowHandleMenu);
  //
  //Construct the parameters
  (*hv_CreateSurfaceModelParamName) = HTuple();
  (*hv_CreateSurfaceModelParamValue) = HTuple();
  (*hv_FindSurfaceModelParamName) = HTuple();
  (*hv_FindSurfaceModelParamValue) = HTuple();

  if (0 != hv_NormalParamsSet)
  {
    (*hv_CreateSurfaceModelParamName) = (*hv_CreateSurfaceModelParamName).TupleConcat(hv_CreateName);
    (*hv_CreateSurfaceModelParamValue) = (*hv_CreateSurfaceModelParamValue).TupleConcat(hv_CreateValue);
    (*hv_FindSurfaceModelParamName) = (*hv_FindSurfaceModelParamName).TupleConcat(hv_FindNames);
    (*hv_FindSurfaceModelParamValue) = (*hv_FindSurfaceModelParamValue).TupleConcat(hv_FindValues);
  }

  if (0 != (hv_MaxGap!=HTuple()))
  {
    (*hv_FindSurfaceModelParamName) = (*hv_FindSurfaceModelParamName).TupleConcat((HTuple("3d_edge_min_amplitude_abs").Append("max_gap")));
    (*hv_FindSurfaceModelParamValue) = ((*hv_FindSurfaceModelParamValue).TupleConcat(hv_MinAmplitudeAbs)).TupleConcat(hv_MaxGap);
  }

  if (0 != (hv_Viewpoint!=HTuple()))
  {
    (*hv_FindSurfaceModelParamName) = (*hv_FindSurfaceModelParamName).TupleConcat("viewpoint");
    (*hv_FindSurfaceModelParamValue) = (*hv_FindSurfaceModelParamValue).TupleConcat((((HTuple(hv_Viewpoint[0])+" ")+HTuple(hv_Viewpoint[1]))+" ")+HTuple(hv_Viewpoint[2]));
  }

}

// Chapter: Graphics / Output
// Short Description: Determine the optimum distance of the object to obtain a reasonable visualization 
void determine_optimum_pose_distance (HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_ImageCoverage, HTuple hv_PoseIn, HTuple *hv_PoseOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumModels, hv_Rows, hv_Cols, hv_MinMinZ;
  HTuple  hv_BB, hv_Seq, hv_DXMax, hv_DYMax, hv_DZMax, hv_Diameter;
  HTuple  hv_ZAdd, hv_IBB, hv_BB0, hv_BB1, hv_BB2, hv_BB3;
  HTuple  hv_BB4, hv_BB5, hv_X, hv_Y, hv_Z, hv_PoseInter;
  HTuple  hv_HomMat3D, hv_QX, hv_QY, hv_QZ, hv_Cx, hv_Cy;
  HTuple  hv_DR, hv_DC, hv_MaxDist, hv_HomMat3DRotate, hv_ImageWidth;
  HTuple  hv_ImageHeight, hv_MinImageSize, hv_Zs, hv_ZDiff;
  HTuple  hv_ScaleZ, hv_ZNew;

  //Determine the optimum distance of the object to obtain
  //a reasonable visualization
  //
  hv_NumModels = hv_ObjectModel3DID.TupleLength();
  hv_Rows = HTuple();
  hv_Cols = HTuple();
  hv_MinMinZ = 1e30;
  GetObjectModel3dParams(hv_ObjectModel3DID, "bounding_box1", &hv_BB);
  //Calculate diameter over all objects to be visualized
  hv_Seq = HTuple::TupleGenSequence(0,(hv_BB.TupleLength())-1,6);
  hv_DXMax = (HTuple(hv_BB[hv_Seq+3]).TupleMax())-(HTuple(hv_BB[hv_Seq]).TupleMin());
  hv_DYMax = (HTuple(hv_BB[hv_Seq+4]).TupleMax())-(HTuple(hv_BB[hv_Seq+1]).TupleMin());
  hv_DZMax = (HTuple(hv_BB[hv_Seq+5]).TupleMax())-(HTuple(hv_BB[hv_Seq+2]).TupleMin());
  hv_Diameter = (((hv_DXMax*hv_DXMax)+(hv_DYMax*hv_DYMax))+(hv_DZMax*hv_DZMax)).TupleSqrt();
  if (0 != (((hv_BB.TupleAbs()).TupleSum())==0.0))
  {
    hv_BB.Clear();
    hv_BB.Append(-(HTuple(HTuple::TupleRand(3)*1e-20).TupleAbs()));
    hv_BB.Append(HTuple(HTuple::TupleRand(3)*1e-20).TupleAbs());
  }
  //Allow the visualization of single points or extremely small objects
  hv_ZAdd = 0.0;
  if (0 != ((hv_Diameter.TupleMax())<1e-10))
  {
    hv_ZAdd = 0.01;
  }
  //Set extremely small diameters to 1e-10 to avoid CZ == 0.0, which would lead
  //to projection errors
  if (0 != ((hv_Diameter.TupleMin())<1e-10))
  {
    hv_Diameter = hv_Diameter-(((((hv_Diameter-1e-10).TupleSgn())-1).TupleSgn())*1e-10);
  }
  hv_IBB = HTuple::TupleGenSequence(0,(hv_BB.TupleLength())-1,6);
  hv_BB0 = HTuple(hv_BB[hv_IBB]);
  hv_BB1 = HTuple(hv_BB[hv_IBB+1]);
  hv_BB2 = HTuple(hv_BB[hv_IBB+2]);
  hv_BB3 = HTuple(hv_BB[hv_IBB+3]);
  hv_BB4 = HTuple(hv_BB[hv_IBB+4]);
  hv_BB5 = HTuple(hv_BB[hv_IBB+5]);
  hv_X.Clear();
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB3);
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB3);
  hv_X.Append(hv_BB3);
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB3);
  hv_Y.Clear();
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB4);
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB4);
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB4);
  hv_Y.Append(hv_BB4);
  hv_Z.Clear();
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB5);
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB5);
  hv_Z.Append(hv_BB5);
  hv_Z.Append(hv_BB5);
  hv_PoseInter = hv_PoseIn.TupleReplace(2,(-(hv_Z.TupleMin()))+(2*(hv_Diameter.TupleMax())));
  PoseToHomMat3d(hv_PoseInter, &hv_HomMat3D);
  //Determine the maximum extension of the projection
  AffineTransPoint3d(hv_HomMat3D, hv_X, hv_Y, hv_Z, &hv_QX, &hv_QY, &hv_QZ);
  Project3dPoint(hv_QX, hv_QY, hv_QZ, hv_CamParam, &hv_Rows, &hv_Cols);
  hv_MinMinZ = hv_QZ.TupleMin();
  get_cam_par_data(hv_CamParam, "cx", &hv_Cx);
  get_cam_par_data(hv_CamParam, "cy", &hv_Cy);
  hv_DR = hv_Rows-hv_Cy;
  hv_DC = hv_Cols-hv_Cx;
  hv_DR = (hv_DR.TupleMax())-(hv_DR.TupleMin());
  hv_DC = (hv_DC.TupleMax())-(hv_DC.TupleMin());
  hv_MaxDist = ((hv_DR*hv_DR)+(hv_DC*hv_DC)).TupleSqrt();
  //
  if (0 != (hv_MaxDist<1e-10))
  {
    //If the object has no extension in the above projection (looking along
    //a line), we determine the extension of the object in a rotated view
    HomMat3dRotateLocal(hv_HomMat3D, HTuple(90).TupleRad(), "x", &hv_HomMat3DRotate);
    AffineTransPoint3d(hv_HomMat3DRotate, hv_X, hv_Y, hv_Z, &hv_QX, &hv_QY, &hv_QZ);
    Project3dPoint(hv_QX, hv_QY, hv_QZ, hv_CamParam, &hv_Rows, &hv_Cols);
    hv_DR = hv_Rows-hv_Cy;
    hv_DC = hv_Cols-hv_Cx;
    hv_DR = (hv_DR.TupleMax())-(hv_DR.TupleMin());
    hv_DC = (hv_DC.TupleMax())-(hv_DC.TupleMin());
    hv_MaxDist = (hv_MaxDist.TupleConcat(((hv_DR*hv_DR)+(hv_DC*hv_DC)).TupleSqrt())).TupleMax();
  }
  //
  get_cam_par_data(hv_CamParam, "image_width", &hv_ImageWidth);
  get_cam_par_data(hv_CamParam, "image_height", &hv_ImageHeight);
  hv_MinImageSize = (hv_ImageWidth.TupleConcat(hv_ImageHeight)).TupleMin();
  //
  hv_Z = ((const HTuple&)hv_PoseInter)[2];
  hv_Zs = hv_MinMinZ;
  hv_ZDiff = hv_Z-hv_Zs;
  hv_ScaleZ = hv_MaxDist/(((0.5*hv_MinImageSize)*hv_ImageCoverage)*2.0);
  hv_ZNew = ((hv_ScaleZ*hv_Zs)+hv_ZDiff)+hv_ZAdd;
  (*hv_PoseOut) = hv_PoseInter.TupleReplace(2,hv_ZNew);
  //
  return;
}

// Chapter: Graphics / Output
// Short Description: Determine the optimum distance of the object to obtain a reasonable visualization 
void determine_optimum_pose_distance_visualize_object_model_3d (HTuple hv_ObjectModel3DID, 
    HTuple hv_CamParam, HTuple hv_ImageCoverage, HTuple hv_PoseIn, HTuple *hv_PoseOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumModels, hv_Rows, hv_Cols, hv_MinMinZ;
  HTuple  hv_BB, hv_Seq, hv_DXMax, hv_DYMax, hv_DZMax, hv_Diameter;
  HTuple  hv_ZAdd, hv_IBB, hv_BB0, hv_BB1, hv_BB2, hv_BB3;
  HTuple  hv_BB4, hv_BB5, hv_X, hv_Y, hv_Z, hv_PoseInter;
  HTuple  hv_HomMat3D, hv_QX, hv_QY, hv_QZ, hv_Cx, hv_Cy;
  HTuple  hv_DR, hv_DC, hv_MaxDist, hv_HomMat3DRotate, hv_ImageWidth;
  HTuple  hv_ImageHeight, hv_MinImageSize, hv_Zs, hv_ZDiff;
  HTuple  hv_ScaleZ, hv_ZNew;

  //Determine the optimum distance of the object to obtain
  //a reasonable visualization
  //
  hv_NumModels = hv_ObjectModel3DID.TupleLength();
  hv_Rows = HTuple();
  hv_Cols = HTuple();
  hv_MinMinZ = 1e30;
  GetObjectModel3dParams(hv_ObjectModel3DID, "bounding_box1", &hv_BB);
  //Calculate diameter over all objects to be visualized
  hv_Seq = HTuple::TupleGenSequence(0,(hv_BB.TupleLength())-1,6);
  hv_DXMax = (HTuple(hv_BB[hv_Seq+3]).TupleMax())-(HTuple(hv_BB[hv_Seq]).TupleMin());
  hv_DYMax = (HTuple(hv_BB[hv_Seq+4]).TupleMax())-(HTuple(hv_BB[hv_Seq+1]).TupleMin());
  hv_DZMax = (HTuple(hv_BB[hv_Seq+5]).TupleMax())-(HTuple(hv_BB[hv_Seq+2]).TupleMin());
  hv_Diameter = (((hv_DXMax*hv_DXMax)+(hv_DYMax*hv_DYMax))+(hv_DZMax*hv_DZMax)).TupleSqrt();
  if (0 != (((hv_BB.TupleAbs()).TupleSum())==0.0))
  {
    hv_BB.Clear();
    hv_BB.Append(-(HTuple(HTuple::TupleRand(3)*1e-20).TupleAbs()));
    hv_BB.Append(HTuple(HTuple::TupleRand(3)*1e-20).TupleAbs());
  }
  //Allow the visualization of single points or extremely small objects
  hv_ZAdd = 0.0;
  if (0 != ((hv_Diameter.TupleMax())<1e-10))
  {
    hv_ZAdd = 0.01;
  }
  //Set extremely small diameters to 1e-10 to avoid CZ == 0.0, which would lead
  //to projection errors
  if (0 != ((hv_Diameter.TupleMin())<1e-10))
  {
    hv_Diameter = hv_Diameter-(((((hv_Diameter-1e-10).TupleSgn())-1).TupleSgn())*1e-10);
  }
  hv_IBB = HTuple::TupleGenSequence(0,(hv_BB.TupleLength())-1,6);
  hv_BB0 = HTuple(hv_BB[hv_IBB]);
  hv_BB1 = HTuple(hv_BB[hv_IBB+1]);
  hv_BB2 = HTuple(hv_BB[hv_IBB+2]);
  hv_BB3 = HTuple(hv_BB[hv_IBB+3]);
  hv_BB4 = HTuple(hv_BB[hv_IBB+4]);
  hv_BB5 = HTuple(hv_BB[hv_IBB+5]);
  hv_X.Clear();
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB3);
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB3);
  hv_X.Append(hv_BB3);
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB3);
  hv_Y.Clear();
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB4);
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB4);
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB4);
  hv_Y.Append(hv_BB4);
  hv_Z.Clear();
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB5);
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB5);
  hv_Z.Append(hv_BB5);
  hv_Z.Append(hv_BB5);
  hv_PoseInter = hv_PoseIn.TupleReplace(2,(-(hv_Z.TupleMin()))+(2*(hv_Diameter.TupleMax())));
  PoseToHomMat3d(hv_PoseInter, &hv_HomMat3D);
  //Determine the maximum extension of the projection
  AffineTransPoint3d(hv_HomMat3D, hv_X, hv_Y, hv_Z, &hv_QX, &hv_QY, &hv_QZ);
  Project3dPoint(hv_QX, hv_QY, hv_QZ, hv_CamParam, &hv_Rows, &hv_Cols);
  hv_MinMinZ = hv_QZ.TupleMin();
  get_cam_par_data(hv_CamParam, "cx", &hv_Cx);
  get_cam_par_data(hv_CamParam, "cy", &hv_Cy);
  hv_DR = hv_Rows-hv_Cy;
  hv_DC = hv_Cols-hv_Cx;
  hv_DR = (hv_DR.TupleMax())-(hv_DR.TupleMin());
  hv_DC = (hv_DC.TupleMax())-(hv_DC.TupleMin());
  hv_MaxDist = ((hv_DR*hv_DR)+(hv_DC*hv_DC)).TupleSqrt();
  //
  if (0 != (hv_MaxDist<1e-10))
  {
    //If the object has no extension in the above projection (looking along
    //a line), we determine the extension of the object in a rotated view
    HomMat3dRotateLocal(hv_HomMat3D, HTuple(90).TupleRad(), "x", &hv_HomMat3DRotate);
    AffineTransPoint3d(hv_HomMat3DRotate, hv_X, hv_Y, hv_Z, &hv_QX, &hv_QY, &hv_QZ);
    Project3dPoint(hv_QX, hv_QY, hv_QZ, hv_CamParam, &hv_Rows, &hv_Cols);
    hv_DR = hv_Rows-hv_Cy;
    hv_DC = hv_Cols-hv_Cx;
    hv_DR = (hv_DR.TupleMax())-(hv_DR.TupleMin());
    hv_DC = (hv_DC.TupleMax())-(hv_DC.TupleMin());
    hv_MaxDist = (hv_MaxDist.TupleConcat(((hv_DR*hv_DR)+(hv_DC*hv_DC)).TupleSqrt())).TupleMax();
  }
  //
  get_cam_par_data(hv_CamParam, "image_width", &hv_ImageWidth);
  get_cam_par_data(hv_CamParam, "image_height", &hv_ImageHeight);
  hv_MinImageSize = (hv_ImageWidth.TupleConcat(hv_ImageHeight)).TupleMin();
  //
  hv_Z = ((const HTuple&)hv_PoseInter)[2];
  hv_Zs = hv_MinMinZ;
  hv_ZDiff = hv_Z-hv_Zs;
  hv_ScaleZ = hv_MaxDist/(((0.5*hv_MinImageSize)*hv_ImageCoverage)*2.0);
  hv_ZNew = ((hv_ScaleZ*hv_Zs)+hv_ZDiff)+hv_ZAdd;
  (*hv_PoseOut) = hv_PoseInter.TupleReplace(2,hv_ZNew);
  //
  return;
}

void determine_visualization_pose_distance_aligned_with_y_axis (HTuple hv_ObjectModel3DRigidTrans5Tmp, 
    HTuple hv_WindowHandle1, HTuple *hv_PoseEstimatedDistance, HTuple *hv_Center)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_PoseCenterScene, hv_ObjectModel3DRigidTrans4;
  HTuple  hv_PoseRot, hv_ObjectModel3DRigidTrans5, hv_PoseTrans;
  HTuple  hv_ObjectModel3DRigidTrans6, hv_ObjectModel3D0;
  HTuple  hv_UnionObjectModel3D1, hv_RowNotUsed, hv_ColumnNotUsed;
  HTuple  hv_Width, hv_Height, hv_CamParam;

  get_object_models_center(hv_ObjectModel3DRigidTrans5Tmp, &(*hv_Center));
  CreatePose(-HTuple((*hv_Center)[0]), -HTuple((*hv_Center)[1]), -HTuple((*hv_Center)[2]), 
      0, 0, 0, "Rp+T", "gba", "point", &hv_PoseCenterScene);
  RigidTransObjectModel3d(hv_ObjectModel3DRigidTrans5Tmp, hv_PoseCenterScene, &hv_ObjectModel3DRigidTrans4);
  hv_PoseRot.Clear();
  hv_PoseRot[0] = 0;
  hv_PoseRot[1] = 0;
  hv_PoseRot[2] = 0;
  hv_PoseRot[3] = 90;
  hv_PoseRot[4] = 0;
  hv_PoseRot[5] = 0;
  hv_PoseRot[6] = 0;
  RigidTransObjectModel3d(hv_ObjectModel3DRigidTrans4, hv_PoseRot, &hv_ObjectModel3DRigidTrans5);
  hv_PoseTrans.Clear();
  hv_PoseTrans.Append(HTuple((*hv_Center)[0]));
  hv_PoseTrans.Append(HTuple((*hv_Center)[2]));
  hv_PoseTrans.Append(HTuple((*hv_Center)[1]));
  hv_PoseTrans.Append(0);
  hv_PoseTrans.Append(0);
  hv_PoseTrans.Append(0);
  hv_PoseTrans.Append(0);
  RigidTransObjectModel3d(hv_ObjectModel3DRigidTrans5, hv_PoseTrans, &hv_ObjectModel3DRigidTrans6);
  GenObjectModel3dFromPoints(0, 0, 0, &hv_ObjectModel3D0);
  UnionObjectModel3d(hv_ObjectModel3D0.TupleConcat(hv_ObjectModel3DRigidTrans6), 
      "points_surface", &hv_UnionObjectModel3D1);
  //
  GetWindowExtents(hv_WindowHandle1, &hv_RowNotUsed, &hv_ColumnNotUsed, &hv_Width, 
      &hv_Height);
  gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
      hv_Width, hv_Height, &hv_CamParam);
  determine_optimum_pose_distance(hv_UnionObjectModel3D1, hv_CamParam, 0.9, hv_PoseCenterScene, 
      &(*hv_PoseEstimatedDistance));
  return;
}

// Short Description: Closes the window if it is still open. 
void dev_close_window_if_open (HTuple hv_WindowHandle)
{

  // Local control variables
  HTuple  hv_CurrWindowHandle;

  HDevWindowStack::SetActive(hv_WindowHandle);
  if (HDevWindowStack::IsOpen())
    hv_CurrWindowHandle = HDevWindowStack::GetActive();
  if (0 != (hv_CurrWindowHandle==hv_WindowHandle))
  {
    if (HDevWindowStack::IsOpen())
      CloseWindow(HDevWindowStack::Pop());
  }
  return;
}

// Chapter: Graphics / Text
void dev_disp_approach_pose_touching_point_instructions (HTuple hv_WindowHandle, 
    HTuple hv_WindowHandleGraphics, HTuple hv_Index)
{

  // Local iconic variables
  HObject  ho_Image, ho_Rectangle;

  // Local control variables
  HTuple  hv_Text, hv_Color, hv_HighlighColumn;

  //
  HDevWindowStack::SetActive(hv_WindowHandle);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  hv_Text = "Calibrate touching point";
  hv_Text[1] = "";
  hv_Text[2] = "General workflow";
  hv_Text[3] = "----------------";
  hv_Text[4] = HTuple("Approach a fixed point in the plane with your gripper, and read the");
  hv_Text[5] = "pose as ToolInBasePoseTouchingPoint.";
  hv_Text[6] = HTuple("Then, approach the same point at least twice again, rotating the tool");
  hv_Text[7] = "around at least two axis and reading the corresponding ";
  hv_Text[8] = "ToolInBasePoseTouchingPoint.";
  hv_Text[9] = "";
  hv_Text[10] = ("Read ToolInBasePoseTouchingPoint "+hv_Index)+HTuple("/3, then press F5.");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "white", 
        "box", "false");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  hv_Color = HTuple(3,"gray");
  hv_Color[hv_Index-1] = "#fbba00";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"   1   ", "window", 255, 12, "black", 
        (HTuple("box_color").Append("shadow")), HTuple(hv_Color[0]).TupleConcat("false"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"   2   ", "window", 255, 112, "black", 
        (HTuple("box_color").Append("shadow")), HTuple(hv_Color[1]).TupleConcat("false"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"   3   ", "window", 255, 212, "black", 
        (HTuple("box_color").Append("shadow")), HTuple(hv_Color[2]).TupleConcat("false"));
  //
  HDevWindowStack::SetActive(hv_WindowHandleGraphics);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  ReadImage(&ho_Image, "3d_machine_vision/hand_eye/instruction_images/tool_in_base_pose_touching_point");
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  hv_HighlighColumn = 255+(hv_Index*200);
  GenRectangle1(&ho_Rectangle, 320, hv_HighlighColumn-100, 630, hv_HighlighColumn+100);
  if (HDevWindowStack::IsOpen())
    SetLineWidth(HDevWindowStack::GetActive(),4);
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"margin");
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),"#fbba00");
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Rectangle, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Read this pose", "image", 6350, hv_HighlighColumn-105, 
        "black", "box_color", "#fbba00");
  return;
}

// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions (HObject ho_Image)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Text;

  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  hv_Text = HTuple("In the code, please");
  hv_Text[1] = HTuple("- read an image of a calibration plate in the measurement plane,");
  hv_Text[2] = HTuple("- specify the location of the calibration plate description file,");
  hv_Text[3] = "- specify the thickness of the calibration plate (in meters) and";
  hv_Text[4] = "- specify initial camera parameters.";
  hv_Text[5] = "";
  hv_Text[6] = HTuple(" (If you did NOT use a standard HALCON calibration plate, ");
  hv_Text[7] = HTuple("  but used create_caltab to create your own calibration plate,");
  hv_Text[8] = HTuple("  you also need to adapt the parameters FinderRow, FinderColumn,");
  hv_Text[9] = "  and MarksPerRow accordingly.)";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        HTuple(), HTuple());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  return;
}

// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions2 (HObject ho_Image)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Text;

  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  hv_Text = HTuple("If you did NOT use a standard HALCON calibration plate, ");
  hv_Text[1] = HTuple("but used create_caltab to create your own calibration plate,");
  hv_Text[2] = HTuple("please adapt the parameters FinderRow, FinderColumn, and MarksPerRow");
  hv_Text[3] = "in the code.";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        HTuple(), HTuple());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  return;
}

// Chapter: Graphics / Text
// Short Description: Display the introduction for the procedure calibrate_robot_touching_point. 
void dev_disp_introduction (HTuple hv_WindowHandle, HTuple hv_WindowHandleGraphics)
{

  // Local iconic variables
  HObject  ho_InstructionImage;

  // Local control variables
  HTuple  hv_Text, hv_Row, hv_Column, hv_Width;
  HTuple  hv_Height;

  //
  HDevWindowStack::SetActive(hv_WindowHandle);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  hv_Text = HTuple("With this procedure, we calibrate the coordinates of the touching point");
  hv_Text[1] = "of a robot with respect to the robot's tool.";
  hv_Text[2] = "";
  hv_Text[3] = "The touching point is a point that has to be fixed with respect to";
  hv_Text[4] = HTuple("the tool coordinate system, but does not have to be located on the");
  hv_Text[5] = HTuple("surface of the gripper. It can, for example, lie halfway between");
  hv_Text[6] = "two fingers of a gripper.";
  hv_Text[7] = "";
  hv_Text[8] = "The touching point should be chosen such that it can approach ";
  hv_Text[9] = "a point in the plane easily and accurately.";
  hv_Text[10] = "";
  hv_Text[11] = "The coordinates of this point (RobotTouchingPointInToolCoordinates)";
  hv_Text[12] = HTuple("are necessary, for example, to perform a hand-eye calibration of a robot");
  hv_Text[13] = "with a stationary camera.";
  hv_Text[14] = "";
  hv_Text[15] = "This procedure is used in the example";
  hv_Text[16] = "calibrate_hand_eye_stationary_cam_approx.hdev.";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "white", 
        "box", "false");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  HDevWindowStack::SetActive(hv_WindowHandleGraphics);
  ReadImage(&ho_InstructionImage, "3d_machine_vision/hand_eye/instruction_images/robot_touching_point_in_tool_coordinates");
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  dev_resize_window_fit_image(ho_InstructionImage, 0, hv_Width+10, 600, -1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_InstructionImage, HDevWindowStack::GetActive());
  return;

}

// Chapter: Identification / Data Code
// Short Description: Display print quality information for individual data code modules. 
void dev_display_data_code_2d_print_quality_results (HTuple hv_DataCodeHandle, HTuple hv_ResultHandle, 
    HTuple hv_Mode, HTuple hv_QualityStandard, HTuple hv_Color, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue)
{

  // Local iconic variables
  HObject  ho_Circle, ho_Cross;

  // Local control variables
  HTuple  hv_MODE_RMMG, hv_MODE_GRID, hv_MODE_BAD;
  HTuple  hv_SupportedModes, hv_SupportedQualityStandards;
  HTuple  hv_GEN_CENTER, hv_GEN_CIRCLE, hv_GEN_LEGEND, hv_GEN_MAX_GRADE;
  HTuple  hv_DisplayCenter, hv_DisplayCircle, hv_DisplayLegend;
  HTuple  hv_MaxGrade, hv_I, hv_QualityParameter, hv_QualityRows;
  HTuple  hv_QualityCols, hv_ModuleGrades, hv_Rows, hv_Cols;
  HTuple  hv_QualityLabels, hv_Grades, hv_Labels, hv_ModuleHeight;
  HTuple  hv_ModuleWidth, hv_Aperture, hv_Radius, hv_Grade;
  HTuple  hv_GradeIdx, hv_GradeRows, hv_GradeCols, hv_GradeRadius;

  //This procedure displays the print quality results for data matrix ECC 200 codes.
  //
  //
  //Available modes
  hv_MODE_RMMG = "reflectance_margin_module_grades";
  hv_MODE_GRID = "grid";
  hv_MODE_BAD = "bad_modules";
  hv_SupportedModes.Clear();
  hv_SupportedModes.Append(hv_MODE_RMMG);
  hv_SupportedModes.Append(hv_MODE_GRID);
  hv_SupportedModes.Append(hv_MODE_BAD);
  //Available standards
  hv_SupportedQualityStandards.Clear();
  hv_SupportedQualityStandards[0] = "isoiec15415";
  hv_SupportedQualityStandards[1] = "isoiec_tr_29158";
  hv_SupportedQualityStandards[2] = "aimdpm_1_2006";
  //Available generic parameters
  hv_GEN_CENTER = "center";
  hv_GEN_CIRCLE = "circle";
  hv_GEN_LEGEND = "legend";
  hv_GEN_MAX_GRADE = "max_grade";
  //Defaults
  hv_DisplayCenter = 0;
  hv_DisplayCircle = 1;
  hv_DisplayLegend = 1;
  hv_MaxGrade = 3;
  //
  //Check modes
  if (0 != ((hv_Mode.TupleLength())!=1))
  {
    throw HException("Please specify exactly one of following modes:"+((" "+hv_SupportedModes).TupleSum()));
  }
  if (0 != ((hv_SupportedModes.TupleFind(hv_Mode))==-1))
  {
    throw HException("Unknown Mode: "+hv_Mode);
  }
  //
  //Check QualityStandard
  if (0 != ((hv_SupportedQualityStandards.TupleFind(hv_QualityStandard))==-1))
  {
    throw HException("Unknown QualityStandard: "+hv_QualityStandard);
  }
  else
  {
    hv_QualityStandard = "quality_"+hv_QualityStandard;
  }
  //
  //Check generic parameters
  //
  //Override defaults in special modes
  if (0 != (hv_Mode==hv_MODE_GRID))
  {
    hv_DisplayCenter = 1;
    hv_DisplayCircle = 0;
    hv_DisplayLegend = 0;
    hv_MaxGrade = 4;
    if (0 != ((hv_Color.TupleLength())==0))
    {
      hv_Color = "gray";
    }
  }
  else if (0 != (hv_Mode==hv_MODE_BAD))
  {
    hv_DisplayCenter = 0;
    hv_DisplayCircle = 1;
    hv_DisplayLegend = 0;
    hv_MaxGrade = 0;
  }
  //
  if (0 != ((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength())))
  {
    //Check if number of values matches number of parameters
    throw HException("GenParamName and GenParamValue do not match.");
  }
  else
  {
    //Set generic parameters
    {
    HTuple end_val59 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val59 = 1;
    for (hv_I=0; hv_I.Continue(end_val59, step_val59); hv_I += step_val59)
    {
      //'center'
      if (0 != (HTuple(hv_GenParamName[hv_I])==hv_GEN_CENTER))
      {
        //Check if values are valid
        if (0 != (HTuple(HTuple(hv_GenParamValue[hv_I])!=HTuple("true")).TupleAnd(HTuple(hv_GenParamValue[hv_I])!=HTuple("false"))))
        {
          throw HException(("Wrong parameter value for generic parameter 'center': "+HTuple(hv_GenParamValue[hv_I]))+" Please use 'true' or 'false'.");
        }
        //Set new value
        hv_DisplayCenter = HTuple(hv_GenParamValue[hv_I])==HTuple("true");
        //'circle'
      }
      else if (0 != (HTuple(hv_GenParamName[hv_I])==hv_GEN_CIRCLE))
      {
        //Check if values are valid
        if (0 != (HTuple(HTuple(hv_GenParamValue[hv_I])!=HTuple("true")).TupleAnd(HTuple(hv_GenParamValue[hv_I])!=HTuple("false"))))
        {
          throw HException(("Wrong parameter value for generic parameter 'circle': "+HTuple(hv_GenParamValue[hv_I]))+" Please use 'true' or 'false'.");
        }
        //Set new value
        hv_DisplayCircle = HTuple(hv_GenParamValue[hv_I])==HTuple("true");
      }
      else if (0 != (HTuple(hv_GenParamName[hv_I])==hv_GEN_LEGEND))
      {
        //Check if values are valid
        if (0 != (HTuple(HTuple(hv_GenParamValue[hv_I])!=HTuple("true")).TupleAnd(HTuple(hv_GenParamValue[hv_I])!=HTuple("false"))))
        {
          throw HException(("Wrong parameter value for generic parameter 'legend': "+HTuple(hv_GenParamValue[hv_I]))+" Please use 'true' or 'false'.");
        }
        //Set new value
        hv_DisplayLegend = HTuple(hv_GenParamValue[hv_I])==HTuple("true");
      }
      else if (0 != (HTuple(hv_GenParamName[hv_I])==hv_GEN_MAX_GRADE))
      {
        //Check if values are valid
        if (0 != (HTuple(HTuple(hv_GenParamValue[hv_I])<0).TupleOr(HTuple(hv_GenParamValue[hv_I])>4)))
        {
          throw HException(("Wrong parameter value for generic parameter 'max_grade': "+HTuple(hv_GenParamValue[hv_I]))+" Please use a value between 0 and 4.");
        }
        //Set new value
        hv_MaxGrade = HTuple(hv_GenParamValue[hv_I]).TupleInt();
      }
      else
      {
        //Unknown parameter
        throw HException("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_I]));
      }
    }
    }
  }
  //
  //Check Color
  if (0 != ((hv_Color.TupleLength())==0))
  {
    hv_Color.Clear();
    hv_Color[0] = "red";
    hv_Color[1] = "orange";
    hv_Color[2] = "yellow";
    hv_Color[3] = "cyan";
    hv_Color[4] = "green";
  }
  //Build color tuple with rotating colors if too few colors are specified
  while (0 != ((hv_Color.TupleLength())<(hv_MaxGrade+1)))
  {
    hv_Color = hv_Color.TupleConcat(hv_Color);
  }
  //
  //Visualization
  //
  //Get modulation grades, rows and cols for all symbol modules incl.
  //the 4 quiet zones adjacent to the symbol and the finder patterns.
  hv_QualityParameter = hv_QualityStandard+"_reflectance_margin_module_grades";
  hv_QualityRows = hv_QualityStandard+"_rows";
  hv_QualityCols = hv_QualityStandard+"_cols";
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityParameter, &hv_ModuleGrades);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityRows, &hv_Rows);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityCols, &hv_Cols);
  hv_QualityLabels = hv_QualityStandard+"_labels";
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityStandard, &hv_Grades);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityLabels, &hv_Labels);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, "module_height", &hv_ModuleHeight);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, "module_width", &hv_ModuleWidth);
  hv_Aperture = HTuple(hv_Grades[hv_Labels.TupleFind("Aperture")]);
  hv_Radius = (0.5*hv_Aperture)*(hv_ModuleHeight.TupleMin2(hv_ModuleWidth));
  //
  //Iterate over all possible modulation grades to visualize
  {
  HTuple end_val125 = hv_MaxGrade;
  HTuple step_val125 = 1;
  for (hv_Grade=0; hv_Grade.Continue(end_val125, step_val125); hv_Grade += step_val125)
  {
    hv_GradeIdx = hv_ModuleGrades.TupleFind(hv_Grade);
    if (0 != (hv_GradeIdx<0))
    {
      continue;
    }
    hv_GradeRows = HTuple(hv_Rows[hv_GradeIdx]);
    hv_GradeCols = HTuple(hv_Cols[hv_GradeIdx]);
    hv_GradeRadius = HTuple(hv_GradeRows.TupleLength(),hv_Radius);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_Grade]));
    if (0 != hv_DisplayCircle)
    {
      GenCircleContourXld(&ho_Circle, hv_GradeRows, hv_GradeCols, hv_GradeRadius, 
          HTuple(0).TupleRad(), HTuple(360).TupleRad(), "positive", 1);
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Circle, HDevWindowStack::GetActive());
    }
    if (0 != hv_DisplayCenter)
    {
      GenCrossContourXld(&ho_Cross, hv_GradeRows, hv_GradeCols, 2*hv_Radius, HTuple(0).TupleRad());
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Cross, HDevWindowStack::GetActive());
    }
  }
  }
  if (0 != hv_DisplayLegend)
  {
    //Display legend with modulation grades
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),HTuple("Reflectance Margin").TupleConcat("Module Grade "+HTuple::TupleGenSequence(0,hv_MaxGrade,1)), 
          "window", "bottom", "left", HTuple("white").TupleConcat(hv_Color), "box_color", 
          "#00000080");
  }
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Visualize and return the heatmap of a deep learning classification. 
void dev_display_dl_classifier_heatmap (HObject ho_Image, HTuple hv_DLClassifierHandle, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle)
{

  // Local iconic variables
  HObject  ho_Partition, ho_RegionGrid, ho_OccludedRegions;
  HObject  ho_ImageR, ho_ImageG, ho_ImageB, ho_ImagesOccluded;
  HObject  ho_OccludedRegion, ho_ImageOccluded, ho_HeatmapRegions;
  HObject  ho_PartsSelected, ho_HeatmapRegion, ho_HeatmapRegionsNegative;
  HObject  ho_HeatmapRegionNegative, ho_BinRegion;

  // Local control variables
  HTuple  hv_FeatureSize, hv_SamplingSize, hv_DisplayConfidence;
  HTuple  hv_GenParamIndex, hv_Number, hv_DLClassifierResultHandle;
  HTuple  hv_OriginalConfidence, hv_OriginalPredictedClass;
  HTuple  hv_ClipRegionSettingBefore, hv_HeightRegion, hv_WidthRegion;
  HTuple  hv_RatioRegion, hv_SamplingSizeUsed, hv_Width, hv_Height;
  HTuple  hv_CenterRows, hv_CenterColumns, hv_NumRegions;
  HTuple  hv_Confidences, hv_MeanRed, hv_DeviationRed, hv_MeanGreen;
  HTuple  hv_DeviationGreen, hv_MeanBlue, hv_DeviationBlue;
  HTuple  hv_BatchSize, hv_BatchIndex, hv_BatchIndices, hv_Index;
  HTuple  hv_NumImagesOccluded, hv_IndexOccluded, hv_PredictedClass;
  HTuple  hv_Confidence, hv_Area, hv_AveragingCenterRows;
  HTuple  hv_AveragingCenterColumns, hv_PartitionConfidences;
  HTuple  hv_PartIndex, hv_ConfidenceIndices, hv_ConfidenceDeviations;
  HTuple  hv_MaxDeviation, hv_NumBins, hv_Step, hv_End, hv_Factor;
  HTuple  hv_Lesser, hv_Greater, hv_IndicesInBin, hv_WidthImage;
  HTuple  hv_HeightImage, hv_Colors, hv_BinIndex, hv_Text;

  //This procedure generates a heatmap for an Image which is classified
  //with the deep learning classifier DLClassifierHandle and displays
  //it in the WindowHandle. The procedure can be adjusted with generic
  //parameters using GenParamName and GenParamValue.
  //
  //Please note that the heatmap is intended for visual inspection.
  //Therefore, the resulting regions and confidence values are not
  //returned. If you require the heatmap regions or confidence values,
  //e.g. for your own visualization, these are the parameters to return:
  //- HeatmapRegions (Regions in which confidence is decreased when occluded)
  //- HeatmapRegionsNegative (Regions in which confidence is increased
  //  when occluded)
  //- OriginalConfidence (Confidence of original class assignment)
  //- MaxDeviation (Maximum absolute deviation from OriginalConfidence in heatmap)
  //
  //Set default parameters.
  hv_FeatureSize = 30;
  hv_SamplingSize = 7;
  hv_DisplayConfidence = 1;
  //
  //Parse the input parameters.
  {
  HTuple end_val21 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val21 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val21, step_val21); hv_GenParamIndex += step_val21)
  {
    if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("feature_size")))
    {
      //Set 'feature_size'.
      hv_FeatureSize = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("sampling_size")))
    {
      //Set 'sampling_size'.
      hv_SamplingSize = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_confidence")))
    {
      //Set 'display_confidence'.
      hv_DisplayConfidence = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //Check the input parameters.
  CountObj(ho_Image, &hv_Number);
  if (0 != (hv_Number>1))
  {
    throw HException("Please use only a single image as input.");
  }
  if (0 != (hv_SamplingSize<0))
  {
    throw HException(("The \"sampling_size\" ("+hv_SamplingSize)+") must be greater than zero.");
  }
  if (0 != (hv_FeatureSize<0))
  {
    throw HException(("The \"feature_size\" ("+hv_FeatureSize)+") must be greater than zero.");
  }
  if (0 != (hv_SamplingSize>=hv_FeatureSize))
  {
    throw HException(((("The \"sampling_size\" ("+hv_SamplingSize)+") must be smaller than the \"feature_size\" (")+hv_FeatureSize)+")");
  }
  //
  //Get the predicted class and its confidence
  //when classifying the original (unoccluded) image.
  ApplyDlClassifier(ho_Image, hv_DLClassifierHandle, &hv_DLClassifierResultHandle);
  GetDlClassifierResult(hv_DLClassifierResultHandle, "all", "confidences", &hv_OriginalConfidence);
  GetDlClassifierResult(hv_DLClassifierResultHandle, "all", "predicted_classes", 
      &hv_OriginalPredictedClass);
  ClearDlClassifierResult(hv_DLClassifierResultHandle);
  //
  GetSystem("clip_region", &hv_ClipRegionSettingBefore);
  SetSystem("clip_region", "false");
  //
  //Partition the image into rectangular regions. The height and width of the
  //rectangles are approximately equal to sampling_size.
  PartitionRectangle(ho_Image, &ho_Partition, hv_SamplingSize, hv_SamplingSize);
  HeightWidthRatio(ho_Partition, &hv_HeightRegion, &hv_WidthRegion, &hv_RatioRegion);
  //
  //Generate a set of regions to be occluded based on the center coordinates
  //and the dimensions of these rectangles. Depending on the values of
  //feature_size and sampling_size, these regions may overlap.
  hv_SamplingSizeUsed = (hv_HeightRegion.TupleConcat(hv_WidthRegion)).TupleMedian();
  GetImageSize(ho_Image, &hv_Width, &hv_Height);
  GenGridRegion(&ho_RegionGrid, hv_SamplingSizeUsed, hv_SamplingSizeUsed, "points", 
      hv_Width+1, hv_Height+1);
  GetRegionPoints(ho_RegionGrid, &hv_CenterRows, &hv_CenterColumns);
  hv_NumRegions = hv_CenterRows.TupleLength();
  GenCircle(&ho_OccludedRegions, hv_CenterRows, hv_CenterColumns, HTuple(hv_NumRegions,hv_FeatureSize/2));
  //
  //Generate and classify the occluded images.
  hv_Confidences = HTuple();
  Decompose3(ho_Image, &ho_ImageR, &ho_ImageG, &ho_ImageB);
  Intensity(ho_OccludedRegions, ho_ImageR, &hv_MeanRed, &hv_DeviationRed);
  Intensity(ho_OccludedRegions, ho_ImageG, &hv_MeanGreen, &hv_DeviationGreen);
  Intensity(ho_OccludedRegions, ho_ImageB, &hv_MeanBlue, &hv_DeviationBlue);
  GetDlClassifierParam(hv_DLClassifierHandle, "batch_size", &hv_BatchSize);
  {
  HTuple end_val83 = (hv_NumRegions/hv_BatchSize).TupleInt();
  HTuple step_val83 = 1;
  for (hv_BatchIndex=0; hv_BatchIndex.Continue(end_val83, step_val83); hv_BatchIndex += step_val83)
  {
    GenEmptyObj(&ho_ImagesOccluded);
    TupleGenSequence((hv_BatchIndex*hv_BatchSize)+1, (((hv_BatchIndex+1)*hv_BatchSize).TupleConcat(hv_NumRegions)).TupleMin(), 
        1, &hv_BatchIndices);
    {
    HTuple end_val86 = (hv_BatchIndices.TupleLength())-1;
    HTuple step_val86 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val86, step_val86); hv_Index += step_val86)
    {
      SelectObj(ho_OccludedRegions, &ho_OccludedRegion, HTuple(hv_BatchIndices[hv_Index]));
      PaintRegion(ho_OccludedRegion, ho_Image, &ho_ImageOccluded, (HTuple(hv_MeanRed[HTuple(hv_BatchIndices[hv_Index])-1]).TupleConcat(HTuple(hv_MeanGreen[HTuple(hv_BatchIndices[hv_Index])-1]))).TupleConcat(HTuple(hv_MeanBlue[HTuple(hv_BatchIndices[hv_Index])-1])), 
          "fill");
      ConcatObj(ho_ImagesOccluded, ho_ImageOccluded, &ho_ImagesOccluded);
    }
    }
    //
    //For each occluded image, get the confidence
    //for the predicted class of the original image.
    CountObj(ho_ImagesOccluded, &hv_NumImagesOccluded);
    if (0 != (hv_NumImagesOccluded>0))
    {
      ApplyDlClassifier(ho_ImagesOccluded, hv_DLClassifierHandle, &hv_DLClassifierResultHandle);
      {
      HTuple end_val97 = hv_NumImagesOccluded-1;
      HTuple step_val97 = 1;
      for (hv_IndexOccluded=0; hv_IndexOccluded.Continue(end_val97, step_val97); hv_IndexOccluded += step_val97)
      {
        GetDlClassifierResult(hv_DLClassifierResultHandle, hv_IndexOccluded, "predicted_classes", 
            &hv_PredictedClass);
        GetDlClassifierResult(hv_DLClassifierResultHandle, hv_IndexOccluded, "confidences", 
            &hv_Confidence);
        hv_Confidences = hv_Confidences.TupleConcat(HTuple(hv_Confidence[hv_PredictedClass.TupleFind(hv_OriginalPredictedClass)]));
      }
      }
      ClearDlClassifierResult(hv_DLClassifierResultHandle);
    }
  }
  }
  //
  //Since it is too expensive to compute the confidence value
  //for each individual pixel, we work with a subsampling of the image.
  //The distance between two sampling points is controlled
  //by the parameter 'sampling_size'. For each sampling point,
  //we average over the confidence values of all images
  //which were occluded with a regions to which this point belongs.
  AreaCenter(ho_Partition, &hv_Area, &hv_AveragingCenterRows, &hv_AveragingCenterColumns);
  TupleGenConst(hv_AveragingCenterRows.TupleLength(), 0, &hv_PartitionConfidences);
  {
  HTuple end_val114 = (hv_AveragingCenterRows.TupleLength())-1;
  HTuple step_val114 = 1;
  for (hv_PartIndex=0; hv_PartIndex.Continue(end_val114, step_val114); hv_PartIndex += step_val114)
  {
    GetRegionIndex(ho_OccludedRegions, HTuple(hv_AveragingCenterRows[hv_PartIndex]).TupleInt(), 
        HTuple(hv_AveragingCenterColumns[hv_PartIndex]).TupleInt(), &hv_ConfidenceIndices);
    hv_PartitionConfidences[hv_PartIndex] = HTuple(hv_Confidences[hv_ConfidenceIndices-1]).TupleMean();
  }
  }
  //
  //Compute the deviation from the original confidence value and its maximum absolute value.
  hv_ConfidenceDeviations = hv_OriginalConfidence-hv_PartitionConfidences;
  hv_MaxDeviation = (hv_ConfidenceDeviations.TupleAbs()).TupleMax();
  //
  //The heatmap is categorized into 'bins'. The regions where the deviation
  //is highest are in the first bin, the regions where the deviation
  //is lowest are in the last bin. This is done separately for deviations with
  //positive and negative sign.
  hv_NumBins = 10;
  hv_Step = 1/(hv_NumBins.TupleReal());
  hv_End = 1-((hv_NumBins-1)*hv_Step);
  GenEmptyObj(&ho_HeatmapRegions);
  {
  HTuple end_val131 = hv_End;
  HTuple step_val131 = -hv_Step;
  for (hv_Factor=1; hv_Factor.Continue(end_val131, step_val131); hv_Factor += step_val131)
  {
    hv_Lesser = hv_ConfidenceDeviations.TupleLessEqualElem(hv_MaxDeviation*hv_Factor);
    hv_Greater = hv_ConfidenceDeviations.TupleGreaterElem(hv_MaxDeviation*(hv_Factor-hv_Step));
    hv_IndicesInBin = (hv_Lesser+hv_Greater).TupleFind(2);
    if (0 != (hv_IndicesInBin!=-1))
    {
      SelectObj(ho_Partition, &ho_PartsSelected, hv_IndicesInBin+1);
      Union1(ho_PartsSelected, &ho_HeatmapRegion);
    }
    else
    {
      GenEmptyRegion(&ho_HeatmapRegion);
    }
    ConcatObj(ho_HeatmapRegions, ho_HeatmapRegion, &ho_HeatmapRegions);
  }
  }
  GenEmptyObj(&ho_HeatmapRegionsNegative);
  {
  HTuple end_val144 = hv_End;
  HTuple step_val144 = -hv_Step;
  for (hv_Factor=1; hv_Factor.Continue(end_val144, step_val144); hv_Factor += step_val144)
  {
    hv_Lesser = hv_ConfidenceDeviations.TupleLessElem((-hv_MaxDeviation)*(hv_Factor-hv_Step));
    hv_Greater = hv_ConfidenceDeviations.TupleGreaterEqualElem((-hv_MaxDeviation)*hv_Factor);
    hv_IndicesInBin = (hv_Lesser+hv_Greater).TupleFind(2);
    if (0 != (hv_IndicesInBin!=-1))
    {
      SelectObj(ho_Partition, &ho_PartsSelected, hv_IndicesInBin+1);
      Union1(ho_PartsSelected, &ho_HeatmapRegionNegative);
    }
    else
    {
      GenEmptyRegion(&ho_HeatmapRegionNegative);
    }
    ConcatObj(ho_HeatmapRegionsNegative, ho_HeatmapRegionNegative, &ho_HeatmapRegionsNegative
        );
  }
  }
  //
  //Visualize the heatmap.
  HDevWindowStack::SetActive(hv_WindowHandle);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_HeightImage-1, hv_WidthImage-1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  //For regions for which the confidence decreased, generate a color palette
  //from red to yellow with 66% transparency
  hv_Colors = ((((HTuple("#ff3300").Append("#ff6600")).Append("#ff9900")).Append("#ffcc00")).Append("#ffff00"))+"66";
  for (hv_BinIndex=1; hv_BinIndex<=5; hv_BinIndex+=1)
  {
    SelectObj(ho_HeatmapRegions, &ho_BinRegion, hv_BinIndex);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),HTuple(hv_Colors[hv_BinIndex-1]));
    if (HDevWindowStack::IsOpen())
      DispObj(ho_BinRegion, HDevWindowStack::GetActive());
  }
  //For regions for which the confidence increased, generate a color palette
  //from blue to cyan with 66% transparency
  hv_Colors = ((((HTuple("#0033ff").Append("#0066ff")).Append("#0099ff")).Append("#00ccff")).Append("#00ffff"))+"66";
  for (hv_BinIndex=1; hv_BinIndex<=5; hv_BinIndex+=1)
  {
    SelectObj(ho_HeatmapRegionsNegative, &ho_BinRegion, hv_BinIndex);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),HTuple(hv_Colors[hv_BinIndex-1]));
    if (HDevWindowStack::IsOpen())
      DispObj(ho_BinRegion, HDevWindowStack::GetActive());
  }
  //
  if (0 != hv_DisplayConfidence)
  {
    hv_Text = HTuple();
    hv_Text[hv_Text.TupleLength()] = "Predicted Class: "+hv_OriginalPredictedClass;
    hv_Text[hv_Text.TupleLength()] = "Original Confidence: "+(hv_OriginalConfidence.TupleString(".3f"));
    hv_Text[hv_Text.TupleLength()] = "Maximum Deviation:   "+(hv_MaxDeviation.TupleString(".3f"));
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "right", (HTuple("black").Append("black")), 
          HTuple(), HTuple());
  }
  //
  SetSystem("clip_region", hv_ClipRegionSettingBefore);
  return;
}

// Chapter: Matching / Correlation-Based
// Short Description: Display the results of Correlation-Based Matching. 
void dev_display_ncc_matching_results (HTuple hv_ModelID, HTuple hv_Color, HTuple hv_Row, 
    HTuple hv_Column, HTuple hv_Angle, HTuple hv_Model)
{

  // Local iconic variables
  HObject  ho_ModelRegion, ho_ModelContours, ho_ContoursAffinTrans;
  HObject  ho_Cross;

  // Local control variables
  HTuple  hv_NumMatches, hv_Index, hv_Match, hv_HomMat2DIdentity;
  HTuple  hv_HomMat2DRotate, hv_HomMat2DTranslate, hv_RowTrans;
  HTuple  hv_ColTrans;

  //This procedure displays the results of Correlation-Based Matching.
  //
  hv_NumMatches = hv_Row.TupleLength();
  if (0 != (hv_NumMatches>0))
  {
    if (0 != ((hv_Model.TupleLength())==0))
    {
      TupleGenConst(hv_NumMatches, 0, &hv_Model);
    }
    else if (0 != ((hv_Model.TupleLength())==1))
    {
      TupleGenConst(hv_NumMatches, hv_Model, &hv_Model);
    }
    {
    HTuple end_val9 = (hv_ModelID.TupleLength())-1;
    HTuple step_val9 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val9, step_val9); hv_Index += step_val9)
    {
      GetNccModelRegion(&ho_ModelRegion, HTuple(hv_ModelID[hv_Index]));
      GenContourRegionXld(ho_ModelRegion, &ho_ModelContours, "border_holes");
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_Index%(hv_Color.TupleLength())]));
      {
      HTuple end_val13 = hv_NumMatches-1;
      HTuple step_val13 = 1;
      for (hv_Match=0; hv_Match.Continue(end_val13, step_val13); hv_Match += step_val13)
      {
        if (0 != (hv_Index==HTuple(hv_Model[hv_Match])))
        {
          HomMat2dIdentity(&hv_HomMat2DIdentity);
          HomMat2dRotate(hv_HomMat2DIdentity, HTuple(hv_Angle[hv_Match]), 0, 0, &hv_HomMat2DRotate);
          HomMat2dTranslate(hv_HomMat2DRotate, HTuple(hv_Row[hv_Match]), HTuple(hv_Column[hv_Match]), 
              &hv_HomMat2DTranslate);
          AffineTransContourXld(ho_ModelContours, &ho_ContoursAffinTrans, hv_HomMat2DTranslate);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ContoursAffinTrans, HDevWindowStack::GetActive());
          AffineTransPixel(hv_HomMat2DTranslate, 0, 0, &hv_RowTrans, &hv_ColTrans);
          GenCrossContourXld(&ho_Cross, hv_RowTrans, hv_ColTrans, 6, HTuple(hv_Angle[hv_Match]));
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Cross, HDevWindowStack::GetActive());
        }
      }
      }
    }
    }
  }
  return;
}

// Chapter: Matching / Shape-Based
// Short Description: Display the results of Shape-Based Matching. 
void dev_display_shape_matching_results (HTuple hv_ModelID, HTuple hv_Color, HTuple hv_Row, 
    HTuple hv_Column, HTuple hv_Angle, HTuple hv_ScaleR, HTuple hv_ScaleC, HTuple hv_Model)
{

  // Local iconic variables
  HObject  ho_ModelContours, ho_ContoursAffinTrans;

  // Local control variables
  HTuple  hv_NumMatches, hv_Index, hv_Match, hv_HomMat2DIdentity;
  HTuple  hv_HomMat2DScale, hv_HomMat2DRotate, hv_HomMat2DTranslate;

  //This procedure displays the results of Shape-Based Matching.
  //
  hv_NumMatches = hv_Row.TupleLength();
  if (0 != (hv_NumMatches>0))
  {
    if (0 != ((hv_ScaleR.TupleLength())==1))
    {
      TupleGenConst(hv_NumMatches, hv_ScaleR, &hv_ScaleR);
    }
    if (0 != ((hv_ScaleC.TupleLength())==1))
    {
      TupleGenConst(hv_NumMatches, hv_ScaleC, &hv_ScaleC);
    }
    if (0 != ((hv_Model.TupleLength())==0))
    {
      TupleGenConst(hv_NumMatches, 0, &hv_Model);
    }
    else if (0 != ((hv_Model.TupleLength())==1))
    {
      TupleGenConst(hv_NumMatches, hv_Model, &hv_Model);
    }
    {
    HTuple end_val15 = (hv_ModelID.TupleLength())-1;
    HTuple step_val15 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val15, step_val15); hv_Index += step_val15)
    {
      GetShapeModelContours(&ho_ModelContours, HTuple(hv_ModelID[hv_Index]), 1);
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_Index%(hv_Color.TupleLength())]));
      {
      HTuple end_val18 = hv_NumMatches-1;
      HTuple step_val18 = 1;
      for (hv_Match=0; hv_Match.Continue(end_val18, step_val18); hv_Match += step_val18)
      {
        if (0 != (hv_Index==HTuple(hv_Model[hv_Match])))
        {
          HomMat2dIdentity(&hv_HomMat2DIdentity);
          HomMat2dScale(hv_HomMat2DIdentity, HTuple(hv_ScaleR[hv_Match]), HTuple(hv_ScaleC[hv_Match]), 
              0, 0, &hv_HomMat2DScale);
          HomMat2dRotate(hv_HomMat2DScale, HTuple(hv_Angle[hv_Match]), 0, 0, &hv_HomMat2DRotate);
          HomMat2dTranslate(hv_HomMat2DRotate, HTuple(hv_Row[hv_Match]), HTuple(hv_Column[hv_Match]), 
              &hv_HomMat2DTranslate);
          AffineTransContourXld(ho_ModelContours, &ho_ContoursAffinTrans, hv_HomMat2DTranslate);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ContoursAffinTrans, HDevWindowStack::GetActive());
        }
      }
      }
    }
    }
  }
  return;
}

void dev_display_surface_matching_results (HTuple hv_WindowHandle1, HTuple hv_SurfaceMatchingResultID, 
    HTuple hv_ObjectModel3DModel, HTuple hv_ObjectModel3DScene, HTuple hv_Score, 
    HTuple hv_Pose, HTuple hv_EdgesTrained)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_SampledEdges, hv_KeyPoints, hv_SampledScene;
  HTuple  hv_Instructions, hv_Colors, hv_Number, hv_ObjectModel3DResult;
  HTuple  hv_ColorsVis, hv_Message, hv_PoseOut;

  //
  //Get Matching data
  if (0 != (hv_EdgesTrained==HTuple("true")))
  {
    GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "sampled_edges", HTuple(), 
        &hv_SampledEdges);
  }
  GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "key_points", HTuple(), &hv_KeyPoints);
  GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "sampled_scene", HTuple(), 
      &hv_SampledScene);
  //
  hv_Instructions[0] = "Rotate: Left button";
  hv_Instructions[1] = "Zoom:   Shift + left button";
  hv_Instructions[2] = "Move:   Ctrl  + left button";
  //
  //Generate color vector for visualization
  hv_Colors.Clear();
  hv_Colors[0] = "red";
  hv_Colors[1] = "green";
  hv_Colors[2] = "blue";
  hv_Colors[3] = "cyan";
  hv_Colors[4] = "magenta";
  hv_Colors[5] = "yellow";
  hv_Colors[6] = "medium slate blue";
  hv_Colors[7] = "coral";
  hv_Colors[8] = "slate blue";
  hv_Colors[9] = "orange red";
  hv_Colors[10] = "dark olive green";
  //
  //Number of Matches
  hv_Number = hv_Score.TupleLength();
  //
  //Move the model into the scene
  RigidTransObjectModel3d(hv_ObjectModel3DModel, hv_Pose, &hv_ObjectModel3DResult);
  hv_ColorsVis = HTuple(hv_Colors[HTuple::TupleGenSequence(0,hv_Number-1,1)%(hv_Colors.TupleLength())]);
  //
  //Visualize results
  if (0 != (hv_EdgesTrained==HTuple("true")))
  {
    hv_Message = "Original scene points (gray)";
    hv_Message[1] = "Sampled scene points (cyan)";
    hv_Message[2] = "Key points (yellow)";
    hv_Message[3] = "Sampled 3d edges (green)";
    hv_Message[4] = hv_Number+" objects are found ";
    visualize_object_model_3d(hv_WindowHandle1, (((hv_ObjectModel3DScene.TupleConcat(hv_SampledEdges)).TupleConcat(hv_SampledScene)).TupleConcat(hv_KeyPoints)).TupleConcat(hv_ObjectModel3DResult), 
        HTuple(), HTuple(), (("color_"+HTuple::TupleGenSequence(0,hv_Number+3,1)).TupleConcat(HTuple("point_size_")+(((HTuple(0).Append(1)).Append(2)).Append(3)))).TupleConcat((HTuple("disp_pose").Append("alpha"))), 
        ((((HTuple("gray").Append("green")).Append("cyan")).Append("yellow")).TupleConcat(hv_ColorsVis)).TupleConcat((((((HTuple(1.0).Append(3.0)).Append(3.0)).Append(5.0)).Append("true")).Append(0.5))), 
        hv_Message, (((HTuple("").Append("")).Append("")).Append("")).TupleConcat(hv_Score), 
        hv_Instructions, &hv_PoseOut);
  }
  else
  {
    hv_Message = "Final Results:";
    hv_Message[1] = "Original scene points (gray)";
    hv_Message[2] = "Sampled scene points (cyan)";
    hv_Message[3] = "Key points (yellow)";
    hv_Message[4] = hv_Number+" objects are found";
    visualize_object_model_3d(hv_WindowHandle1, ((hv_ObjectModel3DScene.TupleConcat(hv_SampledScene)).TupleConcat(hv_KeyPoints)).TupleConcat(hv_ObjectModel3DResult), 
        HTuple(), HTuple(), (("color_"+HTuple::TupleGenSequence(0,hv_Number+2,1)).TupleConcat(HTuple("point_size_")+((HTuple(0).Append(1)).Append(2)))).TupleConcat((HTuple("disp_pose").Append("alpha"))), 
        (((HTuple("gray").Append("cyan")).Append("yellow")).TupleConcat(hv_ColorsVis)).TupleConcat(((((HTuple(1.0).Append(3.0)).Append(5.0)).Append("true")).Append(0.5))), 
        hv_Message, ((HTuple("").Append("")).Append("")).TupleConcat(hv_Score), hv_Instructions, 
        &hv_PoseOut);
  }
  HDevWindowStack::SetActive(hv_WindowHandle1);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  return;
}

// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image. 
void dev_open_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
  HTuple  hv_MaxHeight, hv_ResizeFactor, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_TempWidth, hv_TempHeight, hv_WindowWidth, hv_WindowHeight;

  //This procedure opens a new graphics window and adjusts the size
  //such that it fits into the limits specified by WidthLimit
  //and HeightLimit, but also maintains the correct image aspect ratio.
  //
  //If it is impossible to match the minimum and maximum extent requirements
  //at the same time (f.e. if the image is very long but narrow),
  //the maximum value gets a higher priority,
  //
  //Parse input tuple WidthLimit
  if (0 != (HTuple((hv_WidthLimit.TupleLength())==0).TupleOr(hv_WidthLimit<0)))
  {
    hv_MinWidth = 500;
    hv_MaxWidth = 800;
  }
  else if (0 != ((hv_WidthLimit.TupleLength())==1))
  {
    hv_MinWidth = 0;
    hv_MaxWidth = hv_WidthLimit;
  }
  else
  {
    hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
    hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
  }
  //Parse input tuple HeightLimit
  if (0 != (HTuple((hv_HeightLimit.TupleLength())==0).TupleOr(hv_HeightLimit<0)))
  {
    hv_MinHeight = 400;
    hv_MaxHeight = 600;
  }
  else if (0 != ((hv_HeightLimit.TupleLength())==1))
  {
    hv_MinHeight = 0;
    hv_MaxHeight = hv_HeightLimit;
  }
  else
  {
    hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
    hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
  }
  //
  //Test, if window size has to be changed.
  hv_ResizeFactor = 1;
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  //First, expand window to the minimum extents (if necessary).
  if (0 != (HTuple(hv_MinWidth>hv_ImageWidth).TupleOr(hv_MinHeight>hv_ImageHeight)))
  {
    hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_ImageWidth).TupleConcat((hv_MinHeight.TupleReal())/hv_ImageHeight)).TupleMax();
  }
  hv_TempWidth = hv_ImageWidth*hv_ResizeFactor;
  hv_TempHeight = hv_ImageHeight*hv_ResizeFactor;
  //Then, shrink window to maximum extents (if necessary).
  if (0 != (HTuple(hv_MaxWidth<hv_TempWidth).TupleOr(hv_MaxHeight<hv_TempHeight)))
  {
    hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
  }
  hv_WindowWidth = hv_ImageWidth*hv_ResizeFactor;
  hv_WindowHeight = hv_ImageHeight*hv_ResizeFactor;
  //Resize window
  SetWindowAttr("background_color","black");
  OpenWindow(hv_Row,hv_Column,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandle));
  HDevWindowStack::Push((*hv_WindowHandle));
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_ImageHeight-1, hv_ImageWidth-1);
  return;
}

// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image size. 
void dev_open_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
  HTuple  hv_MaxHeight, hv_ResizeFactor, hv_TempWidth, hv_TempHeight;
  HTuple  hv_WindowWidth, hv_WindowHeight;

  //This procedure open a new graphic window
  //such that it fits into the limits specified by WidthLimit
  //and HeightLimit, but also maintains the correct aspect ratio
  //given by Width and Height.
  //
  //If it is impossible to match the minimum and maximum extent requirements
  //at the same time (f.e. if the image is very long but narrow),
  //the maximum value gets a higher priority.
  //
  //Parse input tuple WidthLimit
  if (0 != (HTuple((hv_WidthLimit.TupleLength())==0).TupleOr(hv_WidthLimit<0)))
  {
    hv_MinWidth = 500;
    hv_MaxWidth = 800;
  }
  else if (0 != ((hv_WidthLimit.TupleLength())==1))
  {
    hv_MinWidth = 0;
    hv_MaxWidth = hv_WidthLimit;
  }
  else
  {
    hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
    hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
  }
  //Parse input tuple HeightLimit
  if (0 != (HTuple((hv_HeightLimit.TupleLength())==0).TupleOr(hv_HeightLimit<0)))
  {
    hv_MinHeight = 400;
    hv_MaxHeight = 600;
  }
  else if (0 != ((hv_HeightLimit.TupleLength())==1))
  {
    hv_MinHeight = 0;
    hv_MaxHeight = hv_HeightLimit;
  }
  else
  {
    hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
    hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
  }
  //
  //Test, if window size has to be changed.
  hv_ResizeFactor = 1;
  //First, expand window to the minimum extents (if necessary).
  if (0 != (HTuple(hv_MinWidth>hv_Width).TupleOr(hv_MinHeight>hv_Height)))
  {
    hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_Width).TupleConcat((hv_MinHeight.TupleReal())/hv_Height)).TupleMax();
  }
  hv_TempWidth = hv_Width*hv_ResizeFactor;
  hv_TempHeight = hv_Height*hv_ResizeFactor;
  //Then, shrink window to maximum extents (if necessary).
  if (0 != (HTuple(hv_MaxWidth<hv_TempWidth).TupleOr(hv_MaxHeight<hv_TempHeight)))
  {
    hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
  }
  hv_WindowWidth = hv_Width*hv_ResizeFactor;
  hv_WindowHeight = hv_Height*hv_ResizeFactor;
  //Resize window
  SetWindowAttr("background_color","black");
  OpenWindow(hv_Row,hv_Column,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandle));
  HDevWindowStack::Push((*hv_WindowHandle));
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  return;
}

// Chapter: Develop
// Short Description: Changes the size of a graphics window with a given maximum and minimum extent such that it preserves the aspect ratio of the given image 
void dev_resize_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
  HTuple  hv_MaxHeight, hv_ResizeFactor, hv_Pointer, hv_Type;
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_TempWidth, hv_TempHeight;
  HTuple  hv_WindowWidth, hv_WindowHeight;

  //This procedure adjusts the size of the current window
  //such that it fits into the limits specified by WidthLimit
  //and HeightLimit, but also maintains the correct image aspect ratio.
  //
  //If it is impossible to match the minimum and maximum extent requirements
  //at the same time (f.e. if the image is very long but narrow),
  //the maximum value gets a higher priority,
  //
  //Parse input tuple WidthLimit
  if (0 != (HTuple((hv_WidthLimit.TupleLength())==0).TupleOr(hv_WidthLimit<0)))
  {
    hv_MinWidth = 500;
    hv_MaxWidth = 800;
  }
  else if (0 != ((hv_WidthLimit.TupleLength())==1))
  {
    hv_MinWidth = 0;
    hv_MaxWidth = hv_WidthLimit;
  }
  else
  {
    hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
    hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
  }
  //Parse input tuple HeightLimit
  if (0 != (HTuple((hv_HeightLimit.TupleLength())==0).TupleOr(hv_HeightLimit<0)))
  {
    hv_MinHeight = 400;
    hv_MaxHeight = 600;
  }
  else if (0 != ((hv_HeightLimit.TupleLength())==1))
  {
    hv_MinHeight = 0;
    hv_MaxHeight = hv_HeightLimit;
  }
  else
  {
    hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
    hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
  }
  //
  //Test, if window size has to be changed.
  hv_ResizeFactor = 1;
  GetImagePointer1(ho_Image, &hv_Pointer, &hv_Type, &hv_ImageWidth, &hv_ImageHeight);
  //First, expand window to the minimum extents (if necessary).
  if (0 != (HTuple(hv_MinWidth>hv_ImageWidth).TupleOr(hv_MinHeight>hv_ImageHeight)))
  {
    hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_ImageWidth).TupleConcat((hv_MinHeight.TupleReal())/hv_ImageHeight)).TupleMax();
  }
  hv_TempWidth = hv_ImageWidth*hv_ResizeFactor;
  hv_TempHeight = hv_ImageHeight*hv_ResizeFactor;
  //Then, shrink window to maximum extents (if necessary).
  if (0 != (HTuple(hv_MaxWidth<hv_TempWidth).TupleOr(hv_MaxHeight<hv_TempHeight)))
  {
    hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
  }
  hv_WindowWidth = hv_ImageWidth*hv_ResizeFactor;
  hv_WindowHeight = hv_ImageHeight*hv_ResizeFactor;
  //Resize window
  if (HDevWindowStack::IsOpen())
    SetWindowExtents(HDevWindowStack::GetActive(),hv_Row, hv_Column, hv_WindowWidth, 
        hv_WindowHeight);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_ImageHeight-1, hv_ImageWidth-1);
  return;
}

// Chapter: Develop
// Short Description: Resizes a graphics window with a given maximum extent such that it preserves the aspect ratio of a given width and height 
void dev_resize_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
  HTuple  hv_MaxHeight, hv_ResizeFactor, hv_TempWidth, hv_TempHeight;
  HTuple  hv_WindowWidth, hv_WindowHeight;

  //This procedure adjusts the size of the current window
  //such that it fits into the limits specified by WidthLimit
  //and HeightLimit, but also maintains the correct aspect ratio
  //given by Width and Height.
  //
  //If it is impossible to match the minimum and maximum extent requirements
  //at the same time (f.e. if the image is very long but narrow),
  //the maximum value gets a higher priority.
  //
  //Parse input tuple WidthLimit
  if (0 != (HTuple((hv_WidthLimit.TupleLength())==0).TupleOr(hv_WidthLimit<0)))
  {
    hv_MinWidth = 500;
    hv_MaxWidth = 800;
  }
  else if (0 != ((hv_WidthLimit.TupleLength())==1))
  {
    hv_MinWidth = 0;
    hv_MaxWidth = hv_WidthLimit;
  }
  else
  {
    hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
    hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
  }
  //Parse input tuple HeightLimit
  if (0 != (HTuple((hv_HeightLimit.TupleLength())==0).TupleOr(hv_HeightLimit<0)))
  {
    hv_MinHeight = 400;
    hv_MaxHeight = 600;
  }
  else if (0 != ((hv_HeightLimit.TupleLength())==1))
  {
    hv_MinHeight = 0;
    hv_MaxHeight = hv_HeightLimit;
  }
  else
  {
    hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
    hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
  }
  //
  //Test, if window size has to be changed.
  hv_ResizeFactor = 1;
  //First, expand window to the minimum extents (if necessary).
  if (0 != (HTuple(hv_MinWidth>hv_Width).TupleOr(hv_MinHeight>hv_Height)))
  {
    hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_Width).TupleConcat((hv_MinHeight.TupleReal())/hv_Height)).TupleMax();
  }
  hv_TempWidth = hv_Width*hv_ResizeFactor;
  hv_TempHeight = hv_Height*hv_ResizeFactor;
  //Then, shrink window to maximum extents (if necessary).
  if (0 != (HTuple(hv_MaxWidth<hv_TempWidth).TupleOr(hv_MaxHeight<hv_TempHeight)))
  {
    hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
  }
  hv_WindowWidth = hv_Width*hv_ResizeFactor;
  hv_WindowHeight = hv_Height*hv_ResizeFactor;
  //Resize window
  if (HDevWindowStack::IsOpen())
    SetWindowExtents(HDevWindowStack::GetActive(),hv_Row, hv_Column, hv_WindowWidth, 
        hv_WindowHeight);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  return;
}

// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'off'. 
void dev_update_off ()
{

  //This procedure sets different update settings to 'off'.
  //This is useful to get the best performance and reduce overhead.
  //
  // dev_update_pc(...); only in hdevelop
  // dev_update_var(...); only in hdevelop
  // dev_update_window(...); only in hdevelop
  return;
}

// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'on'. 
void dev_update_on ()
{

  //This procedure sets different update settings to 'on'.
  //
  // dev_update_pc(...); only in hdevelop
  // dev_update_var(...); only in hdevelop
  // dev_update_window(...); only in hdevelop
  return;
}

// Chapter: Graphics / Output
// Short Description: Display the axes of a 3d coordinate system 
void disp_3d_coord_system (HTuple hv_WindowHandle, HTuple hv_CamParam, HTuple hv_Pose, 
    HTuple hv_CoordAxesLength)
{

  // Local iconic variables
  HObject  ho_Arrows;

  // Local control variables
  HTuple  hv_CameraType, hv_IsTelecentric, hv_TransWorld2Cam;
  HTuple  hv_OrigCamX, hv_OrigCamY, hv_OrigCamZ, hv_Row0;
  HTuple  hv_Column0, hv_X, hv_Y, hv_Z, hv_RowAxX, hv_ColumnAxX;
  HTuple  hv_RowAxY, hv_ColumnAxY, hv_RowAxZ, hv_ColumnAxZ;
  HTuple  hv_Distance, hv_HeadLength, hv_Red, hv_Green, hv_Blue;

  //This procedure displays a 3D coordinate system.
  //It needs the procedure gen_arrow_contour_xld.
  //
  //Input parameters:
  //WindowHandle: The window where the coordinate system shall be displayed
  //CamParam: The camera paramters
  //Pose: The pose to be displayed
  //CoordAxesLength: The length of the coordinate axes in world coordinates
  //
  //Check, if Pose is a correct pose tuple.
  if (0 != ((hv_Pose.TupleLength())!=7))
  {
    return;
  }
  get_cam_par_data(hv_CamParam, "camera_type", &hv_CameraType);
  hv_IsTelecentric = (hv_CameraType.TupleStrstr("telecentric"))!=-1;
  if (0 != (HTuple(HTuple(hv_Pose[2])==0.0).TupleAnd(hv_IsTelecentric.TupleNot())))
  {
    //For projective cameras:
    //Poses with Z position zero cannot be projected
    //(that would lead to a division by zero error).
    return;
  }
  //Convert to pose to a transformation matrix
  PoseToHomMat3d(hv_Pose, &hv_TransWorld2Cam);
  //Project the world origin into the image
  AffineTransPoint3d(hv_TransWorld2Cam, 0, 0, 0, &hv_OrigCamX, &hv_OrigCamY, &hv_OrigCamZ);
  Project3dPoint(hv_OrigCamX, hv_OrigCamY, hv_OrigCamZ, hv_CamParam, &hv_Row0, &hv_Column0);
  //Project the coordinate axes into the image
  AffineTransPoint3d(hv_TransWorld2Cam, hv_CoordAxesLength, 0, 0, &hv_X, &hv_Y, &hv_Z);
  Project3dPoint(hv_X, hv_Y, hv_Z, hv_CamParam, &hv_RowAxX, &hv_ColumnAxX);
  AffineTransPoint3d(hv_TransWorld2Cam, 0, hv_CoordAxesLength, 0, &hv_X, &hv_Y, &hv_Z);
  Project3dPoint(hv_X, hv_Y, hv_Z, hv_CamParam, &hv_RowAxY, &hv_ColumnAxY);
  AffineTransPoint3d(hv_TransWorld2Cam, 0, 0, hv_CoordAxesLength, &hv_X, &hv_Y, &hv_Z);
  Project3dPoint(hv_X, hv_Y, hv_Z, hv_CamParam, &hv_RowAxZ, &hv_ColumnAxZ);
  //
  //Generate an XLD contour for each axis
  DistancePp((hv_Row0.TupleConcat(hv_Row0)).TupleConcat(hv_Row0), (hv_Column0.TupleConcat(hv_Column0)).TupleConcat(hv_Column0), 
      (hv_RowAxX.TupleConcat(hv_RowAxY)).TupleConcat(hv_RowAxZ), (hv_ColumnAxX.TupleConcat(hv_ColumnAxY)).TupleConcat(hv_ColumnAxZ), 
      &hv_Distance);
  hv_HeadLength = ((((hv_Distance.TupleMax())/12.0).TupleConcat(5.0)).TupleMax()).TupleInt();
  gen_arrow_contour_xld(&ho_Arrows, (hv_Row0.TupleConcat(hv_Row0)).TupleConcat(hv_Row0), 
      (hv_Column0.TupleConcat(hv_Column0)).TupleConcat(hv_Column0), (hv_RowAxX.TupleConcat(hv_RowAxY)).TupleConcat(hv_RowAxZ), 
      (hv_ColumnAxX.TupleConcat(hv_ColumnAxY)).TupleConcat(hv_ColumnAxZ), hv_HeadLength, 
      hv_HeadLength);
  //
  //Display coordinate system
  DispXld(ho_Arrows, hv_WindowHandle);
  //
  GetRgb(hv_WindowHandle, &hv_Red, &hv_Green, &hv_Blue);
  SetRgb(hv_WindowHandle, HTuple(hv_Red[0]), HTuple(hv_Green[0]), HTuple(hv_Blue[0]));
  SetTposition(hv_WindowHandle, hv_RowAxX+3, hv_ColumnAxX+3);
  WriteString(hv_WindowHandle, "X");
  SetRgb(hv_WindowHandle, HTuple(hv_Red[1%(hv_Red.TupleLength())]), HTuple(hv_Green[1%(hv_Green.TupleLength())]), 
      HTuple(hv_Blue[1%(hv_Blue.TupleLength())]));
  SetTposition(hv_WindowHandle, hv_RowAxY+3, hv_ColumnAxY+3);
  WriteString(hv_WindowHandle, "Y");
  SetRgb(hv_WindowHandle, HTuple(hv_Red[2%(hv_Red.TupleLength())]), HTuple(hv_Green[2%(hv_Green.TupleLength())]), 
      HTuple(hv_Blue[2%(hv_Blue.TupleLength())]));
  SetTposition(hv_WindowHandle, hv_RowAxZ+3, hv_ColumnAxZ+3);
  WriteString(hv_WindowHandle, "Z");
  SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
  return;
}

// Chapter: Graphics / Output
// Short Description: Displays a continue button. 
void disp_buttons (HTuple hv_Parameters, HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_gButtons, hv_idx, hv_Message;

  //This procedure displays all Buttons in the window.
  //
  //Input parameters:
  //WindowHandle: The window, where the text shall be displayed
  //
  //Use the buttons set in the global variable gButtons.
  GetMessageTuple(hv_Parameters, "gButtons", &hv_gButtons);

  {
  HTuple end_val8 = (hv_gButtons.TupleLength())-1;
  HTuple step_val8 = 5;
  for (hv_idx=0; hv_idx.Continue(end_val8, step_val8); hv_idx += step_val8)
  {
    //Display the continue button
    hv_Message = HTuple(hv_gButtons[hv_idx+0]);
    disp_text_button(hv_WindowHandle, hv_Message, "window", HTuple(hv_gButtons[hv_idx+2]), 
        HTuple(hv_gButtons[hv_idx+1]), "black", "#f28f26");
    //Debug the computed area
    //gen_rectangle1 (Rectangle, gButtons[idx + 2], gButtons[idx + 1], gButtons[idx + 4], gButtons[idx + 3])
    //set_color (WindowHandle, 'white')
    //set_color (WindowHandle, '#ffffFFEE')
    //disp_obj (Rectangle, WindowHandle)
  }
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Displays a continue button. 
void disp_continue_button (HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ContinueMessage, hv_Exception, hv_Row;
  HTuple  hv_Column, hv_Width, hv_Height, hv_Ascent, hv_Descent;
  HTuple  hv_TextWidth, hv_TextHeight;

  //This procedure displays a 'Continue' text button
  //in the lower right corner of the screen.
  //It uses the procedure disp_message.
  //
  //Input parameters:
  //WindowHandle: The window, where the text shall be displayed
  //
  //Use the continue message set in the global variable gTerminationButtonLabel.
  //If this variable is not defined, set a standard text instead.
  //global tuple gTerminationButtonLabel
  try
  {
    hv_ContinueMessage = ExpGetGlobalVar_gTerminationButtonLabel();
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_ContinueMessage = "Continue";
  }
  //Display the continue button
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  GetStringExtents(hv_WindowHandle, (" "+hv_ContinueMessage)+" ", &hv_Ascent, &hv_Descent, 
      &hv_TextWidth, &hv_TextHeight);
  disp_text_button_visualize_object_model_3d(hv_WindowHandle, hv_ContinueMessage, 
      "window", (hv_Height-hv_TextHeight)-22, (hv_Width-hv_TextWidth)-12, "black", 
      "#f28f26");
  return;
}

// Chapter: Graphics / Text
// Short Description: This procedure displays 'Click 'Run' to continue' in the lower right corner of the screen. 
void disp_continue_message (HTuple hv_WindowHandle, HTuple hv_Color, HTuple hv_Box)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_GenParamName, hv_GenParamValue, hv_ContinueMessage;

  //This procedure displays 'Press Run (F5) to continue' in the
  //lower right corner of the screen.
  //It uses the procedure disp_message.
  //
  //Input parameters:
  //WindowHandle: The window, where the text shall be displayed
  //Color: defines the text color.
  //   If set to '' or 'auto', the currently set color is used.
  //Box: If set to 'true', the text is displayed in a box.
  //
  //Convert the parameter Box to generic parameters.
  hv_GenParamName = HTuple();
  hv_GenParamValue = HTuple();
  if (0 != ((hv_Box.TupleLength())>0))
  {
    if (0 != (HTuple(hv_Box[0])==HTuple("false")))
    {
      //Display no box
      hv_GenParamName = hv_GenParamName.TupleConcat("box");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[0])!=HTuple("true")))
    {
      //Set a color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("box_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[0]));
    }
  }
  if (0 != ((hv_Box.TupleLength())>1))
  {
    if (0 != (HTuple(hv_Box[1])==HTuple("false")))
    {
      //Display no shadow.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[1])!=HTuple("true")))
    {
      //Set a shadow color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[1]));
    }
  }
  //
  if (0 != (hv_Color==HTuple("")))
  {
    //disp_text does not accept an empty string for Color.
    hv_Color = HTuple();
  }
  //
  //Display the message.
  hv_ContinueMessage = "Press Run (F5) to continue";
  DispText(hv_WindowHandle, hv_ContinueMessage, "window", "bottom", "right", hv_Color, 
      hv_GenParamName, hv_GenParamValue);
  return;
}

// Chapter: Graphics / Text
// Short Description: This procedure displays 'End of program' in the lower right corner of the screen. 
void disp_end_of_program_message (HTuple hv_WindowHandle, HTuple hv_Color, HTuple hv_Box)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_GenParamName, hv_GenParamValue, hv_EndMessage;

  //This procedure displays 'End of program' in the
  //lower right corner of the screen.
  //It uses the procedure disp_message.
  //
  //Input parameters:
  //WindowHandle: The window, where the text shall be displayed
  //Color: defines the text color.
  //   If set to '' or 'auto', the currently set color is used.
  //Box: If set to 'true', the text is displayed in a box.
  //
  //Convert the parameter Box to generic parameters.
  hv_GenParamName = HTuple();
  hv_GenParamValue = HTuple();
  if (0 != ((hv_Box.TupleLength())>0))
  {
    if (0 != (HTuple(hv_Box[0])==HTuple("false")))
    {
      //Display no box
      hv_GenParamName = hv_GenParamName.TupleConcat("box");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[0])!=HTuple("true")))
    {
      //Set a color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("box_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[0]));
    }
  }
  if (0 != ((hv_Box.TupleLength())>1))
  {
    if (0 != (HTuple(hv_Box[1])==HTuple("false")))
    {
      //Display no shadow.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[1])!=HTuple("true")))
    {
      //Set a shadow color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[1]));
    }
  }
  //
  if (0 != (hv_Color==HTuple("")))
  {
    //disp_text does not accept an empty string for Color.
    hv_Color = HTuple();
  }
  //
  //Display the message.
  hv_EndMessage = "      End of program      ";
  DispText(hv_WindowHandle, hv_EndMessage, "window", "bottom", "right", hv_Color, 
      hv_GenParamName, hv_GenParamValue);
  return;
}

void disp_menu_ext (HObject ho_MenuRegions, HTuple hv_WindowHandleMenu, HTuple hv_MenuText, 
    HTuple hv_CasesDone, HTuple hv_CurrentCase)
{

  // Local iconic variables
  HObject  ho_MenuRegion, ho_RegionBorder, ho_Contour;

  // Local control variables
  HTuple  hv_NumberRegions, hv_NumberTexts, hv_Row;
  HTuple  hv_Column, hv_Width1, hv_Height1, hv_i, hv_Text;
  HTuple  hv_Rows, hv_Cols, hv_Indices, hv_Done, hv_Ascent;
  HTuple  hv_Descent, hv_Width, hv_Height, hv_Col, hv_Scale;

  //Display the previously created menu buttons
  CountObj(ho_MenuRegions, &hv_NumberRegions);
  hv_NumberTexts = hv_MenuText.TupleLength();
  if (0 != (hv_NumberRegions<hv_NumberTexts))
  {
    throw HException((("Too few regions for the given number of texts: "+hv_NumberRegions)+" vs. ")+hv_NumberTexts);
  }

  ClearWindow(hv_WindowHandleMenu);
  GetWindowExtents(hv_WindowHandleMenu, &hv_Row, &hv_Column, &hv_Width1, &hv_Height1);

  {
  HTuple end_val10 = hv_NumberTexts;
  HTuple step_val10 = 1;
  for (hv_i=1; hv_i.Continue(end_val10, step_val10); hv_i += step_val10)
  {
    SelectObj(ho_MenuRegions, &ho_MenuRegion, hv_i);
    hv_Text = HTuple(hv_MenuText[hv_i-1]);
    SetColor(hv_WindowHandleMenu, "light gray");
    HDevWindowStack::SetActive(hv_WindowHandleMenu);
    if (HDevWindowStack::IsOpen())
      SetDraw(HDevWindowStack::GetActive(),"fill");
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),"light gray");
    DispRegion(ho_MenuRegion, hv_WindowHandleMenu);
    GetRegionContour(ho_MenuRegion, &hv_Rows, &hv_Cols);
    SetColor(hv_WindowHandleMenu, "dim gray");
    GenRegionPoints(&ho_RegionBorder, hv_Rows, hv_Cols);
    DispRegion(ho_RegionBorder, hv_WindowHandleMenu);
    //
    TupleFind(hv_CasesDone, hv_i-1, &hv_Indices);
    hv_Done = 0;
    if (0 != ((hv_i-1)==hv_CurrentCase))
    {
      SetColor(hv_WindowHandleMenu, "#FA8072");
    }
    else if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      SetColor(hv_WindowHandleMenu, "#228B22");
      hv_Done = 1;
    }
    else
    {
      SetColor(hv_WindowHandleMenu, "#B22222");
    }
    GetStringExtents(hv_WindowHandleMenu, hv_Text, &hv_Ascent, &hv_Descent, &hv_Width, 
        &hv_Height);
    SetTposition(hv_WindowHandleMenu, (hv_Rows.TupleMin())+6, (((hv_Cols.TupleMax())+(hv_Cols.TupleMin()))/2)-(hv_Width/2));
    WriteString(hv_WindowHandleMenu, hv_Text);
    if (0 != hv_Done)
    {
      hv_Row = 0.5*((hv_Rows.TupleMax())+(hv_Rows.TupleMin()));
      hv_Col = ((((hv_Cols.TupleMax())+(hv_Cols.TupleMin()))/2)+(hv_Width/2))+15;
      hv_Scale = (hv_Rows.TupleMax())-(hv_Rows.TupleMin());
      GenContourPolygonXld(&ho_Contour, hv_Row+((((-hv_Scale)*0.2).TupleConcat(0)).TupleConcat((-hv_Scale)*0.35)), 
          hv_Col+((HTuple(0).TupleConcat(hv_Scale*0.12)).TupleConcat(hv_Scale*0.24)));
      SetLineWidth(hv_WindowHandleMenu, 2);
      DispObj(ho_Contour, hv_WindowHandleMenu);
    }
  }
  }
  return;
}

// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_message (HTuple hv_WindowHandle, HTuple hv_String, HTuple hv_CoordSystem, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_Color, HTuple hv_Box)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_GenParamName, hv_GenParamValue;

  //This procedure displays text in a graphics window.
  //
  //Input parameters:
  //WindowHandle: The WindowHandle of the graphics window, where
  //   the message should be displayed
  //String: A tuple of strings containing the text message to be displayed
  //CoordSystem: If set to 'window', the text position is given
  //   with respect to the window coordinate system.
  //   If set to 'image', image coordinates are used.
  //   (This may be useful in zoomed images.)
  //Row: The row coordinate of the desired text position
  //   A tuple of values is allowed to display text at different
  //   positions.
  //Column: The column coordinate of the desired text position
  //   A tuple of values is allowed to display text at different
  //   positions.
  //Color: defines the color of the text as string.
  //   If set to [], '' or 'auto' the currently set color is used.
  //   If a tuple of strings is passed, the colors are used cyclically...
  //   - if |Row| == |Column| == 1: for each new textline
  //   = else for each text position.
  //Box: If Box[0] is set to 'true', the text is written within an orange box.
  //     If set to' false', no box is displayed.
  //     If set to a color string (e.g. 'white', '#FF00CC', etc.),
  //       the text is written in a box of that color.
  //     An optional second value for Box (Box[1]) controls if a shadow is displayed:
  //       'true' -> display a shadow in a default color
  //       'false' -> display no shadow
  //       otherwise -> use given string as color string for the shadow color
  //
  //It is possible to display multiple text strings in a single call.
  //In this case, some restrictions apply:
  //- Multiple text positions can be defined by specifying a tuple
  //  with multiple Row and/or Column coordinates, i.e.:
  //  - |Row| == n, |Column| == n
  //  - |Row| == n, |Column| == 1
  //  - |Row| == 1, |Column| == n
  //- If |Row| == |Column| == 1,
  //  each element of String is display in a new textline.
  //- If multiple positions or specified, the number of Strings
  //  must match the number of positions, i.e.:
  //  - Either |String| == n (each string is displayed at the
  //                          corresponding position),
  //  - or     |String| == 1 (The string is displayed n times).
  //
  //
  //Convert the parameters for disp_text.
  if (0 != (HTuple(hv_Row==HTuple()).TupleOr(hv_Column==HTuple())))
  {
    return;
  }
  if (0 != (hv_Row==-1))
  {
    hv_Row = 12;
  }
  if (0 != (hv_Column==-1))
  {
    hv_Column = 12;
  }
  //
  //Convert the parameter Box to generic parameters.
  hv_GenParamName = HTuple();
  hv_GenParamValue = HTuple();
  if (0 != ((hv_Box.TupleLength())>0))
  {
    if (0 != (HTuple(hv_Box[0])==HTuple("false")))
    {
      //Display no box
      hv_GenParamName = hv_GenParamName.TupleConcat("box");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[0])!=HTuple("true")))
    {
      //Set a color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("box_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[0]));
    }
  }
  if (0 != ((hv_Box.TupleLength())>1))
  {
    if (0 != (HTuple(hv_Box[1])==HTuple("false")))
    {
      //Display no shadow.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[1])!=HTuple("true")))
    {
      //Set a shadow color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[1]));
    }
  }
  //Restore default CoordSystem behavior.
  if (0 != (hv_CoordSystem!=HTuple("window")))
  {
    hv_CoordSystem = "image";
  }
  //
  if (0 != (hv_Color==HTuple("")))
  {
    //disp_text does not accept an empty string for Color.
    hv_Color = HTuple();
  }
  //
  DispText(hv_WindowHandle, hv_String, hv_CoordSystem, hv_Row, hv_Column, hv_Color, 
      hv_GenParamName, hv_GenParamValue);
  return;
}

// Chapter: Graphics / Output
// Short Description: This procedure calls disp_object_model_3d and a fallback solution if there is no OpenGL Available. 
void disp_object_model_3d_safe (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_Pose, HTuple hv_GenParamName, HTuple hv_GenParamValue)
{

  // Local iconic variables
  HObject  ho_ModelContours;

  // Local control variables
  HTuple  hv_Exception, hv_Center, hv_CPLength;
  HTuple  hv_RowNotUsed, hv_ColumnNotUsed, hv_Width, hv_Height;
  HTuple  hv_CamParamValue, hv_CamWidth, hv_CamHeight, hv_Scale;
  HTuple  hv_NumModels, hv_PoseEstimated, hv_Poses, hv_HomMat3Ds;
  HTuple  hv_Sequence, hv_Indices;

  try
  {
    DispObjectModel3d(hv_WindowHandle, hv_ObjectModel3D, hv_CamParam, hv_Pose, hv_GenParamName, 
        hv_GenParamValue);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    //Read and check the parameter PoseIn for each object
    get_object_models_center(hv_ObjectModel3D, &hv_Center);
    hv_CPLength = hv_CamParam.TupleLength();
    GetWindowExtents(hv_WindowHandle, &hv_RowNotUsed, &hv_ColumnNotUsed, &hv_Width, 
        &hv_Height);
    if (0 != (hv_CPLength==0))
    {
      gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
          hv_Width, hv_Height, &hv_CamParam);
    }
    else
    {
      get_cam_par_data(hv_CamParam, (((((HTuple("sx").Append("sy")).Append("cx")).Append("cy")).Append("image_width")).Append("image_height")), 
          &hv_CamParamValue);
      hv_CamWidth = HTuple(hv_CamParamValue[4]).TupleReal();
      hv_CamHeight = HTuple(hv_CamParamValue[5]).TupleReal();
      hv_Scale = ((hv_Width/hv_CamWidth).TupleConcat(hv_Height/hv_CamHeight)).TupleMin();
      set_cam_par_data(hv_CamParam, "sx", HTuple(hv_CamParamValue[0])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "sy", HTuple(hv_CamParamValue[1])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cx", HTuple(hv_CamParamValue[2])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cy", HTuple(hv_CamParamValue[3])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_width", (HTuple(hv_CamParamValue[4])*hv_Scale).TupleInt(), 
          &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_height", (HTuple(hv_CamParamValue[5])*hv_Scale).TupleInt(), 
          &hv_CamParam);
    }
    hv_NumModels = hv_ObjectModel3D.TupleLength();
    if (0 != ((hv_Pose.TupleLength())==0))
    {
      //If no pose was specified by the caller, automatically calculate
      //a pose that is appropriate for the visualization.
      //Set the initial model reference pose. The orientation is parallel
      //to the object coordinate system, the position is at the center
      //of gravity of all models.
      CreatePose(-HTuple(hv_Center[0]), -HTuple(hv_Center[1]), -HTuple(hv_Center[2]), 
          0, 0, 0, "Rp+T", "gba", "point", &hv_Pose);
      determine_optimum_pose_distance(hv_ObjectModel3D, hv_CamParam, 0.9, hv_Pose, 
          &hv_PoseEstimated);
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_PoseEstimated[hv_Sequence%7]);
    }
    else if (0 != ((hv_Pose.TupleLength())==7))
    {
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_Pose[hv_Sequence%7]);
    }
    else
    {
      if (0 != ((hv_Pose.TupleLength())!=((hv_ObjectModel3D.TupleLength())*7)))
      {
        //Error: Wrong number of values of input control parameter 'PoseIn'
        // stop(...); only in hdevelop
      }
      else
      {
        hv_Poses = hv_Pose;
      }
    }
    TupleFind(hv_GenParamName, "disp_background", &hv_Indices);
    if (0 != (hv_Indices>0))
    {
      if (0 != (HTuple(hv_GenParamValue[hv_Indices])==HTuple("true")))
      {
        //display background do not clear background
      }
      else
      {
        HDevWindowStack::SetActive(hv_WindowHandle);
        if (HDevWindowStack::IsOpen())
          ClearWindow(HDevWindowStack::GetActive());
      }
    }
    else
    {
      //No indication of  'disp_background' clear window
      HDevWindowStack::SetActive(hv_WindowHandle);
      if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
    }
    disp_object_model_no_opengl(&ho_ModelContours, hv_ObjectModel3D, hv_GenParamName, 
        hv_GenParamValue, hv_WindowHandle, hv_CamParam, hv_Poses);
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: This procedure calls disp_object_model_3d and a fallback solution if there is no OpenGL Available. 
void disp_object_model_3d_safe_visualize_object_model_3d (HTuple hv_WindowHandle, 
    HTuple hv_ObjectModel3D, HTuple hv_CamParam, HTuple hv_Pose, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue)
{

  // Local iconic variables
  HObject  ho_ModelContours;

  // Local control variables
  HTuple  hv_Exception, hv_Center, hv_CPLength;
  HTuple  hv_RowNotUsed, hv_ColumnNotUsed, hv_Width, hv_Height;
  HTuple  hv_CamParamValue, hv_CamWidth, hv_CamHeight, hv_Scale;
  HTuple  hv_NumModels, hv_PoseEstimated, hv_Poses, hv_HomMat3Ds;
  HTuple  hv_Sequence, hv_Indices;

  try
  {
    DispObjectModel3d(hv_WindowHandle, hv_ObjectModel3D, hv_CamParam, hv_Pose, hv_GenParamName, 
        hv_GenParamValue);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    //Read and check the parameter PoseIn for each object
    get_object_models_center_visualize_object_model_3d(hv_ObjectModel3D, &hv_Center);
    hv_CPLength = hv_CamParam.TupleLength();
    GetWindowExtents(hv_WindowHandle, &hv_RowNotUsed, &hv_ColumnNotUsed, &hv_Width, 
        &hv_Height);
    if (0 != (hv_CPLength==0))
    {
      gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
          hv_Width, hv_Height, &hv_CamParam);
    }
    else
    {
      get_cam_par_data(hv_CamParam, (((((HTuple("sx").Append("sy")).Append("cx")).Append("cy")).Append("image_width")).Append("image_height")), 
          &hv_CamParamValue);
      hv_CamWidth = HTuple(hv_CamParamValue[4]).TupleReal();
      hv_CamHeight = HTuple(hv_CamParamValue[5]).TupleReal();
      hv_Scale = ((hv_Width/hv_CamWidth).TupleConcat(hv_Height/hv_CamHeight)).TupleMin();
      set_cam_par_data(hv_CamParam, "sx", HTuple(hv_CamParamValue[0])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "sy", HTuple(hv_CamParamValue[1])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cx", HTuple(hv_CamParamValue[2])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cy", HTuple(hv_CamParamValue[3])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_width", (HTuple(hv_CamParamValue[4])*hv_Scale).TupleInt(), 
          &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_height", (HTuple(hv_CamParamValue[5])*hv_Scale).TupleInt(), 
          &hv_CamParam);
    }
    hv_NumModels = hv_ObjectModel3D.TupleLength();
    if (0 != ((hv_Pose.TupleLength())==0))
    {
      //If no pose was specified by the caller, automatically calculate
      //a pose that is appropriate for the visualization.
      //Set the initial model reference pose. The orientation is parallel
      //to the object coordinate system, the position is at the center
      //of gravity of all models.
      CreatePose(-HTuple(hv_Center[0]), -HTuple(hv_Center[1]), -HTuple(hv_Center[2]), 
          0, 0, 0, "Rp+T", "gba", "point", &hv_Pose);
      determine_optimum_pose_distance_visualize_object_model_3d(hv_ObjectModel3D, 
          hv_CamParam, 0.9, hv_Pose, &hv_PoseEstimated);
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_PoseEstimated[hv_Sequence%7]);
    }
    else if (0 != ((hv_Pose.TupleLength())==7))
    {
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_Pose[hv_Sequence%7]);
    }
    else
    {
      if (0 != ((hv_Pose.TupleLength())!=((hv_ObjectModel3D.TupleLength())*7)))
      {
        //Error: Wrong number of values of input control parameter 'PoseIn'
        // stop(...); only in hdevelop
      }
      else
      {
        hv_Poses = hv_Pose;
      }
    }
    TupleFind(hv_GenParamName, "disp_background", &hv_Indices);
    if (0 != (hv_Indices>0))
    {
      if (0 != (HTuple(hv_GenParamValue[hv_Indices])==HTuple("true")))
      {
        //display background do not clear background
      }
      else
      {
        HDevWindowStack::SetActive(hv_WindowHandle);
        if (HDevWindowStack::IsOpen())
          ClearWindow(HDevWindowStack::GetActive());
      }
    }
    else
    {
      //No indication of  'disp_background' clear window
      HDevWindowStack::SetActive(hv_WindowHandle);
      if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
    }
    disp_object_model_no_opengl_visualize_object_model_3d(&ho_ModelContours, hv_ObjectModel3D, 
        hv_GenParamName, hv_GenParamValue, hv_WindowHandle, hv_CamParam, hv_Poses);
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Can replace disp_object_model_3d if there is no OpenGL available. 
void disp_object_model_no_opengl (HObject *ho_ModelContours, HTuple hv_ObjectModel3DID, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandleBuffer, 
    HTuple hv_CamParam, HTuple hv_PosesOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Idx, hv_CustomParamName, hv_CustomParamValue;
  HTuple  hv_Font, hv_IndicesDispBackGround, hv_Indices, hv_ImageWidth;
  HTuple  hv_HasPolygons, hv_HasTri, hv_HasPoints, hv_HasLines;
  HTuple  hv_NumPoints, hv_IsPrimitive, hv_Center, hv_Diameter;
  HTuple  hv_OpenGlHiddenSurface, hv_CenterX, hv_CenterY;
  HTuple  hv_CenterZ, hv_PosObjectsZ, hv_I, hv_Pose, hv_HomMat3DObj;
  HTuple  hv_PosObjCenterX, hv_PosObjCenterY, hv_PosObjCenterZ;
  HTuple  hv_PosObjectsX, hv_PosObjectsY, hv_Color, hv_Indices1;
  HTuple  hv_Indices2, hv_J, hv_Indices3, hv_HomMat3D, hv_SampledObjectModel3D;
  HTuple  hv_X, hv_Y, hv_Z, hv_HomMat3D1, hv_Qx, hv_Qy, hv_Qz;
  HTuple  hv_Row, hv_Column, hv_ObjectModel3DConvexHull, hv_Exception;

  //This procedure allows to use project_object_model_3d to simulate a disp_object_model_3d
  //call for small objects. Large objects are sampled down to display.
  hv_Idx = hv_GenParamName.TupleFind("point_size");
  if (0 != (HTuple(hv_Idx.TupleLength()).TupleAnd(hv_Idx!=-1)))
  {
    hv_CustomParamName = "point_size";
    hv_CustomParamValue = HTuple(hv_GenParamValue[hv_Idx]);
    if (0 != (hv_CustomParamValue==1))
    {
      hv_CustomParamValue = 0;
    }
  }
  else
  {
    hv_CustomParamName = HTuple();
    hv_CustomParamValue = HTuple();
  }
  GetFont(hv_WindowHandleBuffer, &hv_Font);
  TupleFind(hv_GenParamName, "disp_background", &hv_IndicesDispBackGround);
  if (0 != (hv_IndicesDispBackGround!=-1))
  {
    TupleFind(HTuple(hv_GenParamName[hv_IndicesDispBackGround]), "false", &hv_Indices);
    if (0 != (hv_Indices!=-1))
    {
      ClearWindow(hv_WindowHandleBuffer);
    }
  }
  set_display_font(hv_WindowHandleBuffer, 11, "mono", "false", "false");
  get_cam_par_data(hv_CamParam, "image_width", &hv_ImageWidth);
  disp_message(hv_WindowHandleBuffer, "OpenGL missing!", "image", 5, hv_ImageWidth-130, 
      "red", "false");
  SetFont(hv_WindowHandleBuffer, hv_Font);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_polygons", &hv_HasPolygons);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_triangles", &hv_HasTri);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_points", &hv_HasPoints);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_lines", &hv_HasLines);
  GetObjectModel3dParams(hv_ObjectModel3DID, "num_points", &hv_NumPoints);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_primitive_data", &hv_IsPrimitive);
  GetObjectModel3dParams(hv_ObjectModel3DID, "center", &hv_Center);
  GetObjectModel3dParams(hv_ObjectModel3DID, "diameter", &hv_Diameter);
  GetSystem("opengl_hidden_surface_removal_enable", &hv_OpenGlHiddenSurface);
  SetSystem("opengl_hidden_surface_removal_enable", "false");
  //Sort the objects by inverse z
  hv_CenterX = ((const HTuple&)hv_Center)[HTuple::TupleGenSequence(0,(hv_Center.TupleLength())-1,3)];
  hv_CenterY = ((const HTuple&)hv_Center)[HTuple::TupleGenSequence(0,(hv_Center.TupleLength())-1,3)+1];
  hv_CenterZ = ((const HTuple&)hv_Center)[HTuple::TupleGenSequence(0,(hv_Center.TupleLength())-1,3)+2];
  hv_PosObjectsZ = HTuple();
  if (0 != ((hv_PosesOut.TupleLength())>7))
  {
    {
    HTuple end_val41 = (hv_ObjectModel3DID.TupleLength())-1;
    HTuple step_val41 = 1;
    for (hv_I=0; hv_I.Continue(end_val41, step_val41); hv_I += step_val41)
    {
      hv_Pose = hv_PosesOut.TupleSelectRange(hv_I*7,(hv_I*7)+6);
      PoseToHomMat3d(hv_Pose, &hv_HomMat3DObj);
      AffineTransPoint3d(hv_HomMat3DObj, HTuple(hv_CenterX[hv_I]), HTuple(hv_CenterY[hv_I]), 
          HTuple(hv_CenterZ[hv_I]), &hv_PosObjCenterX, &hv_PosObjCenterY, &hv_PosObjCenterZ);
      hv_PosObjectsZ = hv_PosObjectsZ.TupleConcat(hv_PosObjCenterZ);
    }
    }
  }
  else
  {
    hv_Pose = hv_PosesOut.TupleSelectRange(0,6);
    PoseToHomMat3d(hv_Pose, &hv_HomMat3DObj);
    AffineTransPoint3d(hv_HomMat3DObj, hv_CenterX, hv_CenterY, hv_CenterZ, &hv_PosObjectsX, 
        &hv_PosObjectsY, &hv_PosObjectsZ);
  }
  hv_Idx = HTuple(hv_PosObjectsZ.TupleSortIndex()).TupleInverse();
  hv_Color = "white";
  SetColor(hv_WindowHandleBuffer, hv_Color);
  if (0 != ((hv_GenParamName.TupleLength())>0))
  {
    TupleFind(hv_GenParamName, "colored", &hv_Indices1);
    TupleFind(hv_GenParamName, "color", &hv_Indices2);
    if (0 != (HTuple(hv_Indices1[0])!=-1))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices1[0])])==3))
      {
        hv_Color.Clear();
        hv_Color[0] = "red";
        hv_Color[1] = "green";
        hv_Color[2] = "blue";
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices1[0])])==6))
      {
        hv_Color.Clear();
        hv_Color[0] = "red";
        hv_Color[1] = "green";
        hv_Color[2] = "blue";
        hv_Color[3] = "cyan";
        hv_Color[4] = "magenta";
        hv_Color[5] = "yellow";
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices1[0])])==12))
      {
        hv_Color.Clear();
        hv_Color[0] = "red";
        hv_Color[1] = "green";
        hv_Color[2] = "blue";
        hv_Color[3] = "cyan";
        hv_Color[4] = "magenta";
        hv_Color[5] = "yellow";
        hv_Color[6] = "coral";
        hv_Color[7] = "slate blue";
        hv_Color[8] = "spring green";
        hv_Color[9] = "orange red";
        hv_Color[10] = "pink";
        hv_Color[11] = "gold";
      }
    }
    else if (0 != (HTuple(hv_Indices2[0])!=-1))
    {
      hv_Color = HTuple(hv_GenParamValue[HTuple(hv_Indices2[0])]);
    }
  }
  {
  HTuple end_val70 = (hv_ObjectModel3DID.TupleLength())-1;
  HTuple step_val70 = 1;
  for (hv_J=0; hv_J.Continue(end_val70, step_val70); hv_J += step_val70)
  {
    hv_I = HTuple(hv_Idx[hv_J]);
    if (0 != (HTuple(HTuple(HTuple(HTuple(hv_HasPolygons[hv_I])==HTuple("true")).TupleOr(HTuple(hv_HasTri[hv_I])==HTuple("true"))).TupleOr(HTuple(hv_HasPoints[hv_I])==HTuple("true"))).TupleOr(HTuple(hv_HasLines[hv_I])==HTuple("true"))))
    {
      if (0 != ((hv_GenParamName.TupleLength())>0))
      {
        TupleFind(hv_GenParamName, "color_"+hv_I, &hv_Indices3);
        if (0 != (HTuple(hv_Indices3[0])!=-1))
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_GenParamValue[HTuple(hv_Indices3[0])]));
        }
        else
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
        }
      }
      if (0 != ((hv_PosesOut.TupleLength())>=((hv_I*7)+6)))
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(hv_I*7,(hv_I*7)+6);
      }
      else
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(0,6);
      }
      if (0 != (HTuple(hv_NumPoints[hv_I])<10000))
      {
        ProjectObjectModel3d(&(*ho_ModelContours), HTuple(hv_ObjectModel3DID[hv_I]), 
            hv_CamParam, hv_Pose, hv_CustomParamName, hv_CustomParamValue);
        DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
      }
      else
      {
        PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
        SampleObjectModel3d(HTuple(hv_ObjectModel3DID[hv_I]), "fast", 0.01*HTuple(hv_Diameter[hv_I]), 
            HTuple(), HTuple(), &hv_SampledObjectModel3D);
        ProjectObjectModel3d(&(*ho_ModelContours), hv_SampledObjectModel3D, hv_CamParam, 
            hv_Pose, "point_size", 1);
        GetObjectModel3dParams(hv_SampledObjectModel3D, "point_coord_x", &hv_X);
        GetObjectModel3dParams(hv_SampledObjectModel3D, "point_coord_y", &hv_Y);
        GetObjectModel3dParams(hv_SampledObjectModel3D, "point_coord_z", &hv_Z);
        PoseToHomMat3d(hv_Pose, &hv_HomMat3D1);
        AffineTransPoint3d(hv_HomMat3D1, hv_X, hv_Y, hv_Z, &hv_Qx, &hv_Qy, &hv_Qz);
        Project3dPoint(hv_Qx, hv_Qy, hv_Qz, hv_CamParam, &hv_Row, &hv_Column);
        DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
        ClearObjectModel3d(hv_SampledObjectModel3D);
      }
    }
    else
    {
      if (0 != ((hv_GenParamName.TupleLength())>0))
      {
        TupleFind(hv_GenParamName, "color_"+hv_I, &hv_Indices3);
        if (0 != (HTuple(hv_Indices3[0])!=-1))
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_GenParamValue[HTuple(hv_Indices3[0])]));
        }
        else
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
        }
      }
      if (0 != ((hv_PosesOut.TupleLength())>=((hv_I*7)+6)))
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(hv_I*7,(hv_I*7)+6);
      }
      else
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(0,6);
      }
      if (0 != (HTuple(hv_IsPrimitive[hv_I])==HTuple("true")))
      {
        try
        {
          ConvexHullObjectModel3d(HTuple(hv_ObjectModel3DID[hv_I]), &hv_ObjectModel3DConvexHull);
          if (0 != (HTuple(hv_NumPoints[hv_I])<10000))
          {
            ProjectObjectModel3d(&(*ho_ModelContours), hv_ObjectModel3DConvexHull, 
                hv_CamParam, hv_Pose, hv_CustomParamName, hv_CustomParamValue);
            DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
          }
          else
          {
            PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
            SampleObjectModel3d(hv_ObjectModel3DConvexHull, "fast", 0.01*HTuple(hv_Diameter[hv_I]), 
                HTuple(), HTuple(), &hv_SampledObjectModel3D);
            ProjectObjectModel3d(&(*ho_ModelContours), hv_SampledObjectModel3D, hv_CamParam, 
                hv_Pose, "point_size", 1);
            DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
            ClearObjectModel3d(hv_SampledObjectModel3D);
          }
          ClearObjectModel3d(hv_ObjectModel3DConvexHull);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
        }
      }
    }
  }
  }
  SetSystem("opengl_hidden_surface_removal_enable", hv_OpenGlHiddenSurface);
  return;
}

// Chapter: Graphics / Output
// Short Description: Can replace disp_object_model_3d if there is no OpenGL available. 
void disp_object_model_no_opengl_visualize_object_model_3d (HObject *ho_ModelContours, 
    HTuple hv_ObjectModel3DID, HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandleBuffer, 
    HTuple hv_CamParam, HTuple hv_PosesOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Idx, hv_CustomParamName, hv_CustomParamValue;
  HTuple  hv_Font, hv_IndicesDispBackGround, hv_Indices, hv_ImageWidth;
  HTuple  hv_HasPolygons, hv_HasTri, hv_HasPoints, hv_HasLines;
  HTuple  hv_NumPoints, hv_IsPrimitive, hv_Center, hv_Diameter;
  HTuple  hv_OpenGlHiddenSurface, hv_CenterX, hv_CenterY;
  HTuple  hv_CenterZ, hv_PosObjectsZ, hv_I, hv_Pose, hv_HomMat3DObj;
  HTuple  hv_PosObjCenterX, hv_PosObjCenterY, hv_PosObjCenterZ;
  HTuple  hv_PosObjectsX, hv_PosObjectsY, hv_Color, hv_Indices1;
  HTuple  hv_Indices2, hv_J, hv_Indices3, hv_HomMat3D, hv_SampledObjectModel3D;
  HTuple  hv_X, hv_Y, hv_Z, hv_HomMat3D1, hv_Qx, hv_Qy, hv_Qz;
  HTuple  hv_Row, hv_Column, hv_ObjectModel3DConvexHull, hv_Exception;

  //This procedure allows to use project_object_model_3d to simulate a disp_object_model_3d
  //call for small objects. Large objects are sampled down to display.
  hv_Idx = hv_GenParamName.TupleFind("point_size");
  if (0 != (HTuple(hv_Idx.TupleLength()).TupleAnd(hv_Idx!=-1)))
  {
    hv_CustomParamName = "point_size";
    hv_CustomParamValue = HTuple(hv_GenParamValue[hv_Idx]);
    if (0 != (hv_CustomParamValue==1))
    {
      hv_CustomParamValue = 0;
    }
  }
  else
  {
    hv_CustomParamName = HTuple();
    hv_CustomParamValue = HTuple();
  }
  GetFont(hv_WindowHandleBuffer, &hv_Font);
  TupleFind(hv_GenParamName, "disp_background", &hv_IndicesDispBackGround);
  if (0 != (hv_IndicesDispBackGround!=-1))
  {
    TupleFind(HTuple(hv_GenParamName[hv_IndicesDispBackGround]), "false", &hv_Indices);
    if (0 != (hv_Indices!=-1))
    {
      ClearWindow(hv_WindowHandleBuffer);
    }
  }
  set_display_font(hv_WindowHandleBuffer, 11, "mono", "false", "false");
  get_cam_par_data(hv_CamParam, "image_width", &hv_ImageWidth);
  disp_message(hv_WindowHandleBuffer, "OpenGL missing!", "image", 5, hv_ImageWidth-130, 
      "red", "false");
  SetFont(hv_WindowHandleBuffer, hv_Font);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_polygons", &hv_HasPolygons);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_triangles", &hv_HasTri);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_points", &hv_HasPoints);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_lines", &hv_HasLines);
  GetObjectModel3dParams(hv_ObjectModel3DID, "num_points", &hv_NumPoints);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_primitive_data", &hv_IsPrimitive);
  GetObjectModel3dParams(hv_ObjectModel3DID, "center", &hv_Center);
  GetObjectModel3dParams(hv_ObjectModel3DID, "diameter", &hv_Diameter);
  GetSystem("opengl_hidden_surface_removal_enable", &hv_OpenGlHiddenSurface);
  SetSystem("opengl_hidden_surface_removal_enable", "false");
  //Sort the objects by inverse z
  hv_CenterX = ((const HTuple&)hv_Center)[HTuple::TupleGenSequence(0,(hv_Center.TupleLength())-1,3)];
  hv_CenterY = ((const HTuple&)hv_Center)[HTuple::TupleGenSequence(0,(hv_Center.TupleLength())-1,3)+1];
  hv_CenterZ = ((const HTuple&)hv_Center)[HTuple::TupleGenSequence(0,(hv_Center.TupleLength())-1,3)+2];
  hv_PosObjectsZ = HTuple();
  if (0 != ((hv_PosesOut.TupleLength())>7))
  {
    {
    HTuple end_val41 = (hv_ObjectModel3DID.TupleLength())-1;
    HTuple step_val41 = 1;
    for (hv_I=0; hv_I.Continue(end_val41, step_val41); hv_I += step_val41)
    {
      hv_Pose = hv_PosesOut.TupleSelectRange(hv_I*7,(hv_I*7)+6);
      PoseToHomMat3d(hv_Pose, &hv_HomMat3DObj);
      AffineTransPoint3d(hv_HomMat3DObj, HTuple(hv_CenterX[hv_I]), HTuple(hv_CenterY[hv_I]), 
          HTuple(hv_CenterZ[hv_I]), &hv_PosObjCenterX, &hv_PosObjCenterY, &hv_PosObjCenterZ);
      hv_PosObjectsZ = hv_PosObjectsZ.TupleConcat(hv_PosObjCenterZ);
    }
    }
  }
  else
  {
    hv_Pose = hv_PosesOut.TupleSelectRange(0,6);
    PoseToHomMat3d(hv_Pose, &hv_HomMat3DObj);
    AffineTransPoint3d(hv_HomMat3DObj, hv_CenterX, hv_CenterY, hv_CenterZ, &hv_PosObjectsX, 
        &hv_PosObjectsY, &hv_PosObjectsZ);
  }
  hv_Idx = HTuple(hv_PosObjectsZ.TupleSortIndex()).TupleInverse();
  hv_Color = "white";
  SetColor(hv_WindowHandleBuffer, hv_Color);
  if (0 != ((hv_GenParamName.TupleLength())>0))
  {
    TupleFind(hv_GenParamName, "colored", &hv_Indices1);
    TupleFind(hv_GenParamName, "color", &hv_Indices2);
    if (0 != (HTuple(hv_Indices1[0])!=-1))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices1[0])])==3))
      {
        hv_Color.Clear();
        hv_Color[0] = "red";
        hv_Color[1] = "green";
        hv_Color[2] = "blue";
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices1[0])])==6))
      {
        hv_Color.Clear();
        hv_Color[0] = "red";
        hv_Color[1] = "green";
        hv_Color[2] = "blue";
        hv_Color[3] = "cyan";
        hv_Color[4] = "magenta";
        hv_Color[5] = "yellow";
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices1[0])])==12))
      {
        hv_Color.Clear();
        hv_Color[0] = "red";
        hv_Color[1] = "green";
        hv_Color[2] = "blue";
        hv_Color[3] = "cyan";
        hv_Color[4] = "magenta";
        hv_Color[5] = "yellow";
        hv_Color[6] = "coral";
        hv_Color[7] = "slate blue";
        hv_Color[8] = "spring green";
        hv_Color[9] = "orange red";
        hv_Color[10] = "pink";
        hv_Color[11] = "gold";
      }
    }
    else if (0 != (HTuple(hv_Indices2[0])!=-1))
    {
      hv_Color = HTuple(hv_GenParamValue[HTuple(hv_Indices2[0])]);
    }
  }
  {
  HTuple end_val70 = (hv_ObjectModel3DID.TupleLength())-1;
  HTuple step_val70 = 1;
  for (hv_J=0; hv_J.Continue(end_val70, step_val70); hv_J += step_val70)
  {
    hv_I = HTuple(hv_Idx[hv_J]);
    if (0 != (HTuple(HTuple(HTuple(HTuple(hv_HasPolygons[hv_I])==HTuple("true")).TupleOr(HTuple(hv_HasTri[hv_I])==HTuple("true"))).TupleOr(HTuple(hv_HasPoints[hv_I])==HTuple("true"))).TupleOr(HTuple(hv_HasLines[hv_I])==HTuple("true"))))
    {
      if (0 != ((hv_GenParamName.TupleLength())>0))
      {
        TupleFind(hv_GenParamName, "color_"+hv_I, &hv_Indices3);
        if (0 != (HTuple(hv_Indices3[0])!=-1))
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_GenParamValue[HTuple(hv_Indices3[0])]));
        }
        else
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
        }
      }
      if (0 != ((hv_PosesOut.TupleLength())>=((hv_I*7)+6)))
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(hv_I*7,(hv_I*7)+6);
      }
      else
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(0,6);
      }
      if (0 != (HTuple(hv_NumPoints[hv_I])<10000))
      {
        ProjectObjectModel3d(&(*ho_ModelContours), HTuple(hv_ObjectModel3DID[hv_I]), 
            hv_CamParam, hv_Pose, hv_CustomParamName, hv_CustomParamValue);
        DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
      }
      else
      {
        PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
        SampleObjectModel3d(HTuple(hv_ObjectModel3DID[hv_I]), "fast", 0.01*HTuple(hv_Diameter[hv_I]), 
            HTuple(), HTuple(), &hv_SampledObjectModel3D);
        ProjectObjectModel3d(&(*ho_ModelContours), hv_SampledObjectModel3D, hv_CamParam, 
            hv_Pose, "point_size", 1);
        GetObjectModel3dParams(hv_SampledObjectModel3D, "point_coord_x", &hv_X);
        GetObjectModel3dParams(hv_SampledObjectModel3D, "point_coord_y", &hv_Y);
        GetObjectModel3dParams(hv_SampledObjectModel3D, "point_coord_z", &hv_Z);
        PoseToHomMat3d(hv_Pose, &hv_HomMat3D1);
        AffineTransPoint3d(hv_HomMat3D1, hv_X, hv_Y, hv_Z, &hv_Qx, &hv_Qy, &hv_Qz);
        Project3dPoint(hv_Qx, hv_Qy, hv_Qz, hv_CamParam, &hv_Row, &hv_Column);
        DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
        ClearObjectModel3d(hv_SampledObjectModel3D);
      }
    }
    else
    {
      if (0 != ((hv_GenParamName.TupleLength())>0))
      {
        TupleFind(hv_GenParamName, "color_"+hv_I, &hv_Indices3);
        if (0 != (HTuple(hv_Indices3[0])!=-1))
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_GenParamValue[HTuple(hv_Indices3[0])]));
        }
        else
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
        }
      }
      if (0 != ((hv_PosesOut.TupleLength())>=((hv_I*7)+6)))
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(hv_I*7,(hv_I*7)+6);
      }
      else
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(0,6);
      }
      if (0 != (HTuple(hv_IsPrimitive[hv_I])==HTuple("true")))
      {
        try
        {
          ConvexHullObjectModel3d(HTuple(hv_ObjectModel3DID[hv_I]), &hv_ObjectModel3DConvexHull);
          if (0 != (HTuple(hv_NumPoints[hv_I])<10000))
          {
            ProjectObjectModel3d(&(*ho_ModelContours), hv_ObjectModel3DConvexHull, 
                hv_CamParam, hv_Pose, hv_CustomParamName, hv_CustomParamValue);
            DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
          }
          else
          {
            PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
            SampleObjectModel3d(hv_ObjectModel3DConvexHull, "fast", 0.01*HTuple(hv_Diameter[hv_I]), 
                HTuple(), HTuple(), &hv_SampledObjectModel3D);
            ProjectObjectModel3d(&(*ho_ModelContours), hv_SampledObjectModel3D, hv_CamParam, 
                hv_Pose, "point_size", 1);
            DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
            ClearObjectModel3d(hv_SampledObjectModel3D);
          }
          ClearObjectModel3d(hv_ObjectModel3DConvexHull);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
        }
      }
    }
  }
  }
  SetSystem("opengl_hidden_surface_removal_enable", hv_OpenGlHiddenSurface);
  return;
}

void disp_slider (HTuple hv_WindowHandle, HTuple hv_Row, HTuple hv_TotalHeight, HTuple hv_ColLabel, 
    HTuple hv_ColValue, HTuple hv_ColSliderStart, HTuple hv_ColSliderEnd, HTuple hv_Label, 
    HTuple hv_ValueStart, HTuple hv_ValueEnd, HTuple hv_ValueCurr, HTuple hv_FormatString)
{

  // Local iconic variables
  HObject  ho_ButtonRegion, ho_RegionBorder;

  // Local control variables
  HTuple  hv_BarHeight, hv_ButtonHeight, hv_ButtonWidth;
  HTuple  hv_RowMid, hv_SliderPosRel, hv_SliderColMid, hv_Rows;
  HTuple  hv_Cols;

  hv_BarHeight = 2;
  hv_ButtonHeight = hv_TotalHeight*0.6;
  hv_ButtonWidth = 3;

  hv_RowMid = hv_Row+(hv_TotalHeight/2);
  //dev_get_window (WindowHandle)
  //dev_clear_window ()

  //The long bar of the slider
  SetColor(hv_WindowHandle, "light gray");
  DispLine(hv_WindowHandle, hv_RowMid, hv_ColSliderStart, hv_RowMid, hv_ColSliderEnd);
  DispLine(hv_WindowHandle, hv_RowMid-(hv_ButtonHeight/2), hv_ColSliderStart, hv_RowMid+(hv_ButtonHeight/2), 
      hv_ColSliderStart);
  DispLine(hv_WindowHandle, hv_RowMid-(hv_ButtonHeight/2), hv_ColSliderEnd, hv_RowMid+(hv_ButtonHeight/2), 
      hv_ColSliderEnd);

  //The slider itself
  hv_SliderPosRel = ((hv_ValueCurr-hv_ValueStart)*1.0)/(hv_ValueEnd-hv_ValueStart);
  if (0 != (hv_SliderPosRel<0))
  {
    hv_SliderPosRel = 0;
  }
  else if (0 != (hv_SliderPosRel>1))
  {
    hv_SliderPosRel = 1;
  }
  hv_SliderColMid = hv_ColSliderStart+(hv_SliderPosRel*(hv_ColSliderEnd-hv_ColSliderStart));
  GenRectangle1(&ho_ButtonRegion, hv_RowMid-(hv_ButtonHeight/2), hv_SliderColMid-(hv_ButtonWidth/2), 
      hv_RowMid+(hv_ButtonHeight/2), hv_SliderColMid+(hv_ButtonWidth/2));
  SetDraw(hv_WindowHandle, "fill");
  SetColor(hv_WindowHandle, "dark olive green");
  DispRegion(ho_ButtonRegion, hv_WindowHandle);
  GetRegionContour(ho_ButtonRegion, &hv_Rows, &hv_Cols);
  SetColor(hv_WindowHandle, "dim gray");
  GenRegionPoints(&ho_RegionBorder, hv_Rows, hv_Cols);
  DispRegion(ho_RegionBorder, hv_WindowHandle);

  //Label
  DispText(hv_WindowHandle, hv_Label, "window", hv_Row, hv_ColLabel, "white", "box", 
      "false");

  //Value
  DispText(hv_WindowHandle, hv_ValueCurr.TupleString(hv_FormatString), "window", 
      hv_Row, hv_ColValue, "white", "box", "false");

  return;

}

// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_text_button (HTuple hv_WindowHandle, HTuple hv_String, HTuple hv_CoordSystem, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_TextColor, HTuple hv_ButtonColor)
{

  // Local iconic variables
  HObject  ho_UpperLeft, ho_LowerRight, ho_Rectangle;

  // Local control variables
  HTuple  hv_Red, hv_Green, hv_Blue, hv_Row1Part;
  HTuple  hv_Column1Part, hv_Row2Part, hv_Column2Part, hv_RowWin;
  HTuple  hv_ColumnWin, hv_WidthWin, hv_HeightWin, hv_Exception;
  HTuple  hv_Fac, hv_RGB, hv_RGBL, hv_RGBD, hv_ButtonColorBorderL;
  HTuple  hv_ButtonColorBorderD, hv_MaxAscent, hv_MaxDescent;
  HTuple  hv_MaxWidth, hv_MaxHeight, hv_R1, hv_C1, hv_FactorRow;
  HTuple  hv_FactorColumn, hv_Width, hv_Index, hv_Ascent;
  HTuple  hv_Descent, hv_W, hv_H, hv_FrameHeight, hv_FrameWidth;
  HTuple  hv_R2, hv_C2, hv_ClipRegion, hv_DrawMode, hv_BorderWidth;
  HTuple  hv_CurrentColor;

  //This procedure displays text in a graphics window.
  //
  //Input parameters:
  //WindowHandle: The WindowHandle of the graphics window, where
  //   the message should be displayed
  //String: A tuple of strings containing the text message to be displayed
  //CoordSystem: If set to 'window', the text position is given
  //   with respect to the window coordinate system.
  //   If set to 'image', image coordinates are used.
  //   (This may be useful in zoomed images.)
  //Row: The row coordinate of the desired text position
  //   If set to -1, a default value of 12 is used.
  //Column: The column coordinate of the desired text position
  //   If set to -1, a default value of 12 is used.
  //Color: defines the color of the text as string.
  //   If set to [], '' or 'auto' the currently set color is used.
  //   If a tuple of strings is passed, the colors are used cyclically
  //   for each new textline.
  //ButtonColor: Must be set to a color string (e.g. 'white', '#FF00CC', etc.).
  //             The text is written in a box of that color.
  //
  //Prepare window.
  GetRgb(hv_WindowHandle, &hv_Red, &hv_Green, &hv_Blue);
  GetPart(hv_WindowHandle, &hv_Row1Part, &hv_Column1Part, &hv_Row2Part, &hv_Column2Part);
  GetWindowExtents(hv_WindowHandle, &hv_RowWin, &hv_ColumnWin, &hv_WidthWin, &hv_HeightWin);
  SetPart(hv_WindowHandle, 0, 0, hv_HeightWin-1, hv_WidthWin-1);
  //
  //Default settings.
  if (0 != (hv_Row==-1))
  {
    hv_Row = 12;
  }
  if (0 != (hv_Column==-1))
  {
    hv_Column = 12;
  }
  if (0 != (hv_TextColor==HTuple()))
  {
    hv_TextColor = "";
  }
  //
  try
  {
    color_string_to_rgb(hv_ButtonColor, &hv_RGB);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_Exception = "Wrong value of control parameter ButtonColor (must be a valid color string)";
    throw HException(hv_Exception);
  }
  hv_Fac = 0.4;
  hv_RGBL = hv_RGB+((((255.0-hv_RGB)*hv_Fac)+0.5).TupleInt());
  hv_RGBD = hv_RGB-(((hv_RGB*hv_Fac)+0.5).TupleInt());
  hv_ButtonColorBorderL = "#"+((""+(hv_RGBL.TupleString("02x"))).TupleSum());
  hv_ButtonColorBorderD = "#"+((""+(hv_RGBD.TupleString("02x"))).TupleSum());
  //
  hv_String = ((""+hv_String)+"").TupleSplit("\n");
  //
  //Estimate extentions of text depending on font size.
  GetFontExtents(hv_WindowHandle, &hv_MaxAscent, &hv_MaxDescent, &hv_MaxWidth, &hv_MaxHeight);
  if (0 != (hv_CoordSystem==HTuple("window")))
  {
    hv_R1 = hv_Row;
    hv_C1 = hv_Column;
  }
  else
  {
    //Transform image to window coordinates.
    hv_FactorRow = (1.*hv_HeightWin)/((hv_Row2Part-hv_Row1Part)+1);
    hv_FactorColumn = (1.*hv_WidthWin)/((hv_Column2Part-hv_Column1Part)+1);
    hv_R1 = ((hv_Row-hv_Row1Part)+0.5)*hv_FactorRow;
    hv_C1 = ((hv_Column-hv_Column1Part)+0.5)*hv_FactorColumn;
  }
  //
  //Display text box depending on text size.
  //
  //Calculate box extents.
  hv_String = (" "+hv_String)+" ";
  hv_Width = HTuple();
  {
  HTuple end_val70 = (hv_String.TupleLength())-1;
  HTuple step_val70 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val70, step_val70); hv_Index += step_val70)
  {
    GetStringExtents(hv_WindowHandle, HTuple(hv_String[hv_Index]), &hv_Ascent, &hv_Descent, 
        &hv_W, &hv_H);
    hv_Width = hv_Width.TupleConcat(hv_W);
  }
  }
  hv_FrameHeight = hv_MaxHeight*(hv_String.TupleLength());
  hv_FrameWidth = (HTuple(0).TupleConcat(hv_Width)).TupleMax();
  hv_R2 = hv_R1+hv_FrameHeight;
  hv_C2 = hv_C1+hv_FrameWidth;
  //Display rectangles.
  GetSystem("clip_region", &hv_ClipRegion);
  SetSystem("clip_region", "false");
  GetDraw(hv_WindowHandle, &hv_DrawMode);
  SetDraw(hv_WindowHandle, "fill");
  hv_BorderWidth = 2;
  GenRegionPolygonFilled(&ho_UpperLeft, ((((hv_R1-hv_BorderWidth).TupleConcat(hv_R1-hv_BorderWidth)).TupleConcat(hv_R1)).TupleConcat(hv_R2)).TupleConcat(hv_R2+hv_BorderWidth), 
      ((((hv_C1-hv_BorderWidth).TupleConcat(hv_C2+hv_BorderWidth)).TupleConcat(hv_C2)).TupleConcat(hv_C1)).TupleConcat(hv_C1-hv_BorderWidth));
  GenRegionPolygonFilled(&ho_LowerRight, ((((hv_R2+hv_BorderWidth).TupleConcat(hv_R1-hv_BorderWidth)).TupleConcat(hv_R1)).TupleConcat(hv_R2)).TupleConcat(hv_R2+hv_BorderWidth), 
      ((((hv_C2+hv_BorderWidth).TupleConcat(hv_C2+hv_BorderWidth)).TupleConcat(hv_C2)).TupleConcat(hv_C1)).TupleConcat(hv_C1-hv_BorderWidth));
  GenRectangle1(&ho_Rectangle, hv_R1, hv_C1, hv_R2, hv_C2);
  SetColor(hv_WindowHandle, hv_ButtonColorBorderL);
  DispObj(ho_UpperLeft, hv_WindowHandle);
  SetColor(hv_WindowHandle, hv_ButtonColorBorderD);
  DispObj(ho_LowerRight, hv_WindowHandle);
  SetColor(hv_WindowHandle, hv_ButtonColor);
  DispObj(ho_Rectangle, hv_WindowHandle);
  SetDraw(hv_WindowHandle, hv_DrawMode);
  SetSystem("clip_region", hv_ClipRegion);
  //Write text.
  {
  HTuple end_val96 = (hv_String.TupleLength())-1;
  HTuple step_val96 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val96, step_val96); hv_Index += step_val96)
  {
    hv_CurrentColor = HTuple(hv_TextColor[hv_Index%(hv_TextColor.TupleLength())]);
    if (0 != (HTuple(hv_CurrentColor!=HTuple("")).TupleAnd(hv_CurrentColor!=HTuple("auto"))))
    {
      SetColor(hv_WindowHandle, hv_CurrentColor);
    }
    else
    {
      SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
    }
    hv_Row = hv_R1+(hv_MaxHeight*hv_Index);
    DispText(hv_WindowHandle, HTuple(hv_String[hv_Index]), "window", hv_Row, hv_C1, 
        hv_CurrentColor, "box", "false");
  }
  }
  //Reset changed window settings.
  SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
  SetPart(hv_WindowHandle, hv_Row1Part, hv_Column1Part, hv_Row2Part, hv_Column2Part);
  return;
}

// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_text_button_visualize_object_model_3d (HTuple hv_WindowHandle, HTuple hv_String, 
    HTuple hv_CoordSystem, HTuple hv_Row, HTuple hv_Column, HTuple hv_TextColor, 
    HTuple hv_ButtonColor)
{

  // Local iconic variables
  HObject  ho_UpperLeft, ho_LowerRight, ho_Rectangle;

  // Local control variables
  HTuple  hv_Red, hv_Green, hv_Blue, hv_Row1Part;
  HTuple  hv_Column1Part, hv_Row2Part, hv_Column2Part, hv_RowWin;
  HTuple  hv_ColumnWin, hv_WidthWin, hv_HeightWin, hv_Exception;
  HTuple  hv_Fac, hv_RGB, hv_RGBL, hv_RGBD, hv_ButtonColorBorderL;
  HTuple  hv_ButtonColorBorderD, hv_MaxAscent, hv_MaxDescent;
  HTuple  hv_MaxWidth, hv_MaxHeight, hv_R1, hv_C1, hv_FactorRow;
  HTuple  hv_FactorColumn, hv_Width, hv_Index, hv_Ascent;
  HTuple  hv_Descent, hv_W, hv_H, hv_FrameHeight, hv_FrameWidth;
  HTuple  hv_R2, hv_C2, hv_ClipRegion, hv_DrawMode, hv_BorderWidth;
  HTuple  hv_CurrentColor;

  //This procedure displays text in a graphics window.
  //
  //Input parameters:
  //WindowHandle: The WindowHandle of the graphics window, where
  //   the message should be displayed
  //String: A tuple of strings containing the text message to be displayed
  //CoordSystem: If set to 'window', the text position is given
  //   with respect to the window coordinate system.
  //   If set to 'image', image coordinates are used.
  //   (This may be useful in zoomed images.)
  //Row: The row coordinate of the desired text position
  //   If set to -1, a default value of 12 is used.
  //Column: The column coordinate of the desired text position
  //   If set to -1, a default value of 12 is used.
  //Color: defines the color of the text as string.
  //   If set to [], '' or 'auto' the currently set color is used.
  //   If a tuple of strings is passed, the colors are used cyclically
  //   for each new textline.
  //ButtonColor: Must be set to a color string (e.g. 'white', '#FF00CC', etc.).
  //             The text is written in a box of that color.
  //
  //Prepare window.
  GetRgb(hv_WindowHandle, &hv_Red, &hv_Green, &hv_Blue);
  GetPart(hv_WindowHandle, &hv_Row1Part, &hv_Column1Part, &hv_Row2Part, &hv_Column2Part);
  GetWindowExtents(hv_WindowHandle, &hv_RowWin, &hv_ColumnWin, &hv_WidthWin, &hv_HeightWin);
  SetPart(hv_WindowHandle, 0, 0, hv_HeightWin-1, hv_WidthWin-1);
  //
  //Default settings.
  if (0 != (hv_Row==-1))
  {
    hv_Row = 12;
  }
  if (0 != (hv_Column==-1))
  {
    hv_Column = 12;
  }
  if (0 != (hv_TextColor==HTuple()))
  {
    hv_TextColor = "";
  }
  //
  try
  {
    color_string_to_rgb_visualize_object_model_3d(hv_ButtonColor, &hv_RGB);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_Exception = "Wrong value of control parameter ButtonColor (must be a valid color string)";
    throw HException(hv_Exception);
  }
  hv_Fac = 0.4;
  hv_RGBL = hv_RGB+((((255.0-hv_RGB)*hv_Fac)+0.5).TupleInt());
  hv_RGBD = hv_RGB-(((hv_RGB*hv_Fac)+0.5).TupleInt());
  hv_ButtonColorBorderL = "#"+((""+(hv_RGBL.TupleString("02x"))).TupleSum());
  hv_ButtonColorBorderD = "#"+((""+(hv_RGBD.TupleString("02x"))).TupleSum());
  //
  hv_String = ((""+hv_String)+"").TupleSplit("\n");
  //
  //Estimate extentions of text depending on font size.
  GetFontExtents(hv_WindowHandle, &hv_MaxAscent, &hv_MaxDescent, &hv_MaxWidth, &hv_MaxHeight);
  if (0 != (hv_CoordSystem==HTuple("window")))
  {
    hv_R1 = hv_Row;
    hv_C1 = hv_Column;
  }
  else
  {
    //Transform image to window coordinates.
    hv_FactorRow = (1.*hv_HeightWin)/((hv_Row2Part-hv_Row1Part)+1);
    hv_FactorColumn = (1.*hv_WidthWin)/((hv_Column2Part-hv_Column1Part)+1);
    hv_R1 = ((hv_Row-hv_Row1Part)+0.5)*hv_FactorRow;
    hv_C1 = ((hv_Column-hv_Column1Part)+0.5)*hv_FactorColumn;
  }
  //
  //Display text box depending on text size.
  //
  //Calculate box extents.
  hv_String = (" "+hv_String)+" ";
  hv_Width = HTuple();
  {
  HTuple end_val70 = (hv_String.TupleLength())-1;
  HTuple step_val70 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val70, step_val70); hv_Index += step_val70)
  {
    GetStringExtents(hv_WindowHandle, HTuple(hv_String[hv_Index]), &hv_Ascent, &hv_Descent, 
        &hv_W, &hv_H);
    hv_Width = hv_Width.TupleConcat(hv_W);
  }
  }
  hv_FrameHeight = hv_MaxHeight*(hv_String.TupleLength());
  hv_FrameWidth = (HTuple(0).TupleConcat(hv_Width)).TupleMax();
  hv_R2 = hv_R1+hv_FrameHeight;
  hv_C2 = hv_C1+hv_FrameWidth;
  //Display rectangles.
  GetSystem("clip_region", &hv_ClipRegion);
  SetSystem("clip_region", "false");
  GetDraw(hv_WindowHandle, &hv_DrawMode);
  SetDraw(hv_WindowHandle, "fill");
  hv_BorderWidth = 2;
  GenRegionPolygonFilled(&ho_UpperLeft, ((((hv_R1-hv_BorderWidth).TupleConcat(hv_R1-hv_BorderWidth)).TupleConcat(hv_R1)).TupleConcat(hv_R2)).TupleConcat(hv_R2+hv_BorderWidth), 
      ((((hv_C1-hv_BorderWidth).TupleConcat(hv_C2+hv_BorderWidth)).TupleConcat(hv_C2)).TupleConcat(hv_C1)).TupleConcat(hv_C1-hv_BorderWidth));
  GenRegionPolygonFilled(&ho_LowerRight, ((((hv_R2+hv_BorderWidth).TupleConcat(hv_R1-hv_BorderWidth)).TupleConcat(hv_R1)).TupleConcat(hv_R2)).TupleConcat(hv_R2+hv_BorderWidth), 
      ((((hv_C2+hv_BorderWidth).TupleConcat(hv_C2+hv_BorderWidth)).TupleConcat(hv_C2)).TupleConcat(hv_C1)).TupleConcat(hv_C1-hv_BorderWidth));
  GenRectangle1(&ho_Rectangle, hv_R1, hv_C1, hv_R2, hv_C2);
  SetColor(hv_WindowHandle, hv_ButtonColorBorderL);
  DispObj(ho_UpperLeft, hv_WindowHandle);
  SetColor(hv_WindowHandle, hv_ButtonColorBorderD);
  DispObj(ho_LowerRight, hv_WindowHandle);
  SetColor(hv_WindowHandle, hv_ButtonColor);
  DispObj(ho_Rectangle, hv_WindowHandle);
  SetDraw(hv_WindowHandle, hv_DrawMode);
  SetSystem("clip_region", hv_ClipRegion);
  //Write text.
  {
  HTuple end_val96 = (hv_String.TupleLength())-1;
  HTuple step_val96 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val96, step_val96); hv_Index += step_val96)
  {
    hv_CurrentColor = HTuple(hv_TextColor[hv_Index%(hv_TextColor.TupleLength())]);
    if (0 != (HTuple(hv_CurrentColor!=HTuple("")).TupleAnd(hv_CurrentColor!=HTuple("auto"))))
    {
      SetColor(hv_WindowHandle, hv_CurrentColor);
    }
    else
    {
      SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
    }
    hv_Row = hv_R1+(hv_MaxHeight*hv_Index);
    DispText(hv_WindowHandle, HTuple(hv_String[hv_Index]), "window", hv_Row, hv_C1, 
        hv_CurrentColor, "box", "false");
  }
  }
  //Reset changed window settings.
  SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
  SetPart(hv_WindowHandle, hv_Row1Part, hv_Column1Part, hv_Row2Part, hv_Column2Part);
  return;
}

// Chapter: Graphics / Output
void disp_title_and_information (HTuple hv_Parameters, HTuple hv_WindowHandle, HTuple hv_Title, 
    HTuple hv_Information)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_gInfoDecor, hv_gInfoPos, hv_gTitlePos;
  HTuple  hv_gTitleDecor, hv_WinRow, hv_WinColumn, hv_WinWidth;
  HTuple  hv_WinHeight, hv_NumTitleLines, hv_Row, hv_Column;
  HTuple  hv_TextWidth, hv_NumInfoLines, hv_Ascent, hv_Descent;
  HTuple  hv_Width, hv_Height;

  GetMessageTuple(hv_Parameters, "gInfoDecor", &hv_gInfoDecor);
  GetMessageTuple(hv_Parameters, "gInfoPos", &hv_gInfoPos);
  GetMessageTuple(hv_Parameters, "gTitlePos", &hv_gTitlePos);
  GetMessageTuple(hv_Parameters, "gTitleDecor", &hv_gTitleDecor);
  //
  GetWindowExtents(hv_WindowHandle, &hv_WinRow, &hv_WinColumn, &hv_WinWidth, &hv_WinHeight);
  hv_Title = ((""+hv_Title)+"").TupleSplit("\n");
  hv_NumTitleLines = hv_Title.TupleLength();
  if (0 != (hv_NumTitleLines>0))
  {
    hv_Row = 12;
    if (0 != (hv_gTitlePos==HTuple("UpperLeft")))
    {
      hv_Column = 12;
    }
    else if (0 != (hv_gTitlePos==HTuple("UpperCenter")))
    {
      max_line_width(hv_WindowHandle, hv_Title, &hv_TextWidth);
      hv_Column = (hv_WinWidth/2)-(hv_TextWidth/2);
    }
    else if (0 != (hv_gTitlePos==HTuple("UpperRight")))
    {
      if (0 != (HTuple(hv_gTitleDecor[1])==HTuple("true")))
      {
        max_line_width(hv_WindowHandle, hv_Title+"  ", &hv_TextWidth);
      }
      else
      {
        max_line_width(hv_WindowHandle, hv_Title, &hv_TextWidth);
      }
      hv_Column = (hv_WinWidth-hv_TextWidth)-10;
    }
    else
    {
      //Unknown position!
      // stop(...); only in hdevelop
    }
    disp_message(hv_WindowHandle, hv_Title, "window", hv_Row, hv_Column, HTuple(hv_gTitleDecor[0]), 
        HTuple(hv_gTitleDecor[1]));
  }
  hv_Information = ((""+hv_Information)+"").TupleSplit("\n");
  hv_NumInfoLines = hv_Information.TupleLength();
  if (0 != (hv_NumInfoLines>0))
  {
    if (0 != (hv_gInfoPos==HTuple("UpperLeft")))
    {
      hv_Row = 12;
      hv_Column = 12;
    }
    else if (0 != (hv_gInfoPos==HTuple("UpperRight")))
    {
      if (0 != (HTuple(hv_gInfoDecor[1])==HTuple("true")))
      {
        max_line_width(hv_WindowHandle, hv_Information+"  ", &hv_TextWidth);
      }
      else
      {
        max_line_width(hv_WindowHandle, hv_Information, &hv_TextWidth);
      }
      hv_Row = 12;
      hv_Column = (hv_WinWidth-hv_TextWidth)-12;
    }
    else if (0 != (hv_gInfoPos==HTuple("LowerLeft")))
    {
      GetStringExtents(hv_WindowHandle, hv_Information, &hv_Ascent, &hv_Descent, 
          &hv_Width, &hv_Height);
      hv_Row = (hv_WinHeight-(((HTuple(0).TupleMax2(hv_NumInfoLines-1))*(hv_Ascent+hv_Descent))+hv_Height))-70;
      hv_Column = 12;
    }
    else
    {
      //Unknown position!
      // stop(...); only in hdevelop
    }
    disp_message(hv_WindowHandle, hv_Information, "window", hv_Row, hv_Column, HTuple(hv_gInfoDecor[0]), 
        HTuple(hv_gInfoDecor[1]));
  }
  //
  return;
}

// Chapter: Graphics / Output
void disp_title_and_information_visualize_object_model_3d (HTuple hv_WindowHandle, 
    HTuple hv_Title, HTuple hv_Information)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WinRow, hv_WinColumn, hv_WinWidth;
  HTuple  hv_WinHeight, hv_NumTitleLines, hv_Row, hv_Column;
  HTuple  hv_TextWidth, hv_NumInfoLines, hv_Ascent, hv_Descent;
  HTuple  hv_Width, hv_Height;

  //global tuple gInfoDecor
  //global tuple gInfoPos
  //global tuple gTitlePos
  //global tuple gTitleDecor
  //
  GetWindowExtents(hv_WindowHandle, &hv_WinRow, &hv_WinColumn, &hv_WinWidth, &hv_WinHeight);
  hv_Title = ((""+hv_Title)+"").TupleSplit("\n");
  hv_NumTitleLines = hv_Title.TupleLength();
  if (0 != (hv_NumTitleLines>0))
  {
    hv_Row = 12;
    if (0 != (ExpGetGlobalVar_gTitlePos()==HTuple("UpperLeft")))
    {
      hv_Column = 12;
    }
    else if (0 != (ExpGetGlobalVar_gTitlePos()==HTuple("UpperCenter")))
    {
      max_line_width_visualize_object_model_3d(hv_WindowHandle, hv_Title, &hv_TextWidth);
      hv_Column = (hv_WinWidth/2)-(hv_TextWidth/2);
    }
    else if (0 != (ExpGetGlobalVar_gTitlePos()==HTuple("UpperRight")))
    {
      if (0 != (HTuple(ExpGetGlobalVar_gTitleDecor()[1])==HTuple("true")))
      {
        max_line_width_visualize_object_model_3d(hv_WindowHandle, hv_Title+"  ", 
            &hv_TextWidth);
      }
      else
      {
        max_line_width_visualize_object_model_3d(hv_WindowHandle, hv_Title, &hv_TextWidth);
      }
      hv_Column = (hv_WinWidth-hv_TextWidth)-10;
    }
    else
    {
      //Unknown position!
      // stop(...); only in hdevelop
    }
    disp_message(hv_WindowHandle, hv_Title, "window", hv_Row, hv_Column, HTuple(ExpGetGlobalVar_gTitleDecor()[0]), 
        HTuple(ExpGetGlobalVar_gTitleDecor()[1]));
  }
  hv_Information = ((""+hv_Information)+"").TupleSplit("\n");
  hv_NumInfoLines = hv_Information.TupleLength();
  if (0 != (hv_NumInfoLines>0))
  {
    if (0 != (ExpGetGlobalVar_gInfoPos()==HTuple("UpperLeft")))
    {
      hv_Row = 12;
      hv_Column = 12;
    }
    else if (0 != (ExpGetGlobalVar_gInfoPos()==HTuple("UpperRight")))
    {
      if (0 != (HTuple(ExpGetGlobalVar_gInfoDecor()[1])==HTuple("true")))
      {
        max_line_width_visualize_object_model_3d(hv_WindowHandle, hv_Information+"  ", 
            &hv_TextWidth);
      }
      else
      {
        max_line_width_visualize_object_model_3d(hv_WindowHandle, hv_Information, 
            &hv_TextWidth);
      }
      hv_Row = 12;
      hv_Column = (hv_WinWidth-hv_TextWidth)-12;
    }
    else if (0 != (ExpGetGlobalVar_gInfoPos()==HTuple("LowerLeft")))
    {
      GetStringExtents(hv_WindowHandle, hv_Information, &hv_Ascent, &hv_Descent, 
          &hv_Width, &hv_Height);
      hv_Row = (hv_WinHeight-(((HTuple(0).TupleMax2(hv_NumInfoLines-1))*(hv_Ascent+hv_Descent))+hv_Height))-12;
      hv_Column = 12;
    }
    else
    {
      //Unknown position!
      // stop(...); only in hdevelop
    }
    disp_message(hv_WindowHandle, hv_Information, "window", hv_Row, hv_Column, HTuple(ExpGetGlobalVar_gInfoDecor()[0]), 
        HTuple(ExpGetGlobalVar_gInfoDecor()[1]));
  }
  //
  return;
}

// Chapter: Graphics / Output
// Short Description: Renders 3D object models in a buffer window. 
void dump_image_output (HObject ho_BackgroundImage, HTuple hv_Parameters, HTuple hv_WindowHandleBuffer, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_CamParam, HTuple hv_Poses, HTuple hv_ColorImage, 
    HTuple hv_Title, HTuple hv_Information, HTuple hv_Labels, HTuple hv_VisualizeTrackball, 
    HTuple hv_DisplayButtons, HTuple hv_TrackballCenterRow, HTuple hv_TrackballCenterCol, 
    HTuple hv_TrackballRadiusPixel, HTuple hv_SelectedObject, HTuple hv_VisualizeRotationCenter, 
    HTuple hv_RotationCenter, HTuple hv_Type, HTuple hv_Message, HTuple hv_DispViewPoint, 
    HTuple hv_ViewPoint)
{

  // Local iconic variables
  HObject  ho_ModelContours, ho_TrackballContour;
  HObject  ho_CrossRotCenter;

  // Local control variables
  HTuple  hv_gUsesOpenGL, hv_gAlphaDeselected, hv_gButtons;
  HTuple  hv_Exception, hv_Index, hv_Exception1, hv_DeselectedIdx;
  HTuple  hv_DeselectedName, hv_DeselectedValue, hv_gLabelsDecor;
  HTuple  hv_Pose, hv_HomMat3D, hv_Center, hv_CenterCamX;
  HTuple  hv_CenterCamY, hv_CenterCamZ, hv_CenterRow, hv_CenterCol;
  HTuple  hv_Label, hv_Ascent, hv_Descent, hv_TextWidth, hv_TextHeight;
  HTuple  hv_gDispObjOffset, hv_RotCenterRow, hv_RotCenterCol;
  HTuple  hv_Orientation, hv_Colors, hv_Type1, hv_Message1;
  HTuple  hv_Type2, hv_Message2;

  GetMessageTuple(hv_Parameters, "gUsesOpenGL", &hv_gUsesOpenGL);
  GetMessageTuple(hv_Parameters, "gAlphaDeselected", &hv_gAlphaDeselected);
  GetMessageTuple(hv_Parameters, "gButtons", &hv_gButtons);

  //
  //Display background image
  ClearWindow(hv_WindowHandleBuffer);
  if (0 != hv_ColorImage)
  {
    DispColor(ho_BackgroundImage, hv_WindowHandleBuffer);
  }
  else
  {
    DispImage(ho_BackgroundImage, hv_WindowHandleBuffer);
  }
  //
  //Display objects
  if (0 != ((hv_SelectedObject.TupleSum())==(hv_SelectedObject.TupleLength())))
  {
    if (0 != (hv_gUsesOpenGL==HTuple("true")))
    {
      try
      {
        DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (HTuple(HTuple(HTuple(hv_Exception[0])==5185).TupleOr(HTuple(hv_Exception[0])==5188)).TupleOr(HTuple(hv_Exception[0])==5187)))
        {
          hv_gUsesOpenGL = "false";
          SetMessageTuple(hv_Parameters, "gUsesOpenGL", hv_gUsesOpenGL);
        }
        else
        {
          throw HException(hv_Exception);
        }
      }
    }
    if (0 != (hv_gUsesOpenGL==HTuple("false")))
    {
      //* NO OpenGL, use fallback
      disp_object_model_no_opengl(&ho_ModelContours, hv_ObjectModel3DID, hv_GenParamName, 
          hv_GenParamValue, hv_WindowHandleBuffer, hv_CamParam, hv_Poses);
    }
  }
  else
  {
    {
    HTuple end_val32 = (hv_AlphaOrig.TupleLength())-1;
    HTuple step_val32 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val32, step_val32); hv_Index += step_val32)
    {
      if (0 != (HTuple(hv_SelectedObject[hv_Index])==1))
      {
        SetScene3dInstanceParam(hv_Scene3D, hv_Index, "alpha", HTuple(hv_AlphaOrig[hv_Index]));
      }
      else
      {
        SetScene3dInstanceParam(hv_Scene3D, hv_Index, "alpha", hv_gAlphaDeselected);
      }
    }
    }
    try
    {
      if (0 != (hv_gUsesOpenGL==HTuple("false")))
      {
        throw HException(HTuple());
      }
      DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
    }
    // catch (Exception1) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception1);
      //* NO OpenGL, use fallback
      hv_DeselectedIdx = hv_SelectedObject.TupleFind(0);
      if (0 != (hv_DeselectedIdx!=-1))
      {
        hv_DeselectedName = "color_"+hv_DeselectedIdx;
        hv_DeselectedValue = HTuple(hv_DeselectedName.TupleLength(),"gray");
      }
      disp_object_model_no_opengl(&ho_ModelContours, hv_ObjectModel3DID, hv_GenParamName.TupleConcat(hv_DeselectedName), 
          hv_GenParamValue.TupleConcat(hv_DeselectedValue), hv_WindowHandleBuffer, 
          hv_CamParam, hv_Poses);
    }
    {
    HTuple end_val53 = (hv_AlphaOrig.TupleLength())-1;
    HTuple step_val53 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val53, step_val53); hv_Index += step_val53)
    {
      SetScene3dInstanceParam(hv_Scene3D, hv_Index, "alpha", HTuple(hv_AlphaOrig[hv_Index]));
    }
    }
  }
  //
  //Display labels
  if (0 != (hv_Labels!=0))
  {
    GetMessageTuple(hv_Parameters, "gLabelsDecor", &hv_gLabelsDecor);
    SetColor(hv_WindowHandleBuffer, HTuple(hv_gLabelsDecor[0]));
    {
    HTuple end_val62 = (hv_ObjectModel3DID.TupleLength())-1;
    HTuple step_val62 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val62, step_val62); hv_Index += step_val62)
    {
      //Project the center point of the current model
      hv_Pose = hv_Poses.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
      PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
      GetObjectModel3dParams(HTuple(hv_ObjectModel3DID[hv_Index]), "center", &hv_Center);
      AffineTransPoint3d(hv_HomMat3D, HTuple(hv_Center[0]), HTuple(hv_Center[1]), 
          HTuple(hv_Center[2]), &hv_CenterCamX, &hv_CenterCamY, &hv_CenterCamZ);
      Project3dPoint(hv_CenterCamX, hv_CenterCamY, hv_CenterCamZ, hv_CamParam, &hv_CenterRow, 
          &hv_CenterCol);
      hv_Label = HTuple(hv_Labels[hv_Index]);
      if (0 != (hv_Label!=HTuple("")))
      {
        GetStringExtents(hv_WindowHandleBuffer, hv_Label, &hv_Ascent, &hv_Descent, 
            &hv_TextWidth, &hv_TextHeight);
        GetMessageTuple(hv_Parameters, "gDispObjOffset", &hv_gDispObjOffset);
        disp_message(hv_WindowHandleBuffer, hv_Label, "window", (hv_CenterRow-(hv_TextHeight/2))+HTuple(hv_gDispObjOffset[0]), 
            (hv_CenterCol-(hv_TextWidth/2))+HTuple(hv_gDispObjOffset[1]), HTuple(), 
            HTuple(hv_gLabelsDecor[1]));
      }
    }
    }
  }
  //
  //Visualize the trackball if desired
  if (0 != hv_VisualizeTrackball)
  {
    SetLineWidth(hv_WindowHandleBuffer, 1);
    GenEllipseContourXld(&ho_TrackballContour, hv_TrackballCenterRow, hv_TrackballCenterCol, 
        0, hv_TrackballRadiusPixel, hv_TrackballRadiusPixel, 0, 6.28318, "positive", 
        1.5);
    SetColor(hv_WindowHandleBuffer, "dim gray");
    DispXld(ho_TrackballContour, hv_WindowHandleBuffer);
  }
  //
  //Visualize the rotation center if desired
  if (0 != (HTuple(hv_VisualizeRotationCenter!=0).TupleAnd((hv_RotationCenter.TupleLength())==3)))
  {
    if (0 != (HTuple(hv_RotationCenter[2])<1e-10))
    {
      hv_RotationCenter[2] = 1e-10;
    }
    Project3dPoint(HTuple(hv_RotationCenter[0]), HTuple(hv_RotationCenter[1]), HTuple(hv_RotationCenter[2]), 
        hv_CamParam, &hv_RotCenterRow, &hv_RotCenterCol);
    hv_Orientation = HTuple(90).TupleRad();
    if (0 != (hv_VisualizeRotationCenter==1))
    {
      hv_Orientation = HTuple(45).TupleRad();
    }
    GenCrossContourXld(&ho_CrossRotCenter, hv_RotCenterRow, hv_RotCenterCol, hv_TrackballRadiusPixel/25.0, 
        hv_Orientation);
    SetLineWidth(hv_WindowHandleBuffer, 3);
    QueryColor(hv_WindowHandleBuffer, &hv_Colors);
    SetColor(hv_WindowHandleBuffer, "light gray");
    DispXld(ho_CrossRotCenter, hv_WindowHandleBuffer);
    SetLineWidth(hv_WindowHandleBuffer, 1);
    SetColor(hv_WindowHandleBuffer, "dim gray");
    DispXld(ho_CrossRotCenter, hv_WindowHandleBuffer);
  }
  //
  //Display title
  if (0 != ((hv_Type.TupleLength())==1))
  {
    hv_Type1 = hv_Type;
    hv_Message1 = hv_Message;
    write_note(hv_WindowHandleBuffer, hv_Type1, hv_Message1);
  }
  else if (0 != ((hv_Type.TupleLength())==2))
  {
    hv_Type1 = ((const HTuple&)hv_Type)[0];
    hv_Type2 = ((const HTuple&)hv_Type)[1];
    hv_Message1 = ((const HTuple&)hv_Message)[0];
    hv_Message2 = hv_Message.TupleSelectRange(1,(hv_Message.TupleLength())-1);
    write_note(hv_WindowHandleBuffer, hv_Type1, hv_Message1);
    SetTposition(hv_WindowHandleBuffer, 1, 12);
    write_note(hv_WindowHandleBuffer, hv_Type2, hv_Message2);
  }
  if (0 != (hv_DispViewPoint==HTuple("true")))
  {
    disp_message(hv_WindowHandleBuffer, (((("ViewPoint [m]\n   X :"+(HTuple(hv_ViewPoint[0]).TupleString(".2f")))+"\n   Y: ")+(HTuple(hv_ViewPoint[1]).TupleString(".2f")))+"\n   Z: ")+(HTuple(hv_ViewPoint[2]).TupleString(".2f")), 
        "window", 300, 12, "#FFA500", "false");
  }

  disp_title_and_information(hv_Parameters, hv_WindowHandleBuffer, hv_Title, hv_Information);
  //
  //Display the 'Exit' button
  if (0 != (hv_DisplayButtons==HTuple("true")))
  {
    disp_buttons(hv_Parameters, hv_WindowHandleBuffer);
  }
  //
  return;
}

// Chapter: Graphics / Output
// Short Description: Renders 3D object models in a buffer window. 
void dump_image_output_visualize_object_model_3d (HObject ho_BackgroundImage, HTuple hv_WindowHandleBuffer, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_CamParam, HTuple hv_Poses, HTuple hv_ColorImage, 
    HTuple hv_Title, HTuple hv_Information, HTuple hv_Labels, HTuple hv_VisualizeTrackball, 
    HTuple hv_DisplayContinueButton, HTuple hv_TrackballCenterRow, HTuple hv_TrackballCenterCol, 
    HTuple hv_TrackballRadiusPixel, HTuple hv_SelectedObject, HTuple hv_VisualizeRotationCenter, 
    HTuple hv_RotationCenter)
{

  // Local iconic variables
  HObject  ho_TrackballContour, ho_CrossRotCenter;
  HObject  ho_ModelContours;

  // Local control variables
  HTuple  ExpTmpLocalVar_gUsesOpenGL, hv_Exception;
  HTuple  hv_Index, hv_Exception1, hv_DeselectedIdx, hv_DeselectedName;
  HTuple  hv_DeselectedValue, hv_Pose, hv_HomMat3D, hv_Center;
  HTuple  hv_CenterCamX, hv_CenterCamY, hv_CenterCamZ, hv_CenterRow;
  HTuple  hv_CenterCol, hv_Label, hv_Ascent, hv_Descent, hv_TextWidth;
  HTuple  hv_TextHeight, hv_RotCenterRow, hv_RotCenterCol;
  HTuple  hv_Orientation, hv_Colors;

  //global tuple gAlphaDeselected
  //global tuple gTerminationButtonLabel
  //global tuple gDispObjOffset
  //global tuple gLabelsDecor
  //global tuple gUsesOpenGL
  //
  //Display background image
  ClearWindow(hv_WindowHandleBuffer);
  if (0 != hv_ColorImage)
  {
    DispColor(ho_BackgroundImage, hv_WindowHandleBuffer);
  }
  else
  {
    DispImage(ho_BackgroundImage, hv_WindowHandleBuffer);
  }
  //
  //Display objects
  if (0 != ((hv_SelectedObject.TupleSum())==(hv_SelectedObject.TupleLength())))
  {
    if (0 != (ExpGetGlobalVar_gUsesOpenGL()==HTuple("true")))
    {
      try
      {
        DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (HTuple(HTuple(HTuple(hv_Exception[0])==5185).TupleOr(HTuple(hv_Exception[0])==5188)).TupleOr(HTuple(hv_Exception[0])==5187)))
        {
          ExpTmpLocalVar_gUsesOpenGL = "false";
          ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
        }
        else
        {
          throw HException(hv_Exception);
        }
      }
    }
    if (0 != (ExpGetGlobalVar_gUsesOpenGL()==HTuple("false")))
    {
      //* NO OpenGL, use fallback
      disp_object_model_no_opengl_visualize_object_model_3d(&ho_ModelContours, hv_ObjectModel3DID, 
          hv_GenParamName, hv_GenParamValue, hv_WindowHandleBuffer, hv_CamParam, 
          hv_Poses);
    }
  }
  else
  {
    {
    HTuple end_val32 = (hv_AlphaOrig.TupleLength())-1;
    HTuple step_val32 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val32, step_val32); hv_Index += step_val32)
    {
      if (0 != (HTuple(hv_SelectedObject[hv_Index])==1))
      {
        SetScene3dInstanceParam(hv_Scene3D, hv_Index, "alpha", HTuple(hv_AlphaOrig[hv_Index]));
      }
      else
      {
        SetScene3dInstanceParam(hv_Scene3D, hv_Index, "alpha", ExpGetGlobalVar_gAlphaDeselected());
      }
    }
    }
    try
    {
      if (0 != (ExpGetGlobalVar_gUsesOpenGL()==HTuple("false")))
      {
        throw HException(HTuple());
      }
      DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
    }
    // catch (Exception1) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception1);
      //* NO OpenGL, use fallback
      hv_DeselectedIdx = hv_SelectedObject.TupleFind(0);
      if (0 != (hv_DeselectedIdx!=-1))
      {
        hv_DeselectedName = "color_"+hv_DeselectedIdx;
        hv_DeselectedValue = HTuple(hv_DeselectedName.TupleLength(),"gray");
      }
      disp_object_model_no_opengl_visualize_object_model_3d(&ho_ModelContours, hv_ObjectModel3DID, 
          hv_GenParamName.TupleConcat(hv_DeselectedName), hv_GenParamValue.TupleConcat(hv_DeselectedValue), 
          hv_WindowHandleBuffer, hv_CamParam, hv_Poses);
    }
    {
    HTuple end_val53 = (hv_AlphaOrig.TupleLength())-1;
    HTuple step_val53 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val53, step_val53); hv_Index += step_val53)
    {
      SetScene3dInstanceParam(hv_Scene3D, hv_Index, "alpha", HTuple(hv_AlphaOrig[hv_Index]));
    }
    }
  }
  //
  //Display labels
  if (0 != (hv_Labels!=0))
  {
    SetColor(hv_WindowHandleBuffer, HTuple(ExpGetGlobalVar_gLabelsDecor()[0]));
    {
    HTuple end_val61 = (hv_ObjectModel3DID.TupleLength())-1;
    HTuple step_val61 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val61, step_val61); hv_Index += step_val61)
    {
      //Project the center point of the current model
      hv_Pose = hv_Poses.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
      PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
      GetObjectModel3dParams(HTuple(hv_ObjectModel3DID[hv_Index]), "center", &hv_Center);
      AffineTransPoint3d(hv_HomMat3D, HTuple(hv_Center[0]), HTuple(hv_Center[1]), 
          HTuple(hv_Center[2]), &hv_CenterCamX, &hv_CenterCamY, &hv_CenterCamZ);
      Project3dPoint(hv_CenterCamX, hv_CenterCamY, hv_CenterCamZ, hv_CamParam, &hv_CenterRow, 
          &hv_CenterCol);
      hv_Label = HTuple(hv_Labels[hv_Index]);
      if (0 != (hv_Label!=HTuple("")))
      {
        GetStringExtents(hv_WindowHandleBuffer, hv_Label, &hv_Ascent, &hv_Descent, 
            &hv_TextWidth, &hv_TextHeight);
        disp_message(hv_WindowHandleBuffer, hv_Label, "window", (hv_CenterRow-(hv_TextHeight/2))+HTuple(ExpGetGlobalVar_gDispObjOffset()[0]), 
            (hv_CenterCol-(hv_TextWidth/2))+HTuple(ExpGetGlobalVar_gDispObjOffset()[1]), 
            HTuple(), HTuple(ExpGetGlobalVar_gLabelsDecor()[1]));
      }
    }
    }
  }
  //
  //Visualize the trackball if desired
  if (0 != hv_VisualizeTrackball)
  {
    SetLineWidth(hv_WindowHandleBuffer, 1);
    GenEllipseContourXld(&ho_TrackballContour, hv_TrackballCenterRow, hv_TrackballCenterCol, 
        0, hv_TrackballRadiusPixel, hv_TrackballRadiusPixel, 0, 6.28318, "positive", 
        1.5);
    SetColor(hv_WindowHandleBuffer, "dim gray");
    DispXld(ho_TrackballContour, hv_WindowHandleBuffer);
  }
  //
  //Visualize the rotation center if desired
  if (0 != (HTuple(hv_VisualizeRotationCenter!=0).TupleAnd((hv_RotationCenter.TupleLength())==3)))
  {
    if (0 != (HTuple(hv_RotationCenter[2])<1e-10))
    {
      hv_RotationCenter[2] = 1e-10;
    }
    Project3dPoint(HTuple(hv_RotationCenter[0]), HTuple(hv_RotationCenter[1]), HTuple(hv_RotationCenter[2]), 
        hv_CamParam, &hv_RotCenterRow, &hv_RotCenterCol);
    hv_Orientation = HTuple(90).TupleRad();
    if (0 != (hv_VisualizeRotationCenter==1))
    {
      hv_Orientation = HTuple(45).TupleRad();
    }
    GenCrossContourXld(&ho_CrossRotCenter, hv_RotCenterRow, hv_RotCenterCol, hv_TrackballRadiusPixel/25.0, 
        hv_Orientation);
    SetLineWidth(hv_WindowHandleBuffer, 3);
    QueryColor(hv_WindowHandleBuffer, &hv_Colors);
    SetColor(hv_WindowHandleBuffer, "light gray");
    DispXld(ho_CrossRotCenter, hv_WindowHandleBuffer);
    SetLineWidth(hv_WindowHandleBuffer, 1);
    SetColor(hv_WindowHandleBuffer, "dim gray");
    DispXld(ho_CrossRotCenter, hv_WindowHandleBuffer);
  }
  //
  //Display title
  disp_title_and_information_visualize_object_model_3d(hv_WindowHandleBuffer, hv_Title, 
      hv_Information);
  //
  //Display the 'Exit' button
  if (0 != (hv_DisplayContinueButton==HTuple("true")))
  {
    disp_continue_button(hv_WindowHandleBuffer);
  }
  //
  return;
}

// Chapter: 3D Reconstruction / Multi-View Stereo
// Short Description: Estimate a bounding box for 3D reconstruction based on a stereo setup. 
void estimate_bounding_box_3d_reconstruction (HTuple hv_StereoModelID, HTuple hv_ObjectHeight, 
    HTuple *hv_BoundingBox)
{

  // Local iconic variables
  HObject  ho_PlaneConeIntersections, ho_ContourFrom;
  HObject  ho_ContourTo, ho_RectangleFrom, ho_RectangleTo;
  HObject  ho_ContoursIntersection, ho_PlaneConeIntersectionUnion;
  HObject  ho_ObjectSelected;

  // Local control variables
  HTuple  hv_CameraSetupModelID, hv_ReferenceCamera;
  HTuple  hv_From, hv_To, hv_NumCameras, hv_ObjectModel3DCone;
  HTuple  hv_DistanceCameras, hv_CameraIndex, hv_CamPose;
  HTuple  hv_DistanceCamera, hv_ConeLength, hv_Type, hv_ObjectModel3D;
  HTuple  hv_Index1, hv_ObjectModel3DIntersectionFrom, hv_ObjectModel3DIntersectionTo;
  HTuple  hv_XFrom, hv_YFrom, hv_XTo, hv_YTo, hv_Row, hv_Column;
  HTuple  hv_Phi, hv_Length1, hv_Length2, hv_Number, hv_Index2;
  HTuple  hv_RowContour, hv_ColumnContour;

  //The goal of this procedure is to estimate bounding box parameters
  //for 3D reconstruction. This is done by intersecting the
  //cones of sight of the cameras with a plane defined by the pose
  //of the reference calibration plate.
  //
  if (0 != (hv_ObjectHeight==0))
  {
    throw HException("Object height must not be zero.");
  }
  //Check whether the coordinate system has been moved by setting a pose
  //with the parameter 'coord_transf_pose' in set_camera_setup_param.
  //If this is not the case, the origin is still in one of the cameras.
  //However, this procedures needs the origin to be in a calibration plate.
  GetStereoModelParam(hv_StereoModelID, "camera_setup_model", &hv_CameraSetupModelID);
  GetCameraSetupParam(hv_CameraSetupModelID, "general", "reference_camera", &hv_ReferenceCamera);
  if (0 != (hv_ReferenceCamera!=-1))
  {
    throw HException("Please set the 'coord_transf_pose' to the pose of an calibration plate that lies horizontally in the image using the get_calib_data and set_camera_setup_param.");
  }
  //Check whether the image pairs have been set.
  GetStereoModelImagePairs(hv_StereoModelID, &hv_From, &hv_To);
  if (0 != (HTuple((hv_From.TupleLength())==0).TupleOr((hv_To.TupleLength())==0)))
  {
    throw HException("Please define the image pairs first with 'get_stereo_model_image_pairs.'");
  }
  //
  //First, we generate 3D object models that represent the cones of sight of the cameras,
  //like in the procedure gen_camera_setup_object_model_3d.
  GetCameraSetupParam(hv_CameraSetupModelID, "general", "num_cameras", &hv_NumCameras);
  hv_ObjectModel3DCone = HTuple();
  hv_DistanceCameras = HTuple();
  {
  HTuple end_val28 = hv_NumCameras-1;
  HTuple step_val28 = 1;
  for (hv_CameraIndex=0; hv_CameraIndex.Continue(end_val28, step_val28); hv_CameraIndex += step_val28)
  {
    GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "pose", &hv_CamPose);
    hv_DistanceCamera = (((HTuple(hv_CamPose[0])*HTuple(hv_CamPose[0]))+(HTuple(hv_CamPose[1])*HTuple(hv_CamPose[1])))+(HTuple(hv_CamPose[2])*HTuple(hv_CamPose[2]))).TupleSqrt();
    hv_DistanceCameras = hv_DistanceCameras.TupleConcat(hv_DistanceCamera);
    hv_ConeLength = hv_DistanceCamera*2.0;
    //Distinguish cases with/without projection center.
    GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "type", &hv_Type);
    if (0 != (hv_Type.TupleRegexpTest("telecentric")))
    {
      gen_cone_telecentric_object_model_3d(hv_CameraSetupModelID, hv_CameraIndex, 
          hv_ConeLength, &hv_ObjectModel3D);
    }
    else
    {
      gen_cone_perspective_object_model_3d(hv_CameraSetupModelID, hv_CameraIndex, 
          hv_ConeLength, &hv_ObjectModel3D);
    }
    hv_ObjectModel3DCone = hv_ObjectModel3DCone.TupleConcat(hv_ObjectModel3D);
  }
  }
  //
  //Then, we intersect these cones of sight with a plane that lies horizontally
  //in the origin of the stereo setup. We do this simultaneously for the
  //previously defined image pairs.
  GenEmptyObj(&ho_PlaneConeIntersections);
  {
  HTuple end_val47 = (hv_From.TupleLength())-1;
  HTuple step_val47 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val47, step_val47); hv_Index1 += step_val47)
  {
    IntersectPlaneObjectModel3d(HTuple(hv_ObjectModel3DCone[HTuple(hv_From[hv_Index1])]), 
        ((((((HTuple(0).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)), 
        &hv_ObjectModel3DIntersectionFrom);
    IntersectPlaneObjectModel3d(HTuple(hv_ObjectModel3DCone[HTuple(hv_To[hv_Index1])]), 
        ((((((HTuple(0).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)), 
        &hv_ObjectModel3DIntersectionTo);
    //
    //Get the coordinates of the 3D object models that represent the intersection.
    GetObjectModel3dParams(hv_ObjectModel3DIntersectionFrom, "point_coord_x", &hv_XFrom);
    GetObjectModel3dParams(hv_ObjectModel3DIntersectionFrom, "point_coord_y", &hv_YFrom);
    GetObjectModel3dParams(hv_ObjectModel3DIntersectionTo, "point_coord_x", &hv_XTo);
    GetObjectModel3dParams(hv_ObjectModel3DIntersectionTo, "point_coord_y", &hv_YTo);
    //
    //The, we want to intersect the intersections of the image pair. We do this in 2D using XLDs.
    //Generate the XLD of the 'From' intersection.
    GenContourPolygonXld(&ho_ContourFrom, hv_XFrom, hv_YFrom);
    //Generate the XLD of the 'To' intersection.
    GenContourPolygonXld(&ho_ContourTo, hv_XTo, hv_YTo);
    //
    //The order of the coordinates from get_object_model_3d_params might not be ideal.
    //Thus, we compute the smallest rectangle around the created XLD.
    SmallestRectangle2Xld(ho_ContourFrom, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, 
        &hv_Length2);
    GenRectangle2ContourXld(&ho_RectangleFrom, hv_Row, hv_Column, hv_Phi, hv_Length1, 
        hv_Length2);
    SmallestRectangle2Xld(ho_ContourTo, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, 
        &hv_Length2);
    GenRectangle2ContourXld(&ho_RectangleTo, hv_Row, hv_Column, hv_Phi, hv_Length1, 
        hv_Length2);
    //
    //Intersect and concatenate the intersections
    IntersectionClosedContoursXld(ho_RectangleFrom, ho_RectangleTo, &ho_ContoursIntersection
        );
    ConcatObj(ho_PlaneConeIntersections, ho_ContoursIntersection, &ho_PlaneConeIntersections
        );
    ClearObjectModel3d(hv_ObjectModel3DIntersectionFrom);
    ClearObjectModel3d(hv_ObjectModel3DIntersectionTo);
  }
  }
  //
  //Union all intersections of all image pairs.
  GenEmptyObj(&ho_PlaneConeIntersectionUnion);
  CountObj(ho_PlaneConeIntersections, &hv_Number);
  {
  HTuple end_val80 = hv_Number;
  HTuple step_val80 = 1;
  for (hv_Index2=1; hv_Index2.Continue(end_val80, step_val80); hv_Index2 += step_val80)
  {
    SelectObj(ho_PlaneConeIntersections, &ho_ObjectSelected, hv_Index2);
    Union2ClosedContoursXld(ho_ObjectSelected, ho_PlaneConeIntersectionUnion, &ho_PlaneConeIntersectionUnion
        );
  }
  }
  //
  //Get the coordinates of the resulting XLD, which represents the area
  //in 2D where the reconstruction is possible.
  GetContourXld(ho_PlaneConeIntersectionUnion, &hv_RowContour, &hv_ColumnContour);
  //
  //Based on this contour, we can easily access the parameters of the bounding box.
  if (0 != (hv_ObjectHeight>0))
  {
    (*hv_BoundingBox).Clear();
    (*hv_BoundingBox).Append(hv_RowContour.TupleMin());
    (*hv_BoundingBox).Append(hv_ColumnContour.TupleMin());
    (*hv_BoundingBox).Append(-hv_ObjectHeight);
    (*hv_BoundingBox).Append(hv_RowContour.TupleMax());
    (*hv_BoundingBox).Append(hv_ColumnContour.TupleMax());
    (*hv_BoundingBox).Append(0);
  }
  else
  {
    (*hv_BoundingBox).Clear();
    (*hv_BoundingBox).Append(hv_RowContour.TupleMin());
    (*hv_BoundingBox).Append(hv_ColumnContour.TupleMin());
    (*hv_BoundingBox).Append(0);
    (*hv_BoundingBox).Append(hv_RowContour.TupleMax());
    (*hv_BoundingBox).Append(hv_ColumnContour.TupleMax());
    (*hv_BoundingBox).Append(-hv_ObjectHeight);
  }
  //
  //Clean up.
  ClearCameraSetupModel(hv_CameraSetupModelID);
  ClearObjectModel3d(hv_ObjectModel3DCone);
  return;
}

void estimate_noise_real (HObject ho_Image, HTuple hv_OutlierRemovalAmount, HTuple *hv_Sigma)
{

  // Local iconic variables
  HObject  ho_ImageFiltered, ho_RegionErosion;

  // Local control variables
  HTuple  hv_Rows, hv_Columns, hv_Grayval, hv_NumToRemove;
  HTuple  hv_Exception;

  //See documentation of estimate_noise for more information
  //about the used immerkaer noise estimation method.

  ConvolImage(ho_Image, &ho_ImageFiltered, (((((((((((HTuple(3).Append(3)).Append(1)).Append(1)).Append(-2)).Append(1)).Append(-2)).Append(4)).Append(-2)).Append(1)).Append(-2)).Append(1)), 
      "mirrored");

  //convol_image will use parts of the background, which might have undefined pixels
  //Remove those parts
  ErosionRectangle1(ho_Image, &ho_RegionErosion, 3, 3);

  GetRegionPoints(ho_RegionErosion, &hv_Rows, &hv_Columns);
  if (0 != ((hv_Rows.TupleLength())<30))
  {
    //Too few points for a robust noise estimation
    //This can happen, for example, if the points are very sparse in the XYZ images
    (*hv_Sigma) = -1;
  }
  else
  {
    GetGrayval(ho_ImageFiltered, hv_Rows, hv_Columns, &hv_Grayval);
    hv_Grayval = hv_Grayval.TupleAbs();
    //Instead of the original formula, we use the more robust median
    //to avoid false negatives
    if (0 != (hv_OutlierRemovalAmount>0))
    {
      TupleSort(hv_Grayval, &hv_Grayval);
      hv_NumToRemove = (((hv_Grayval.TupleLength())*hv_OutlierRemovalAmount)*0.5).TupleInt();
      //Catch some special cases
      try
      {
        hv_Grayval = hv_Grayval.TupleSelectRange(hv_NumToRemove,((hv_Grayval.TupleLength())-hv_NumToRemove)-1);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        //Catch the special case when we'd remove all values
        hv_Grayval = hv_Grayval.TupleMedian();
      }
    }
    (*hv_Sigma) = ((HTuple((HTuple(180).TupleRad())/2.0).TupleSqrt())*(1.0/6.0))*((hv_Grayval.TupleAbs()).TupleMean());
  }

  return;

}

void estimate_visualization_pose (HTuple hv_SampledModel, HTuple hv_WindowHandleModel, 
    HTuple *hv_PoseEstimated)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Center, hv_RowNotUsed, hv_ColumnNotUsed;
  HTuple  hv_Width, hv_Height, hv_WPRow1, hv_WPColumn1, hv_WPRow2;
  HTuple  hv_WPColumn2, hv_CamParam, hv_PoseIn, hv_Moments;
  HTuple  hv_PoseInvert, hv_ObjectModel3DRigidTrans;

  get_object_models_center(hv_SampledModel, &hv_Center);
  GetWindowExtents(hv_WindowHandleModel, &hv_RowNotUsed, &hv_ColumnNotUsed, &hv_Width, 
      &hv_Height);
  GetPart(hv_WindowHandleModel, &hv_WPRow1, &hv_WPColumn1, &hv_WPRow2, &hv_WPColumn2);
  SetPart(hv_WindowHandleModel, 0, 0, hv_Height-1, hv_Width-1);
  gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
      hv_Width, hv_Height, &hv_CamParam);
  CreatePose(-HTuple(hv_Center[0]), -HTuple(hv_Center[1]), -HTuple(hv_Center[2]), 
      0, 0, 0, "Rp+T", "gba", "point", &hv_PoseIn);
  //
  MomentsObjectModel3d(hv_SampledModel, "principal_axes", &hv_Moments);
  PoseInvert(hv_Moments, &hv_PoseInvert);
  RigidTransObjectModel3d(hv_SampledModel, hv_PoseInvert, &hv_ObjectModel3DRigidTrans);
  determine_optimum_pose_distance(hv_ObjectModel3DRigidTrans, hv_CamParam, 0.9, hv_PoseIn, 
      &(*hv_PoseEstimated));
  (*hv_PoseEstimated) = (((((HTuple((*hv_PoseEstimated)[0]).TupleConcat(-HTuple(hv_Moments[2]))).TupleConcat(HTuple((*hv_PoseEstimated)[2]))).TupleConcat(HTuple((*hv_PoseEstimated)[3])-90)).TupleConcat(HTuple((*hv_PoseEstimated)[4]))).TupleConcat(HTuple((*hv_PoseEstimated)[5]))).TupleConcat(0);

  return;
}

void estimate_visualization_pose_simple (HTuple hv_SampledModel, HTuple hv_WindowHandleModel, 
    HTuple *hv_PoseEstimated)
{

  // Local control variables
  HTuple  hv_Center, hv_RowNotUsed, hv_ColumnNotUsed;
  HTuple  hv_Width, hv_Height, hv_WPRow1, hv_WPColumn1, hv_WPRow2;
  HTuple  hv_WPColumn2, hv_CamParam, hv_PoseIn;

  get_object_models_center(hv_SampledModel, &hv_Center);
  GetWindowExtents(hv_WindowHandleModel, &hv_RowNotUsed, &hv_ColumnNotUsed, &hv_Width, 
      &hv_Height);
  GetPart(hv_WindowHandleModel, &hv_WPRow1, &hv_WPColumn1, &hv_WPRow2, &hv_WPColumn2);
  SetPart(hv_WindowHandleModel, 0, 0, hv_Height-1, hv_Width-1);
  gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
      hv_Width, hv_Height, &hv_CamParam);
  CreatePose(-HTuple(hv_Center[0]), -HTuple(hv_Center[1]), -HTuple(hv_Center[2]), 
      0, 0, 0, "Rp+T", "gba", "point", &hv_PoseIn);
  //
  determine_optimum_pose_distance(hv_SampledModel, hv_CamParam, 0.9, hv_PoseIn, &(*hv_PoseEstimated));

  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Evaluate the performance of a deep-learning-based classifier. 
void evaluate_dl_classifier (HTuple hv_GroundTruthLabels, HTuple hv_DLClassifierHandle, 
    HTuple hv_DLClassifierResultID, HTuple hv_EvaluationMeasureType, HTuple hv_ClassesToEvaluate, 
    HTuple *hv_EvaluationMeasure)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Classes, hv_TestClassesToEvaluate;
  HTuple  hv_NumEvalMeasureTypes, hv_NumEvalClasses, hv_ComputePrecision;
  HTuple  hv_ComputeRecall, hv_ComputeFScore, hv_ComputeConfusionMatrix;
  HTuple  hv_PredictedClasses, hv_Index, hv_PredictedClass;
  HTuple  hv_ConfusionMatrix, hv_EvalMeasureTypeIndex, hv_CurrentEvalMeasure;
  HTuple  hv_CurrentEvalClass, hv_RegExpTopKError, hv_ComputeTopKError;
  HTuple  hv_K, hv_Indices, hv_TopKError, hv_NumClasses, hv_IndexClass;
  HTuple  hv_ClassPrecisions, hv_MatrixRowSumID, hv_TruePositive;
  HTuple  hv_SumPredictedClass, hv_ClassPrecision, hv_Precision;
  HTuple  hv_ClassRecalls, hv_MatrixColumnSumID, hv_SumLabel;
  HTuple  hv_ClassRecall, hv_Recall, hv_FScore;

  //This procedure can be used to compute various evaluation measures
  //to check the performance of your trained
  //deep-learning-based classifier DLClassifierHandle.
  //For this, the GroundTruthLabels must be given. Additionally,
  //the results of the classification must be given in DLClassifierResultID,
  //as returned by apply_dl_classifier and apply_dl_classifier_batchwise.
  //With EvaluationMeasureType, you can choose which evaluation measure
  //to return. With ClassesToEvaluate, you can choose whether to return
  //the result for a single class, a result for every class, or
  //for all classes combined. The result is returned in EvaluationMeasure.
  //
  //Check input.
  //Check whether ClassesToEvaluate is a class or 'global'.
  GetDlClassifierParam(hv_DLClassifierHandle, "classes", &hv_Classes);
  //
  //Convert the class indices to class labels if necessary
  if (0 != (((hv_GroundTruthLabels.TupleIsIntElem()).TupleFind(0))==-1))
  {
    if (0 != (HTuple((hv_GroundTruthLabels.TupleMin())<0).TupleOr((hv_GroundTruthLabels.TupleMax())>((hv_Classes.TupleLength())-1))))
    {
      throw HException("The Indices of the GroundTruthLabels exceed the range of classes. \nPlease check your data split.");
    }
    hv_GroundTruthLabels = HTuple(hv_Classes[hv_GroundTruthLabels]);
  }
  if (0 != (((hv_GroundTruthLabels.TupleSort()).TupleUniq())!=(hv_Classes.TupleSort())))
  {
    throw HException("Not all classes are represented in the GroundTruthLabels. \nPlease check your data split.");
  }
  hv_TestClassesToEvaluate.Clear();
  hv_TestClassesToEvaluate[0] = "global";
  hv_TestClassesToEvaluate.Append(hv_Classes);
  if (0 != ((hv_ClassesToEvaluate.TupleDifference(hv_TestClassesToEvaluate))!=HTuple()))
  {
    throw HException("ClassesToEvaluate invalid.");
  }
  //
  //Count the measure types and modes of ClassesToEvaluate.
  hv_NumEvalMeasureTypes = hv_EvaluationMeasureType.TupleLength();
  hv_NumEvalClasses = hv_ClassesToEvaluate.TupleLength();
  //
  //If the numbers are not equal, extend the shorter one.
  if (0 != (hv_NumEvalMeasureTypes>hv_NumEvalClasses))
  {
    if (0 != (HTuple(hv_NumEvalMeasureTypes>1).TupleAnd(hv_NumEvalClasses>1)))
    {
      throw HException("Invalid number of elements in EvaluationMeasureType/ClassesToEvaluate.");
    }
    else
    {
      hv_ClassesToEvaluate = HTuple(hv_NumEvalMeasureTypes,hv_ClassesToEvaluate);
    }
  }
  if (0 != (hv_NumEvalMeasureTypes<hv_NumEvalClasses))
  {
    if (0 != (HTuple(hv_NumEvalMeasureTypes>1).TupleAnd(hv_NumEvalClasses>1)))
    {
      throw HException("Invalid number of elements in EvaluationMeasureType/ClassesToEvaluate.");
    }
    else
    {
      hv_EvaluationMeasureType = HTuple(hv_NumEvalClasses,hv_EvaluationMeasureType);
    }
  }
  //
  //Check whether we need to compute a confusion matrix.
  //We want to do this only once to save run time.
  hv_ComputePrecision = hv_EvaluationMeasureType.TupleRegexpTest("precision");
  hv_ComputeRecall = hv_EvaluationMeasureType.TupleRegexpTest("recall");
  hv_ComputeFScore = hv_EvaluationMeasureType.TupleRegexpTest("f_score");
  hv_ComputeConfusionMatrix = (hv_ComputePrecision+hv_ComputeRecall)+hv_ComputeFScore;
  if (0 != (hv_ComputeConfusionMatrix>0))
  {
    //Get the top-1 predicted classes from the result handle(s).
    hv_PredictedClasses = HTuple();
    {
    HTuple end_val59 = (hv_DLClassifierResultID.TupleLength())-1;
    HTuple step_val59 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val59, step_val59); hv_Index += step_val59)
    {
      GetDlClassifierResult(HTuple(hv_DLClassifierResultID[hv_Index]), "all", "predicted_classes", 
          &hv_PredictedClass);
      hv_PredictedClasses = hv_PredictedClasses.TupleConcat(hv_PredictedClass);
    }
    }
    //Compute the confusion matrix.
    gen_confusion_matrix(hv_GroundTruthLabels, hv_PredictedClasses, "display_matrix", 
        "none", HTuple(), &hv_ConfusionMatrix);
  }
  //
  //Loop through all given measure types.
  (*hv_EvaluationMeasure) = HTuple();
  {
  HTuple end_val69 = ((hv_NumEvalMeasureTypes.TupleConcat(hv_NumEvalClasses)).TupleMax())-1;
  HTuple step_val69 = 1;
  for (hv_EvalMeasureTypeIndex=0; hv_EvalMeasureTypeIndex.Continue(end_val69, step_val69); hv_EvalMeasureTypeIndex += step_val69)
  {
    //Select the current combination.
    hv_CurrentEvalMeasure = HTuple(hv_EvaluationMeasureType[hv_EvalMeasureTypeIndex]);
    hv_CurrentEvalClass = HTuple(hv_ClassesToEvaluate[hv_EvalMeasureTypeIndex]);
    //Set the output accordingly.
    //Check whether to compute the top-k error.
    hv_RegExpTopKError = "top([0-9]+)_error";
    hv_ComputeTopKError = hv_CurrentEvalMeasure.TupleRegexpTest(hv_RegExpTopKError);
    //Check whether to compute the precision, recall, F-score.
    hv_ComputePrecision = hv_CurrentEvalMeasure.TupleRegexpTest("precision");
    hv_ComputeRecall = hv_CurrentEvalMeasure.TupleRegexpTest("recall");
    hv_ComputeFScore = hv_CurrentEvalMeasure.TupleRegexpTest("f_score");
    //
    if (0 != hv_ComputeTopKError)
    {
      //Get the K from the input string 'topK_error'.
      hv_K = (hv_CurrentEvalMeasure.TupleRegexpMatch(hv_RegExpTopKError)).TupleNumber();
      //Select all labels or only the labels with the respective class.
      if (0 != (hv_CurrentEvalClass==HTuple("global")))
      {
        hv_Indices = HTuple::TupleGenSequence(0,(hv_GroundTruthLabels.TupleLength())-1,1);
      }
      else
      {
        hv_Indices = hv_GroundTruthLabels.TupleFind(hv_CurrentEvalClass);
      }
      compute_top_k_error(hv_DLClassifierHandle, hv_DLClassifierResultID, hv_GroundTruthLabels, 
          hv_Indices, hv_K, &hv_TopKError);
      (*hv_EvaluationMeasure)[hv_EvalMeasureTypeIndex] = hv_TopKError;
    }
    else if (0 != (HTuple(hv_ComputePrecision.TupleOr(hv_ComputeRecall)).TupleOr(hv_ComputeFScore)))
    {
      if (0 != (hv_CurrentEvalClass==HTuple("global")))
      {
        //Compute the mean of the measures for all classes.
        hv_NumClasses = hv_Classes.TupleLength();
        hv_IndexClass = HTuple::TupleGenSequence(0,hv_NumClasses-1,1);
      }
      else
      {
        //Compute the measures for a certain class.
        hv_NumClasses = 1;
        hv_IndexClass = hv_Classes.TupleFind(hv_CurrentEvalClass);
      }
      if (0 != (hv_ComputePrecision.TupleOr(hv_ComputeFScore)))
      {
        hv_ClassPrecisions = HTuple();
        SumMatrix(hv_ConfusionMatrix, "rows", &hv_MatrixRowSumID);
        {
        HTuple end_val106 = hv_NumClasses-1;
        HTuple step_val106 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val106, step_val106); hv_Index += step_val106)
        {
          //Compute the precision for every selected class.
          GetValueMatrix(hv_ConfusionMatrix, HTuple(hv_IndexClass[hv_Index]), HTuple(hv_IndexClass[hv_Index]), 
              &hv_TruePositive);
          GetValueMatrix(hv_MatrixRowSumID, HTuple(hv_IndexClass[hv_Index]), 0, &hv_SumPredictedClass);
          if (0 != (hv_SumPredictedClass==0))
          {
            hv_ClassPrecision = 0;
          }
          else
          {
            hv_ClassPrecision = hv_TruePositive/hv_SumPredictedClass;
          }
          hv_ClassPrecisions = hv_ClassPrecisions.TupleConcat(hv_ClassPrecision);
        }
        }
        hv_Precision = hv_ClassPrecisions.TupleMean();
        ClearMatrix(hv_MatrixRowSumID);
        if (0 != hv_ComputePrecision)
        {
          (*hv_EvaluationMeasure)[hv_EvalMeasureTypeIndex] = hv_Precision;
        }
      }
      if (0 != (hv_ComputeRecall.TupleOr(hv_ComputeFScore)))
      {
        hv_ClassRecalls = HTuple();
        SumMatrix(hv_ConfusionMatrix, "columns", &hv_MatrixColumnSumID);
        {
        HTuple end_val126 = hv_NumClasses-1;
        HTuple step_val126 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val126, step_val126); hv_Index += step_val126)
        {
          //Compute the recall for every class.
          GetValueMatrix(hv_ConfusionMatrix, HTuple(hv_IndexClass[hv_Index]), HTuple(hv_IndexClass[hv_Index]), 
              &hv_TruePositive);
          GetValueMatrix(hv_MatrixColumnSumID, 0, HTuple(hv_IndexClass[hv_Index]), 
              &hv_SumLabel);
          hv_ClassRecall = hv_TruePositive/hv_SumLabel;
          hv_ClassRecalls = hv_ClassRecalls.TupleConcat(hv_ClassRecall);
        }
        }
        hv_Recall = hv_ClassRecalls.TupleMean();
        ClearMatrix(hv_MatrixColumnSumID);
        if (0 != hv_ComputeRecall)
        {
          (*hv_EvaluationMeasure)[hv_EvalMeasureTypeIndex] = hv_Recall;
        }
      }
      if (0 != hv_ComputeFScore)
      {
        //Compute the F-score for a certain class or globally
        //for the averaged precision and recall.
        //Precision and recall were already computed above.
        if (0 != ((hv_Precision+hv_Recall)==0))
        {
          hv_FScore = 0.0;
        }
        else
        {
          hv_FScore = ((2*hv_Precision)*hv_Recall)/(hv_Precision+hv_Recall);
        }
        (*hv_EvaluationMeasure)[hv_EvalMeasureTypeIndex] = hv_FScore;
      }
    }
    else
    {
      throw HException(("Invalid option for EvaluationMeasureType: '"+hv_CurrentEvalMeasure)+"'");
    }
  }
  }
  if (0 != hv_ComputeConfusionMatrix)
  {
    ClearMatrix(hv_ConfusionMatrix);
  }
  return;

}

// Chapter: XLD / Creation
// Short Description: Creates an arrow shaped XLD contour. 
void gen_arrow_contour_xld (HObject *ho_Arrow, HTuple hv_Row1, HTuple hv_Column1, 
    HTuple hv_Row2, HTuple hv_Column2, HTuple hv_HeadLength, HTuple hv_HeadWidth)
{

  // Local iconic variables
  HObject  ho_TempArrow;

  // Local control variables
  HTuple  hv_Length, hv_ZeroLengthIndices, hv_DR;
  HTuple  hv_DC, hv_HalfHeadWidth, hv_RowP1, hv_ColP1, hv_RowP2;
  HTuple  hv_ColP2, hv_Index;

  //This procedure generates arrow shaped XLD contours,
  //pointing from (Row1, Column1) to (Row2, Column2).
  //If starting and end point are identical, a contour consisting
  //of a single point is returned.
  //
  //input parameteres:
  //Row1, Column1: Coordinates of the arrows' starting points
  //Row2, Column2: Coordinates of the arrows' end points
  //HeadLength, HeadWidth: Size of the arrow heads in pixels
  //
  //output parameter:
  //Arrow: The resulting XLD contour
  //
  //The input tuples Row1, Column1, Row2, and Column2 have to be of
  //the same length.
  //HeadLength and HeadWidth either have to be of the same length as
  //Row1, Column1, Row2, and Column2 or have to be a single element.
  //If one of the above restrictions is violated, an error will occur.
  //
  //
  //Init
  GenEmptyObj(&(*ho_Arrow));
  //
  //Calculate the arrow length
  DistancePp(hv_Row1, hv_Column1, hv_Row2, hv_Column2, &hv_Length);
  //
  //Mark arrows with identical start and end point
  //(set Length to -1 to avoid division-by-zero exception)
  hv_ZeroLengthIndices = hv_Length.TupleFind(0);
  if (0 != (hv_ZeroLengthIndices!=-1))
  {
    hv_Length[hv_ZeroLengthIndices] = -1;
  }
  //
  //Calculate auxiliary variables.
  hv_DR = (1.0*(hv_Row2-hv_Row1))/hv_Length;
  hv_DC = (1.0*(hv_Column2-hv_Column1))/hv_Length;
  hv_HalfHeadWidth = hv_HeadWidth/2.0;
  //
  //Calculate end points of the arrow head.
  hv_RowP1 = (hv_Row1+((hv_Length-hv_HeadLength)*hv_DR))+(hv_HalfHeadWidth*hv_DC);
  hv_ColP1 = (hv_Column1+((hv_Length-hv_HeadLength)*hv_DC))-(hv_HalfHeadWidth*hv_DR);
  hv_RowP2 = (hv_Row1+((hv_Length-hv_HeadLength)*hv_DR))-(hv_HalfHeadWidth*hv_DC);
  hv_ColP2 = (hv_Column1+((hv_Length-hv_HeadLength)*hv_DC))+(hv_HalfHeadWidth*hv_DR);
  //
  //Finally create output XLD contour for each input point pair
  {
  HTuple end_val45 = (hv_Length.TupleLength())-1;
  HTuple step_val45 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val45, step_val45); hv_Index += step_val45)
  {
    if (0 != (HTuple(hv_Length[hv_Index])==-1))
    {
      //Create_ single points for arrows with identical start and end point
      GenContourPolygonXld(&ho_TempArrow, HTuple(hv_Row1[hv_Index]), HTuple(hv_Column1[hv_Index]));
    }
    else
    {
      //Create arrow contour
      GenContourPolygonXld(&ho_TempArrow, ((((HTuple(hv_Row1[hv_Index]).TupleConcat(HTuple(hv_Row2[hv_Index]))).TupleConcat(HTuple(hv_RowP1[hv_Index]))).TupleConcat(HTuple(hv_Row2[hv_Index]))).TupleConcat(HTuple(hv_RowP2[hv_Index]))).TupleConcat(HTuple(hv_Row2[hv_Index])), 
          ((((HTuple(hv_Column1[hv_Index]).TupleConcat(HTuple(hv_Column2[hv_Index]))).TupleConcat(HTuple(hv_ColP1[hv_Index]))).TupleConcat(HTuple(hv_Column2[hv_Index]))).TupleConcat(HTuple(hv_ColP2[hv_Index]))).TupleConcat(HTuple(hv_Column2[hv_Index])));
    }
    ConcatObj((*ho_Arrow), ho_TempArrow, &(*ho_Arrow));
  }
  }
  return;
}

// Chapter: 3D Object Model / Creation
void gen_arrow_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowStart, HTuple hv_ArrowEnd, 
    HTuple *hv_OM3DArrow)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_DirectionVector, hv_ArrowLength, hv_ConeRadius;
  HTuple  hv_ConeLength, hv_CylinderLength, hv_pi, hv_X, hv_Y;
  HTuple  hv_Z, hv_Index, hv_OM3DConeTmp, hv_OM3DCone, hv_ZZero;
  HTuple  hv_ZTop, hv_OM3DCylinderTmp, hv_OM3DCylinder, hv_OM3DArrowTmp;
  HTuple  hv_Scale, hv_OriginX, hv_OriginY, hv_OriginZ, hv_TargetX;
  HTuple  hv_TargetY, hv_TargetZ, hv_HomMat3D;

  //
  //This procedure draws an arrow that starts at the point ArrowStart and ends at ArrowEnd.
  //
  //Get parameters.
  hv_DirectionVector = (hv_ArrowEnd.TupleSelectRange(0,2))-(hv_ArrowStart.TupleSelectRange(0,2));
  hv_ArrowLength = (((HTuple(hv_DirectionVector[0])*HTuple(hv_DirectionVector[0]))+(HTuple(hv_DirectionVector[1])*HTuple(hv_DirectionVector[1])))+(HTuple(hv_DirectionVector[2])*HTuple(hv_DirectionVector[2]))).TupleSqrt();
  hv_ConeRadius = 2.0*hv_ArrowThickness;
  hv_ConeLength = ((2.0*hv_ConeRadius).TupleConcat(hv_ArrowLength*0.9)).TupleMin();
  hv_CylinderLength = hv_ArrowLength-hv_ConeLength;
  //
  //Create cone.
  hv_pi = HTuple(180).TupleRad();
  hv_X = 0;
  hv_Y = 0;
  hv_Z = hv_CylinderLength+hv_ConeLength;
  {
  HTuple end_val15 = 2*hv_pi;
  HTuple step_val15 = 0.1;
  for (hv_Index=0; hv_Index.Continue(end_val15, step_val15); hv_Index += step_val15)
  {
    hv_X = hv_X.TupleConcat(hv_ConeRadius*(hv_Index.TupleCos()));
    hv_Y = hv_Y.TupleConcat(hv_ConeRadius*(hv_Index.TupleSin()));
    hv_Z = hv_Z.TupleConcat(hv_CylinderLength);
  }
  }
  GenObjectModel3dFromPoints(hv_X, hv_Y, hv_Z, &hv_OM3DConeTmp);
  ConvexHullObjectModel3d(hv_OM3DConeTmp, &hv_OM3DCone);
  ClearObjectModel3d(hv_OM3DConeTmp);
  //
  //Create cylinder.
  hv_X = HTuple();
  hv_Y = HTuple();
  {
  HTuple end_val27 = 2*hv_pi;
  HTuple step_val27 = 0.1;
  for (hv_Index=0; hv_Index.Continue(end_val27, step_val27); hv_Index += step_val27)
  {
    hv_X = hv_X.TupleConcat(hv_ArrowThickness*(hv_Index.TupleCos()));
    hv_Y = hv_Y.TupleConcat(hv_ArrowThickness*(hv_Index.TupleSin()));
  }
  }
  TupleGenConst(hv_Y.TupleLength(), 0, &hv_ZZero);
  TupleGenConst(hv_Y.TupleLength(), hv_CylinderLength, &hv_ZTop);
  GenObjectModel3dFromPoints(hv_X.TupleConcat(hv_X), hv_Y.TupleConcat(hv_Y), hv_ZZero.TupleConcat(hv_ZTop), 
      &hv_OM3DCylinderTmp);
  ConvexHullObjectModel3d(hv_OM3DCylinderTmp, &hv_OM3DCylinder);
  ClearObjectModel3d(hv_OM3DCylinderTmp);
  //
  //Union cone and cylinder Create arrow.
  UnionObjectModel3d(hv_OM3DCone.TupleConcat(hv_OM3DCylinder), "points_surface", 
      &hv_OM3DArrowTmp);
  ClearObjectModel3d(hv_OM3DCone);
  ClearObjectModel3d(hv_OM3DCylinder);
  hv_Scale = hv_CylinderLength/hv_ArrowLength;
  hv_OriginX.Clear();
  hv_OriginX[0] = 0;
  hv_OriginX[1] = 0;
  hv_OriginX[2] = 0;
  hv_OriginY.Clear();
  hv_OriginY[0] = 0;
  hv_OriginY[1] = 0;
  hv_OriginY[2] = 0;
  hv_OriginZ.Clear();
  hv_OriginZ[0] = 0;
  hv_OriginZ.Append(hv_CylinderLength);
  hv_OriginZ.Append(hv_ArrowLength);
  hv_TargetX.Clear();
  hv_TargetX.Append(HTuple(hv_ArrowStart[0]));
  hv_TargetX.Append(HTuple(hv_ArrowStart[0])+(hv_Scale*HTuple(hv_DirectionVector[0])));
  hv_TargetX.Append(HTuple(hv_ArrowEnd[0]));
  hv_TargetY.Clear();
  hv_TargetY.Append(HTuple(hv_ArrowStart[1]));
  hv_TargetY.Append(HTuple(hv_ArrowStart[1])+(hv_Scale*HTuple(hv_DirectionVector[1])));
  hv_TargetY.Append(HTuple(hv_ArrowEnd[1]));
  hv_TargetZ.Clear();
  hv_TargetZ.Append(HTuple(hv_ArrowStart[2]));
  hv_TargetZ.Append(HTuple(hv_ArrowStart[2])+(hv_Scale*HTuple(hv_DirectionVector[2])));
  hv_TargetZ.Append(HTuple(hv_ArrowEnd[2]));
  VectorToHomMat3d("rigid", hv_OriginX, hv_OriginY, hv_OriginZ, hv_TargetX, hv_TargetY, 
      hv_TargetZ, &hv_HomMat3D);
  AffineTransObjectModel3d(hv_OM3DArrowTmp, hv_HomMat3D, &(*hv_OM3DArrow));
  ClearObjectModel3d(hv_OM3DArrowTmp);
  return;
}

// Chapter: 3D Object Model / Creation
void gen_arrow_object_model_3d_visualize_object_model_3d (HTuple hv_ArrowThickness, 
    HTuple hv_ArrowStart, HTuple hv_ArrowEnd, HTuple *hv_OM3DArrow)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_DirectionVector, hv_ArrowLength, hv_ConeRadius;
  HTuple  hv_ConeLength, hv_CylinderLength, hv_pi, hv_X, hv_Y;
  HTuple  hv_Z, hv_Index, hv_OM3DConeTmp, hv_OM3DCone, hv_ZZero;
  HTuple  hv_ZTop, hv_OM3DCylinderTmp, hv_OM3DCylinder, hv_OM3DArrowTmp;
  HTuple  hv_Scale, hv_OriginX, hv_OriginY, hv_OriginZ, hv_TargetX;
  HTuple  hv_TargetY, hv_TargetZ, hv_HomMat3D;

  //
  //This procedure draws an arrow that starts at the point ArrowStart and ends at ArrowEnd.
  //
  //Get parameters.
  hv_DirectionVector = (hv_ArrowEnd.TupleSelectRange(0,2))-(hv_ArrowStart.TupleSelectRange(0,2));
  hv_ArrowLength = (((HTuple(hv_DirectionVector[0])*HTuple(hv_DirectionVector[0]))+(HTuple(hv_DirectionVector[1])*HTuple(hv_DirectionVector[1])))+(HTuple(hv_DirectionVector[2])*HTuple(hv_DirectionVector[2]))).TupleSqrt();
  hv_ConeRadius = 2.0*hv_ArrowThickness;
  hv_ConeLength = ((2.0*hv_ConeRadius).TupleConcat(hv_ArrowLength*0.9)).TupleMin();
  hv_CylinderLength = hv_ArrowLength-hv_ConeLength;
  //
  //Create cone.
  hv_pi = HTuple(180).TupleRad();
  hv_X = 0;
  hv_Y = 0;
  hv_Z = hv_CylinderLength+hv_ConeLength;
  {
  HTuple end_val15 = 2*hv_pi;
  HTuple step_val15 = 0.1;
  for (hv_Index=0; hv_Index.Continue(end_val15, step_val15); hv_Index += step_val15)
  {
    hv_X = hv_X.TupleConcat(hv_ConeRadius*(hv_Index.TupleCos()));
    hv_Y = hv_Y.TupleConcat(hv_ConeRadius*(hv_Index.TupleSin()));
    hv_Z = hv_Z.TupleConcat(hv_CylinderLength);
  }
  }
  GenObjectModel3dFromPoints(hv_X, hv_Y, hv_Z, &hv_OM3DConeTmp);
  ConvexHullObjectModel3d(hv_OM3DConeTmp, &hv_OM3DCone);
  ClearObjectModel3d(hv_OM3DConeTmp);
  //
  //Create cylinder.
  hv_X = HTuple();
  hv_Y = HTuple();
  {
  HTuple end_val27 = 2*hv_pi;
  HTuple step_val27 = 0.1;
  for (hv_Index=0; hv_Index.Continue(end_val27, step_val27); hv_Index += step_val27)
  {
    hv_X = hv_X.TupleConcat(hv_ArrowThickness*(hv_Index.TupleCos()));
    hv_Y = hv_Y.TupleConcat(hv_ArrowThickness*(hv_Index.TupleSin()));
  }
  }
  TupleGenConst(hv_Y.TupleLength(), 0, &hv_ZZero);
  TupleGenConst(hv_Y.TupleLength(), hv_CylinderLength, &hv_ZTop);
  GenObjectModel3dFromPoints(hv_X.TupleConcat(hv_X), hv_Y.TupleConcat(hv_Y), hv_ZZero.TupleConcat(hv_ZTop), 
      &hv_OM3DCylinderTmp);
  ConvexHullObjectModel3d(hv_OM3DCylinderTmp, &hv_OM3DCylinder);
  ClearObjectModel3d(hv_OM3DCylinderTmp);
  //
  //Union cone and cylinder Create arrow.
  UnionObjectModel3d(hv_OM3DCone.TupleConcat(hv_OM3DCylinder), "points_surface", 
      &hv_OM3DArrowTmp);
  ClearObjectModel3d(hv_OM3DCone);
  ClearObjectModel3d(hv_OM3DCylinder);
  hv_Scale = hv_CylinderLength/hv_ArrowLength;
  hv_OriginX.Clear();
  hv_OriginX[0] = 0;
  hv_OriginX[1] = 0;
  hv_OriginX[2] = 0;
  hv_OriginY.Clear();
  hv_OriginY[0] = 0;
  hv_OriginY[1] = 0;
  hv_OriginY[2] = 0;
  hv_OriginZ.Clear();
  hv_OriginZ[0] = 0;
  hv_OriginZ.Append(hv_CylinderLength);
  hv_OriginZ.Append(hv_ArrowLength);
  hv_TargetX.Clear();
  hv_TargetX.Append(HTuple(hv_ArrowStart[0]));
  hv_TargetX.Append(HTuple(hv_ArrowStart[0])+(hv_Scale*HTuple(hv_DirectionVector[0])));
  hv_TargetX.Append(HTuple(hv_ArrowEnd[0]));
  hv_TargetY.Clear();
  hv_TargetY.Append(HTuple(hv_ArrowStart[1]));
  hv_TargetY.Append(HTuple(hv_ArrowStart[1])+(hv_Scale*HTuple(hv_DirectionVector[1])));
  hv_TargetY.Append(HTuple(hv_ArrowEnd[1]));
  hv_TargetZ.Clear();
  hv_TargetZ.Append(HTuple(hv_ArrowStart[2]));
  hv_TargetZ.Append(HTuple(hv_ArrowStart[2])+(hv_Scale*HTuple(hv_DirectionVector[2])));
  hv_TargetZ.Append(HTuple(hv_ArrowEnd[2]));
  VectorToHomMat3d("rigid", hv_OriginX, hv_OriginY, hv_OriginZ, hv_TargetX, hv_TargetY, 
      hv_TargetZ, &hv_HomMat3D);
  AffineTransObjectModel3d(hv_OM3DArrowTmp, hv_HomMat3D, &(*hv_OM3DArrow));
  ClearObjectModel3d(hv_OM3DArrowTmp);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model which visualizes the bounding box of a stereo model. 
void gen_bounding_box_object_model_3d (HTuple hv_StereoModelID, HTuple *hv_ObjectModel3DBoundingBox)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_BoundingBox, hv_PX, hv_PY, hv_PZ, hv_Index;
  HTuple  hv_Faces;
  HTupleVector  hvec_Points(1);

  //
  //Consistency check:
  GetStereoModelParam(hv_StereoModelID, "bounding_box", &hv_BoundingBox);
  if (0 != (HTuple(HTuple(HTuple(hv_BoundingBox[3])<HTuple(hv_BoundingBox[0])).TupleOr(HTuple(hv_BoundingBox[4])<HTuple(hv_BoundingBox[1]))).TupleOr(HTuple(hv_BoundingBox[5])<HTuple(hv_BoundingBox[2]))))
  {
    throw HException("Invalid bounding box or bounding box not set yet.");
  }
  //
  //Get the eight corner points from the min/max representation.
  hvec_Points = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  hvec_Points[0] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[1] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[2] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[3] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[4] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[5] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[6] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[7] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  //
  //Sort the corner points by coordinate direction.
  hv_PX = HTuple();
  hv_PY = HTuple();
  hv_PZ = HTuple();
  for (hv_Index=0; hv_Index<=7; hv_Index+=1)
  {
    hv_PX = hv_PX.TupleConcat(HTuple(hvec_Points[hv_Index].T()[0]));
    hv_PY = hv_PY.TupleConcat(HTuple(hvec_Points[hv_Index].T()[1]));
    hv_PZ = hv_PZ.TupleConcat(HTuple(hvec_Points[hv_Index].T()[2]));
  }
  GenObjectModel3dFromPoints(hv_PX, hv_PY, hv_PZ, &(*hv_ObjectModel3DBoundingBox));
  //
  //Set the sides of the cuboid.
  hv_Faces = HTuple();
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(0)).Append(1)).Append(5)).Append(4)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(1)).Append(2)).Append(6)).Append(5)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(2)).Append(3)).Append(7)).Append(6)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(3)).Append(0)).Append(4)).Append(7)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(0)).Append(1)).Append(2)).Append(3)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(4)).Append(5)).Append(6)).Append(7)));
  SetObjectModel3dAttribMod((*hv_ObjectModel3DBoundingBox), "polygons", HTuple(), 
      hv_Faces);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the division model. 
void gen_cam_par_area_scan_division (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_Sx, 
    HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with distortions modeled by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_division";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the division model. 
void gen_cam_par_area_scan_hypercentric_division (HTuple hv_Focus, HTuple hv_Kappa, 
    HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with a hypercentric lens and with distortions modeled by the
  //division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_hypercentric_division";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a hypercentric lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_hypercentric_polynomial (HTuple hv_Focus, HTuple hv_K1, 
    HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with a hypercentric lens and with distortions modeled by the
  //polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_hypercentric_polynomial";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_polynomial (HTuple hv_Focus, HTuple hv_K1, HTuple hv_K2, 
    HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with distortions modeled by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_polynomial";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a telecentric lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_telecentric_division (HTuple hv_Magnification, HTuple hv_Kappa, 
    HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with a telecentric lens and with distortions modeled by the
  //division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_telecentric_division";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a telecentric lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_telecentric_polynomial (HTuple hv_Magnification, HTuple hv_K1, 
    HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with a telecentric lens and with distortions modeled by the
  //polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_telecentric_polynomial";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a bilateral telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_bilateral_telecentric_division (HTuple hv_Magnification, 
    HTuple hv_Kappa, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //a bilateral telecentric tilt lens and with distortions modeled
  //by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_bilateral_telecentric_division";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a bilateral telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_bilateral_telecentric_polynomial (HTuple hv_Magnification, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //a bilateral telecentric tilt lens and with distortions modeled
  //by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_bilateral_telecentric_polynomial";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_division (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_ImagePlaneDist, 
    HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, 
    HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //a tilt lens and with distortions modeled by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_division";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_ImagePlaneDist);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an image-side telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_image_side_telecentric_division (HTuple hv_Focus, 
    HTuple hv_Kappa, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //an image-side telecentric tilt lens and with distortions modeled
  //by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_image_side_telecentric_division";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an image-side telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_image_side_telecentric_polynomial (HTuple hv_Focus, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //an image-side telecentric tilt lens and with distortions modeled
  //by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_image_side_telecentric_polynomial";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an object-side telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_object_side_telecentric_division (HTuple hv_Magnification, 
    HTuple hv_Kappa, HTuple hv_ImagePlaneDist, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, 
    HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //an object-side telecentric tilt lens and with distortions modeled
  //by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_object_side_telecentric_division";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_ImagePlaneDist);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an object-side telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_object_side_telecentric_polynomial (HTuple hv_Magnification, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_ImagePlaneDist, 
    HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, 
    HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //an object-side telecentric tilt lens and with distortions modeled
  //by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_object_side_telecentric_polynomial";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_ImagePlaneDist);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_polynomial (HTuple hv_Focus, HTuple hv_K1, HTuple hv_K2, 
    HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_ImagePlaneDist, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //a tilt lens and with distortions modeled by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_polynomial";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_ImagePlaneDist);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for a line scan camera. 
void gen_cam_par_line_scan (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple hv_Vx, 
    HTuple hv_Vy, HTuple hv_Vz, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for a line scan camera.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "line_scan";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  (*hv_CameraParam).Append(hv_Vx);
  (*hv_CameraParam).Append(hv_Vy);
  (*hv_CameraParam).Append(hv_Vz);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera and the robot's tool. 
void gen_camera_and_tool_moving_cam_object_model_3d (HTuple hv_ToolInCamPose, HTuple hv_ToolInBasePose, 
    HTuple hv_CameraSize, HTuple hv_ConeLength, HTuple hv_OM3DToolOrig, HTuple hv_CamParam, 
    HTuple *hv_OM3DCamera, HTuple *hv_OM3DTool)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_IdentityPose, hv_CameraSetupModelID;
  HTuple  hv_OM3DCameraOrigin, hv_OM3DConeOrig, hv_CamInToolPose;
  HTuple  hv_CamInBasePose;

  //This procedure helps visualize the camera and its cone, as well
  //as the robot's tool in their current positions.
  //
  //Visualize Tool.
  RigidTransObjectModel3d(hv_OM3DToolOrig, hv_ToolInBasePose, &(*hv_OM3DTool));
  //
  //Visualize Camera.
  CreatePose(0, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_IdentityPose);
  CreateCameraSetupModel(1, &hv_CameraSetupModelID);
  SetCameraSetupCamParam(hv_CameraSetupModelID, 0, HTuple(), hv_CamParam, hv_IdentityPose);
  gen_camera_setup_object_model_3d(hv_CameraSetupModelID, hv_CameraSize, hv_ConeLength, 
      &hv_OM3DCameraOrigin, &hv_OM3DConeOrig);
  ClearCameraSetupModel(hv_CameraSetupModelID);
  hv_OM3DCameraOrigin = hv_OM3DCameraOrigin.TupleConcat(hv_OM3DConeOrig);
  //
  PoseInvert(hv_ToolInCamPose, &hv_CamInToolPose);
  PoseCompose(hv_ToolInBasePose, hv_CamInToolPose, &hv_CamInBasePose);
  RigidTransObjectModel3d(hv_OM3DCameraOrigin, hv_CamInBasePose, &(*hv_OM3DCamera));
  ClearObjectModel3d(hv_OM3DCameraOrigin);
  return;
}

void gen_camera_facing_scene (HTuple hv_Viewpoint, HTuple hv_Center, HTuple hv_DiameterModel, 
    HTuple *hv_OM3DCamera)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Direction, hv_DirectionLength, hv_DirNorm;
  HTuple  hv_Axis, hv_AxisNorm, hv_HomMat3DIdentity, hv_HomMat3DRotate;
  HTuple  hv_Pose;

  hv_Direction = hv_Viewpoint-hv_Center;
  hv_DirectionLength = ((hv_Direction*hv_Direction).TupleSum()).TupleSqrt();
  if (0 != (hv_DirectionLength<(1e-1*hv_DiameterModel)))
  {
    hv_DirectionLength = 0;
    GenSphereObjectModel3d(hv_Viewpoint.TupleConcat((((HTuple(0).Append(0)).Append(0)).Append(0))), 
        hv_DiameterModel*0.1, &(*hv_OM3DCamera));
  }
  else
  {
    //Create a rotation such that the camera faces the center of gravity of the scene
    hv_DirNorm = hv_Direction/hv_DirectionLength;
    if (0 != (((hv_DirNorm*((HTuple(0).Append(0)).Append(-1))).TupleSum())>-0.99999))
    {
      //Angle between the vectors is > 0.25
      hv_Axis = hv_DirNorm+((HTuple(0).Append(0)).Append(-1));
      hv_AxisNorm = hv_Axis/(((hv_Axis*hv_Axis).TupleSum()).TupleSqrt());
    }
    else
    {
      hv_Axis.Clear();
      hv_Axis[0] = 0;
      hv_Axis[1] = 1;
      hv_Axis[2] = 0;
    }
    HomMat3dIdentity(&hv_HomMat3DIdentity);
    HomMat3dRotateLocal(hv_HomMat3DIdentity, HTuple(180).TupleRad(), hv_Axis, &hv_HomMat3DRotate);
    HomMat3dToPose(hv_HomMat3DRotate, &hv_Pose);
    hv_Pose[HTuple::TupleGenSequence(0,2,1)] = hv_Viewpoint;
    gen_camera_object_model_3d(hv_Pose, hv_DiameterModel*0.1, &(*hv_OM3DCamera));
  }
  return;
}

// Short Description: Create a 3D object model that resembles a camera 
void gen_camera_object_model_3d (HTuple hv_Pose, HTuple hv_Size, HTuple *hv_OM3DCamera)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OM3DBox, hv_OM3DBoxTriangulated, hv_Information;
  HTuple  hv_OM3DCylinder, hv_OMSampledCylinder, hv_CX, hv_CY;
  HTuple  hv_CZ, hv_Lin, hv_Fac, hv_OM3DCylinder2;

  //Create the box
  GenBoxObjectModel3d(((((((HTuple(0).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)), 
      hv_Size, hv_Size, hv_Size, &hv_OM3DBox);
  TriangulateObjectModel3d(hv_OM3DBox, "greedy", HTuple(), HTuple(), &hv_OM3DBoxTriangulated, 
      &hv_Information);
  //Create the cone frustum
  GenCylinderObjectModel3d(((((((HTuple(0).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)), 
      hv_Size*0.5, hv_Size*0.5, hv_Size*1, &hv_OM3DCylinder);
  SampleObjectModel3d(hv_OM3DCylinder, "fast", hv_Size*0.02, HTuple(), HTuple(), 
      &hv_OMSampledCylinder);
  GetObjectModel3dParams(hv_OMSampledCylinder, "point_coord_x", &hv_CX);
  GetObjectModel3dParams(hv_OMSampledCylinder, "point_coord_y", &hv_CY);
  GetObjectModel3dParams(hv_OMSampledCylinder, "point_coord_z", &hv_CZ);
  hv_Lin = (hv_CZ-(hv_Size*0.5))/((hv_CZ.TupleMax())-(hv_CZ.TupleMin()));
  hv_Fac = (hv_Lin*0.5)+0.5;
  SetObjectModel3dAttribMod(hv_OMSampledCylinder, "point_coord_x", HTuple(), hv_CX*hv_Fac);
  SetObjectModel3dAttribMod(hv_OMSampledCylinder, "point_coord_y", HTuple(), hv_CY*hv_Fac);
  ConvexHullObjectModel3d(hv_OMSampledCylinder, &hv_OM3DCylinder2);
  //
  //Make it a single model and move to desired pose
  UnionObjectModel3d(hv_OM3DBoxTriangulated.TupleConcat(hv_OM3DCylinder2), "points_surface", 
      &(*hv_OM3DCamera));
  RigidTransObjectModel3d((*hv_OM3DCamera), hv_Pose, &(*hv_OM3DCamera));
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a symbolic 3D object model of a camera. 
void gen_camera_object_model_3d_reconstruction_3d (HTuple hv_CameraSetupModel, HTuple hv_CamIndex, 
    HTuple hv_CameraSize, HTuple *hv_OM3DCam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_LensePose, hv_CylinderLength, hv_ObjectModel3DLense;
  HTuple  hv_ObjectModel3DInit, hv_CamParams, hv_Type, hv_Tilt;
  HTuple  hv_Rot, hv_HomMat3DIdentity, hv_HomMat3DRotate;
  HTuple  hv_SensorToLenseRotation, hv_ObjectModel3DInitTilted;
  HTuple  hv_BoundingBox, hv_PX, hv_PY, hv_QZ, hv_PoseBack;
  HTuple  hv_ObjectModel3DInitTiltedBack, hv_CamPose, hv_OM3DSensor;
  HTuple  hv_OM3DLense;

  //
  //Generate a cylinder (lens) and move it behind the origin in direction z.
  CreatePose(0.0, 0.0, 0.0, 0, 0, 0, "Rp+T", "gba", "point", &hv_LensePose);
  hv_CylinderLength = hv_CameraSize/4.0;
  GenCylinderObjectModel3d(hv_LensePose, hv_CameraSize/2.0, (-hv_CylinderLength)/2.0, 
      0.0, &hv_ObjectModel3DLense);
  //
  //Generate a box (sensor housing) and tilt it, if necessary.
  GenBoxObjectModel3d(hv_LensePose, 1.0*hv_CameraSize, 1.0*hv_CameraSize, 1.0*hv_CameraSize, 
      &hv_ObjectModel3DInit);
  GetCameraSetupParam(hv_CameraSetupModel, hv_CamIndex, "params", &hv_CamParams);
  GetCameraSetupParam(hv_CameraSetupModel, hv_CamIndex, "type", &hv_Type);
  //
  //Distinguish cases with/without tilt.
  if (0 != (hv_Type.TupleRegexpTest("tilt")))
  {
    get_cam_par_data(hv_CamParams, "tilt", &hv_Tilt);
    get_cam_par_data(hv_CamParams, "rot", &hv_Rot);
  }
  else
  {
    hv_Tilt = 0;
    hv_Rot = 0;
  }
  HomMat3dIdentity(&hv_HomMat3DIdentity);
  HomMat3dRotate(hv_HomMat3DIdentity, hv_Tilt.TupleRad(), (((hv_Rot.TupleRad()).TupleCos()).TupleConcat((hv_Rot.TupleRad()).TupleSin())).TupleConcat(0), 
      0, 0, 0, &hv_HomMat3DRotate);
  HomMat3dToPose(hv_HomMat3DRotate, &hv_SensorToLenseRotation);
  RigidTransObjectModel3d(hv_ObjectModel3DInit, hv_SensorToLenseRotation, &hv_ObjectModel3DInitTilted);
  //
  //Move the sensor to a convenient position behind the lens.
  GetObjectModel3dParams(hv_ObjectModel3DInitTilted, "bounding_box1", &hv_BoundingBox);
  AffineTransPoint3d(hv_HomMat3DRotate, 0.0, 0.0, 0.5*hv_CameraSize, &hv_PX, &hv_PY, 
      &hv_QZ);
  CreatePose(-hv_PX, -hv_PY, (-HTuple(hv_BoundingBox[5]))-(hv_CylinderLength/2.0), 
      0, 0, 0, "Rp+T", "gba", "point", &hv_PoseBack);
  RigidTransObjectModel3d(hv_ObjectModel3DInitTilted, hv_PoseBack, &hv_ObjectModel3DInitTiltedBack);
  //
  //Move to the position of the camera in world coordinates.
  GetCameraSetupParam(hv_CameraSetupModel, hv_CamIndex, "pose", &hv_CamPose);
  RigidTransObjectModel3d(hv_ObjectModel3DInitTiltedBack, hv_CamPose, &hv_OM3DSensor);
  RigidTransObjectModel3d(hv_ObjectModel3DLense, hv_CamPose, &hv_OM3DLense);
  (*hv_OM3DCam).Clear();
  (*hv_OM3DCam).Append(hv_OM3DSensor);
  (*hv_OM3DCam).Append(hv_OM3DLense);
  //
  //Clean up.
  ClearObjectModel3d(hv_ObjectModel3DInit);
  ClearObjectModel3d(hv_ObjectModel3DInitTilted);
  ClearObjectModel3d(hv_ObjectModel3DInitTiltedBack);
  ClearObjectModel3d(hv_ObjectModel3DLense);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models which visualize the cameras of a stereo model. 
void gen_camera_setup_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraSize, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3DCamera, HTuple *hv_ObjectModel3DCone)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumCameras, hv_AutoConeLength, hv_AllCameras;
  HTuple  hv_CurrentCamera, hv_ConcatZ, hv_OtherCameras, hv_Index;
  HTuple  hv_CamParam0, hv_Pose0, hv_CamParam1, hv_Pose1;
  HTuple  hv_PoseInvert, hv_RelPose, hv_CX0, hv_CY0, hv_CX1;
  HTuple  hv_CY1, hv_X, hv_Y, hv_Z, hv_Dist, hv_Exception;
  HTuple  hv_CameraType, hv_ObjectModel3DConeTmp, hv_ObjectModel3DCameraTmp;

  GetCameraSetupParam(hv_CameraSetupModelID, "general", "num_cameras", &hv_NumCameras);
  //
  //Consistency check:
  if (0 != (hv_NumCameras<1))
  {
    throw HException("No camera set.");
  }
  if (0 != (hv_CameraSize.TupleIsNumber()))
  {
    if (0 != (hv_CameraSize<=0.0))
    {
      throw HException("Invalid value for CameraSize. CameraSize must be positive or 'auto'.");
    }
  }
  else if (0 != (hv_CameraSize!=HTuple("auto")))
  {
    throw HException("Invalid value for CameraSize. CameraSize must be positive or 'auto'.");
  }
  if (0 != (hv_ConeLength.TupleIsNumber()))
  {
    if (0 != (hv_ConeLength<=0.0))
    {
      throw HException("Invalid value for ConeLength. ConeLength must be positive or 'auto'.");
    }
  }
  else if (0 != (hv_ConeLength!=HTuple("auto")))
  {
    throw HException("Invalid value for ConeLength. ConeLength must be positive or 'auto'.");
  }
  //
  hv_AutoConeLength = hv_ConeLength==HTuple("auto");
  //
  (*hv_ObjectModel3DCamera) = HTuple();
  (*hv_ObjectModel3DCone) = HTuple();
  hv_AllCameras = HTuple::TupleGenSequence(0,hv_NumCameras-1,1);
  {
  HTuple end_val26 = hv_NumCameras-1;
  HTuple step_val26 = 1;
  for (hv_CurrentCamera=0; hv_CurrentCamera.Continue(end_val26, step_val26); hv_CurrentCamera += step_val26)
  {
    hv_ConcatZ = HTuple();
    if (0 != hv_AutoConeLength)
    {
      if (0 != (hv_NumCameras<2))
      {
        throw HException("You need at least two cameras for ConeLength == auto.");
      }
      //Intersect the line of sight of each camera with all other cameras.
      hv_OtherCameras = hv_AllCameras.TupleRemove(hv_AllCameras.TupleFind(hv_CurrentCamera));
      {
      HTuple end_val34 = (hv_OtherCameras.TupleLength())-1;
      HTuple step_val34 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val34, step_val34); hv_Index += step_val34)
      {
        GetCameraSetupParam(hv_CameraSetupModelID, hv_CurrentCamera, "params", &hv_CamParam0);
        GetCameraSetupParam(hv_CameraSetupModelID, hv_CurrentCamera, "pose", &hv_Pose0);
        GetCameraSetupParam(hv_CameraSetupModelID, HTuple(hv_OtherCameras[hv_Index]), 
            "params", &hv_CamParam1);
        GetCameraSetupParam(hv_CameraSetupModelID, HTuple(hv_OtherCameras[hv_Index]), 
            "pose", &hv_Pose1);
        //Intersect the lines of sight of the camera pair.
        PoseInvert(hv_Pose1, &hv_PoseInvert);
        PoseCompose(hv_PoseInvert, hv_Pose0, &hv_RelPose);
        get_cam_par_data(hv_CamParam0, "cx", &hv_CX0);
        get_cam_par_data(hv_CamParam0, "cy", &hv_CY0);
        get_cam_par_data(hv_CamParam1, "cx", &hv_CX1);
        get_cam_par_data(hv_CamParam1, "cy", &hv_CY1);
        try
        {
          IntersectLinesOfSight(hv_CamParam0, hv_CamParam1, hv_RelPose, hv_CY0, hv_CX0, 
              hv_CY1, hv_CX1, &hv_X, &hv_Y, &hv_Z, &hv_Dist);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          throw HException("Estimating a value for ConeLength automatically was not possible. Please use a number instead.");
        }
        hv_ConcatZ = hv_ConcatZ.TupleConcat(hv_Z);
      }
      }
      //Use the Z value of the determined coordinates as basis for the ConeLength.
      hv_ConeLength = (hv_ConcatZ.TupleMax())*1.05;
    }
    //
    //Create cone of sight 3D object models.
    //Distinguish cases with/without projection center.
    GetCameraSetupParam(hv_CameraSetupModelID, hv_CurrentCamera, "type", &hv_CameraType);
    if (0 != (hv_CameraType.TupleRegexpTest("telecentric")))
    {
      gen_cone_telecentric_object_model_3d(hv_CameraSetupModelID, hv_CurrentCamera, 
          hv_ConeLength, &hv_ObjectModel3DConeTmp);
    }
    else
    {
      gen_cone_perspective_object_model_3d(hv_CameraSetupModelID, hv_CurrentCamera, 
          hv_ConeLength, &hv_ObjectModel3DConeTmp);
    }
    (*hv_ObjectModel3DCone) = (*hv_ObjectModel3DCone).TupleConcat(hv_ObjectModel3DConeTmp);
    //
    //Create camera 3D object models.
    if (0 != (hv_CameraSize==HTuple("auto")))
    {
      //In auto mode, the camera size for all cameras
      //is defined by the first camera's cone length.
      hv_CameraSize = hv_ConeLength*0.1;
    }
    gen_camera_object_model_3d_reconstruction_3d(hv_CameraSetupModelID, hv_CurrentCamera, 
        hv_CameraSize, &hv_ObjectModel3DCameraTmp);
    (*hv_ObjectModel3DCamera) = (*hv_ObjectModel3DCamera).TupleConcat(hv_ObjectModel3DCameraTmp);
  }
  }
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model representing the view cone of a perspective camera. 
void gen_cone_perspective_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraIndex, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3D)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamPose, hv_HomMat3D, hv_CamParam;
  HTuple  hv_PX, hv_PY, hv_PZ, hv_QX, hv_QY, hv_QZ, hv_QXT;
  HTuple  hv_QYT, hv_QZT, hv_QX1, hv_QY1, hv_QZ1, hv_Index;
  HTuple  hv_Faces;
  HTupleVector  hvec_Points(1);

  GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "pose", &hv_CamPose);
  PoseToHomMat3d(hv_CamPose, &hv_HomMat3D);
  GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "params", &hv_CamParam);
  //
  //Get the lines of sight of the four corner points of the image.
  //Scale them to the given length and transform into world coordinates.
  hvec_Points = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  //First corner.
  GetLineOfSight(0, 0, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  hv_QXT = (hv_QX/hv_QZ)*hv_ConeLength;
  hv_QYT = (hv_QY/hv_QZ)*hv_ConeLength;
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QXT, hv_QYT, hv_QZT, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[0] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  //Second corner.
  GetLineOfSight(HTuple(hv_CamParam[(hv_CamParam.TupleLength())-1])-1, 0, hv_CamParam, 
      &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  hv_QXT = (hv_QX/hv_QZ)*hv_ConeLength;
  hv_QYT = (hv_QY/hv_QZ)*hv_ConeLength;
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QXT, hv_QYT, hv_QZT, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[1] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  //Third corner.
  GetLineOfSight(HTuple(hv_CamParam[(hv_CamParam.TupleLength())-1])-1, HTuple(hv_CamParam[(hv_CamParam.TupleLength())-2])-1, 
      hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  hv_QXT = (hv_QX/hv_QZ)*hv_ConeLength;
  hv_QYT = (hv_QY/hv_QZ)*hv_ConeLength;
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QXT, hv_QYT, hv_QZT, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[2] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  //Fourth corner.
  GetLineOfSight(0, HTuple(hv_CamParam[(hv_CamParam.TupleLength())-2])-1, hv_CamParam, 
      &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  hv_QXT = (hv_QX/hv_QZ)*hv_ConeLength;
  hv_QYT = (hv_QY/hv_QZ)*hv_ConeLength;
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QXT, hv_QYT, hv_QZT, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[3] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  //
  //Get camera center.
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 0, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[4] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  //
  //Sort the points by coordinate direction.
  hv_PX = HTuple();
  hv_PY = HTuple();
  hv_PZ = HTuple();
  for (hv_Index=0; hv_Index<=4; hv_Index+=1)
  {
    hv_PX = hv_PX.TupleConcat(HTuple(hvec_Points[hv_Index].T()[0]));
    hv_PY = hv_PY.TupleConcat(HTuple(hvec_Points[hv_Index].T()[1]));
    hv_PZ = hv_PZ.TupleConcat(HTuple(hvec_Points[hv_Index].T()[2]));
  }
  GenObjectModel3dFromPoints(hv_PX, hv_PY, hv_PZ, &(*hv_ObjectModel3D));
  //
  //Set the sides of the cone.
  hv_Faces = HTuple();
  hv_Faces = hv_Faces.TupleConcat(((HTuple(4).Append(0)).Append(1)));
  hv_Faces = hv_Faces.TupleConcat(((HTuple(4).Append(1)).Append(2)));
  hv_Faces = hv_Faces.TupleConcat(((HTuple(4).Append(2)).Append(3)));
  hv_Faces = hv_Faces.TupleConcat(((HTuple(4).Append(3)).Append(0)));
  SetObjectModel3dAttribMod((*hv_ObjectModel3D), "triangles", HTuple(), hv_Faces);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model representing the view cone of a telecentric camera. 
void gen_cone_telecentric_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraIndex, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3D)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamPose, hv_HomMat3D, hv_CamParam;
  HTuple  hv_PX, hv_PY, hv_PZ, hv_QX, hv_QY, hv_QZ, hv_QX1;
  HTuple  hv_QY1, hv_QZ1, hv_QZT, hv_Index, hv_Faces;
  HTupleVector  hvec_Points(1);

  GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "pose", &hv_CamPose);
  PoseToHomMat3d(hv_CamPose, &hv_HomMat3D);
  GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "params", &hv_CamParam);
  //
  //Get the lines of sight of the four corner points of the image.
  //Scale them to the given length and transform into world coordinates.
  hvec_Points = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  //First corner.
  GetLineOfSight(0, 0, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  AffineTransPoint3d(hv_HomMat3D, hv_PX, hv_PY, hv_PZ, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[0] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QX, hv_QY, hv_QZT, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[1] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  //Second corner.
  GetLineOfSight(HTuple(hv_CamParam[(hv_CamParam.TupleLength())-1])-1, 0, hv_CamParam, 
      &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  AffineTransPoint3d(hv_HomMat3D, hv_PX, hv_PY, hv_PZ, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[2] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QX, hv_QY, hv_QZT, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[3] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  //Third corner.
  GetLineOfSight(HTuple(hv_CamParam[(hv_CamParam.TupleLength())-1])-1, HTuple(hv_CamParam[(hv_CamParam.TupleLength())-2])-1, 
      hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  AffineTransPoint3d(hv_HomMat3D, hv_PX, hv_PY, hv_PZ, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[4] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QX, hv_QY, hv_QZT, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[5] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  //Fourth corner.
  GetLineOfSight(0, HTuple(hv_CamParam[(hv_CamParam.TupleLength())-2])-1, hv_CamParam, 
      &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  AffineTransPoint3d(hv_HomMat3D, hv_PX, hv_PY, hv_PZ, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[6] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QX, hv_QY, hv_QZT, &hv_QX1, &hv_QY1, &hv_QZ1);
  hvec_Points[7] = HTupleVector((hv_QX1.TupleConcat(hv_QY1)).TupleConcat(hv_QZ1));
  //
  //Sort the points by coordinate direction.
  hv_PX = HTuple();
  hv_PY = HTuple();
  hv_PZ = HTuple();
  for (hv_Index=0; hv_Index<=7; hv_Index+=1)
  {
    hv_PX = hv_PX.TupleConcat(HTuple(hvec_Points[hv_Index].T()[0]));
    hv_PY = hv_PY.TupleConcat(HTuple(hvec_Points[hv_Index].T()[1]));
    hv_PZ = hv_PZ.TupleConcat(HTuple(hvec_Points[hv_Index].T()[2]));
  }
  GenObjectModel3dFromPoints(hv_PX, hv_PY, hv_PZ, &(*hv_ObjectModel3D));
  //
  //Set the sides of the cone.
  hv_Faces = HTuple();
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(0)).Append(1)).Append(3)).Append(2)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(2)).Append(3)).Append(5)).Append(4)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(4)).Append(5)).Append(7)).Append(6)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(6)).Append(7)).Append(1)).Append(0)));
  SetObjectModel3dAttribMod((*hv_ObjectModel3D), "polygons", HTuple(), hv_Faces);
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Visualize and return the confusion matrix for the given labels.  
void gen_confusion_matrix (HTuple hv_GroundTruthLabels, HTuple hv_PredictedClasses, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_DisplayMatrix, hv_ReturnMatrix, hv_DisplayColor;
  HTuple  hv_DisplayColumnWidth, hv_GenParamIndex, hv_CalculateRelativeMatrix;
  HTuple  hv_Classes, hv_NumClasses, hv_AbsoluteMatrixID;
  HTuple  hv_RelativeMatrixID, hv_ColumnMatrix, hv_Class;
  HTuple  hv_ThisLabel, hv_NumClassGroundTruth, hv_RowMatrix;
  HTuple  hv_PredictedClass, hv_ThisPredictedClass, hv_NumMatches;
  HTuple  hv_RelativeError, hv_StringWidths, hv_StringIndex;
  HTuple  hv_String, hv_Ascent, hv_Descent, hv_StringWidth;
  HTuple  hv_StringHeight, hv_MaxStringWidth, hv_RowStart;
  HTuple  hv_RowDistance, hv_RowEnd, hv_ColumnStart, hv_ColumnOffset;
  HTuple  hv_ColumnEnd, hv_Width, hv_Height, hv_WidthLimit;
  HTuple  hv_HeightLimit, hv_TextRow, hv_TextColumn, hv_Index;
  HTuple  hv_Text, hv_Row, hv_Column, hv_AbsoluteTransposedMatrixID;
  HTuple  hv_MatrixText, hv_MatrixMaxID, hv_MaxValue, hv_StringConversion;
  HTuple  hv_RelativeTransposedMatrixID, hv_TextColor, hv_RelativeValues;
  HTuple  hv_Thresholds, hv_Colors, hv_Greater, hv_Indices;
  HTuple  hv_DiagonalIndex, hv_Value;

  //This procedure computes a confusion matrix.
  //Therefore, it compares the classes
  //assigned in GroundTruthLabels and PredictedClasses.
  //The resulting confusion matrix can be
  //visualized, returned, or both.
  //In each case, the output can be changed
  //via generic parameters using GenParamName and GenParamValue.
  //For the visualization, the graphics window
  //must be specified with WindowHandle.
  //
  if (0 != ((hv_GroundTruthLabels.TupleLength())!=(hv_PredictedClasses.TupleLength())))
  {
    throw HException("Number of ground truth labels and predicted classes must be equal.");
  }
  //
  //Set generic parameter defaults.
  hv_DisplayMatrix = "absolute";
  hv_ReturnMatrix = "absolute";
  hv_DisplayColor = "true";
  hv_DisplayColumnWidth = "minimal";
  //
  //Parse generic parameters.
  {
  HTuple end_val21 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val21 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val21, step_val21); hv_GenParamIndex += step_val21)
  {
    if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_matrix")))
    {
      //Set 'display_matrix'.
      hv_DisplayMatrix = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("return_matrix")))
    {
      //Set 'return_matrix'.
      hv_ReturnMatrix = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_color")))
    {
      //Set 'display_color'.
      hv_DisplayColor = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_column_width")))
    {
      //Set 'display_column_width'.
      hv_DisplayColumnWidth = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  if (0 != (HTuple(HTuple(hv_DisplayMatrix==HTuple("relative")).TupleOr(hv_ReturnMatrix==HTuple("relative"))).TupleOr(hv_DisplayColor==HTuple("true"))))
  {
    hv_CalculateRelativeMatrix = 1;
  }
  else
  {
    hv_CalculateRelativeMatrix = 0;
  }
  //
  //Calculate the confusion matrix with absolute values
  //and the confusion matrix with relative errors.
  //We start with an empty matrix
  //and add the number of matching labels.
  hv_Classes = (hv_GroundTruthLabels.TupleSort()).TupleUniq();
  hv_NumClasses = hv_Classes.TupleLength();
  CreateMatrix(hv_NumClasses, hv_NumClasses, 0, &hv_AbsoluteMatrixID);
  if (0 != hv_CalculateRelativeMatrix)
  {
    CreateMatrix(hv_NumClasses, hv_NumClasses, 0, &hv_RelativeMatrixID);
  }
  {
  HTuple end_val55 = hv_NumClasses-1;
  HTuple step_val55 = 1;
  for (hv_ColumnMatrix=0; hv_ColumnMatrix.Continue(end_val55, step_val55); hv_ColumnMatrix += step_val55)
  {
    hv_Class = HTuple(hv_Classes[hv_ColumnMatrix]);
    hv_ThisLabel = hv_GroundTruthLabels.TupleEqualElem(hv_Class);
    if (0 != hv_CalculateRelativeMatrix)
    {
      //Obtain the number of ground truth labels per class.
      hv_NumClassGroundTruth = hv_ThisLabel.TupleSum();
    }
    {
    HTuple end_val62 = hv_NumClasses-1;
    HTuple step_val62 = 1;
    for (hv_RowMatrix=0; hv_RowMatrix.Continue(end_val62, step_val62); hv_RowMatrix += step_val62)
    {
      //Select classes for this row/column.
      hv_PredictedClass = HTuple(hv_Classes[hv_RowMatrix]);
      //Check whether the input data
      //corresponds to these classes.
      hv_ThisPredictedClass = hv_PredictedClasses.TupleEqualElem(hv_PredictedClass);
      //Count the number of elements where the predicted class
      //matches the ground truth label.
      hv_NumMatches = ((hv_ThisLabel+hv_ThisPredictedClass).TupleEqualElem(2)).TupleSum();
      //Set value in matrix.
      SetValueMatrix(hv_AbsoluteMatrixID, hv_RowMatrix, hv_ColumnMatrix, hv_NumMatches);
      if (0 != hv_CalculateRelativeMatrix)
      {
        if (0 != (hv_NumClassGroundTruth>0))
        {
          hv_RelativeError = (hv_NumMatches.TupleReal())/hv_NumClassGroundTruth;
        }
        else
        {
          hv_RelativeError = 0;
        }
        SetValueMatrix(hv_RelativeMatrixID, hv_RowMatrix, hv_ColumnMatrix, hv_RelativeError);
      }
    }
    }
  }
  }
  //
  //Return the result.
  if (0 != (hv_ReturnMatrix==HTuple("absolute")))
  {
    CopyMatrix(hv_AbsoluteMatrixID, &(*hv_ConfusionMatrix));
  }
  else if (0 != (hv_ReturnMatrix==HTuple("relative")))
  {
    CopyMatrix(hv_RelativeMatrixID, &(*hv_ConfusionMatrix));
  }
  else if (0 != (hv_ReturnMatrix==HTuple("none")))
  {
    //No matrix is returned.
  }
  else
  {
    throw HException("Unsupported mode for 'return_matrix'");
  }
  //
  //Display the matrix.
  if (0 != (hv_DisplayMatrix!=HTuple("none")))
  {
    //
    //Find maximal string width and set display position parameters.
    hv_StringWidths = HTuple();
    //Get the string width of each class.
    {
    HTuple end_val101 = (hv_Classes.TupleLength())-1;
    HTuple step_val101 = 1;
    for (hv_StringIndex=0; hv_StringIndex.Continue(end_val101, step_val101); hv_StringIndex += step_val101)
    {
      hv_String = HTuple(hv_Classes[hv_StringIndex]);
      GetStringExtents(hv_WindowHandle, hv_String, &hv_Ascent, &hv_Descent, &hv_StringWidth, 
          &hv_StringHeight);
      hv_StringWidths = hv_StringWidths.TupleConcat(hv_StringWidth);
    }
    }
    //The columns should have a minimum width for 4 characters.
    GetStringExtents(hv_WindowHandle, "test", &hv_Ascent, &hv_Descent, &hv_StringWidth, 
        &hv_StringHeight);
    hv_MaxStringWidth = (hv_StringWidths.TupleMax()).TupleMax2(hv_StringWidth);
    //Get the maximum string width
    //and resize the window accordingly.
    hv_RowStart = 80;
    hv_RowDistance = hv_StringHeight+10;
    hv_RowEnd = hv_StringHeight*7;
    hv_ColumnStart = 50+hv_MaxStringWidth;
    hv_ColumnOffset = 20;
    hv_ColumnEnd = hv_ColumnOffset;
    //
    //Adapt the window size to fit the confusion matrix.
    if (0 != (hv_DisplayColumnWidth==HTuple("minimal")))
    {
      //Every column of the confusion matrix is as narrow as possible
      //based to the respective string widths.
      hv_Width = (((hv_StringWidths.TupleSum())+(hv_ColumnOffset*hv_NumClasses))+hv_ColumnStart)+hv_ColumnEnd;
    }
    else if (0 != (hv_DisplayColumnWidth==HTuple("equal")))
    {
      //Every column of the confusion matrix should have the same width.
      //based on the maximum string width.
      hv_Width = (((hv_MaxStringWidth+hv_ColumnOffset)*hv_NumClasses)+hv_ColumnStart)+hv_ColumnEnd;
    }
    else
    {
      throw HException("");
    }
    hv_Height = ((hv_RowDistance*hv_NumClasses)+hv_RowStart)+hv_RowEnd;
    HDevWindowStack::SetActive(hv_WindowHandle);
    if (HDevWindowStack::IsOpen())
      ClearWindow(HDevWindowStack::GetActive());
    //
    //Set reasonable limits for graphics window (adapt if necessary).
    hv_WidthLimit.Clear();
    hv_WidthLimit[0] = 450;
    hv_WidthLimit[1] = 1920;
    hv_HeightLimit.Clear();
    hv_HeightLimit[0] = 250;
    hv_HeightLimit[1] = 1080;
    if (0 != (HTuple(hv_Width>HTuple(hv_WidthLimit[1])).TupleOr(hv_Height>HTuple(hv_HeightLimit[1]))))
    {
      throw HException("Confusion Matrix does not fit into graphics window. Please adapt font and/or size limits.");
    }
    dev_resize_window_fit_size(0, 0, hv_Width, hv_Height, hv_WidthLimit, hv_HeightLimit);
    //
    //Get display coordinates.
    //Get row coordinates for display.
    hv_TextRow = HTuple();
    {
    HTuple end_val145 = hv_NumClasses-1;
    HTuple step_val145 = 1;
    for (hv_ColumnMatrix=0; hv_ColumnMatrix.Continue(end_val145, step_val145); hv_ColumnMatrix += step_val145)
    {
      hv_TextRow = hv_TextRow.TupleConcat(HTuple::TupleGenSequence(0,(hv_NumClasses-1)*hv_RowDistance,hv_RowDistance));
    }
    }
    //Get column coordinates for display.
    hv_TextColumn = HTuple();
    {
    HTuple end_val150 = hv_NumClasses-1;
    HTuple step_val150 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val150, step_val150); hv_Index += step_val150)
    {
      hv_TextColumn = hv_TextColumn.TupleConcat(HTuple(hv_NumClasses,hv_ColumnStart));
      if (0 != (hv_DisplayColumnWidth==HTuple("minimal")))
      {
        hv_ColumnStart = (hv_ColumnStart+HTuple(hv_StringWidths[hv_Index]))+hv_ColumnOffset;
      }
      else if (0 != (hv_DisplayColumnWidth==HTuple("equal")))
      {
        hv_ColumnStart = (hv_ColumnStart+hv_MaxStringWidth)+hv_ColumnOffset;
      }
    }
    }
    //Display the confusion matrix with a margin from the top.
    hv_TextRow += hv_RowStart;
    //Display axis titles.
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),"Ground truth labels", "window", "top", 
          "right", "white", "box", "false");
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),"Predicted classes", "window", "bottom", 
          "left", "white", "box", "false");
    {
    HTuple end_val163 = (hv_Classes.TupleLength())-1;
    HTuple step_val163 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val163, step_val163); hv_Index += step_val163)
    {
      hv_Text = HTuple(hv_Classes[hv_Index]);
      //Display predicted class names.
      hv_Row = HTuple(hv_TextRow[hv_Index]);
      hv_Column = (HTuple(hv_TextColumn[0])-hv_MaxStringWidth)-hv_ColumnOffset;
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_Row, hv_Column, 
            "light gray", "box", "false");
      //Display ground truth label names.
      hv_Row = HTuple(hv_TextRow[0])-25;
      hv_Column = HTuple(hv_TextColumn[hv_Index*hv_NumClasses]);
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_Row, hv_Column, 
            "light gray", "box", "false");
    }
    }
    //
    //Get the confusion matrix values for display.
    if (0 != (hv_DisplayMatrix==HTuple("absolute")))
    {
      //Displayed matrix corresponds to the transposed returned matrix.
      TransposeMatrix(hv_AbsoluteMatrixID, &hv_AbsoluteTransposedMatrixID);
      GetFullMatrix(hv_AbsoluteTransposedMatrixID, &hv_MatrixText);
      ClearMatrix(hv_AbsoluteTransposedMatrixID);
      //Align the numbers right.
      MaxMatrix(hv_AbsoluteMatrixID, "full", &hv_MatrixMaxID);
      GetFullMatrix(hv_MatrixMaxID, &hv_MaxValue);
      ClearMatrix(hv_MatrixMaxID);
      hv_StringConversion = (((hv_MaxValue.TupleLog10()).TupleCeil()).TupleInt())+".0f";
      hv_MatrixText = hv_MatrixText.TupleString(hv_StringConversion);
    }
    else
    {
      //Displayed matrix corresponds to the transposed returned matrix.
      TransposeMatrix(hv_RelativeMatrixID, &hv_RelativeTransposedMatrixID);
      GetFullMatrix(hv_RelativeTransposedMatrixID, &hv_MatrixText);
      ClearMatrix(hv_RelativeTransposedMatrixID);
      hv_MatrixText = hv_MatrixText.TupleString(".2f");
    }
    //Set color for displayed confusion matrix.
    if (0 != (hv_DisplayColor==HTuple("true")))
    {
      TupleGenConst(hv_MatrixText.TupleLength(), "#666666", &hv_TextColor);
      //Use the relative values to adapt the color of the text.
      TransposeMatrix(hv_RelativeMatrixID, &hv_RelativeTransposedMatrixID);
      GetFullMatrix(hv_RelativeTransposedMatrixID, &hv_RelativeValues);
      ClearMatrix(hv_RelativeTransposedMatrixID);
      //Set the colors and respective thresholds for the off-diagonal values.
      hv_Thresholds.Clear();
      hv_Thresholds[0] = 0.0;
      hv_Thresholds[1] = 0.05;
      hv_Thresholds[2] = 0.1;
      hv_Thresholds[3] = 0.2;
      hv_Colors.Clear();
      hv_Colors[0] = "#8C4D4D";
      hv_Colors[1] = "#B33333";
      hv_Colors[2] = "#D91A1A";
      hv_Colors[3] = "#FF0000";
      {
      HTuple end_val204 = (hv_Thresholds.TupleLength())-1;
      HTuple step_val204 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val204, step_val204); hv_Index += step_val204)
      {
        TupleGreaterElem(hv_RelativeValues, HTuple(hv_Thresholds[hv_Index]), &hv_Greater);
        TupleFind(hv_Greater, 1, &hv_Indices);
        if (0 != (hv_Indices!=-1))
        {
          TupleReplace(hv_TextColor, hv_Indices, HTuple(hv_Colors[hv_Index]), &hv_TextColor);
        }
        else
        {
          break;
        }
      }
      }
      //Set the colors and respective thresholds for the diagonal values.
      hv_Thresholds.Clear();
      hv_Thresholds[0] = -0.01;
      hv_Thresholds[1] = 0.60;
      hv_Thresholds[2] = 0.80;
      hv_Thresholds[3] = 0.90;
      hv_Thresholds[4] = 0.95;
      hv_Thresholds[5] = 0.98;
      hv_Colors.Clear();
      hv_Colors[0] = "#666666";
      hv_Colors[1] = "#508650";
      hv_Colors[2] = "#419C41";
      hv_Colors[3] = "#2BBD2B";
      hv_Colors[4] = "#15DE15";
      hv_Colors[5] = "#00FF00";
      {
      HTuple end_val216 = hv_NumClasses-1;
      HTuple step_val216 = 1;
      for (hv_DiagonalIndex=0; hv_DiagonalIndex.Continue(end_val216, step_val216); hv_DiagonalIndex += step_val216)
      {
        GetValueMatrix(hv_RelativeMatrixID, hv_DiagonalIndex, hv_DiagonalIndex, &hv_Value);
        {
        HTuple end_val218 = (hv_Thresholds.TupleLength())-1;
        HTuple step_val218 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val218, step_val218); hv_Index += step_val218)
        {
          if (0 != (hv_Value>HTuple(hv_Thresholds[hv_Index])))
          {
            hv_TextColor[hv_DiagonalIndex*(hv_NumClasses+1)] = HTuple(hv_Colors[hv_Index]);
          }
          else
          {
            break;
          }
        }
        }
      }
      }
    }
    else
    {
      //Default value for the text color.
      TupleGenConst(hv_MatrixText.TupleLength(), "white", &hv_TextColor);
    }
    //
    //Display confusion matrix.
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_MatrixText, "window", hv_TextRow, 
          hv_TextColumn, hv_TextColor, "box", "false");
    //
    //Clean up.
    if (0 != hv_CalculateRelativeMatrix)
    {
      ClearMatrix(hv_RelativeMatrixID);
    }
    ClearMatrix(hv_AbsoluteMatrixID);
  }
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, robot's tool and plane. 
void gen_current_setup_moving_cam_object_model_3d (HTuple hv_CameraSize, HTuple hv_ToolInBasePose, 
    HTuple hv_HandEyeCalibData, HTuple hv_OM3DToolOrigin, HTuple hv_OM3DBase, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DTool, HTuple *hv_OM3DPlane)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ToolInCamPose, hv_CamParam, hv_PlaneInBasePose0;
  HTuple  hv_BaseInToolPose, hv_PlaneInToolPose, hv_PlaneInCamPose;
  HTuple  hv_CX, hv_CY, hv_OptAxisPlaneX, hv_OptAxisPlaneY;
  HTuple  hv_HomMat3D, hv_OptAxisCamX, hv_OptAxisCamY, hv_OptAxisCamZ;
  HTuple  hv_ConeLength, hv_FactorBorder;

  //This procedure visualizes the camera, tool, and plane in their
  //current positions.
  //
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInBasePose0", &hv_PlaneInBasePose0);
  //
  if (0 != (hv_CameraSize<=0))
  {
    throw HException("CameraSize should be > 0");
  }
  //
  //Visualize current camera and tool position.
  //
  //Get the intersection of the optical axis of the camera and the plane
  PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
  PoseCompose(hv_BaseInToolPose, hv_PlaneInBasePose0, &hv_PlaneInToolPose);
  PoseCompose(hv_ToolInCamPose, hv_PlaneInToolPose, &hv_PlaneInCamPose);
  get_cam_par_data(hv_CamParam, "cx", &hv_CX);
  get_cam_par_data(hv_CamParam, "cy", &hv_CY);
  ImagePointsToWorldPlane(hv_CamParam, hv_PlaneInCamPose, hv_CY, hv_CX, "m", &hv_OptAxisPlaneX, 
      &hv_OptAxisPlaneY);
  //Transform to camera coordinates
  PoseToHomMat3d(hv_PlaneInCamPose, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_OptAxisPlaneX, hv_OptAxisPlaneY, 0, &hv_OptAxisCamX, 
      &hv_OptAxisCamY, &hv_OptAxisCamZ);
  hv_ConeLength = hv_OptAxisCamZ*1.1;
  //If the optical axis does not intersect the plane, we still want to visualize the camera.
  if (0 != (hv_ConeLength<=0.0))
  {
    hv_ConeLength = hv_CameraSize;
  }
  gen_camera_and_tool_moving_cam_object_model_3d(hv_ToolInCamPose, hv_ToolInBasePose, 
      hv_CameraSize, hv_ConeLength, hv_OM3DToolOrigin, hv_CamParam, &(*hv_OM3DCamera), 
      &(*hv_OM3DTool));
  //
  //Create 3D object model of plane.
  hv_FactorBorder = 1.5;
  gen_ground_plane_object_model_3d((*hv_OM3DTool), (*hv_OM3DCamera), hv_OM3DBase, 
      hv_FactorBorder, hv_PlaneInBasePose0, &(*hv_OM3DPlane));
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, the plane, the robot's base and the robot's tool in a stationary camera setup. 
void gen_current_setup_stationary_cam_object_model_3d (HTuple hv_ArrowThickness, 
    HTuple hv_ArrowLength, HTuple hv_CameraSize, HTuple hv_HandEyeCalibData, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DPlane, HTuple *hv_OM3DBase, HTuple *hv_OM3DToolOrigin)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_PlaneInCamPose0, hv_BaseInCamPose;
  HTuple  hv_CX, hv_CY, hv_OptAxisPlaneX, hv_OptAxisPlaneY;
  HTuple  hv_HomMat3D, hv_OptAxisCamX, hv_OptAxisCamY, hv_OptAxisCamZ;
  HTuple  hv_ConeLength, hv_IdentityPose, hv_CameraSetupModelID;
  HTuple  hv_OM3DCameraOrigin, hv_OM3DConeOrig, hv_CamInBasePose;
  HTuple  hv_FactorBorder, hv_PlaneInBasePose;

  //This procedure generates the 3D object models of the camera and its
  //cone, the plane, the robot's base and the robot's tool at its
  //initial position.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInCamPose0", &hv_PlaneInCamPose0);
  read_message_tuple(hv_HandEyeCalibData, "BaseInCamPose", &hv_BaseInCamPose);
  //
  //Visualize base and tool in the origin.
  gen_robot_tool_and_base_object_model_3d(hv_ArrowThickness, hv_ArrowLength, &(*hv_OM3DToolOrigin), 
      &(*hv_OM3DBase));
  //Visualize camera.
  get_cam_par_data(hv_CamParam, "cx", &hv_CX);
  get_cam_par_data(hv_CamParam, "cy", &hv_CY);
  ImagePointsToWorldPlane(hv_CamParam, hv_PlaneInCamPose0, hv_CY, hv_CX, "m", &hv_OptAxisPlaneX, 
      &hv_OptAxisPlaneY);
  PoseToHomMat3d(hv_PlaneInCamPose0, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_OptAxisPlaneX, hv_OptAxisPlaneY, 0, &hv_OptAxisCamX, 
      &hv_OptAxisCamY, &hv_OptAxisCamZ);
  hv_ConeLength = hv_OptAxisCamZ*1.1;
  //If the optical axis does not intersect the plane, we still want to visualize the camera.
  if (0 != (hv_ConeLength<=0.0))
  {
    hv_ConeLength = hv_CameraSize;
  }
  CreatePose(0, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_IdentityPose);
  CreateCameraSetupModel(1, &hv_CameraSetupModelID);
  SetCameraSetupCamParam(hv_CameraSetupModelID, 0, HTuple(), hv_CamParam, hv_IdentityPose);
  gen_camera_setup_object_model_3d(hv_CameraSetupModelID, hv_CameraSize, hv_ConeLength, 
      &hv_OM3DCameraOrigin, &hv_OM3DConeOrig);
  ClearCameraSetupModel(hv_CameraSetupModelID);
  hv_OM3DCameraOrigin = hv_OM3DCameraOrigin.TupleConcat(hv_OM3DConeOrig);
  PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
  RigidTransObjectModel3d(hv_OM3DCameraOrigin, hv_CamInBasePose, &(*hv_OM3DCamera));
  ClearObjectModel3d(hv_OM3DCameraOrigin);
  //
  //Create 3D object model of plane.
  hv_FactorBorder = 1.5;
  PoseCompose(hv_CamInBasePose, hv_PlaneInCamPose0, &hv_PlaneInBasePose);
  gen_ground_plane_object_model_3d((*hv_OM3DToolOrigin), (*hv_OM3DCamera), (*hv_OM3DBase), 
      hv_FactorBorder, hv_PlaneInBasePose, &(*hv_OM3DPlane));
  return;

}

// Chapter: Deep Learning / Classification
// Short Description: Do not use this procedure, use dev_display_dl_classifier_heatmap.  
void gen_dl_classifier_heatmap (HObject ho_Image, HObject *ho_HeatmapRegions, HTuple hv_DLClassifierHandle, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Text;

  //The procedure gen_dl_classifier_heatmap has been revised and renamed.
  //From now on the heatmap functionality is available in the procedure
  //dev_display_dl_classifier_heatmap.
  //This procedure now displays a text to guide the user to the correct procedure.
  //
  hv_Text = HTuple();
  hv_Text[hv_Text.TupleLength()] = "ERROR: This procedure (gen_dl_classifier_heatmap) ";
  hv_Text[hv_Text.TupleLength()] = "has been revised and renamed.";
  hv_Text[hv_Text.TupleLength()] = "Please use the procedure dev_display_dl_classifier_heatmap";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "center", "center", 
        (HTuple("red").Append("red")), HTuple(), HTuple());
  return;
}

// Chapter: Classification / Misc
// Short Description: Generate a dummy image and region that are, e.g., used to determine the lengths of the feature vectors in get_feature_lengths. 
void gen_dummy_objects (HObject *ho_Region, HObject *ho_Image)
{

  //
  //Create dummy objects for the feature calculation
  //(may be used to determine the lengths of the
  //vectors etc.).
  //
  GenImageConst(&(*ho_Image), "byte", 3, 3);
  Compose3((*ho_Image), (*ho_Image), (*ho_Image), &(*ho_Image));
  GetDomain((*ho_Image), &(*ho_Region));
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate the 3D object model of the plane. 
void gen_ground_plane_object_model_3d (HTuple hv_OM3DTool, HTuple hv_OM3DCamera, 
    HTuple hv_OM3DBase, HTuple hv_FactorBorder, HTuple hv_PlaneInBasePose, HTuple *hv_OM3DPlane)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_XBase, hv_YBase, hv_ZBase, hv_MinXt;
  HTuple  hv_MinYt, hv_MinZt, hv_MaxXt, hv_MaxYt, hv_MaxZt;
  HTuple  hv_Min, hv_Max, hv_MinT, hv_MaxT, hv_BoundingBox;
  HTuple  hv_PXBB, hv_PYBB, hv_PZBB, hv_BaseInPlanePose, hv_HomMat3D;
  HTuple  hv_PX, hv_PY, hv_PZ, hv_Qx, hv_Qx1, hv_Qy, hv_Qy1;
  HTuple  hv_XPlane, hv_YPlane, hv_ZPlane, hv_HomMat3D1, hv_Qx2;
  HTuple  hv_Qy2, hv_Qz, hv_Faces;

  //This procedure generates the 3D object model of
  //the plane on which objects are matched and grasped.
  //
  hv_XBase = HTuple();
  hv_YBase = HTuple();
  hv_ZBase = HTuple();
  //Extent of tool in base coordinates.
  get_extent_by_axis(hv_OM3DTool, hv_XBase, hv_YBase, hv_ZBase, &hv_XBase, &hv_YBase, 
      &hv_ZBase);
  //Extent of camera in base coordinates.
  get_extent_by_axis(hv_OM3DCamera, hv_XBase, hv_YBase, hv_ZBase, &hv_XBase, &hv_YBase, 
      &hv_ZBase);
  //Extent of base in base coordinates.
  get_extent_by_axis(hv_OM3DBase, hv_XBase, hv_YBase, hv_ZBase, &hv_XBase, &hv_YBase, 
      &hv_ZBase);
  //
  //Joint bounding box.
  hv_MinXt = hv_XBase.TupleMin();
  hv_MinYt = hv_YBase.TupleMin();
  hv_MinZt = hv_ZBase.TupleMin();
  hv_MaxXt = hv_XBase.TupleMax();
  hv_MaxYt = hv_YBase.TupleMax();
  hv_MaxZt = hv_ZBase.TupleMax();
  hv_Min.Clear();
  hv_Min.Append(hv_MinXt);
  hv_Min.Append(hv_MinYt);
  hv_Min.Append(hv_MinZt);
  hv_Max.Clear();
  hv_Max.Append(hv_MaxXt);
  hv_Max.Append(hv_MaxYt);
  hv_Max.Append(hv_MaxZt);
  //
  //Joint bounding box extended by a factor of FactorBorder.
  hv_MinT = ((hv_Max*(1.0-hv_FactorBorder))/2.0)+((hv_Min*(1.0+hv_FactorBorder))/2.0);
  hv_MaxT = ((hv_Max*(1.0+hv_FactorBorder))/2.0)+((hv_Min*(1.0-hv_FactorBorder))/2.0);
  hv_BoundingBox.Clear();
  hv_BoundingBox.Append(hv_MinT);
  hv_BoundingBox.Append(hv_MaxT);
  //
  //Get the eight corner points of the bounding box from the min/max representation.
  get_bounding_box_points_from_min_max(hv_BoundingBox, &hv_PXBB, &hv_PYBB, &hv_PZBB);

  //Transform to plane coordinates (z is direction of the normal of the plane).
  PoseInvert(hv_PlaneInBasePose, &hv_BaseInPlanePose);
  PoseToHomMat3d(hv_BaseInPlanePose, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_PXBB, hv_PYBB, hv_PZBB, &hv_PX, &hv_PY, &hv_PZ);
  //
  //Get outline of projection onto the plane.
  hv_Qx = hv_PX.TupleMin();
  hv_Qx1 = hv_PX.TupleMax();
  hv_Qy = hv_PY.TupleMin();
  hv_Qy1 = hv_PY.TupleMax();
  hv_XPlane.Clear();
  hv_XPlane.Append(hv_Qx);
  hv_XPlane.Append(hv_Qx);
  hv_XPlane.Append(hv_Qx1);
  hv_XPlane.Append(hv_Qx1);
  hv_YPlane.Clear();
  hv_YPlane.Append(hv_Qy);
  hv_YPlane.Append(hv_Qy1);
  hv_YPlane.Append(hv_Qy1);
  hv_YPlane.Append(hv_Qy);
  TupleGenConst(4, 0, &hv_ZPlane);
  //
  //Transform back to base coordinates.
  PoseToHomMat3d(hv_PlaneInBasePose, &hv_HomMat3D1);
  AffineTransPoint3d(hv_HomMat3D1, hv_XPlane, hv_YPlane, hv_ZPlane, &hv_Qx2, &hv_Qy2, 
      &hv_Qz);
  //
  //Generate the visualization.
  GenObjectModel3dFromPoints(hv_Qx2, hv_Qy2, hv_Qz, &(*hv_OM3DPlane));
  hv_Faces = HTuple();
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(0)).Append(1)).Append(2)).Append(3)));
  SetObjectModel3dAttribMod((*hv_OM3DPlane), "polygons", HTuple(), hv_Faces);
  //
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object of the matched model, in the case of rectification. 
void gen_matching_object_model_3d (HTuple hv_ModelID, HTuple hv_ObjectHeight, HTuple hv_Poses, 
    HTuple hv_HandEyeCalibData, HTuple hv_RectificationData, HTuple *hv_OM3DModel)
{

  // Local iconic variables
  HObject  ho_ModelContours, ho_ObjectSelected;

  // Local control variables
  HTuple  hv_CamParam, hv_MatchingPlaneInCamPose;
  HTuple  hv_RectifyImage, hv_ScaleRectification, hv_Number;
  HTuple  hv_ModelRows, hv_ModelCols, hv_Index, hv_Row1, hv_Col1;
  HTuple  hv_PX, hv_PY, hv_PXPlane, hv_PYPlane, hv_PXPlaneOrig;
  HTuple  hv_PYPlaneOrig, hv_PZ1, hv_PZ2, hv_PlanePartRectToModelPose;
  HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_Qz;

  //This procedure generates a 3D model from a shape model for
  //visualization for a known (rectified) matching plane.
  //
  //The 3D model consists of the model-contours transformed to
  //their real world size. The origin of the 3D model coordinate system
  //lies in the origin of the input shape model with the z-axis
  //pointing towards the camera. The model contours are displayed
  //twice, at z = 0 and z = ObjectHeight.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_Poses, "MatchingPlaneInCamPose", &hv_MatchingPlaneInCamPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (HTuple(HTuple(hv_RectifyImage==HTuple("true")).TupleOr(hv_RectifyImage==HTuple("only_rectify"))).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  //
  //Get shape model contours.
  GetShapeModelContours(&ho_ModelContours, hv_ModelID, 1);
  CountObj(ho_ModelContours, &hv_Number);
  hv_ModelRows = HTuple();
  hv_ModelCols = HTuple();
  {
  HTuple end_val21 = hv_Number;
  HTuple step_val21 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
  {
    SelectObj(ho_ModelContours, &ho_ObjectSelected, hv_Index);
    GetContourXld(ho_ObjectSelected, &hv_Row1, &hv_Col1);
    hv_ModelRows = hv_ModelRows.TupleConcat(hv_Row1);
    hv_ModelCols = hv_ModelCols.TupleConcat(hv_Col1);
  }
  }
  //Obtain real world size (col = x, row = y), centered around the shape model origin (0,0).
  if (0 != (HTuple(HTuple(hv_RectifyImage==HTuple("true")).TupleOr(hv_RectifyImage==HTuple("only_rectify"))).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    hv_PX = hv_ModelCols*hv_ScaleRectification;
    hv_PY = hv_ModelRows*hv_ScaleRectification;
  }
  else
  {
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_ModelRows, 
        hv_ModelCols, "m", &hv_PXPlane, &hv_PYPlane);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, 0, 0, "m", &hv_PXPlaneOrig, 
        &hv_PYPlaneOrig);
    hv_PX = hv_PXPlane-hv_PXPlaneOrig;
    hv_PY = hv_PYPlane-hv_PYPlaneOrig;
  }
  //Display the contours twice, once in the plane, once above.
  TupleGenConst(hv_PY.TupleLength(), 0, &hv_PZ1);
  TupleGenConst(hv_PY.TupleLength(), hv_ObjectHeight, &hv_PZ2);
  //Transform from plane to model coordinate system. The plane
  //coordinate system has previously been adapted such that its
  //z-axis points away from the camera.
  CreatePose(0, 0, hv_ObjectHeight, 180, 0, 0, "Rp+T", "gba", "point", &hv_PlanePartRectToModelPose);
  PoseToHomMat3d(hv_PlanePartRectToModelPose, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_PX.TupleConcat(hv_PX), hv_PY.TupleConcat(hv_PY), 
      hv_PZ1.TupleConcat(hv_PZ2), &hv_Qx, &hv_Qy, &hv_Qz);
  GenObjectModel3dFromPoints(hv_Qx, hv_Qy, hv_Qz, &(*hv_OM3DModel));
  return;
}

void gen_menu_regions_ext (HObject *ho_MenuRegions, HTuple hv_TopBottom, HTuple hv_WindowHandleMenu, 
    HTuple hv_PercentageHeight, HTuple hv_NumRows, HTuple hv_NumCols)
{

  // Local iconic variables
  HObject  ho_Rectangle;

  // Local control variables
  HTuple  hv_PartRow1, hv_PartCol1, hv_PartRow2;
  HTuple  hv_PartCol2, hv_Height, hv_Width, hv_MenuHeight;
  HTuple  hv_MenuWidth, hv_ButtonHeight, hv_ButtonWidth, hv_Row0;
  HTuple  hv_Col0, hv_r, hv_c;

  if (0 != (HTuple(hv_TopBottom!=HTuple("top")).TupleAnd(hv_TopBottom!=HTuple("bottom"))))
  {
    throw HException("Invalid parameter: TopBottom must be \"top\" or \"bottom\"");
  }

  GetPart(hv_WindowHandleMenu, &hv_PartRow1, &hv_PartCol1, &hv_PartRow2, &hv_PartCol2);
  hv_Height = (hv_PartRow2-hv_PartRow1)+1;
  hv_Width = (hv_PartCol2-hv_PartCol1)+1;
  hv_MenuHeight = (hv_Height*hv_PercentageHeight)/100.0;
  hv_MenuWidth = hv_Width;
  hv_ButtonHeight = hv_MenuHeight/hv_NumRows;
  hv_ButtonWidth = hv_MenuWidth/hv_NumCols;
  if (0 != (hv_TopBottom==HTuple("top")))
  {
    hv_Row0 = hv_PartRow1;
  }
  if (0 != (hv_TopBottom==HTuple("bottom")))
  {
    hv_Row0 = hv_PartRow2-hv_MenuHeight;
  }
  hv_Col0 = hv_PartCol1;
  SetSystem("clip_region", "false");
  GenEmptyObj(&(*ho_MenuRegions));
  {
  HTuple end_val20 = hv_NumRows-1;
  HTuple step_val20 = 1;
  for (hv_r=0; hv_r.Continue(end_val20, step_val20); hv_r += step_val20)
  {
    {
    HTuple end_val21 = hv_NumCols-1;
    HTuple step_val21 = 1;
    for (hv_c=0; hv_c.Continue(end_val21, step_val21); hv_c += step_val21)
    {
      GenRectangle1(&ho_Rectangle, hv_Row0+(hv_r*hv_ButtonHeight), hv_Col0+(hv_c*hv_ButtonWidth), 
          ((hv_Row0+(hv_r*hv_ButtonHeight))+hv_ButtonHeight)-1, ((hv_Col0+(hv_c*hv_ButtonWidth))+hv_ButtonWidth)-1);
      ConcatObj((*ho_MenuRegions), ho_Rectangle, &(*ho_MenuRegions));
    }
    }
  }
  }
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate base and tool 3D models of the robot. 
void gen_robot_tool_and_base_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowLength, 
    HTuple *hv_OM3DToolOrigin, HTuple *hv_OM3DBase)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_IdentityPose, hv_TransXPose, hv_OM3DToolXOrigin;
  HTuple  hv_TransYPose, hv_OM3DToolYOrigin, hv_TransZPose;
  HTuple  hv_OM3DToolZOrigin, hv_FactorVisBase, hv_OM3DBasePlate;
  HTuple  hv_OM3DBaseX, hv_OM3DBaseY, hv_OM3DBaseZ;

  //This procedure creates 3D models that represent the tool and the base
  //of the robot.
  //
  if (0 != (hv_ArrowThickness<=0))
  {
    throw HException("ArrowThickness should be > 0");
  }
  if (0 != (hv_ArrowLength<=0))
  {
    throw HException("ArrowLength should be > 0");
  }
  CreatePose(0, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_IdentityPose);
  //
  //3D model for the tool.
  CreatePose(hv_ArrowLength, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransXPose);
  gen_arrow_object_model_3d_visualize_object_model_3d(hv_ArrowThickness, hv_IdentityPose, 
      hv_TransXPose, &hv_OM3DToolXOrigin);
  CreatePose(0, hv_ArrowLength, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransYPose);
  gen_arrow_object_model_3d_visualize_object_model_3d(hv_ArrowThickness, hv_IdentityPose, 
      hv_TransYPose, &hv_OM3DToolYOrigin);
  CreatePose(0, 0, hv_ArrowLength, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransZPose);
  gen_arrow_object_model_3d_visualize_object_model_3d(hv_ArrowThickness, hv_IdentityPose, 
      hv_TransZPose, &hv_OM3DToolZOrigin);
  (*hv_OM3DToolOrigin).Clear();
  (*hv_OM3DToolOrigin).Append(hv_OM3DToolXOrigin);
  (*hv_OM3DToolOrigin).Append(hv_OM3DToolYOrigin);
  (*hv_OM3DToolOrigin).Append(hv_OM3DToolZOrigin);
  //
  //3D model for the base.
  hv_FactorVisBase = hv_ArrowThickness*10;
  GenBoxObjectModel3d(hv_IdentityPose, hv_FactorVisBase*1.5, hv_FactorVisBase*1.5, 
      hv_FactorVisBase/12, &hv_OM3DBasePlate);
  CreatePose(hv_ArrowLength, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransXPose);
  gen_arrow_object_model_3d_visualize_object_model_3d(hv_ArrowThickness, hv_IdentityPose, 
      hv_TransXPose, &hv_OM3DBaseX);
  CreatePose(0, hv_ArrowLength, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransYPose);
  gen_arrow_object_model_3d_visualize_object_model_3d(hv_ArrowThickness, hv_IdentityPose, 
      hv_TransYPose, &hv_OM3DBaseY);
  CreatePose(0, 0, hv_ArrowLength, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransZPose);
  gen_arrow_object_model_3d_visualize_object_model_3d(hv_ArrowThickness, hv_IdentityPose, 
      hv_TransZPose, &hv_OM3DBaseZ);
  (*hv_OM3DBase).Clear();
  (*hv_OM3DBase).Append(hv_OM3DBaseX);
  (*hv_OM3DBase).Append(hv_OM3DBaseY);
  (*hv_OM3DBase).Append(hv_OM3DBaseZ);
  (*hv_OM3DBase).Append(hv_OM3DBasePlate);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models which visualize a sheet of light setup. 
void gen_sheet_of_light_object_model_3d (HTuple hv_SheetOfLightModelID, HTuple hv_PlaneAndMovementSize, 
    HTuple hv_CameraSize, HTuple hv_ConeLength, HTuple *hv_OM3DLightPlane, HTuple *hv_OM3DMovement, 
    HTuple *hv_OM3DCamera, HTuple *hv_OM3DCone)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CalibrationType, hv_CamParam, hv_CameraPose;
  HTuple  hv_LPPose, hv_MovementPose, hv_LightPlanePoseVis;
  HTuple  hv_XVis, hv_YVis, hv_Norm, hv_ArrowStart, hv_ArrowEnd;
  HTuple  hv_CameraSetupModelID, hv_CameraPoseVis;

  //
  GetSheetOfLightParam(hv_SheetOfLightModelID, "calibration", &hv_CalibrationType);
  if (0 != (hv_CalibrationType!=HTuple("xyz")))
  {
    throw HException("The 'calibration' of the sheet of light model has to be 'xyz'.");
  }
  //
  if (0 != (hv_PlaneAndMovementSize<=0.0))
  {
    throw HException("Invalid value for PlaneAndMovementSize. PlaneAndMovementSize must be positive.");
  }
  //
  GetSheetOfLightParam(hv_SheetOfLightModelID, "camera_parameter", &hv_CamParam);
  GetSheetOfLightParam(hv_SheetOfLightModelID, "camera_pose", &hv_CameraPose);
  GetSheetOfLightParam(hv_SheetOfLightModelID, "lightplane_pose", &hv_LPPose);
  GetSheetOfLightParam(hv_SheetOfLightModelID, "movement_pose", &hv_MovementPose);
  if (0 != (HTuple(HTuple(HTuple(hv_CamParam==HTuple()).TupleOr(hv_CameraPose==HTuple())).TupleOr(hv_LPPose==HTuple())).TupleOr(hv_MovementPose==HTuple())))
  {
    throw HException("The sheet of light model has to contain all calibration results.");
  }
  //
  //Create object model 3D of light plane.
  PoseInvert(hv_LPPose, &hv_LightPlanePoseVis);
  hv_XVis = (((HTuple(-1.0).Append(1.0)).Append(1.0)).Append(-1.0))*hv_PlaneAndMovementSize;
  hv_YVis = (((HTuple(-1.0).Append(-1.0)).Append(1.0)).Append(1.0))*hv_PlaneAndMovementSize;
  GenPlaneObjectModel3d(hv_LightPlanePoseVis, hv_XVis, hv_YVis, &(*hv_OM3DLightPlane));
  //
  //Create object model 3D of movement.
  hv_Norm = (((hv_MovementPose.TupleSelectRange(0,2))*(hv_MovementPose.TupleSelectRange(0,2))).TupleSum()).TupleSqrt();
  hv_ArrowStart.Clear();
  hv_ArrowStart[0] = 0.0;
  hv_ArrowStart[1] = 0.0;
  hv_ArrowStart[2] = 0.0;
  hv_ArrowEnd = ((hv_MovementPose.TupleSelectRange(0,2))*hv_PlaneAndMovementSize)/hv_Norm;
  gen_arrow_object_model_3d_visualize_object_model_3d(hv_PlaneAndMovementSize/40.0, 
      hv_ArrowStart, hv_ArrowEnd, &(*hv_OM3DMovement));
  //
  //Create object model 3D of camera.
  CreateCameraSetupModel(1, &hv_CameraSetupModelID);
  PoseInvert(hv_CameraPose, &hv_CameraPoseVis);
  SetCameraSetupCamParam(hv_CameraSetupModelID, 0, HTuple(), hv_CamParam, hv_CameraPoseVis);
  gen_camera_setup_object_model_3d(hv_CameraSetupModelID, hv_CameraSize, hv_ConeLength, 
      &(*hv_OM3DCamera), &(*hv_OM3DCone));
  ClearCameraSetupModel(hv_CameraSetupModelID);
  return;
}

// Chapter: 3D Object Model / Creation
void gen_tool_to_touching_point_object_model_3d (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple *hv_OM3DToolTouchingPoint)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OM3DToolOrigin, hv_OM3DToolTouchingPointTmp;
  HTuple  hv_Index, hv_OM3DRigidTrans, hv_OM3DBase;

  //
  gen_robot_tool_and_base_object_model_3d(0.0025, 0.05, &hv_OM3DToolOrigin, &hv_OM3DBase);
  GenObjectModel3dFromPoints(HTuple(0).TupleConcat(HTuple(hv_RobotTouchingPointInToolCoordinates[0])), 
      HTuple(0).TupleConcat(HTuple(hv_RobotTouchingPointInToolCoordinates[1])), HTuple(0).TupleConcat(HTuple(hv_RobotTouchingPointInToolCoordinates[2])), 
      &(*hv_OM3DToolTouchingPoint));
  SetObjectModel3dAttribMod((*hv_OM3DToolTouchingPoint), "lines", HTuple(), ((HTuple(2).Append(0)).Append(1)));
  hv_OM3DToolTouchingPointTmp.Clear();
  hv_OM3DToolTouchingPointTmp.Append(hv_OM3DToolOrigin);
  hv_OM3DToolTouchingPointTmp.Append((*hv_OM3DToolTouchingPoint));
  //
  (*hv_OM3DToolTouchingPoint) = HTuple();
  {
  HTuple end_val7 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
  HTuple step_val7 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val7, step_val7); hv_Index += step_val7)
  {
    RigidTransObjectModel3d(hv_OM3DToolTouchingPointTmp, hvec_ToolInBasePosesTouchingPoint[hv_Index].T(), 
        &hv_OM3DRigidTrans);
    (*hv_OM3DToolTouchingPoint) = (*hv_OM3DToolTouchingPoint).TupleConcat(hv_OM3DRigidTrans);
  }
  }
  return;
}

// Chapter: 3D Object Model / Features
void get_bounding_box_points_from_min_max (HTuple hv_BoundingBox, HTuple *hv_PX, 
    HTuple *hv_PY, HTuple *hv_PZ)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index;
  HTupleVector  hvec_Points(1);

  hvec_Points = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  hvec_Points[0] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[1] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[2] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[3] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[4] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[5] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[6] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[7] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  (*hv_PX) = HTuple();
  (*hv_PY) = HTuple();
  (*hv_PZ) = HTuple();
  for (hv_Index=0; hv_Index<=7; hv_Index+=1)
  {
    (*hv_PX) = (*hv_PX).TupleConcat(HTuple(hvec_Points[hv_Index].T()[0]));
    (*hv_PY) = (*hv_PY).TupleConcat(HTuple(hvec_Points[hv_Index].T()[1]));
    (*hv_PZ) = (*hv_PZ).TupleConcat(HTuple(hvec_Points[hv_Index].T()[2]));
  }
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Get the value of a specified camera parameter from the camera parameter tuple. 
void get_cam_par_data (HTuple hv_CameraParam, HTuple hv_ParamName, HTuple *hv_ParamValue)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CameraType, hv_CameraParamNames, hv_Index;
  HTuple  hv_ParamNameInd, hv_I;

  //get_cam_par_data returns in ParamValue the value of the
  //parameter that is given in ParamName from the tuple of
  //camera parameters that is given in CameraParam.
  //
  //Get the parameter names that correspond to the
  //elements in the input camera parameter tuple.
  get_cam_par_names(hv_CameraParam, &hv_CameraType, &hv_CameraParamNames);
  //
  //Find the index of the requested camera data and return
  //the corresponding value.
  (*hv_ParamValue) = HTuple();
  {
  HTuple end_val11 = (hv_ParamName.TupleLength())-1;
  HTuple step_val11 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val11, step_val11); hv_Index += step_val11)
  {
    hv_ParamNameInd = HTuple(hv_ParamName[hv_Index]);
    if (0 != (hv_ParamNameInd==HTuple("camera_type")))
    {
      (*hv_ParamValue) = (*hv_ParamValue).TupleConcat(hv_CameraType);
      continue;
    }
    hv_I = hv_CameraParamNames.TupleFind(hv_ParamNameInd);
    if (0 != (hv_I!=-1))
    {
      (*hv_ParamValue) = (*hv_ParamValue).TupleConcat(HTuple(hv_CameraParam[hv_I]));
    }
    else
    {
      throw HException("Unknown camera parameter "+hv_ParamNameInd);
    }
  }
  }
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Get the names of the parameters in a camera parameter tuple. 
void get_cam_par_names (HTuple hv_CameraParam, HTuple *hv_CameraType, HTuple *hv_ParamNames)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CameraParamAreaScanDivision, hv_CameraParamAreaScanPolynomial;
  HTuple  hv_CameraParamAreaScanTelecentricDivision, hv_CameraParamAreaScanTelecentricPolynomial;
  HTuple  hv_CameraParamAreaScanTiltDivision, hv_CameraParamAreaScanTiltPolynomial;
  HTuple  hv_CameraParamAreaScanImageSideTelecentricTiltDivision;
  HTuple  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial;
  HTuple  hv_CameraParamAreaScanBilateralTelecentricTiltDivision;
  HTuple  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial;
  HTuple  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision;
  HTuple  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial;
  HTuple  hv_CameraParamAreaScanHypercentricDivision, hv_CameraParamAreaScanHypercentricPolynomial;
  HTuple  hv_CameraParamLinesScan, hv_CameraParamAreaScanTiltDivisionLegacy;
  HTuple  hv_CameraParamAreaScanTiltPolynomialLegacy, hv_CameraParamAreaScanTelecentricDivisionLegacy;
  HTuple  hv_CameraParamAreaScanTelecentricPolynomialLegacy;
  HTuple  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy;
  HTuple  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy;

  //get_cam_par_names returns for each element in the camera
  //parameter tuple that is passed in CameraParam the name
  //of the respective camera parameter. The parameter names
  //are returned in ParamNames. Additionally, the camera
  //type is returned in CameraType. Alternatively, instead of
  //the camera parameters, the camera type can be passed in
  //CameraParam in form of one of the following strings:
  //  - 'area_scan_division'
  //  - 'area_scan_polynomial'
  //  - 'area_scan_tilt_division'
  //  - 'area_scan_tilt_polynomial'
  //  - 'area_scan_telecentric_division'
  //  - 'area_scan_telecentric_polynomial'
  //  - 'area_scan_tilt_bilateral_telecentric_division'
  //  - 'area_scan_tilt_bilateral_telecentric_polynomial'
  //  - 'area_scan_tilt_object_side_telecentric_division'
  //  - 'area_scan_tilt_object_side_telecentric_polynomial'
  //  - 'area_scan_hypercentric_division'
  //  - 'area_scan_hypercentric_polynomial'
  //  - 'line_scan'
  //
  hv_CameraParamAreaScanDivision.Clear();
  hv_CameraParamAreaScanDivision[0] = "focus";
  hv_CameraParamAreaScanDivision[1] = "kappa";
  hv_CameraParamAreaScanDivision[2] = "sx";
  hv_CameraParamAreaScanDivision[3] = "sy";
  hv_CameraParamAreaScanDivision[4] = "cx";
  hv_CameraParamAreaScanDivision[5] = "cy";
  hv_CameraParamAreaScanDivision[6] = "image_width";
  hv_CameraParamAreaScanDivision[7] = "image_height";
  hv_CameraParamAreaScanPolynomial.Clear();
  hv_CameraParamAreaScanPolynomial[0] = "focus";
  hv_CameraParamAreaScanPolynomial[1] = "k1";
  hv_CameraParamAreaScanPolynomial[2] = "k2";
  hv_CameraParamAreaScanPolynomial[3] = "k3";
  hv_CameraParamAreaScanPolynomial[4] = "p1";
  hv_CameraParamAreaScanPolynomial[5] = "p2";
  hv_CameraParamAreaScanPolynomial[6] = "sx";
  hv_CameraParamAreaScanPolynomial[7] = "sy";
  hv_CameraParamAreaScanPolynomial[8] = "cx";
  hv_CameraParamAreaScanPolynomial[9] = "cy";
  hv_CameraParamAreaScanPolynomial[10] = "image_width";
  hv_CameraParamAreaScanPolynomial[11] = "image_height";
  hv_CameraParamAreaScanTelecentricDivision.Clear();
  hv_CameraParamAreaScanTelecentricDivision[0] = "magnification";
  hv_CameraParamAreaScanTelecentricDivision[1] = "kappa";
  hv_CameraParamAreaScanTelecentricDivision[2] = "sx";
  hv_CameraParamAreaScanTelecentricDivision[3] = "sy";
  hv_CameraParamAreaScanTelecentricDivision[4] = "cx";
  hv_CameraParamAreaScanTelecentricDivision[5] = "cy";
  hv_CameraParamAreaScanTelecentricDivision[6] = "image_width";
  hv_CameraParamAreaScanTelecentricDivision[7] = "image_height";
  hv_CameraParamAreaScanTelecentricPolynomial.Clear();
  hv_CameraParamAreaScanTelecentricPolynomial[0] = "magnification";
  hv_CameraParamAreaScanTelecentricPolynomial[1] = "k1";
  hv_CameraParamAreaScanTelecentricPolynomial[2] = "k2";
  hv_CameraParamAreaScanTelecentricPolynomial[3] = "k3";
  hv_CameraParamAreaScanTelecentricPolynomial[4] = "p1";
  hv_CameraParamAreaScanTelecentricPolynomial[5] = "p2";
  hv_CameraParamAreaScanTelecentricPolynomial[6] = "sx";
  hv_CameraParamAreaScanTelecentricPolynomial[7] = "sy";
  hv_CameraParamAreaScanTelecentricPolynomial[8] = "cx";
  hv_CameraParamAreaScanTelecentricPolynomial[9] = "cy";
  hv_CameraParamAreaScanTelecentricPolynomial[10] = "image_width";
  hv_CameraParamAreaScanTelecentricPolynomial[11] = "image_height";
  hv_CameraParamAreaScanTiltDivision.Clear();
  hv_CameraParamAreaScanTiltDivision[0] = "focus";
  hv_CameraParamAreaScanTiltDivision[1] = "kappa";
  hv_CameraParamAreaScanTiltDivision[2] = "image_plane_dist";
  hv_CameraParamAreaScanTiltDivision[3] = "tilt";
  hv_CameraParamAreaScanTiltDivision[4] = "rot";
  hv_CameraParamAreaScanTiltDivision[5] = "sx";
  hv_CameraParamAreaScanTiltDivision[6] = "sy";
  hv_CameraParamAreaScanTiltDivision[7] = "cx";
  hv_CameraParamAreaScanTiltDivision[8] = "cy";
  hv_CameraParamAreaScanTiltDivision[9] = "image_width";
  hv_CameraParamAreaScanTiltDivision[10] = "image_height";
  hv_CameraParamAreaScanTiltPolynomial.Clear();
  hv_CameraParamAreaScanTiltPolynomial[0] = "focus";
  hv_CameraParamAreaScanTiltPolynomial[1] = "k1";
  hv_CameraParamAreaScanTiltPolynomial[2] = "k2";
  hv_CameraParamAreaScanTiltPolynomial[3] = "k3";
  hv_CameraParamAreaScanTiltPolynomial[4] = "p1";
  hv_CameraParamAreaScanTiltPolynomial[5] = "p2";
  hv_CameraParamAreaScanTiltPolynomial[6] = "image_plane_dist";
  hv_CameraParamAreaScanTiltPolynomial[7] = "tilt";
  hv_CameraParamAreaScanTiltPolynomial[8] = "rot";
  hv_CameraParamAreaScanTiltPolynomial[9] = "sx";
  hv_CameraParamAreaScanTiltPolynomial[10] = "sy";
  hv_CameraParamAreaScanTiltPolynomial[11] = "cx";
  hv_CameraParamAreaScanTiltPolynomial[12] = "cy";
  hv_CameraParamAreaScanTiltPolynomial[13] = "image_width";
  hv_CameraParamAreaScanTiltPolynomial[14] = "image_height";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision.Clear();
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[0] = "focus";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[1] = "kappa";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[2] = "tilt";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[3] = "rot";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[4] = "sx";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[5] = "sy";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[6] = "cx";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[7] = "cy";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[8] = "image_width";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[9] = "image_height";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial.Clear();
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[0] = "focus";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[1] = "k1";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[2] = "k2";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[3] = "k3";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[4] = "p1";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[5] = "p2";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[6] = "tilt";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[7] = "rot";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[8] = "sx";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[9] = "sy";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[10] = "cx";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[11] = "cy";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[12] = "image_width";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[13] = "image_height";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision.Clear();
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[0] = "magnification";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[1] = "kappa";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[2] = "tilt";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[3] = "rot";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[4] = "sx";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[5] = "sy";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[6] = "cx";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[7] = "cy";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[8] = "image_width";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[9] = "image_height";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial.Clear();
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[0] = "magnification";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[1] = "k1";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[2] = "k2";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[3] = "k3";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[4] = "p1";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[5] = "p2";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[6] = "tilt";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[7] = "rot";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[8] = "sx";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[9] = "sy";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[10] = "cx";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[11] = "cy";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[12] = "image_width";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[13] = "image_height";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision.Clear();
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[0] = "magnification";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[1] = "kappa";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[2] = "image_plane_dist";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[3] = "tilt";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[4] = "rot";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[5] = "sx";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[6] = "sy";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[7] = "cx";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[8] = "cy";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[9] = "image_width";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[10] = "image_height";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial.Clear();
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[0] = "magnification";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[1] = "k1";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[2] = "k2";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[3] = "k3";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[4] = "p1";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[5] = "p2";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[6] = "image_plane_dist";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[7] = "tilt";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[8] = "rot";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[9] = "sx";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[10] = "sy";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[11] = "cx";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[12] = "cy";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[13] = "image_width";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[14] = "image_height";
  hv_CameraParamAreaScanHypercentricDivision.Clear();
  hv_CameraParamAreaScanHypercentricDivision[0] = "focus";
  hv_CameraParamAreaScanHypercentricDivision[1] = "kappa";
  hv_CameraParamAreaScanHypercentricDivision[2] = "sx";
  hv_CameraParamAreaScanHypercentricDivision[3] = "sy";
  hv_CameraParamAreaScanHypercentricDivision[4] = "cx";
  hv_CameraParamAreaScanHypercentricDivision[5] = "cy";
  hv_CameraParamAreaScanHypercentricDivision[6] = "image_width";
  hv_CameraParamAreaScanHypercentricDivision[7] = "image_height";
  hv_CameraParamAreaScanHypercentricPolynomial.Clear();
  hv_CameraParamAreaScanHypercentricPolynomial[0] = "focus";
  hv_CameraParamAreaScanHypercentricPolynomial[1] = "k1";
  hv_CameraParamAreaScanHypercentricPolynomial[2] = "k2";
  hv_CameraParamAreaScanHypercentricPolynomial[3] = "k3";
  hv_CameraParamAreaScanHypercentricPolynomial[4] = "p1";
  hv_CameraParamAreaScanHypercentricPolynomial[5] = "p2";
  hv_CameraParamAreaScanHypercentricPolynomial[6] = "sx";
  hv_CameraParamAreaScanHypercentricPolynomial[7] = "sy";
  hv_CameraParamAreaScanHypercentricPolynomial[8] = "cx";
  hv_CameraParamAreaScanHypercentricPolynomial[9] = "cy";
  hv_CameraParamAreaScanHypercentricPolynomial[10] = "image_width";
  hv_CameraParamAreaScanHypercentricPolynomial[11] = "image_height";
  hv_CameraParamLinesScan.Clear();
  hv_CameraParamLinesScan[0] = "focus";
  hv_CameraParamLinesScan[1] = "kappa";
  hv_CameraParamLinesScan[2] = "sx";
  hv_CameraParamLinesScan[3] = "sy";
  hv_CameraParamLinesScan[4] = "cx";
  hv_CameraParamLinesScan[5] = "cy";
  hv_CameraParamLinesScan[6] = "image_width";
  hv_CameraParamLinesScan[7] = "image_height";
  hv_CameraParamLinesScan[8] = "vx";
  hv_CameraParamLinesScan[9] = "vy";
  hv_CameraParamLinesScan[10] = "vz";
  //Legacy parameter names
  hv_CameraParamAreaScanTiltDivisionLegacy.Clear();
  hv_CameraParamAreaScanTiltDivisionLegacy[0] = "focus";
  hv_CameraParamAreaScanTiltDivisionLegacy[1] = "kappa";
  hv_CameraParamAreaScanTiltDivisionLegacy[2] = "tilt";
  hv_CameraParamAreaScanTiltDivisionLegacy[3] = "rot";
  hv_CameraParamAreaScanTiltDivisionLegacy[4] = "sx";
  hv_CameraParamAreaScanTiltDivisionLegacy[5] = "sy";
  hv_CameraParamAreaScanTiltDivisionLegacy[6] = "cx";
  hv_CameraParamAreaScanTiltDivisionLegacy[7] = "cy";
  hv_CameraParamAreaScanTiltDivisionLegacy[8] = "image_width";
  hv_CameraParamAreaScanTiltDivisionLegacy[9] = "image_height";
  hv_CameraParamAreaScanTiltPolynomialLegacy.Clear();
  hv_CameraParamAreaScanTiltPolynomialLegacy[0] = "focus";
  hv_CameraParamAreaScanTiltPolynomialLegacy[1] = "k1";
  hv_CameraParamAreaScanTiltPolynomialLegacy[2] = "k2";
  hv_CameraParamAreaScanTiltPolynomialLegacy[3] = "k3";
  hv_CameraParamAreaScanTiltPolynomialLegacy[4] = "p1";
  hv_CameraParamAreaScanTiltPolynomialLegacy[5] = "p2";
  hv_CameraParamAreaScanTiltPolynomialLegacy[6] = "tilt";
  hv_CameraParamAreaScanTiltPolynomialLegacy[7] = "rot";
  hv_CameraParamAreaScanTiltPolynomialLegacy[8] = "sx";
  hv_CameraParamAreaScanTiltPolynomialLegacy[9] = "sy";
  hv_CameraParamAreaScanTiltPolynomialLegacy[10] = "cx";
  hv_CameraParamAreaScanTiltPolynomialLegacy[11] = "cy";
  hv_CameraParamAreaScanTiltPolynomialLegacy[12] = "image_width";
  hv_CameraParamAreaScanTiltPolynomialLegacy[13] = "image_height";
  hv_CameraParamAreaScanTelecentricDivisionLegacy.Clear();
  hv_CameraParamAreaScanTelecentricDivisionLegacy[0] = "focus";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[1] = "kappa";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[2] = "sx";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[3] = "sy";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[4] = "cx";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[5] = "cy";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[6] = "image_width";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[7] = "image_height";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy.Clear();
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[0] = "focus";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[1] = "k1";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[2] = "k2";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[3] = "k3";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[4] = "p1";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[5] = "p2";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[6] = "sx";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[7] = "sy";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[8] = "cx";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[9] = "cy";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[10] = "image_width";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[11] = "image_height";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy.Clear();
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[0] = "focus";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[1] = "kappa";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[2] = "tilt";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[3] = "rot";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[4] = "sx";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[5] = "sy";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[6] = "cx";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[7] = "cy";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[8] = "image_width";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[9] = "image_height";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy.Clear();
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[0] = "focus";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[1] = "k1";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[2] = "k2";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[3] = "k3";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[4] = "p1";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[5] = "p2";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[6] = "tilt";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[7] = "rot";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[8] = "sx";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[9] = "sy";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[10] = "cx";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[11] = "cy";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[12] = "image_width";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[13] = "image_height";
  //
  //If the camera type is passed in CameraParam
  if (0 != (HTuple((hv_CameraParam.TupleLength())==1).TupleAnd(HTuple(hv_CameraParam[0]).TupleIsString())))
  {
    (*hv_CameraType) = ((const HTuple&)hv_CameraParam)[0];
    if (0 != ((*hv_CameraType)==HTuple("area_scan_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_telecentric_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTelecentricDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_telecentric_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTelecentricPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_image_side_telecentric_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanImageSideTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_image_side_telecentric_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_bilateral_telecentric_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanBilateralTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_bilateral_telecentric_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_object_side_telecentric_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanObjectSideTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_object_side_telecentric_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_hypercentric_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanHypercentricDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_hypercentric_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanHypercentricPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("line_scan")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamLinesScan);
    }
    else
    {
      throw HException(("Unknown camera type '"+(*hv_CameraType))+"' passed in CameraParam.");
    }
    return;
  }
  //
  //If the camera parameters are passed in CameraParam
  if (0 != ((HTuple(hv_CameraParam[0]).TupleIsString()).TupleNot()))
  {
    //Format of camera parameters for HALCON 12 and earlier
    switch ((hv_CameraParam.TupleLength()).I())
    {
      //
      //Area Scan
    case 8:
      //CameraType: 'area_scan_division' or 'area_scan_telecentric_division'
      if (0 != (HTuple(hv_CameraParam[0])!=0.0))
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanDivision;
        (*hv_CameraType) = "area_scan_division";
      }
      else
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanTelecentricDivisionLegacy;
        (*hv_CameraType) = "area_scan_telecentric_division";
      }
      break;
    case 10:
      //CameraType: 'area_scan_tilt_division' or 'area_scan_telecentric_tilt_division'
      if (0 != (HTuple(hv_CameraParam[0])!=0.0))
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanTiltDivisionLegacy;
        (*hv_CameraType) = "area_scan_tilt_division";
      }
      else
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy;
        (*hv_CameraType) = "area_scan_tilt_bilateral_telecentric_division";
      }
      break;
    case 12:
      //CameraType: 'area_scan_polynomial' or 'area_scan_telecentric_polynomial'
      if (0 != (HTuple(hv_CameraParam[0])!=0.0))
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanPolynomial;
        (*hv_CameraType) = "area_scan_polynomial";
      }
      else
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanTelecentricPolynomialLegacy;
        (*hv_CameraType) = "area_scan_telecentric_polynomial";
      }
      break;
    case 14:
      //CameraType: 'area_scan_tilt_polynomial' or 'area_scan_telecentric_tilt_polynomial'
      if (0 != (HTuple(hv_CameraParam[0])!=0.0))
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanTiltPolynomialLegacy;
        (*hv_CameraType) = "area_scan_tilt_polynomial";
      }
      else
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy;
        (*hv_CameraType) = "area_scan_tilt_bilateral_telecentric_polynomial";
      }
      break;
      //
      //Line Scan
    case 11:
      //CameraType: 'line_scan'
      (*hv_ParamNames) = hv_CameraParamLinesScan;
      (*hv_CameraType) = "line_scan";
      break;
    default:
      throw HException("Wrong number of values in CameraParam.");
    }
  }
  else
  {
    //Format of camera parameters since HALCON 13
    (*hv_CameraType) = ((const HTuple&)hv_CameraParam)[0];
    if (0 != ((*hv_CameraType)==HTuple("area_scan_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=9))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=13))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_telecentric_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=9))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTelecentricDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_telecentric_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=13))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTelecentricPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=12))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=16))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_image_side_telecentric_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=11))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanImageSideTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_image_side_telecentric_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=15))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_bilateral_telecentric_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=11))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanBilateralTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_bilateral_telecentric_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=15))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_object_side_telecentric_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=12))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanObjectSideTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_object_side_telecentric_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=16))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_hypercentric_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=9))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanHypercentricDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_hypercentric_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=13))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanHypercentricPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("line_scan")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=12))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamLinesScan);
    }
    else
    {
      throw HException("Unknown camera type in CameraParam.");
    }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Describe and calculate user-defined features to be used in conjunction with the calculate_feature_set procedure library. 
void get_custom_features (HObject ho_Region, HObject ho_Image, HTuple hv_CurrentName, 
    HTuple hv_Mode, HTuple *hv_Output)
{

  // Local iconic variables
  HObject  ho_RegionSelected, ho_Contours, ho_ContoursSelected;
  HObject  ho_ContoursSplit;

  // Local control variables
  HTuple  hv_TmpResults, hv_Name, hv_Groups, hv_Feature;
  HTuple  hv_NumRegions, hv_I, hv_NumContours, hv_NumLines;
  HTuple  hv_J, hv_NumSplit;

  //
  //This procedure can be used to extend the functionality
  //of the calculate_feature_set procedure library by
  //user-defined features.
  //
  //Instructions:
  //
  //1. Find the template block at the beginning the procedure
  //(marked by comments) and duplicate it.
  //
  //2. In the copy edit the two marked areas as follows:
  //
  //2.1. Feature name and groups:
  //Assign a unique identifier for your feature to the variable "Name".
  //Then, assign the groups that you want your feature to belong to
  //to the variable "Groups".
  //
  //2.2. Feature calculation:
  //Enter the code that calculates your feature and
  //assign the result to the variable "Feature".
  //
  //3. Test
  //Use the "test_feature" procedure to check,
  //if the feature is calculated correctly.
  //If the procedure throws an exception,
  //maybe the order of the feature vector is wrong
  //(See note below).
  //
  //4. Integration
  //- Save your modified procedure get_custom_features.hdvp
  //  to a location of your choice.
  //  (We recommend not to overwrite the template.)
  //- Make sure, that your version of get_custom_procedures
  //  is included in the procedure directories of HDevelop.
  //  (Choose Procedures -> Manage Procedures -> Directories -> Add from the HDevelop menu bar.)
  //
  //Note:
  //The current implementation supports region arrays as input.
  //In that case, multi-dimensional feature vectors are simply concatenated.
  //Example: The feature 'center' has two dimensions [Row,Column].
  //If an array of three regions is passed, the correct order of the "Feature" variable is
  //[Row1, Column1, Row2, Column2, Row3, Column3].
  //
  hv_TmpResults = HTuple();
  //************************************************
  //************************************************
  //**** Copy the following template block     *****
  //**** and edit the two marked code sections *****
  //**** to add user-defined features          *****
  //************************************************
  //************************************************
  //
  //***************************************
  //*********** TEMPLATE BLOCK ************
  //***************************************
  //
  //********************************************************************
  //** Section 1:
  //** Enter unique feature name and groups to which it belongs here ***
  hv_Name = "custom_feature_numlines";
  hv_Groups = "custom";
  //** Enter unique feature name and groups above this line ************
  //********************************************************************
  if (0 != (hv_Name==hv_CurrentName))
  {
    //******************************************************
    //** Section 2:
    //** Enter code to calculate feature here **************
    hv_Feature = HTuple();
    CountObj(ho_Region, &hv_NumRegions);
    {
    HTuple end_val69 = hv_NumRegions;
    HTuple step_val69 = 1;
    for (hv_I=1; hv_I.Continue(end_val69, step_val69); hv_I += step_val69)
    {
      SelectObj(ho_Region, &ho_RegionSelected, hv_I);
      GenContourRegionXld(ho_RegionSelected, &ho_Contours, "border");
      CountObj(ho_Contours, &hv_NumContours);
      hv_NumLines = 0;
      {
      HTuple end_val74 = hv_NumContours;
      HTuple step_val74 = 1;
      for (hv_J=1; hv_J.Continue(end_val74, step_val74); hv_J += step_val74)
      {
        SelectObj(ho_Contours, &ho_ContoursSelected, hv_J);
        SegmentContoursXld(ho_ContoursSelected, &ho_ContoursSplit, "lines", 5, 2, 
            1);
        CountObj(ho_ContoursSplit, &hv_NumSplit);
        hv_NumLines += hv_NumSplit;
      }
      }
      hv_Feature = hv_Feature.TupleConcat(hv_NumLines);
    }
    }
    //** Enter code to calculate feature above this line ***
    //******************************************************
    append_length_or_values(hv_Mode, hv_Feature, hv_TmpResults, &hv_TmpResults);
  }
  append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_TmpResults, 
      &hv_TmpResults);
  //
  //************************************
  //****** END OF TEMPLATE BLOCK *******
  //************************************
  //
  (*hv_Output) = hv_TmpResults;
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Display and return the classified images. 
void get_dl_classifier_image_results (HObject *ho_Images, HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_PredictedClasses, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_WindowHandle)
{

  // Local iconic variables
  HObject  ho_Image;

  // Local control variables
  HTuple  hv_LabelSelection, hv_PredictedClassSelection;
  HTuple  hv_GlobalSelection, hv_DisplayImages, hv_GenParamIndex;
  HTuple  hv_Mask, hv_ImageIndex, hv_Label, hv_PredictedClass;
  HTuple  hv_Text, hv_Color;

  //This procedure can be used to visualize classified
  //ImageFiles selected according to the specifications
  //given with GenParamName and GenParamValue.
  //
  //Set parameter defaults.
  hv_LabelSelection = "all";
  hv_PredictedClassSelection = "all";
  hv_GlobalSelection = "erroneously_classified";
  hv_DisplayImages = "true";
  //
  //Check if number of elements in
  //GenParamName and GenParamValue is equal.
  if (0 != ((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength())))
  {
    throw HException("Number of generic parameter names does not match number of generic parameter values.");
  }
  //
  //Parse generic parameters.
  {
  HTuple end_val17 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val17 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val17, step_val17); hv_GenParamIndex += step_val17)
  {
    if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("label_selection")))
    {
      //Set 'label_selection'.
      hv_LabelSelection = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("predicted_class_selection")))
    {
      //Set 'predicted_class_selection'.
      hv_PredictedClassSelection = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("global_selection")))
    {
      //Set 'global_selection'.
      hv_GlobalSelection = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_images")))
    {
      //Set 'display_images'.
      hv_DisplayImages = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //Filter data according to LabelSelection.
  if (0 != (hv_LabelSelection!=HTuple("all")))
  {
    hv_Mask = hv_GroundTruthLabels.TupleEqualElem(hv_LabelSelection);
    if (0 != ((hv_Mask.TupleSum())==0))
    {
      throw HException(("LabelSelection '"+hv_LabelSelection)+"' not found in GroundTruthLabels.");
    }
    hv_ImageFiles = hv_ImageFiles.TupleSelectMask(hv_Mask);
    hv_GroundTruthLabels = hv_GroundTruthLabels.TupleSelectMask(hv_Mask);
    hv_PredictedClasses = hv_PredictedClasses.TupleSelectMask(hv_Mask);
  }
  //
  //Filter data according to PredictedClassSelection.
  if (0 != (hv_PredictedClassSelection!=HTuple("all")))
  {
    hv_Mask = hv_PredictedClasses.TupleEqualElem(hv_PredictedClassSelection);
    if (0 != ((hv_Mask.TupleSum())==0))
    {
      throw HException(("PredictedClassSelection '"+hv_PredictedClassSelection)+"' not found in PredictedClasses.");
    }
    hv_ImageFiles = hv_ImageFiles.TupleSelectMask(hv_Mask);
    hv_GroundTruthLabels = hv_GroundTruthLabels.TupleSelectMask(hv_Mask);
    hv_PredictedClasses = hv_PredictedClasses.TupleSelectMask(hv_Mask);
  }
  //
  //Filter data according to GlobalSelection.
  if (0 != (hv_GlobalSelection!=HTuple("all")))
  {
    hv_Mask = hv_GroundTruthLabels.TupleEqualElem(hv_PredictedClasses);
    if (0 != (hv_GlobalSelection==HTuple("erroneously_classified")))
    {
      //Flip the mask.
      hv_Mask = (hv_Mask-1).TupleAbs();
    }
    hv_ImageFiles = hv_ImageFiles.TupleSelectMask(hv_Mask);
    hv_GroundTruthLabels = hv_GroundTruthLabels.TupleSelectMask(hv_Mask);
    hv_PredictedClasses = hv_PredictedClasses.TupleSelectMask(hv_Mask);
  }
  //
  if (0 != (hv_DisplayImages==HTuple("true")))
  {
    //Loop over the images.
    GenEmptyObj(&(*ho_Images));
    {
    HTuple end_val72 = (hv_ImageFiles.TupleLength())-1;
    HTuple step_val72 = 1;
    for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val72, step_val72); hv_ImageIndex += step_val72)
    {
      //
      //Concatenate selected images.
      ReadImage(&ho_Image, HTuple(hv_ImageFiles[hv_ImageIndex]));
      ConcatObj((*ho_Images), ho_Image, &(*ho_Images));
      //
      hv_Label = HTuple(hv_GroundTruthLabels[hv_ImageIndex]);
      hv_PredictedClass = HTuple(hv_PredictedClasses[hv_ImageIndex]);
      //
      hv_Text[0] = (("Image "+(hv_ImageIndex+1))+"/")+(hv_ImageFiles.TupleLength());
      hv_Text[1] = "Label: "+hv_Label;
      hv_Text[2] = "Predicted Class: "+hv_PredictedClass;
      if (0 != (hv_Label==hv_PredictedClass))
      {
        hv_Color = "forest green";
      }
      else
      {
        hv_Color = "red";
      }
      //
      //Display the image.
      dev_resize_window_fit_image(ho_Image, 0, 0, -1, -1);
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", (HTuple("black").Append("black")).TupleConcat(hv_Color), 
            "box_color", "#ffffffaa");
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
            "bottom", "right", "black", "box_color", "#ffffffaa");
      // stop(...); only in hdevelop
    }
    }
  }
  else
  {
    ReadImage(&(*ho_Images), hv_ImageFiles);
  }
  return;
}

// Chapter: 3D Object Model / Transformations
void get_extent_by_axis (HTuple hv_OM3D, HTuple hv_XExtent, HTuple hv_YExtent, HTuple hv_ZExtent, 
    HTuple *hv_XExtentOut, HTuple *hv_YExtentOut, HTuple *hv_ZExtentOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_BB, hv_Index;

  (*hv_XExtentOut) = hv_XExtent;
  (*hv_YExtentOut) = hv_YExtent;
  (*hv_ZExtentOut) = hv_ZExtent;
  GetObjectModel3dParams(hv_OM3D, "bounding_box1", &hv_BB);
  {
  HTuple end_val4 = ((hv_BB.TupleLength())/6)-1;
  HTuple step_val4 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val4, step_val4); hv_Index += step_val4)
  {
    (*hv_XExtentOut) = ((*hv_XExtentOut).TupleConcat(HTuple(hv_BB[hv_Index*6]))).TupleConcat(HTuple(hv_BB[(hv_Index*6)+3]));
    (*hv_YExtentOut) = ((*hv_YExtentOut).TupleConcat(HTuple(hv_BB[(hv_Index*6)+1]))).TupleConcat(HTuple(hv_BB[(hv_Index*6)+4]));
    (*hv_ZExtentOut) = ((*hv_ZExtentOut).TupleConcat(HTuple(hv_BB[(hv_Index*6)+2]))).TupleConcat(HTuple(hv_BB[(hv_Index*6)+5]));
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Returns the length of the feature vector for each feature name. 
void get_feature_lengths (HTuple hv_FeatureNames, HTuple *hv_Lengths)
{

  // Local iconic variables
  HObject  ho_Region, ho_Image;

  //
  //Calculate the lengths of the feature vectors of
  //the features in FeatureNames.
  //
  gen_dummy_objects(&ho_Region, &ho_Image);
  get_features(ho_Region, ho_Image, hv_FeatureNames, "get_lengths", &(*hv_Lengths));
  return;
}

// Chapter: Classification / Misc
// Short Description: Returns a list of feature names that belong to the feature groups given in GroupNames. 
void get_feature_names (HTuple hv_GroupNames, HTuple *hv_Names)
{

  // Local iconic variables
  HObject  ho_Region, ho_Image;

  //
  //Return all features that belong to
  //at least one of the groups in GroupNames
  //
  gen_dummy_objects(&ho_Region, &ho_Image);
  get_features(ho_Region, ho_Image, hv_GroupNames, "get_names", &(*hv_Names));
  return;
}

// Chapter: Classification / Misc
// Short Description: This procedure contains all relevant information about the supported features. 
void get_features (HObject ho_Region, HObject ho_Image, HTuple hv_Namelist, HTuple hv_Mode, 
    HTuple *hv_Output)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_EmptyRegionResult, hv_AccumulatedResults;
  HTuple  hv_CustomResults, hv_NumRegions, hv_ImageWidth;
  HTuple  hv_ImageHeight, hv_I, hv_CurrentName, hv_Name, hv_Groups;
  HTuple  hv_Feature, hv__, hv_ExtendedResults, hv_Row1, hv_Column1;
  HTuple  hv_Row2, hv_Column2, hv_Ra, hv_Rb, hv_Phi, hv_Distance;
  HTuple  hv_Sigma, hv_Roundness, hv_Sides, hv_NumConnected;
  HTuple  hv_NumHoles, hv_Diameter, hv_Row, hv_Column, hv_Anisometry;
  HTuple  hv_Bulkiness, hv_StructureFactor, hv_Length1, hv_Length2;
  HTuple  hv_ContLength, hv_AreaHoles, hv_Area, hv_Min, hv_Max;
  HTuple  hv_Range, hv_Mean, hv_Deviation, hv_Entropy, hv_Anisotropy;
  HTuple  hv_Size, hv_NumBins, hv_NameRegExp, hv_Names, hv_NumPyramids;
  HTuple  hv_Energy, hv_Correlation, hv_Homogeneity, hv_Contrast;
  HTuple  hv_Index, hv_Width, hv_Height, hv_Projection, hv_Start;
  HTuple  hv_Histo, hv_BinSize;

  //*********************************************************
  //Feature procedure
  //Contains the names, properties and calculation of
  //all supproted features.
  //It consists of similar blocks for each feature.
  //
  //If you like to add your own features, please use
  //the external procedure get_custom_features.hdvp
  //in the HALCON procedures/templates directory.
  //*********************************************************
  //
  //Insert location of your custom procedure here
  //
  GetSystem("empty_region_result", &hv_EmptyRegionResult);
  SetSystem("empty_region_result", "true");
  hv_AccumulatedResults = HTuple();
  hv_CustomResults = HTuple();
  CountObj(ho_Region, &hv_NumRegions);
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  //
  {
  HTuple end_val20 = (hv_Namelist.TupleLength())-1;
  HTuple step_val20 = 1;
  for (hv_I=0; hv_I.Continue(end_val20, step_val20); hv_I += step_val20)
  {
    hv_CurrentName = HTuple(hv_Namelist[hv_I]);
    //
    get_custom_features(ho_Region, ho_Image, hv_CurrentName, hv_Mode, &hv_CustomResults);
    hv_AccumulatedResults = hv_AccumulatedResults.TupleConcat(hv_CustomResults);
    //
    //
    //************************************
    //HALCON REGION FEATURES
    //************************************
    //
    //************************************
    //BASIC
    //************************************
    //** area ***
    hv_Name = "area";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      AreaCenter(ho_Region, &hv_Feature, &hv__, &hv__);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** width ***
    hv_Name = "width";
    hv_Groups = "region";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle1(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_Feature = (hv_Column2-hv_Column1)+1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** height ***
    hv_Name = "height";
    hv_Groups = "region";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle1(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_Feature = (hv_Row2-hv_Row1)+1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** ra ***
    hv_Name = "ra";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxis(ho_Region, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Ra;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** rb ***
    hv_Name = "rb";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxis(ho_Region, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Rb;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** phi ***
    hv_Name = "phi";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxis(ho_Region, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Phi;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** roundness ***
    hv_Name = "roundness";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Roundness(ho_Region, &hv_Distance, &hv_Sigma, &hv_Roundness, &hv_Sides);
      hv_Feature = hv_Roundness;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** num_sides ***
    hv_Name = "num_sides";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Roundness(ho_Region, &hv_Distance, &hv_Sigma, &hv_Roundness, &hv_Sides);
      hv_Feature = hv_Sides;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** num_connected ***
    hv_Name = "num_connected";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      ConnectAndHoles(ho_Region, &hv_NumConnected, &hv_NumHoles);
      hv_Feature = hv_NumConnected;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** num_holes ***
    hv_Name = "num_holes";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      ConnectAndHoles(ho_Region, &hv_NumConnected, &hv_NumHoles);
      hv_Feature = hv_NumHoles;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** area_holes ***
    hv_Name = "area_holes";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      AreaHoles(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** max_diameter ***
    hv_Name = "max_diameter";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      DiameterRegion(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2, &hv_Diameter);
      hv_Feature = hv_Diameter;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** orientation ***
    hv_Name = "orientation";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      OrientationRegion(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //SHAPE
    //************************************
    //
    //************************************
    //** outer_radius ***
    hv_Name = "outer_radius";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestCircle(ho_Region, &hv_Row, &hv_Column, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** inner_radius ***
    hv_Name = "inner_radius";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      InnerCircle(ho_Region, &hv_Row, &hv_Column, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** inner_width ***
    hv_Name = "inner_width";
    hv_Groups = "region";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      InnerRectangle1(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_Feature = (hv_Column2-hv_Column1)+1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** inner_height ***
    hv_Name = "inner_height";
    hv_Groups = "region";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      InnerRectangle1(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_Feature = (hv_Row2-hv_Row1)+1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** circularity ***
    hv_Name = "circularity";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Circularity(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** compactness ***
    hv_Name = "compactness";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Compactness(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** convexity ***
    hv_Name = "convexity";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Convexity(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** rectangularity ***
    hv_Name = "rectangularity";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Rectangularity(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** anisometry ***
    hv_Name = "anisometry";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Eccentricity(ho_Region, &hv_Anisometry, &hv_Bulkiness, &hv_StructureFactor);
      hv_Feature = hv_Anisometry;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** bulkiness ***
    hv_Name = "bulkiness";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Eccentricity(ho_Region, &hv_Anisometry, &hv_Bulkiness, &hv_StructureFactor);
      hv_Feature = hv_Bulkiness;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** struct_factor ***
    hv_Name = "struct_factor";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Eccentricity(ho_Region, &hv_Anisometry, &hv_Bulkiness, &hv_StructureFactor);
      hv_Feature = hv_StructureFactor;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** dist_mean ***
    hv_Name = "dist_mean";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Roundness(ho_Region, &hv_Distance, &hv_Sigma, &hv_Roundness, &hv_Sides);
      hv_Feature = hv_Distance;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** dist_deviation ***
    hv_Name = "dist_deviation";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Roundness(ho_Region, &hv_Distance, &hv_Sigma, &hv_Roundness, &hv_Sides);
      hv_Feature = hv_Sigma;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** euler_number ***
    hv_Name = "euler_number";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EulerNumber(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** rect2_phi ***
    hv_Name = "rect2_phi";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle2(ho_Region, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, &hv_Length2);
      hv_Feature = hv_Phi;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** rect2_len1 ***
    hv_Name = "rect2_len1";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle2(ho_Region, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, &hv_Length2);
      hv_Feature = hv_Length1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** rect2_len2 ***
    hv_Name = "rect2_len2";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle2(ho_Region, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, &hv_Length2);
      hv_Feature = hv_Length2;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** contlength ***
    hv_Name = "contlength";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Contlength(ho_Region, &hv_ContLength);
      hv_Feature = hv_ContLength;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //REGION FEATURES
    //************************************
    //MISC
    //************************************
    //** porosity ***
    hv_Name = "porosity";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      AreaHoles(ho_Region, &hv_AreaHoles);
      AreaCenter(ho_Region, &hv_Area, &hv_Row, &hv_Column);
      if (0 != (hv_Area==0))
      {
        hv_Feature = 0.0;
      }
      else
      {
        hv_Feature = (hv_AreaHoles.TupleReal())/(hv_Area+hv_AreaHoles);
      }
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //HALCON GRAY VALUE FEATURES
    //************************************
    //BASIC
    //************************************
    //
    //** gray_area ***
    hv_Name = "gray_area";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      AreaCenterGray(ho_Region, ho_Image, &hv_Area, &hv_Row, &hv_Column);
      hv_Feature = hv_Area;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_ra ***
    hv_Name = "gray_ra";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxisGray(ho_Region, ho_Image, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Ra;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_rb ***
    hv_Name = "gray_rb";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxisGray(ho_Region, ho_Image, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Rb;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_phi ***
    hv_Name = "gray_phi";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxisGray(ho_Region, ho_Image, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Phi;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_min ***
    hv_Name = "gray_min";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      MinMaxGray(ho_Region, ho_Image, 0, &hv_Min, &hv_Max, &hv_Range);
      hv_Feature = hv_Min;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_max ***
    hv_Name = "gray_max";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      MinMaxGray(ho_Region, ho_Image, 0, &hv_Min, &hv_Max, &hv_Range);
      hv_Feature = hv_Max;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_range ***
    hv_Name = "gray_range";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      MinMaxGray(ho_Region, ho_Image, 0, &hv_Min, &hv_Max, &hv_Range);
      hv_Feature = hv_Range;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //TEXTURE
    //************************************
    //
    //************************************
    //** gray_mean ***
    hv_Name = "gray_mean";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Intensity(ho_Region, ho_Image, &hv_Mean, &hv_Deviation);
      hv_Feature = hv_Mean;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_deviation ***
    hv_Name = "gray_deviation";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Intensity(ho_Region, ho_Image, &hv_Mean, &hv_Deviation);
      hv_Feature = hv_Deviation;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_plane_deviation ***
    hv_Name = "gray_plane_deviation";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      PlaneDeviation(ho_Region, ho_Image, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_anisotropy ***
    hv_Name = "gray_anisotropy";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EntropyGray(ho_Region, ho_Image, &hv_Entropy, &hv_Anisotropy);
      hv_Feature = hv_Anisotropy;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_entropy ***
    hv_Name = "gray_entropy";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EntropyGray(ho_Region, ho_Image, &hv_Entropy, &hv_Anisotropy);
      hv_Feature = hv_Entropy;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_hor_proj ***
    hv_Name = "gray_hor_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Size = 20;
      calc_feature_gray_proj(ho_Region, ho_Image, "hor", hv_Size, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_vert_proj ***
    hv_Name = "gray_vert_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Size = 20;
      calc_feature_gray_proj(ho_Region, ho_Image, "vert", hv_Size, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_hor_proj_histo ***
    hv_Name = "gray_hor_proj_histo";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Size = 20;
      calc_feature_gray_proj(ho_Region, ho_Image, "hor_histo", hv_Size, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_vert_proj_histo ***
    hv_Name = "gray_vert_proj_histo";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Size = 20;
      calc_feature_gray_proj(ho_Region, ho_Image, "vert_histo", hv_Size, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** grad_dir_histo ***
    hv_Name = "grad_dir_histo";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_NumBins = 20;
      calc_feature_grad_dir_histo(ho_Region, ho_Image, hv_NumBins, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** edge_density ***
    hv_Name = "edge_density";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_edge_density(ho_Region, ho_Image, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** edge_density_histogram ***
    hv_Name = "edge_density_histogram";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_NumBins = 4;
      calc_feature_edge_density_histogram(ho_Region, ho_Image, hv_NumBins, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** edge_density_pyramid ***
    hv_NameRegExp = "edge_density_pyramid_([234])";
    hv_Names = HTuple("edge_density_pyramid_")+HTuple::TupleGenSequence(2,4,1);
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_CurrentName.TupleRegexpTest(hv_NameRegExp)))
    {
      //** Calculate feature ***
      hv_NumPyramids = (hv_CurrentName.TupleRegexpMatch(hv_NameRegExp)).TupleNumber();
      calc_feature_pyramid(ho_Region, ho_Image, "edge_density", hv_NumPyramids, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups_pyramid(hv_Mode, hv_Groups, hv_CurrentName, hv_Names, 
        hv_NameRegExp, hv_AccumulatedResults, &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** edge_density_histogram_pyramid ***
    hv_NameRegExp = "edge_density_histogram_pyramid_([234])";
    hv_Names = HTuple("edge_density_histogram_pyramid_")+HTuple::TupleGenSequence(2,4,1);
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_CurrentName.TupleRegexpTest(hv_NameRegExp)))
    {
      //** Calculate feature ***
      hv_NumPyramids = (hv_CurrentName.TupleRegexpMatch(hv_NameRegExp)).TupleNumber();
      calc_feature_pyramid(ho_Region, ho_Image, "edge_density_histogram", hv_NumPyramids, 
          &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups_pyramid(hv_Mode, hv_Groups, hv_CurrentName, hv_Names, 
        hv_NameRegExp, hv_AccumulatedResults, &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** cooc ***
    hv_Name = "cooc";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Feature = HTuple();
      CoocFeatureImage(ho_Region, ho_Image, 6, 0, &hv_Energy, &hv_Correlation, &hv_Homogeneity, 
          &hv_Contrast);
      if (0 != (hv_NumRegions>0))
      {
        hv_Index = HTuple::TupleGenSequence(0,(4*hv_NumRegions)-1,4);
        hv_Feature[hv_Index] = hv_Energy;
        hv_Feature[1+hv_Index] = hv_Correlation;
        hv_Feature[2+hv_Index] = hv_Homogeneity;
        hv_Feature[3+hv_Index] = hv_Contrast;
      }
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** cooc_pyramid ***
    hv_NameRegExp = "cooc_pyramid_([234])";
    hv_Names = HTuple("cooc_pyramid_")+HTuple::TupleGenSequence(2,4,1);
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    //****************
    if (0 != (hv_CurrentName.TupleRegexpTest(hv_NameRegExp)))
    {
      //** Calculate feature ***
      hv_NumPyramids = (hv_CurrentName.TupleRegexpMatch(hv_NameRegExp)).TupleNumber();
      calc_feature_pyramid(ho_Region, ho_Image, "cooc", hv_NumPyramids, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups_pyramid(hv_Mode, hv_Groups, hv_CurrentName, hv_Names, 
        hv_NameRegExp, hv_AccumulatedResults, &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //POLAR TRANSFORM FEATURES
    //************************************
    //
    //************************************
    //** polar_gray_proj ***
    hv_Name = "polar_gray_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "hor_gray", hv_Width, hv_Height, 
          &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** polar_grad_proj ***
    hv_Name = "polar_grad_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "hor_sobel_amp", hv_Width, 
          hv_Height, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** polar_grad_x_proj ***
    hv_Name = "polar_grad_x_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "hor_sobel_x", hv_Width, 
          hv_Height, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** polar_grad_y_proj ***
    hv_Name = "polar_grad_y_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "hor_sobel_y", hv_Width, 
          hv_Height, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** polar_gray_proj_histo ***
    hv_Name = "polar_gray_proj_histo";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "vert_gray", hv_Width, hv_Height, 
          &hv_Projection);
      hv_NumBins = 20;
      hv_Feature = HTuple();
      {
      HTuple end_val1093 = hv_NumRegions;
      HTuple step_val1093 = 1;
      for (hv_Index=1; hv_Index.Continue(end_val1093, step_val1093); hv_Index += step_val1093)
      {
        hv_Start = (hv_Index-1)*hv_Width;
        TupleHistoRange(hv_Projection.TupleSelectRange(hv_Start,(hv_Start+hv_Width)-1), 
            0, 255, hv_NumBins, &hv_Histo, &hv_BinSize);
        hv_Feature = hv_Feature.TupleConcat(hv_Histo);
      }
      }
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //COLOR FEATURES
    //************************************
    //
    //************************************
    //** cielab_mean ***
    hv_Name = "cielab_mean";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "cielab", "mean", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** cielab_dev ***
    hv_Name = "cielab_dev";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "cielab", "deviation", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** hls_mean ***
    hv_Name = "hls_mean";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "hls", "mean", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** hls_dev ***
    hv_Name = "hls_dev";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "hls", "deviation", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** rgb_mean ***
    hv_Name = "rgb_mean";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "rgb", "mean", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** rgb_dev ***
    hv_Name = "rgb_dev";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "rgb", "deviation", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
  }
  }
  (*hv_Output) = hv_AccumulatedResults;
  SetSystem("empty_region_result", hv_EmptyRegionResult);
  return;
}

void get_find_parameter (HTuple hv_GenParamNames, HTuple hv_GenParamValues, HTuple hv_ParamName, 
    HTuple hv_DefaultValue, HTuple *hv_ParamValue)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Idx;

  (*hv_ParamValue) = hv_DefaultValue;
  TupleFind(hv_GenParamNames, hv_ParamName, &hv_Idx);
  if (0 != (HTuple(hv_Idx!=-1).TupleAnd(hv_Idx!=HTuple())))
  {
    (*hv_ParamValue) = HTuple(hv_GenParamValues[hv_Idx]);
  }
  return;
}

void get_find_surface_model_param (HTuple hv_ParamName, HTuple hv_DefaultValue, HTuple hv_GenParamNames, 
    HTuple hv_GenParamValues, HTuple hv_ConvertBoolToInt, HTuple *hv_ParamValue)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ValidParamNames, hv_Pos;

  if (0 != 1)
  {
    //Debug Check: Is the parameter valid?
    GetParamInfo("find_surface_model_image", "GenParamName", "value_list", &hv_ValidParamNames);
    TupleFind(hv_ValidParamNames, hv_ParamName, &hv_Pos);
    if (0 != (HTuple(hv_Pos==-1).TupleOr(hv_Pos==HTuple())))
    {
      throw HException("Invalid parameter name: "+hv_ParamName);
    }
  }

  hv_Pos = hv_GenParamNames.TupleFind(hv_ParamName);
  if (0 != (HTuple(hv_Pos!=HTuple()).TupleAnd(hv_Pos!=-1)))
  {
    //If the parameter is set multiple times, use the last.
    (*hv_ParamValue) = HTuple(hv_GenParamValues[HTuple(hv_Pos[(hv_Pos.TupleLength())-1])]);
  }
  else
  {
    (*hv_ParamValue) = hv_DefaultValue;
  }

  if (0 != hv_ConvertBoolToInt)
  {
    if (0 != ((*hv_ParamValue)==HTuple("true")))
    {
      (*hv_ParamValue) = 1;
    }
    if (0 != ((*hv_ParamValue)==HTuple("false")))
    {
      (*hv_ParamValue) = 0;
    }
  }

  return;
}

void get_image_direction (HObject ho_Image, HTuple *hv_MedianDirection)
{

  // Local iconic variables
  HObject  ho_Domain, ho_RegionTrans, ho_XWithNeighbor;

  // Local control variables
  HTuple  hv_Direction, hv_Rows, hv_Columns, hv_Grayval1;
  HTuple  hv_Grayval2, hv_Diff, hv_MedianDiff1, hv_MedianDiff2;

  hv_Direction.Clear();
  hv_Direction[0] = 1;
  hv_Direction[1] = 0;
  GetDomain(ho_Image, &ho_Domain);
  AffineTransRegion(ho_Domain, &ho_RegionTrans, (((HTuple(1).Append(0)).TupleConcat(HTuple(hv_Direction[1]))).TupleConcat((HTuple(0).Append(1)))).TupleConcat(HTuple(hv_Direction[0])), 
      "false");
  Intersection(ho_Image, ho_RegionTrans, &ho_XWithNeighbor);
  GetRegionPoints(ho_XWithNeighbor, &hv_Rows, &hv_Columns);
  if (0 != ((hv_Columns.TupleLength())>0))
  {
    GetGrayval(ho_Image, hv_Rows-HTuple(hv_Direction[1]), hv_Columns-HTuple(hv_Direction[0]), 
        &hv_Grayval1);
    GetGrayval(ho_Image, hv_Rows, hv_Columns, &hv_Grayval2);
    hv_Diff = hv_Grayval2-hv_Grayval1;
    hv_MedianDiff1 = hv_Diff.TupleMedian();
  }
  else
  {
    (*hv_MedianDirection).Clear();
    (*hv_MedianDirection)[0] = 0;
    (*hv_MedianDirection)[1] = 0;
    return;
  }

  hv_Direction.Clear();
  hv_Direction[0] = 0;
  hv_Direction[1] = 1;
  AffineTransRegion(ho_Image, &ho_RegionTrans, (((HTuple(1).Append(0)).TupleConcat(HTuple(hv_Direction[1]))).TupleConcat((HTuple(0).Append(1)))).TupleConcat(HTuple(hv_Direction[0])), 
      "nearest_neighbor");
  Intersection(ho_Image, ho_RegionTrans, &ho_XWithNeighbor);
  GetRegionPoints(ho_XWithNeighbor, &hv_Rows, &hv_Columns);
  if (0 != ((hv_Columns.TupleLength())>0))
  {
    GetGrayval(ho_Image, hv_Rows-HTuple(hv_Direction[1]), hv_Columns-HTuple(hv_Direction[0]), 
        &hv_Grayval1);
    GetGrayval(ho_Image, hv_Rows, hv_Columns, &hv_Grayval2);
    hv_Diff = hv_Grayval2-hv_Grayval1;
    hv_MedianDiff2 = hv_Diff.TupleMedian();
  }
  else
  {
    (*hv_MedianDirection).Clear();
    (*hv_MedianDirection)[0] = 0;
    (*hv_MedianDirection)[1] = 0;
    return;
  }

  (*hv_MedianDirection).Clear();
  (*hv_MedianDirection).Append(hv_MedianDiff1);
  (*hv_MedianDirection).Append(hv_MedianDiff2);

  return;
}

void get_mouse_info (HTuple hv_WindowHandle, HTuple hv_MessageQueue, HTuple hv_Timeout, 
    HTuple *hv_Row, HTuple *hv_Column, HTuple *hv_Button)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MessageHandle, hv_Exception, hv_H_ERR_TIMEOUT;
  HTuple  hv_MessageType;

  //Initialize as "no event"
  (*hv_Row) = -1;
  (*hv_Column) = -1;
  (*hv_Button) = -1;
  //
  if (0 != (hv_MessageQueue==HTuple()))
  {
    GetMpositionSubPix(hv_WindowHandle, &(*hv_Row), &(*hv_Column), &(*hv_Button));
  }
  else
  {
    //Queue-based visualization
    if (0 != (hv_Timeout==HTuple()))
    {
      DequeueMessage(HTuple(hv_MessageQueue[0]), HTuple(), HTuple(), &hv_MessageHandle);
    }
    else
    {
      try
      {
        DequeueMessage(HTuple(hv_MessageQueue[0]), "timeout", hv_Timeout, &hv_MessageHandle);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_H_ERR_TIMEOUT = 9400;
        if (0 != (HTuple(hv_Exception[0])==hv_H_ERR_TIMEOUT))
        {
          return;
        }
        else
        {
          throw HException(hv_Exception);
        }
      }
    }
    GetMessageTuple(hv_MessageHandle, "type", &hv_MessageType);
    if (0 != (hv_MessageType==HTuple("mouse_event")))
    {
      GetMessageTuple(hv_MessageHandle, "mouse_row", &(*hv_Row));
      GetMessageTuple(hv_MessageHandle, "mouse_col", &(*hv_Column));
      GetMessageTuple(hv_MessageHandle, "mouse_button", &(*hv_Button));
      ClearMessage(hv_MessageHandle);
    }
    else
    {
      ClearMessage(hv_MessageHandle);
      throw HException("Unknown or unexpected message type: "+hv_MessageType);
    }
  }

  //Normalize the button
  if (0 != ((*hv_Button)==HTuple()))
  {
    (*hv_Button) = 0;
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Get the coordinates of the central mark of the closest finder pattern. 
void get_nearest_finder_pattern_coordinates (HObject ho_CalibPlateImage, HTuple hv_RowNearFinderPattern, 
    HTuple hv_ColumNearFinderPattern, HTuple hv_CalibObjectData, HTuple *hv_RowFinderPattern, 
    HTuple *hv_ColumnFinderPattern)
{

  // Local iconic variables
  HObject  ho_Contours, ho_Region, ho_RegionUnion;

  // Local control variables
  HTuple  hv_CamParam, hv_CalPlateDescr, hv_MarksPerRow;
  HTuple  hv_FinderRow, hv_FinderColumn, hv_CalibDataID, hv_Exception;
  HTuple  hv_Row, hv_Column, hv_Index1, hv_Pose, hv_Area1;
  HTuple  hv_Row2, hv_Column2, hv_RowTmp, hv_ColTmp, hv_Diff;
  HTuple  hv_IndexFinal, hv_RowToApproach1, hv_ColToApproach1;
  HTuple  hv_XCal, hv_YCal, hv_ZCal, hv_XFP, hv_YFP, hv_HomMat3D;
  HTuple  hv_ZFP, hv_X1, hv_Y1, hv_Z1;

  //
  read_message_tuple(hv_CalibObjectData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_CalibObjectData, "CalPlateDescr", &hv_CalPlateDescr);
  read_message_tuple(hv_CalibObjectData, "MarksPerRow", &hv_MarksPerRow);
  read_message_tuple(hv_CalibObjectData, "FinderRow", &hv_FinderRow);
  read_message_tuple(hv_CalibObjectData, "FinderColumn", &hv_FinderColumn);
  //
  //Check input.
  //
  //Check image coordinates.
  if (0 != (HTuple((hv_RowNearFinderPattern.TupleLength())>1).TupleOr((hv_ColumNearFinderPattern.TupleLength())>1)))
  {
    throw HException("Please specify only one image coordinate.");
  }
  //Check number of marks per row.
  if (0 != (hv_MarksPerRow<3))
  {
    throw HException("At least three marks per row are necessary for a valid finder pattern.");
  }
  //Find calibration plate.
  CreateCalibData("calibration_object", 1, 1, &hv_CalibDataID);
  SetCalibDataCamParam(hv_CalibDataID, 0, HTuple(), hv_CamParam);
  SetCalibDataCalibObject(hv_CalibDataID, 0, hv_CalPlateDescr);
  try
  {
    FindCalibObject(ho_CalibPlateImage, hv_CalibDataID, 0, 0, 0, HTuple(), HTuple());
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException(HTuple("Calibration plate could not be find, please make sure that at least one finder pattern is visible."));
  }
  GetCalibDataObservPoints(hv_CalibDataID, 0, 0, 0, &hv_Row, &hv_Column, &hv_Index1, 
      &hv_Pose);
  GetCalibDataObservContours(&ho_Contours, hv_CalibDataID, "caltab", 0, 0, 0);
  //Get the finder pattern used to find the calibration plate.
  GenRegionContourXld(ho_Contours, &ho_Region, "filled");
  Union1(ho_Region, &ho_RegionUnion);
  AreaCenter(ho_RegionUnion, &hv_Area1, &hv_Row2, &hv_Column2);
  hv_RowTmp = (hv_Row-hv_Row2).TupleAbs();
  hv_ColTmp = (hv_Column-hv_Column2).TupleAbs();
  hv_Diff = ((hv_RowTmp*hv_RowTmp)+(hv_ColTmp*hv_ColTmp)).TupleSqrt();
  TupleFind(hv_Diff, hv_Diff.TupleMin(), &hv_IndexFinal);
  hv_RowToApproach1 = HTuple(hv_Row[hv_IndexFinal]);
  hv_ColToApproach1 = HTuple(hv_Column[hv_IndexFinal]);
  ClearCalibData(hv_CalibDataID);
  //Get remaining finder pattern.
  //
  //Get finder pattern in world coordinates.
  CaltabPoints(hv_CalPlateDescr, &hv_XCal, &hv_YCal, &hv_ZCal);
  hv_XFP = HTuple(hv_XCal[(hv_FinderRow*hv_MarksPerRow)+hv_FinderColumn]);
  hv_YFP = HTuple(hv_YCal[(hv_FinderRow*hv_MarksPerRow)+hv_FinderColumn]);
  //Get finder pattern in camera coordinates.
  PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
  TupleGenConst(hv_XFP.TupleLength(), 0.0, &hv_ZFP);
  AffineTransPoint3d(hv_HomMat3D, hv_XFP, hv_YFP, hv_ZFP, &hv_X1, &hv_Y1, &hv_Z1);
  //Project into the image.
  Project3dPoint(hv_X1, hv_Y1, hv_Z1, hv_CamParam, &hv_Row, &hv_Column);
  //
  //Get the image coordinates that are the closest ones to the passed ones.
  hv_RowTmp = (hv_Row-hv_RowNearFinderPattern).TupleAbs();
  hv_ColTmp = (hv_Column-hv_ColumNearFinderPattern).TupleAbs();
  hv_Diff = ((hv_RowTmp*hv_RowTmp)+(hv_ColTmp*hv_ColTmp)).TupleSqrt();
  TupleFind(hv_Diff, hv_Diff.TupleMin(), &hv_IndexFinal);
  //Return the image coordinates.
  (*hv_RowFinderPattern) = HTuple(hv_Row[hv_IndexFinal]);
  (*hv_ColumnFinderPattern) = HTuple(hv_Column[hv_IndexFinal]);
  return;
}

// Chapter: Graphics / Output
// Short Description: Compute the center of all given 3D object models. 
void get_object_models_center (HTuple hv_ObjectModel3DID, HTuple *hv_Center)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Diameter, hv_MD, hv_Weight, hv_SumW;
  HTuple  hv_Index, hv_ObjectModel3DIDSelected, hv_C, hv_InvSum;

  //Compute the mean of all model centers (weighted by the diameter of the object models)
  if (0 != ((hv_ObjectModel3DID.TupleLength())>0))
  {
    GetObjectModel3dParams(hv_ObjectModel3DID, "diameter_axis_aligned_bounding_box", 
        &hv_Diameter);
    //Normalize Diameter to use it as weights for a weighted mean of the individual centers
    hv_MD = hv_Diameter.TupleMean();
    if (0 != (hv_MD>1e-10))
    {
      hv_Weight = hv_Diameter/hv_MD;
    }
    else
    {
      hv_Weight = hv_Diameter;
    }
    hv_SumW = hv_Weight.TupleSum();
    if (0 != (hv_SumW<1e-10))
    {
      hv_Weight = HTuple(hv_Weight.TupleLength(),1.0);
      hv_SumW = hv_Weight.TupleSum();
    }
    (*hv_Center).Clear();
    (*hv_Center)[0] = 0;
    (*hv_Center)[1] = 0;
    (*hv_Center)[2] = 0;
    {
    HTuple end_val16 = (hv_ObjectModel3DID.TupleLength())-1;
    HTuple step_val16 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val16, step_val16); hv_Index += step_val16)
    {
      hv_ObjectModel3DIDSelected = HTuple(hv_ObjectModel3DID[hv_Index]);
      GetObjectModel3dParams(hv_ObjectModel3DIDSelected, "center", &hv_C);
      (*hv_Center)[0] = HTuple((*hv_Center)[0])+(HTuple(hv_C[0])*HTuple(hv_Weight[hv_Index]));
      (*hv_Center)[1] = HTuple((*hv_Center)[1])+(HTuple(hv_C[1])*HTuple(hv_Weight[hv_Index]));
      (*hv_Center)[2] = HTuple((*hv_Center)[2])+(HTuple(hv_C[2])*HTuple(hv_Weight[hv_Index]));
    }
    }
    hv_InvSum = 1.0/hv_SumW;
    (*hv_Center)[0] = HTuple((*hv_Center)[0])*hv_InvSum;
    (*hv_Center)[1] = HTuple((*hv_Center)[1])*hv_InvSum;
    (*hv_Center)[2] = HTuple((*hv_Center)[2])*hv_InvSum;
  }
  else
  {
    (*hv_Center) = HTuple();
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Compute the center of all given 3D object models. 
void get_object_models_center_visualize_object_model_3d (HTuple hv_ObjectModel3DID, 
    HTuple *hv_Center)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Diameter, hv_MD, hv_Weight, hv_SumW;
  HTuple  hv_Index, hv_ObjectModel3DIDSelected, hv_C, hv_InvSum;

  //Compute the mean of all model centers (weighted by the diameter of the object models)
  if (0 != ((hv_ObjectModel3DID.TupleLength())>0))
  {
    GetObjectModel3dParams(hv_ObjectModel3DID, "diameter_axis_aligned_bounding_box", 
        &hv_Diameter);
    //Normalize Diameter to use it as weights for a weighted mean of the individual centers
    hv_MD = hv_Diameter.TupleMean();
    if (0 != (hv_MD>1e-10))
    {
      hv_Weight = hv_Diameter/hv_MD;
    }
    else
    {
      hv_Weight = hv_Diameter;
    }
    hv_SumW = hv_Weight.TupleSum();
    if (0 != (hv_SumW<1e-10))
    {
      hv_Weight = HTuple(hv_Weight.TupleLength(),1.0);
      hv_SumW = hv_Weight.TupleSum();
    }
    (*hv_Center).Clear();
    (*hv_Center)[0] = 0;
    (*hv_Center)[1] = 0;
    (*hv_Center)[2] = 0;
    {
    HTuple end_val16 = (hv_ObjectModel3DID.TupleLength())-1;
    HTuple step_val16 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val16, step_val16); hv_Index += step_val16)
    {
      hv_ObjectModel3DIDSelected = HTuple(hv_ObjectModel3DID[hv_Index]);
      GetObjectModel3dParams(hv_ObjectModel3DIDSelected, "center", &hv_C);
      (*hv_Center)[0] = HTuple((*hv_Center)[0])+(HTuple(hv_C[0])*HTuple(hv_Weight[hv_Index]));
      (*hv_Center)[1] = HTuple((*hv_Center)[1])+(HTuple(hv_C[1])*HTuple(hv_Weight[hv_Index]));
      (*hv_Center)[2] = HTuple((*hv_Center)[2])+(HTuple(hv_C[2])*HTuple(hv_Weight[hv_Index]));
    }
    }
    hv_InvSum = 1.0/hv_SumW;
    (*hv_Center)[0] = HTuple((*hv_Center)[0])*hv_InvSum;
    (*hv_Center)[1] = HTuple((*hv_Center)[1])*hv_InvSum;
    (*hv_Center)[2] = HTuple((*hv_Center)[2])*hv_InvSum;
  }
  else
  {
    (*hv_Center) = HTuple();
  }
  return;
}

// Chapter: Transformations / Misc
// Short Description: Calculate the touching point in tool coordinates. 
void get_robot_touching_point_in_tool_coordinates (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple *hv_RobotTouchingPointInToolCoordinates)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_LHS, hv_RHS, hv_HomMat3D0, hv_Mat0;
  HTuple  hv_MatRot0, hv_MatTrans0, hv_Index, hv_HomMat3D;
  HTuple  hv_Mat, hv_MatRot, hv_MatTrans, hv_MatrixResultID;
  HTuple  hv_DetailedErrors, hv_MinDiffToIdentity, hv_MinCosAngle;
  HTuple  hv_Index1, hv_CosAngle, hv_MaxAngleBetweenRotationAxes;
  HTuple  hv_MatrixUID, hv_MatrixSID, hv_MatrixVID, hv_SingularValues;
  HTuple  hv_MinSingularValue;
  HTupleVector  hvec_RotationAxisRelativ(1), hvec_DiffToIdentity(1);

  //To estimate the touching point with respect to the tool coordinate system, we have to
  //arrange three equations in the following form:
  //Rp + T = q,
  //where R is a is the rotation matrix that rotates a point from the tool to the base coordinate
  //system and T is a translation that translates a point from the tool to the base coordinate.
  //q is the touching point with respect to the base coordinate system
  //and p the unknown touching point with respect to the tool coordinate system.
  //
  //Approaching the same point three times while rotating the tool leads to three rotation matrices
  //R0, R1 and R2 and three translations T0, T1 and T2.
  //Solving this equation for the unknown touching point yields therefore:
  //R0*p + T0 = q, R1*p + T1 = q and R2*p + T2 = q.
  //After building two equations in the form (R1-R0)*p = T0-T1 and (R2-R0)*p = T0-T2,
  //the DLT (direct linear transformation) can be used to efficiently solve for the unknown
  //touching point p.


  //Check input.
  if (0 != (HTuple(hvec_ToolInBasePosesTouchingPoint.Length())<3))
  {
    throw HException("Please specify at least three robot poses.");
  }

  //Initialize equation.
  CreateMatrix((HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1)*3, 3, 0, &hv_LHS);
  CreateMatrix((HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1)*3, 1, 0, &hv_RHS);
  hvec_RotationAxisRelativ = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  hvec_DiffToIdentity = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  //Decompose first pose.
  PoseToHomMat3d(hvec_ToolInBasePosesTouchingPoint[0].T(), &hv_HomMat3D0);
  CreateMatrix(3, 4, hv_HomMat3D0, &hv_Mat0);
  GetSubMatrix(hv_Mat0, 0, 0, 3, 3, &hv_MatRot0);
  GetSubMatrix(hv_Mat0, 0, 3, 3, 1, &hv_MatTrans0);
  //
  {
  HTuple end_val33 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
  HTuple step_val33 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val33, step_val33); hv_Index += step_val33)
  {
    //Decompose current pose.
    PoseToHomMat3d(hvec_ToolInBasePosesTouchingPoint[hv_Index].T(), &hv_HomMat3D);
    CreateMatrix(3, 4, hv_HomMat3D, &hv_Mat);
    GetSubMatrix(hv_Mat, 0, 0, 3, 3, &hv_MatRot);
    GetSubMatrix(hv_Mat, 0, 3, 3, 1, &hv_MatTrans);
    //Get rotation axis relativ to first pose.
    {
    HTuple ExpTmpOutVar_0;HTuple ExpTmpOutVar_1;
    get_rotation_axis(hv_MatRot, hv_MatRot0, &ExpTmpOutVar_0, &ExpTmpOutVar_1);
    hvec_RotationAxisRelativ[hv_Index].T() = ExpTmpOutVar_0;
    hvec_DiffToIdentity[hv_Index].T() = ExpTmpOutVar_1;
    }
    //Fill equation.
    SubMatrixMod(hv_MatRot, hv_MatRot0);
    SetSubMatrix(hv_LHS, hv_MatRot, (hv_Index-1)*3, 0);
    SubMatrixMod(hv_MatTrans, hv_MatTrans0);
    ScaleMatrixMod(hv_MatTrans, -1.0);
    SetSubMatrix(hv_RHS, hv_MatTrans, (hv_Index-1)*3, 0);
    //Clear.
    ClearMatrix(hv_Mat);
    ClearMatrix(hv_MatRot);
    ClearMatrix(hv_MatTrans);
  }
  }
  //Solve.
  SolveMatrix(hv_LHS, "general", 0, hv_RHS, &hv_MatrixResultID);
  GetFullMatrix(hv_MatrixResultID, &(*hv_RobotTouchingPointInToolCoordinates));
  //Detailed errors.
  hv_DetailedErrors = 0;
  if (0 != hv_DetailedErrors)
  {
    //Check that the tool was tilted enough compared to the first pose.
    hv_MinDiffToIdentity = 1e8;
    {
    HTuple end_val60 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
    HTuple step_val60 = 1;
    for (hv_Index=1; hv_Index.Continue(end_val60, step_val60); hv_Index += step_val60)
    {
      if (0 != (hvec_DiffToIdentity[hv_Index].T()<hv_MinDiffToIdentity))
      {
        hv_MinDiffToIdentity = hvec_DiffToIdentity[hv_Index].T();
      }
    }
    }
    //Check that different rotation axis were used when tilted away from first pose.
    hv_MinCosAngle = 1.5;
    {
    HTuple end_val67 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-2;
    HTuple step_val67 = 1;
    for (hv_Index=1; hv_Index.Continue(end_val67, step_val67); hv_Index += step_val67)
    {
      {
      HTuple end_val68 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
      HTuple step_val68 = 1;
      for (hv_Index1=hv_Index+1; hv_Index1.Continue(end_val68, step_val68); hv_Index1 += step_val68)
      {
        hv_CosAngle = ((hvec_RotationAxisRelativ[hv_Index].T()*hvec_RotationAxisRelativ[hv_Index1].T()).TupleSum()).TupleAbs();
        if (0 != (hv_CosAngle<hv_MinCosAngle))
        {
          hv_MinCosAngle = hv_CosAngle;
        }
      }
      }
    }
    }
    hv_MaxAngleBetweenRotationAxes = (hv_MinCosAngle.TupleAcos()).TupleDeg();
  }
  SvdMatrix(hv_LHS, "full", "both", &hv_MatrixUID, &hv_MatrixSID, &hv_MatrixVID);
  GetValueMatrix(hv_MatrixSID, ((HTuple(0).Append(1)).Append(2)), ((HTuple(0).Append(1)).Append(2)), 
      &hv_SingularValues);
  hv_MinSingularValue = (hv_SingularValues.TupleAbs()).TupleMin();
  if (0 != (hv_MinSingularValue<0.15))
  {
    //Consider the rotations of the tool from its first position to each following position.
    //Please rotate the tool enough away from the first position.
    //Furthermore, please use at least two significantly different rotation axis when rotating the tool
    //from its first position (preferably orthogonal directions?).
    //The maximum angle between the corresponding rotation axis is MaxAngleBetweenRotationAxes.
    //
    throw HException("The estimated touching point might not be reliable. Try to use at least two different rotation axis and/or increase the rotations around these axis.");
  }
  //
  //Clear.
  ClearMatrix(hv_MatrixUID);
  ClearMatrix(hv_MatrixSID);
  ClearMatrix(hv_MatrixVID);
  ClearMatrix(hv_Mat0);
  ClearMatrix(hv_MatRot0);
  ClearMatrix(hv_MatTrans0);
  ClearMatrix(hv_LHS);
  ClearMatrix(hv_RHS);
  return;
}

// Chapter: Matrix / Arithmetic
void get_rotation_axis (HTuple hv_MatRot, HTuple hv_MatRot0, HTuple *hv_RotationAxis, 
    HTuple *hv_DiffToIdentity)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MatrixMultID, hv_Identity, hv_MatrixSubID;
  HTuple  hv_Values, hv_MatrixUID, hv_MatrixSID, hv_MatrixVID;
  HTuple  hv_SingularValues, hv_AbsSingularValues, hv_Indices;

  //
  //Get (R_i)^(-1)R_0
  MultMatrix(hv_MatRot, hv_MatRot0, "ATB", &hv_MatrixMultID);
  //Get some measure for how far the matrix is from the identity.
  CreateMatrix(3, 3, "identity", &hv_Identity);
  SubMatrix(hv_MatrixMultID, hv_Identity, &hv_MatrixSubID);
  GetFullMatrix(hv_MatrixSubID, &hv_Values);
  (*hv_DiffToIdentity) = (hv_Values*hv_Values).TupleSum();
  //Get its rotation axis.
  SvdMatrix(hv_MatrixSubID, "full", "both", &hv_MatrixUID, &hv_MatrixSID, &hv_MatrixVID);
  GetValueMatrix(hv_MatrixSID, ((HTuple(0).Append(1)).Append(2)), ((HTuple(0).Append(1)).Append(2)), 
      &hv_SingularValues);
  hv_AbsSingularValues = hv_SingularValues.TupleAbs();
  TupleSortIndex(hv_AbsSingularValues, &hv_Indices);
  GetValueMatrix(hv_MatrixVID, ((HTuple(0).Append(1)).Append(2)), (HTuple(hv_Indices[0]).TupleConcat(HTuple(hv_Indices[0]))).TupleConcat(HTuple(hv_Indices[0])), 
      &(*hv_RotationAxis));
  //Clear matrices.
  ClearMatrix(hv_MatrixMultID);
  ClearMatrix(hv_MatrixUID);
  ClearMatrix(hv_MatrixSID);
  ClearMatrix(hv_MatrixVID);
  ClearMatrix(hv_MatrixSubID);
  ClearMatrix(hv_Identity);
  return;
}

// Chapter: 3D Reconstruction / Sheet of Light
// Short Description: Calculate the dimensions of a sheet-of-light calibration object. 
void get_sheet_of_light_calib_object_dimensions (HTuple hv_Width, HTuple hv_Length, 
    HTuple hv_HeightMin, HTuple hv_HeightMax, HTuple *hv_DiameterCircle, HTuple *hv_PyramidHeight, 
    HTuple *hv_PyramidDistanceFromFront, HTuple *hv_PyramidBottomDiagonal, HTuple *hv_PyramidTopDiagonal, 
    HTuple *hv_Angle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CircleFactor, hv_PyramidBottomFactor;
  HTuple  hv_PyramidTopFactor, hv_OffsetFactor, hv_MaxAngle;
  HTuple  hv_Pi, hv_Height, hv_Hypotenuse, hv_CosAlpha, hv_SinAlpha;
  HTuple  hv_Dist, hv_PyramidHeight1, hv_PyramidHeight2;

  //
  //Constants:
  hv_CircleFactor = 0.075;
  hv_PyramidBottomFactor = 0.9;
  hv_PyramidTopFactor = 0.5;
  hv_OffsetFactor = 0.1;
  hv_MaxAngle = HTuple(45).TupleRad();
  hv_Pi = HTuple(180).TupleRad();
  //
  //Circle:
  (*hv_DiameterCircle) = hv_CircleFactor*hv_Width;
  //
  (*hv_PyramidBottomDiagonal) = hv_Width*hv_PyramidBottomFactor;
  (*hv_PyramidTopDiagonal) = (*hv_PyramidBottomDiagonal)*hv_PyramidTopFactor;
  (*hv_PyramidDistanceFromFront) = 0.1*hv_Length;
  //
  //Find the height of the truncated pyramid such that
  //its highest point's Z coordinate is equal to HeightMax.
  hv_Height = hv_HeightMax-hv_HeightMin;
  hv_Hypotenuse = ((hv_Length*hv_Length)+(hv_Height*hv_Height)).TupleSqrt();
  hv_CosAlpha = hv_Length/hv_Hypotenuse;
  hv_SinAlpha = hv_Height/hv_Hypotenuse;
  (*hv_Angle) = hv_CosAlpha.TupleAcos();
  hv_Dist = ((hv_OffsetFactor*hv_Length)+(0.5*(*hv_PyramidBottomDiagonal)))+(0.5*(*hv_PyramidTopDiagonal));
  hv_PyramidHeight1 = (hv_Height-(hv_Dist*hv_SinAlpha))/hv_CosAlpha;
  //
  //Limit the height of the pyramid such that the angle of
  //its side planes to the ground plane is at most MaxAngle.
  hv_PyramidHeight2 = ((hv_MaxAngle.TupleTan())*0.5)*((*hv_PyramidBottomDiagonal)-(*hv_PyramidTopDiagonal));
  (*hv_PyramidHeight) = hv_PyramidHeight1.TupleMin2(hv_PyramidHeight2);
  return;
}

// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera. 
void get_trackball_center (HTuple hv_SelectedObject, HTuple hv_TrackballRadiusPixel, 
    HTuple hv_ObjectModel3D, HTuple hv_Poses, HTuple *hv_TBCenter, HTuple *hv_TBSize)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumModels, hv_Centers, hv_Diameter;
  HTuple  hv_MD, hv_Weight, hv_SumW, hv_Index, hv_ObjectModel3DIDSelected;
  HTuple  hv_PoseSelected, hv_HomMat3D, hv_TBCenterCamX, hv_TBCenterCamY;
  HTuple  hv_TBCenterCamZ, hv_InvSum;

  hv_NumModels = hv_ObjectModel3D.TupleLength();
  (*hv_TBCenter)[0] = 0;
  (*hv_TBCenter)[1] = 0;
  (*hv_TBCenter)[2] = 0;
  GetObjectModel3dParams(hv_ObjectModel3D, "center", &hv_Centers);
  GetObjectModel3dParams(hv_ObjectModel3D, "diameter_axis_aligned_bounding_box", 
      &hv_Diameter);
  //Normalize Diameter to use it as weights for a weighted mean of the individual centers
  hv_MD = hv_Diameter.TupleMean();
  if (0 != (hv_MD>1e-10))
  {
    hv_Weight = hv_Diameter/hv_MD;
  }
  else
  {
    hv_Weight = hv_Diameter;
  }
  hv_SumW = (hv_Weight.TupleSelectMask((hv_SelectedObject.TupleSgn()).TupleAbs())).TupleSum();
  if (0 != (hv_SumW<1e-10))
  {
    hv_Weight = HTuple(hv_Weight.TupleLength(),1.0);
    hv_SumW = (hv_Weight.TupleSelectMask((hv_SelectedObject.TupleSgn()).TupleAbs())).TupleSum();
  }
  {
  HTuple end_val18 = hv_NumModels-1;
  HTuple step_val18 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val18, step_val18); hv_Index += step_val18)
  {
    if (0 != (HTuple(hv_SelectedObject[hv_Index])))
    {
      hv_ObjectModel3DIDSelected = HTuple(hv_ObjectModel3D[hv_Index]);
      hv_PoseSelected = hv_Poses.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
      PoseToHomMat3d(hv_PoseSelected, &hv_HomMat3D);
      AffineTransPoint3d(hv_HomMat3D, HTuple(hv_Centers[(hv_Index*3)+0]), HTuple(hv_Centers[(hv_Index*3)+1]), 
          HTuple(hv_Centers[(hv_Index*3)+2]), &hv_TBCenterCamX, &hv_TBCenterCamY, 
          &hv_TBCenterCamZ);
      (*hv_TBCenter)[0] = HTuple((*hv_TBCenter)[0])+(hv_TBCenterCamX*HTuple(hv_Weight[hv_Index]));
      (*hv_TBCenter)[1] = HTuple((*hv_TBCenter)[1])+(hv_TBCenterCamY*HTuple(hv_Weight[hv_Index]));
      (*hv_TBCenter)[2] = HTuple((*hv_TBCenter)[2])+(hv_TBCenterCamZ*HTuple(hv_Weight[hv_Index]));
    }
  }
  }
  if (0 != ((hv_SelectedObject.TupleMax())!=0))
  {
    hv_InvSum = 1.0/hv_SumW;
    (*hv_TBCenter)[0] = HTuple((*hv_TBCenter)[0])*hv_InvSum;
    (*hv_TBCenter)[1] = HTuple((*hv_TBCenter)[1])*hv_InvSum;
    (*hv_TBCenter)[2] = HTuple((*hv_TBCenter)[2])*hv_InvSum;
    (*hv_TBSize) = (0.5+((0.5*(hv_SelectedObject.TupleSum()))/hv_NumModels))*hv_TrackballRadiusPixel;
  }
  else
  {
    (*hv_TBCenter) = HTuple();
    (*hv_TBSize) = 0;
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera. 
void get_trackball_center_visualize_object_model_3d (HTuple hv_SelectedObject, HTuple hv_TrackballRadiusPixel, 
    HTuple hv_ObjectModel3D, HTuple hv_Poses, HTuple *hv_TBCenter, HTuple *hv_TBSize)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumModels, hv_Centers, hv_Diameter;
  HTuple  hv_MD, hv_Weight, hv_SumW, hv_Index, hv_ObjectModel3DIDSelected;
  HTuple  hv_PoseSelected, hv_HomMat3D, hv_TBCenterCamX, hv_TBCenterCamY;
  HTuple  hv_TBCenterCamZ, hv_InvSum;

  hv_NumModels = hv_ObjectModel3D.TupleLength();
  (*hv_TBCenter)[0] = 0;
  (*hv_TBCenter)[1] = 0;
  (*hv_TBCenter)[2] = 0;
  GetObjectModel3dParams(hv_ObjectModel3D, "center", &hv_Centers);
  GetObjectModel3dParams(hv_ObjectModel3D, "diameter_axis_aligned_bounding_box", 
      &hv_Diameter);
  //Normalize Diameter to use it as weights for a weighted mean of the individual centers
  hv_MD = hv_Diameter.TupleMean();
  if (0 != (hv_MD>1e-10))
  {
    hv_Weight = hv_Diameter/hv_MD;
  }
  else
  {
    hv_Weight = hv_Diameter;
  }
  hv_SumW = (hv_Weight.TupleSelectMask((hv_SelectedObject.TupleSgn()).TupleAbs())).TupleSum();
  if (0 != (hv_SumW<1e-10))
  {
    hv_Weight = HTuple(hv_Weight.TupleLength(),1.0);
    hv_SumW = (hv_Weight.TupleSelectMask((hv_SelectedObject.TupleSgn()).TupleAbs())).TupleSum();
  }
  {
  HTuple end_val18 = hv_NumModels-1;
  HTuple step_val18 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val18, step_val18); hv_Index += step_val18)
  {
    if (0 != (HTuple(hv_SelectedObject[hv_Index])))
    {
      hv_ObjectModel3DIDSelected = HTuple(hv_ObjectModel3D[hv_Index]);
      hv_PoseSelected = hv_Poses.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
      PoseToHomMat3d(hv_PoseSelected, &hv_HomMat3D);
      AffineTransPoint3d(hv_HomMat3D, HTuple(hv_Centers[(hv_Index*3)+0]), HTuple(hv_Centers[(hv_Index*3)+1]), 
          HTuple(hv_Centers[(hv_Index*3)+2]), &hv_TBCenterCamX, &hv_TBCenterCamY, 
          &hv_TBCenterCamZ);
      (*hv_TBCenter)[0] = HTuple((*hv_TBCenter)[0])+(hv_TBCenterCamX*HTuple(hv_Weight[hv_Index]));
      (*hv_TBCenter)[1] = HTuple((*hv_TBCenter)[1])+(hv_TBCenterCamY*HTuple(hv_Weight[hv_Index]));
      (*hv_TBCenter)[2] = HTuple((*hv_TBCenter)[2])+(hv_TBCenterCamZ*HTuple(hv_Weight[hv_Index]));
    }
  }
  }
  if (0 != ((hv_SelectedObject.TupleMax())!=0))
  {
    hv_InvSum = 1.0/hv_SumW;
    (*hv_TBCenter)[0] = HTuple((*hv_TBCenter)[0])*hv_InvSum;
    (*hv_TBCenter)[1] = HTuple((*hv_TBCenter)[1])*hv_InvSum;
    (*hv_TBCenter)[2] = HTuple((*hv_TBCenter)[2])*hv_InvSum;
    (*hv_TBSize) = (0.5+((0.5*(hv_SelectedObject.TupleSum()))/hv_NumModels))*hv_TrackballRadiusPixel;
  }
  else
  {
    (*hv_TBCenter) = HTuple();
    (*hv_TBSize) = 0;
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera (version for inspection_mode = 'surface'). 
void get_trackball_center_fixed (HTuple hv_SelectedObject, HTuple hv_TrackballCenterRow, 
    HTuple hv_TrackballCenterCol, HTuple hv_TrackballRadiusPixel, HTuple hv_Scene3D, 
    HTuple hv_ObjectModel3DID, HTuple hv_Poses, HTuple hv_WindowHandleBuffer, HTuple hv_CamParam, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple *hv_TBCenter, HTuple *hv_TBSize)
{

  // Local iconic variables
  HObject  ho_RegionCenter, ho_DistanceImage, ho_Domain;

  // Local control variables
  HTuple  hv_NumModels, hv_Width, hv_Height, hv_SelectPose;
  HTuple  hv_Index1, hv_Rows, hv_Columns, hv_Grayval, hv_IndicesG;
  HTuple  hv_Value, hv_Pos;

  //Determine the trackball center for the fixed trackball
  hv_NumModels = hv_ObjectModel3DID.TupleLength();
  get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
  get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
  //
  //Project the selected objects
  hv_SelectPose = HTuple();
  {
  HTuple end_val7 = (hv_SelectedObject.TupleLength())-1;
  HTuple step_val7 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val7, step_val7); hv_Index1 += step_val7)
  {
    hv_SelectPose = hv_SelectPose.TupleConcat(HTuple(7,HTuple(hv_SelectedObject[hv_Index1])));
    if (0 != (HTuple(hv_SelectedObject[hv_Index1])==0))
    {
      SetScene3dInstanceParam(hv_Scene3D, hv_Index1, "visible", "false");
    }
  }
  }
  SetScene3dParam(hv_Scene3D, "depth_persistence", "true");
  DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
  SetScene3dParam(hv_Scene3D, "visible", "true");
  //
  //determine the depth of the object point that appears closest to the trackball
  //center
  GenRegionPoints(&ho_RegionCenter, hv_TrackballCenterRow, hv_TrackballCenterCol);
  DistanceTransform(ho_RegionCenter, &ho_DistanceImage, "chamfer-3-4-unnormalized", 
      "false", hv_Width, hv_Height);
  GetDomain(ho_DistanceImage, &ho_Domain);
  GetRegionPoints(ho_Domain, &hv_Rows, &hv_Columns);
  GetGrayval(ho_DistanceImage, hv_Rows, hv_Columns, &hv_Grayval);
  TupleSortIndex(hv_Grayval, &hv_IndicesG);
  GetDisplayScene3dInfo(hv_WindowHandleBuffer, hv_Scene3D, hv_Rows.TupleSelect(hv_IndicesG), 
      hv_Columns.TupleSelect(hv_IndicesG), "depth", &hv_Value);
  TupleFind(hv_Value.TupleSgn(), 1, &hv_Pos);
  //
  SetScene3dParam(hv_Scene3D, "depth_persistence", "false");
  //
  //
  //set TBCenter
  if (0 != (hv_Pos!=-1))
  {
    //if the object is visible in the image
    (*hv_TBCenter).Clear();
    (*hv_TBCenter)[0] = 0;
    (*hv_TBCenter)[1] = 0;
    (*hv_TBCenter).Append(HTuple(hv_Value[HTuple(hv_Pos[0])]));
  }
  else
  {
    //if the object is not visible in the image, set the z coordinate to -1
    //to indicate, the the previous z value should be used instead
    (*hv_TBCenter).Clear();
    (*hv_TBCenter)[0] = 0;
    (*hv_TBCenter)[1] = 0;
    (*hv_TBCenter)[2] = -1;
  }
  //
  if (0 != ((hv_SelectedObject.TupleMax())!=0))
  {
    (*hv_TBSize) = (0.5+((0.5*(hv_SelectedObject.TupleSum()))/hv_NumModels))*hv_TrackballRadiusPixel;
  }
  else
  {
    (*hv_TBCenter) = HTuple();
    (*hv_TBSize) = 0;
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera (version for inspection_mode = 'surface'). 
void get_trackball_center_fixed_visualize_object_model_3d (HTuple hv_SelectedObject, 
    HTuple hv_TrackballCenterRow, HTuple hv_TrackballCenterCol, HTuple hv_TrackballRadiusPixel, 
    HTuple hv_Scene3D, HTuple hv_ObjectModel3DID, HTuple hv_Poses, HTuple hv_WindowHandleBuffer, 
    HTuple hv_CamParam, HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple *hv_TBCenter, 
    HTuple *hv_TBSize)
{

  // Local iconic variables
  HObject  ho_RegionCenter, ho_DistanceImage, ho_Domain;

  // Local control variables
  HTuple  hv_NumModels, hv_Width, hv_Height, hv_SelectPose;
  HTuple  hv_Index1, hv_Rows, hv_Columns, hv_Grayval, hv_IndicesG;
  HTuple  hv_Value, hv_Pos;

  //Determine the trackball center for the fixed trackball
  hv_NumModels = hv_ObjectModel3DID.TupleLength();
  get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
  get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
  //
  //Project the selected objects
  hv_SelectPose = HTuple();
  {
  HTuple end_val7 = (hv_SelectedObject.TupleLength())-1;
  HTuple step_val7 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val7, step_val7); hv_Index1 += step_val7)
  {
    hv_SelectPose = hv_SelectPose.TupleConcat(HTuple(7,HTuple(hv_SelectedObject[hv_Index1])));
    if (0 != (HTuple(hv_SelectedObject[hv_Index1])==0))
    {
      SetScene3dInstanceParam(hv_Scene3D, hv_Index1, "visible", "false");
    }
  }
  }
  SetScene3dParam(hv_Scene3D, "depth_persistence", "true");
  DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
  SetScene3dParam(hv_Scene3D, "visible", "true");
  //
  //determine the depth of the object point that appears closest to the trackball
  //center
  GenRegionPoints(&ho_RegionCenter, hv_TrackballCenterRow, hv_TrackballCenterCol);
  DistanceTransform(ho_RegionCenter, &ho_DistanceImage, "chamfer-3-4-unnormalized", 
      "false", hv_Width, hv_Height);
  GetDomain(ho_DistanceImage, &ho_Domain);
  GetRegionPoints(ho_Domain, &hv_Rows, &hv_Columns);
  GetGrayval(ho_DistanceImage, hv_Rows, hv_Columns, &hv_Grayval);
  TupleSortIndex(hv_Grayval, &hv_IndicesG);
  GetDisplayScene3dInfo(hv_WindowHandleBuffer, hv_Scene3D, hv_Rows.TupleSelect(hv_IndicesG), 
      hv_Columns.TupleSelect(hv_IndicesG), "depth", &hv_Value);
  TupleFind(hv_Value.TupleSgn(), 1, &hv_Pos);
  //
  SetScene3dParam(hv_Scene3D, "depth_persistence", "false");
  //
  //
  //set TBCenter
  if (0 != (hv_Pos!=-1))
  {
    //if the object is visible in the image
    (*hv_TBCenter).Clear();
    (*hv_TBCenter)[0] = 0;
    (*hv_TBCenter)[1] = 0;
    (*hv_TBCenter).Append(HTuple(hv_Value[HTuple(hv_Pos[0])]));
  }
  else
  {
    //if the object is not visible in the image, set the z coordinate to -1
    //to indicate, the the previous z value should be used instead
    (*hv_TBCenter).Clear();
    (*hv_TBCenter)[0] = 0;
    (*hv_TBCenter)[1] = 0;
    (*hv_TBCenter)[2] = -1;
  }
  //
  if (0 != ((hv_SelectedObject.TupleMax())!=0))
  {
    (*hv_TBSize) = (0.5+((0.5*(hv_SelectedObject.TupleSum()))/hv_NumModels))*hv_TrackballRadiusPixel;
  }
  else
  {
    (*hv_TBCenter) = HTuple();
    (*hv_TBSize) = 0;
  }
  return;
}

void inspect_normal_direction (HObject ho_MenuRegions, HTuple hv_WindowHandle1, HTuple hv_WindowHandle2, 
    HTuple hv_WindowHandleMenu, HTuple hv_SurfaceModelID, HTuple hv_Scene, HTuple hv_RelSamplingDistance, 
    HTuple hv_KeyPointFraction, HTuple hv_MinScore, HTuple hv_GenParamNames, HTuple hv_GenParamValues, 
    HTuple hv_SurfaceMatchingResultID, HTuple hv_MenuText, HTuple hv_CurrentCase, 
    HTuple hv_CasesDone, HTuple hv_FontSize, HTuple *hv_CreateNames, HTuple *hv_CreateValues, 
    HTuple *hv_FindNames, HTuple *hv_FindValues)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Instructions, hv_SampledScene, hv_SampledModel;
  HTuple  hv_VC_P_Model, hv_Diameter, hv_VC_P_Scene, hv_NXYZOrig;
  HTuple  hv_MessageQueues1, hv_Buttons, hv_ShowNormals1;
  HTuple  hv_MessageQueues2, hv_ShowNormals2, hv_PreviousState1;
  HTuple  hv_PreviousState2, hv_DidFinish1, hv_DidFinish2;
  HTuple  hv_Row, hv_Column, hv_Width, hv_Height, hv_WindowHandleBufferMenu;
  HTuple  hv_SceneFast, hv_SceneMLS, hv_NormalsInverted, hv_ModelNormalsToggled;
  HTuple  hv_NormalCompMode, hv_SceneHasNormals, hv_FastMethod;
  HTuple  hv_Message, hv_MessageChanged, hv_ButtonPressed;
  HTuple  hv_Poses, hv_NXYZ, hv_MessageHandle, hv_Pose, hv_Score;
  HTuple  hv_Row1, hv_Column1, hv_Row2, hv_Column2, hv_TIT;
  HTupleVector  hvec_TI(1);

  // +++ Threading variables 
  HDevThread*         hcppthread_handle;
  HDevThreadContext   hcppthread_context; // <-signals begin of procedure

  //
  hv_Instructions[0] = "Rotate: Left button";
  hv_Instructions[1] = "Zoom:   Shift + left button";
  hv_Instructions[2] = "Move:   Ctrl  + left button";
  //
  GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "sampled_scene", HTuple(), 
      &hv_SampledScene);
  GetSurfaceModelParam(hv_SurfaceModelID, "sampled_model", &hv_SampledModel);
  //
  //Visualization of the model's normals
  estimate_visualization_pose(hv_SampledModel, hv_WindowHandle1, &hv_VC_P_Model);
  //
  //Visualization of the scene's normals
  GetObjectModel3dParams(hv_SampledScene, "diameter", &hv_Diameter);
  //
  estimate_visualization_pose(hv_SampledScene, hv_WindowHandle2, &hv_VC_P_Scene);
  //
  GetObjectModel3dParams(hv_SampledModel, HTuple("point_normal_")+((HTuple("x").Append("y")).Append("z")), 
      &hv_NXYZOrig);
  //
  create_visualization_message_queues(&hv_MessageQueues1);
  hv_Buttons.Clear();
  hv_Buttons[0] = "Continue";
  hv_Buttons[1] = "right";
  hv_Buttons[2] = "bottom";
  hv_Buttons[3] = -1;
  hv_Buttons[4] = -1;
  hv_Buttons[5] = "Invert Normals";
  hv_Buttons[6] = "left";
  hv_Buttons[7] = "bottom";
  hv_Buttons[8] = -1;
  hv_Buttons[9] = -1;
  hv_Buttons[10] = "Hide Normals";
  hv_Buttons[11] = "center";
  hv_Buttons[12] = "bottom";
  hv_Buttons[13] = -1;
  hv_Buttons[14] = -1;
  hv_ShowNormals1 = 1;
  // Create a thread instance
  hcppthread_handle = new HDevThread(hcppthread_context,
              (void*)HDevExportCpp::_hcppthread_visualize_object_model_3d_ext,15,0);
  // Set thread procedure call arguments 
  hcppthread_handle->SetInputCtrlParamTuple(0,hv_WindowHandle1);
  hcppthread_handle->SetInputCtrlParamTuple(1,hv_SampledModel);
  hcppthread_handle->SetInputCtrlParamTuple(2,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(3,hv_VC_P_Model);
  hcppthread_handle->SetInputCtrlParamTuple(4,(((HTuple("color_0").Append("normal_color_0")).Append("disp_normals")).Append("disp_pose")));
  hcppthread_handle->SetInputCtrlParamTuple(5,(((HTuple("cyan").Append("gray")).Append("true")).Append("true")));
  hcppthread_handle->SetInputCtrlParamTuple(6,"Model");
  hcppthread_handle->SetInputCtrlParamTuple(7,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(8,hv_Instructions);
  hcppthread_handle->SetInputCtrlParamTuple(9,hv_MessageQueues1);
  hcppthread_handle->SetInputCtrlParamTuple(10,hv_Buttons);
  hcppthread_handle->SetInputCtrlParamTuple(11,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(12,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(13,"false");
  hcppthread_handle->SetInputCtrlParamTuple(14,HTuple());

  // Start proc line in thread
  hcppthread_handle->ParStart(&hvec_TI[0].T());


  create_visualization_message_queues(&hv_MessageQueues2);
  hv_Buttons.Clear();
  hv_Buttons[0] = "Hide Normals";
  hv_Buttons[1] = "right";
  hv_Buttons[2] = "bottom";
  hv_Buttons[3] = -1;
  hv_Buttons[4] = -1;
  hv_Buttons[5] = "Normals: fast";
  hv_Buttons[6] = "left";
  hv_Buttons[7] = "bottom";
  hv_Buttons[8] = -1;
  hv_Buttons[9] = -1;
  hv_Buttons[10] = "Normals: mls";
  hv_Buttons[11] = "center";
  hv_Buttons[12] = "bottom";
  hv_Buttons[13] = -1;
  hv_Buttons[14] = -1;
  hv_ShowNormals2 = 1;
  // Create a thread instance
  hcppthread_handle = new HDevThread(hcppthread_context,
              (void*)HDevExportCpp::_hcppthread_visualize_object_model_3d_ext,15,0);
  // Set thread procedure call arguments 
  hcppthread_handle->SetInputCtrlParamTuple(0,hv_WindowHandle2);
  hcppthread_handle->SetInputCtrlParamTuple(1,hv_SampledScene);
  hcppthread_handle->SetInputCtrlParamTuple(2,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(3,hv_VC_P_Scene);
  hcppthread_handle->SetInputCtrlParamTuple(4,(((HTuple("color_0").Append("normal_color_0")).Append("disp_normals")).Append("disp_pose")));
  hcppthread_handle->SetInputCtrlParamTuple(5,(((HTuple("cyan").Append("gray")).Append("true")).Append("true")));
  hcppthread_handle->SetInputCtrlParamTuple(6,"Scene");
  hcppthread_handle->SetInputCtrlParamTuple(7,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(8,hv_Instructions);
  hcppthread_handle->SetInputCtrlParamTuple(9,hv_MessageQueues2);
  hcppthread_handle->SetInputCtrlParamTuple(10,hv_Buttons);
  hcppthread_handle->SetInputCtrlParamTuple(11,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(12,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(13,"false");
  hcppthread_handle->SetInputCtrlParamTuple(14,HTuple());

  // Start proc line in thread
  hcppthread_handle->ParStart(&hvec_TI[1].T());

  hv_PreviousState1 = HTuple();
  hv_PreviousState2 = HTuple();
  hv_DidFinish1 = 0;
  hv_DidFinish2 = 0;
  //
  //Open a second (invisible) buffer window to avoid flickering
  GetWindowExtents(hv_WindowHandleMenu, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  OpenWindow(0, 0, hv_Width, hv_Height, 0, "buffer", "", &hv_WindowHandleBufferMenu);
  SetPart(hv_WindowHandleBufferMenu, 0, 0, hv_Height-1, hv_Width-1);
  set_display_font(hv_WindowHandleBufferMenu, hv_FontSize, "mono", "true", "false");
  //
  //Cached normals
  hv_SceneFast = HTuple();
  hv_SceneMLS = HTuple();
  GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "model_invert_normals", HTuple(), 
      &hv_NormalsInverted);
  if (0 != (hv_NormalsInverted==HTuple("true")))
  {
    hv_ModelNormalsToggled = 1;
  }
  else
  {
    hv_ModelNormalsToggled = 0;
  }
  get_find_parameter(hv_GenParamNames, hv_GenParamValues, "scene_normal_computation", 
      "fast", &hv_NormalCompMode);
  GetObjectModel3dParams(hv_Scene, "has_point_normals", &hv_SceneHasNormals);
  if (0 != (hv_SceneHasNormals==HTuple("true")))
  {
    hv_FastMethod = HTuple("(default, using existing scene normals)");
  }
  else
  {
    hv_FastMethod = HTuple("(default, using XYZ-mapping)");
  }
  (*hv_CreateNames) = HTuple();
  (*hv_CreateValues) = HTuple();
  (*hv_FindNames) = HTuple();
  (*hv_FindValues) = HTuple();
  //
  hv_Message[0] = HTuple("Check visually, if the normals of the model point approximately in the same direction as the normals of the scene by moving the model and the scene accordingly");
  if (0 != (hv_ModelNormalsToggled.TupleNot()))
  {
    hv_Message[1] = "Model normals are not inverted (default)";
  }
  else
  {
    hv_Message[1] = "Model normals are inverted";
  }
  if (0 != (hv_NormalCompMode==HTuple("fast")))
  {
    hv_Message[2] = "Scene normals are computed based on the fast method "+hv_FastMethod;
  }
  else if (0 != (hv_NormalCompMode==HTuple("mls")))
  {
    hv_Message[2] = "Scene normals are computed based on the mls method";
  }
  else
  {
    hv_Message[2] = "Scene normals are computed based on an unknown method";
  }
  hv_MessageChanged = 1;
  //
  do
  {
    //Process first visualization window
    process_visualize_events_generic(hv_WindowHandle1, hv_MessageQueues1, hv_PreviousState1, 
        &hv_DidFinish1, &hv_PreviousState1, &hv_ButtonPressed, &hv_Poses);

    if (0 != (HTuple(hv_ButtonPressed==0).TupleOr(hv_DidFinish1)))
    {
      //Exit-button
      break;
    }
    else if (0 != (hv_ButtonPressed==1))
    {
      //Invert Normals
      GetObjectModel3dParams(hv_SampledModel, HTuple("point_normal_")+((HTuple("x").Append("y")).Append("z")), 
          &hv_NXYZ);
      SetObjectModel3dAttribMod(hv_SampledModel, HTuple("point_normal_")+((HTuple("x").Append("y")).Append("z")), 
          HTuple(), -hv_NXYZ);
      //Redraw to show the flipped normals
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "force_redraw");
      EnqueueMessage(HTuple(hv_MessageQueues1[1]), hv_MessageHandle, HTuple(), HTuple());
      hv_ModelNormalsToggled = hv_ModelNormalsToggled.TupleNot();
      //Update parameter display
      if (0 != (hv_ModelNormalsToggled.TupleNot()))
      {
        hv_Message[1] = "Model normals are not inverted (default)";
        (*hv_CreateNames) = HTuple();
        (*hv_CreateValues) = HTuple();
      }
      else
      {
        hv_Message[1] = "Model normals are inverted";
        (*hv_CreateNames) = "model_invert_normals";
        (*hv_CreateValues) = "true";
      }
      hv_MessageChanged = 1;
    }
    else if (0 != (hv_ButtonPressed==2))
    {
      //Toggle normals
      hv_ShowNormals1 = hv_ShowNormals1.TupleNot();
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "toggle_param");
      SetMessageTuple(hv_MessageHandle, "param", "disp_normals");
      EnqueueMessage(HTuple(hv_MessageQueues1[1]), hv_MessageHandle, HTuple(), HTuple());
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "change_button_text");
      SetMessageTuple(hv_MessageHandle, "index", 2);
      if (0 != hv_ShowNormals1)
      {
        SetMessageTuple(hv_MessageHandle, "text", "Hide Normals");
      }
      else
      {
        SetMessageTuple(hv_MessageHandle, "text", "Show Normals");
      }
      EnqueueMessage(HTuple(hv_MessageQueues1[1]), hv_MessageHandle, HTuple(), HTuple());
    }

    //Process second visualization window
    process_visualize_events_generic(hv_WindowHandle2, hv_MessageQueues2, hv_PreviousState2, 
        &hv_DidFinish2, &hv_PreviousState2, &hv_ButtonPressed, &hv_Pose);

    if (0 != (hv_ButtonPressed==0))
    {
      hv_ShowNormals2 = hv_ShowNormals2.TupleNot();
      //Toggle normals
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "toggle_param");
      SetMessageTuple(hv_MessageHandle, "param", "disp_normals");
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "change_button_text");
      SetMessageTuple(hv_MessageHandle, "index", 0);
      if (0 != hv_ShowNormals2)
      {
        SetMessageTuple(hv_MessageHandle, "text", "Hide Normals");
      }
      else
      {
        SetMessageTuple(hv_MessageHandle, "text", "Show Normals");
      }
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
    }
    else if (0 != (hv_ButtonPressed==1))
    {
      //FAST
      //Use very fast find parameters, since we are only interested in the sampled scene
      if (0 != (hv_SceneFast==HTuple()))
      {
        FindSurfaceModel(hv_SurfaceModelID, hv_Scene, hv_RelSamplingDistance, 0.00001, 
            0, "true", ((HTuple("dense_pose_refinement").Append("sparse_pose_refinement")).Append("scene_normal_computation")), 
            ((HTuple("false").Append("false")).Append("fast")), &hv_Pose, &hv_Score, 
            &hv_SurfaceMatchingResultID);
        GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "sampled_scene", 0, 
            &hv_SceneFast);
      }
      //Send the new 3D object model to the visualization thread
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "replace_object_model");
      SetMessageTuple(hv_MessageHandle, "index", 0);
      SetMessageTuple(hv_MessageHandle, "model", hv_SceneFast);
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
      hv_Message[2] = "Scene normals are computed based on the fast method "+hv_FastMethod;
      hv_MessageChanged = 1;
      (*hv_FindNames) = HTuple();
      (*hv_FindValues) = HTuple();
    }
    else if (0 != (hv_ButtonPressed==2))
    {
      //MLS
      if (0 != (hv_SceneMLS==HTuple()))
      {
        //Use very fast find parameters, since we are only interested in the sampled scene
        FindSurfaceModel(hv_SurfaceModelID, hv_Scene, hv_RelSamplingDistance, 0.00001, 
            0, "true", ((HTuple("dense_pose_refinement").Append("sparse_pose_refinement")).Append("scene_normal_computation")), 
            ((HTuple("false").Append("false")).Append("mls")), &hv_Pose, &hv_Score, 
            &hv_SurfaceMatchingResultID);
        GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "sampled_scene", 0, 
            &hv_SceneMLS);
      }
      //Send the new 3D object model to the visualization thread
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "replace_object_model");
      SetMessageTuple(hv_MessageHandle, "index", 0);
      SetMessageTuple(hv_MessageHandle, "model", hv_SceneMLS);
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
      hv_Message[2] = "Scene normals are computed based on the mls method";
      hv_MessageChanged = 1;
      (*hv_FindNames) = "scene_normal_computation";
      (*hv_FindValues) = "mls";
    }

    //Update the menu window
    if (0 != hv_MessageChanged)
    {
      ClearWindow(hv_WindowHandleBufferMenu);
      SetColor(hv_WindowHandleBufferMenu, "black");
      disp_menu_ext(ho_MenuRegions, hv_WindowHandleBufferMenu, hv_MenuText, hv_CasesDone, 
          hv_CurrentCase);
      //
      SmallestRectangle1(ho_MenuRegions, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      SetTposition(hv_WindowHandleBufferMenu, (hv_Row2.TupleMax())+6, 1);
      write_note(hv_WindowHandleBufferMenu, "instruction", HTuple(hv_Message[0]));
      write_note(hv_WindowHandleBufferMenu, "info", HTuple(hv_Message[1]));
      write_note(hv_WindowHandleBufferMenu, "none", HTuple(hv_Message[2]));
      CopyRectangle(hv_WindowHandleBufferMenu, hv_WindowHandleMenu, 0, 0, hv_Height-1, 
          (hv_Width*2)-1, 0, 0);
      hv_MessageChanged = 0;
    }
  }
  while (0 == (hv_DidFinish1.TupleOr(hv_DidFinish2)));
  //
  //Send termination message to all subthreads
  CreateMessage(&hv_MessageHandle);
  SetMessageTuple(hv_MessageHandle, "type", "exit");
  EnqueueMessage(HTuple(hv_MessageQueues1[1]), hv_MessageHandle, HTuple(), HTuple());
  CreateMessage(&hv_MessageHandle);
  SetMessageTuple(hv_MessageHandle, "type", "exit");
  EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
  //
  hv_TIT = hvec_TI.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_TIT);
  //
  return;
}

void inspect_scene_edge_directions (HTuple hv_WindowHandle1, HTuple hv_WindowHandle2, 
    HTuple hv_SurfaceModelID, HTuple hv_ObjectModel3DScene, HTuple hv_SurfaceMatchingResultID, 
    HTuple hv_MaxGapIn, HTuple hv_MinAmplitudeIn, HTuple hv_ViewpointIn, HTuple *hv_Viewpoint)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Diameter, hv_DefaultAmplitude, hv_MinAmplitude;
  HTuple  hv_MaxAmplitude, hv_DefaultMaxGap, hv_MappingSize;
  HTuple  hv_MinMaxGap, hv_MaxMaxGap, hv_CenterScene, hv_DiameterScene;
  HTuple  hv_DiameterModel, hv_ViewpointStr, hv_Direction;
  HTuple  hv_Length, hv_LengthRel, hv_ViewpointViz, hv_ObjectModel3DSceneSampled;
  HTuple  hv_ObjectModel3DEdges, hv_EdgeDirs, hv_ObjectModel3DEdgeDirs;
  HTuple  hv_CenterSceneGravity, hv_OM3DCamera, hv_OM3DLineSphereToScene;
  HTuple  hv_DirectionLength, hv_ViewpointAsPoseIn, hv_DirNorm;
  HTuple  hv_Axis, hv_AxisNorm, hv_OrthogonalDirection, hv_RotationAxis;
  HTuple  hv_DirectionProjected, hv_AngleToX, hv_HomMat3DIdentity;
  HTuple  hv_HomMat3DRotate, hv_Instructions, hv_Row, hv_Column;
  HTuple  hv_Width, hv_Height, hv_CameraParam, hv_Buttons;
  HTuple  hv_MessageQueues1, hv_PreviousState1, hv_DidFinish1;
  HTuple  hv_VizCenter, hv_HomMat3DIdentity1, hv_PoseIn, hv_VizposeIn;
  HTuple  hv_ShowViewDir, hv_ShowEdgeDir, hv_MessageQueues2;
  HTuple  hv_PreviousState2, hv_ButtonPressed, hv_Pose, hv_MessageHandle;
  HTuple  hv_HomMat3D, hv_HomMat3DInvert, hv_Qx, hv_Qy, hv_Qz;
  HTuple  hv_DidFinish2, hv_Poses, hv_TIT;
  HTupleVector  hvec_TI(1);

  // +++ Threading variables 
  HDevThread*         hcppthread_handle;
  HDevThreadContext   hcppthread_context; // <-signals begin of procedure

  //Initial, Minimum and Maximum parameter values
  GetSurfaceModelParam(hv_SurfaceModelID, "diameter", &hv_Diameter);
  hv_DefaultAmplitude = hv_MinAmplitudeIn;
  hv_MinAmplitude = 0.0001*hv_Diameter;
  hv_MaxAmplitude = hv_Diameter;
  hv_DefaultMaxGap = hv_MaxGapIn;
  GetObjectModel3dParams(hv_ObjectModel3DScene, "mapping_size", &hv_MappingSize);
  hv_MinMaxGap = 0;
  hv_MaxMaxGap = hv_MappingSize.TupleMax();
  //
  GetObjectModel3dParams(hv_ObjectModel3DScene, "center", &hv_CenterScene);
  GetObjectModel3dParams(hv_ObjectModel3DScene, "diameter", &hv_DiameterScene);
  //
  GetSurfaceModelParam(hv_SurfaceModelID, "diameter", &hv_DiameterModel);
  (*hv_Viewpoint) = hv_ViewpointIn;
  hv_ViewpointStr = (((HTuple((*hv_Viewpoint)[0])+" ")+HTuple((*hv_Viewpoint)[1]))+" ")+HTuple((*hv_Viewpoint)[2]);
  //With this method, the viewpoint would be very far away in view 2, leading to not-so-nice
  //visualization. Adapt the distance to be always <= SceneDiameter.
  hv_Direction = (*hv_Viewpoint)-hv_CenterScene;
  hv_Length = ((hv_Direction*hv_Direction).TupleSum()).TupleSqrt();
  hv_LengthRel = hv_Length/hv_DiameterScene;
  if (0 != (hv_LengthRel>1))
  {
    hv_Direction = hv_Direction/hv_LengthRel;
  }
  hv_ViewpointViz = hv_CenterScene+hv_Direction;
  //
  GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "sampled_scene", 0, &hv_ObjectModel3DSceneSampled);
  EdgesObjectModel3d(hv_ObjectModel3DScene, hv_DefaultAmplitude, (HTuple("max_gap").Append("viewpoint")), 
      hv_DefaultMaxGap.TupleConcat(hv_ViewpointStr), &hv_ObjectModel3DEdges);
  SampleObjectModel3d(hv_ObjectModel3DEdges, "fast_compute_normals", hv_DiameterModel*0.02, 
      HTuple(), HTuple(), &hv_ObjectModel3DEdges);
  GetObjectModel3dParams(hv_ObjectModel3DEdges, HTuple("edge_dir_")+((HTuple("x").Append("y")).Append("z")), 
      &hv_EdgeDirs);
  SetObjectModel3dAttrib(hv_ObjectModel3DEdges, HTuple("point_normal_")+((HTuple("x").Append("y")).Append("z")), 
      HTuple(), hv_EdgeDirs, &hv_ObjectModel3DEdgeDirs);
  //
  //We only define a viewpoint, not a full camera. "Fake" a camera that looks towards the center of
  //gravity of the scene. Do not point it towards the center of the bounding box, since that is rather
  //unstable (a single outlier point would distort it).
  MomentsObjectModel3d(hv_ObjectModel3DScene, "mean_points", &hv_CenterSceneGravity);
  gen_camera_facing_scene(hv_ViewpointViz, hv_CenterSceneGravity, hv_DiameterModel*2, 
      &hv_OM3DCamera);
  GenObjectModel3dFromPoints(HTuple(hv_ViewpointViz[0]).TupleConcat(HTuple(hv_CenterScene[0])), 
      HTuple(hv_ViewpointViz[1]).TupleConcat(HTuple(hv_CenterScene[1])), HTuple(hv_ViewpointViz[2]).TupleConcat(HTuple(hv_CenterScene[2])), 
      &hv_OM3DLineSphereToScene);
  SetObjectModel3dAttribMod(hv_OM3DLineSphereToScene, "lines", HTuple(), ((HTuple(2).Append(0)).Append(1)));
  //
  //Convert input viewpoint into initial pose
  hv_Direction = (*hv_Viewpoint)-hv_CenterScene;
  hv_DirectionLength = ((hv_Direction*hv_Direction).TupleSum()).TupleSqrt();
  if (0 != (hv_DirectionLength<(1e-1*hv_DiameterModel)))
  {
    hv_ViewpointAsPoseIn.Clear();
    hv_ViewpointAsPoseIn[0] = 0;
    hv_ViewpointAsPoseIn[1] = 0;
    hv_ViewpointAsPoseIn[2] = 0;
    hv_ViewpointAsPoseIn[3] = 0;
    hv_ViewpointAsPoseIn[4] = 0;
    hv_ViewpointAsPoseIn[5] = 0;
    hv_ViewpointAsPoseIn[6] = 0;
  }
  else
  {
    //Create a rotation such that the camera faces the center of gravity of the scene
    hv_DirNorm = hv_Direction/hv_DirectionLength;
    if (0 != (((hv_DirNorm*((HTuple(0).Append(0)).Append(-1))).TupleSum())>-0.99999))
    {
      //Angle between the vectors is > 0.25
      hv_Axis = hv_DirNorm+((HTuple(0).Append(0)).Append(-1));
      hv_AxisNorm = hv_Axis/(((hv_Axis*hv_Axis).TupleSum()).TupleSqrt());
      tuple_vector_cross_product(hv_DirNorm, ((HTuple(0).Append(0)).Append(1)), &hv_OrthogonalDirection);
      hv_OrthogonalDirection = hv_OrthogonalDirection/(((hv_OrthogonalDirection*hv_OrthogonalDirection).TupleSum()).TupleSqrt());
    }
    else
    {
      hv_Axis.Clear();
      hv_Axis[0] = 0;
      hv_Axis[1] = 1;
      hv_Axis[2] = 0;
      hv_OrthogonalDirection.Clear();
      hv_OrthogonalDirection[0] = 1;
      hv_OrthogonalDirection[1] = 0;
      hv_OrthogonalDirection[2] = 0;
    }
    tuple_vector_cross_product(((HTuple(0).Append(0)).Append(1)), hv_OrthogonalDirection, 
        &hv_RotationAxis);
    tuple_vector_cross_product(((HTuple(0).Append(0)).Append(1)), hv_RotationAxis, 
        &hv_DirectionProjected);
    hv_AngleToX = HTuple(hv_DirectionProjected[0]).TupleAtan2(HTuple(hv_DirectionProjected[1]));
    HomMat3dIdentity(&hv_HomMat3DIdentity);
    HomMat3dRotateLocal(hv_HomMat3DIdentity, HTuple(180).TupleRad(), hv_Axis, &hv_HomMat3DRotate);
    HomMat3dToPose(hv_HomMat3DRotate, &hv_ViewpointAsPoseIn);
  }
  hv_ViewpointAsPoseIn[HTuple::TupleGenSequence(0,2,1)] = (*hv_Viewpoint);
  PoseInvert(hv_ViewpointAsPoseIn, &hv_ViewpointAsPoseIn);
  //
  //Start the first 3D visualization window
  //In this window, one can set the viewpoint position
  hv_Instructions[0] = "Rotate: Left button";
  hv_Instructions[1] = "Zoom:   Shift + left button";
  hv_Instructions[2] = "Move:   Ctrl  + left button";
  //
  GetWindowExtents(hv_WindowHandle1, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  gen_cam_par_area_scan_division(0.005, 0, 5.2e-06, 5.2e-06, (hv_Width*0.5)+0.5, 
      (hv_Height*0.5)+0.5, hv_Width, hv_Height, &hv_CameraParam);
  hv_Buttons.Clear();
  hv_Buttons[0] = "Continue";
  hv_Buttons[1] = "right";
  hv_Buttons[2] = "bottom";
  hv_Buttons[3] = -1;
  hv_Buttons[4] = -1;
  hv_Buttons[5] = "Reset";
  hv_Buttons[6] = "left";
  hv_Buttons[7] = "bottom";
  hv_Buttons[8] = -1;
  hv_Buttons[9] = -1;
  create_visualization_message_queues(&hv_MessageQueues1);
  // Create a thread instance
  hcppthread_handle = new HDevThread(hcppthread_context,
              (void*)HDevExportCpp::_hcppthread_visualize_object_model_3d_ext,15,0);
  // Set thread procedure call arguments 
  hcppthread_handle->SetInputCtrlParamTuple(0,hv_WindowHandle1);
  hcppthread_handle->SetInputCtrlParamTuple(1,hv_ObjectModel3DSceneSampled.TupleConcat(hv_ObjectModel3DEdges));
  hcppthread_handle->SetInputCtrlParamTuple(2,hv_CameraParam);
  hcppthread_handle->SetInputCtrlParamTuple(3,hv_ViewpointAsPoseIn);
  hcppthread_handle->SetInputCtrlParamTuple(4,((HTuple("color_0").Append("color_1")).Append("disp_pose")));
  hcppthread_handle->SetInputCtrlParamTuple(5,((HTuple("gray").Append("red")).Append("true")));
  hcppthread_handle->SetInputCtrlParamTuple(6,"Define Viewpoint");
  hcppthread_handle->SetInputCtrlParamTuple(7,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(8,hv_Instructions);
  hcppthread_handle->SetInputCtrlParamTuple(9,hv_MessageQueues1);
  hcppthread_handle->SetInputCtrlParamTuple(10,hv_Buttons);
  hcppthread_handle->SetInputCtrlParamTuple(11,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(12,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(13,"false");
  hcppthread_handle->SetInputCtrlParamTuple(14,HTuple());

  // Start proc line in thread
  hcppthread_handle->ParStart(&hvec_TI[0].T());

  hv_PreviousState1 = HTuple();
  hv_DidFinish1 = 0;
  //
  //Start the second 3D visualization window
  //Here, the edge directions are visualized
  //Find a viewpoint such that we see the scene and the camera "from the side".
  //This makes it easier to see what is going on.
  //To keep the scene upright, we first rotate around the x-axis, then around the
  //(original) z-axis.
  get_object_models_center(hv_ObjectModel3DSceneSampled.TupleConcat(hv_OM3DCamera), 
      &hv_VizCenter);
  HomMat3dIdentity(&hv_HomMat3DIdentity1);
  HomMat3dRotate(hv_HomMat3DIdentity1, HTuple(-90).TupleRad(), ((HTuple(1).Append(0)).Append(0)), 
      HTuple(hv_VizCenter[0]), HTuple(hv_VizCenter[1]), HTuple(hv_VizCenter[2]), 
      &hv_HomMat3DRotate);
  HomMat3dRotateLocal(hv_HomMat3DRotate, hv_AngleToX, ((HTuple(0).Append(0)).Append(1)), 
      &hv_HomMat3DRotate);
  HomMat3dToPose(hv_HomMat3DRotate, &hv_PoseIn);
  determine_optimum_pose_distance(hv_ObjectModel3DSceneSampled.TupleConcat(hv_OM3DCamera), 
      hv_CameraParam, 0.5, hv_PoseIn, &hv_VizposeIn);
  //
  hv_Buttons.Clear();
  hv_Buttons[0] = "Hide Viewing Direction";
  hv_Buttons[1] = "left";
  hv_Buttons[2] = "bottom";
  hv_Buttons[3] = -1;
  hv_Buttons[4] = -1;
  hv_Buttons[5] = "Hide Edge Direction";
  hv_Buttons[6] = "right";
  hv_Buttons[7] = "bottom";
  hv_Buttons[8] = -1;
  hv_Buttons[9] = -1;
  hv_ShowViewDir = 1;
  hv_ShowEdgeDir = 1;
  create_visualization_message_queues(&hv_MessageQueues2);
  // Create a thread instance
  hcppthread_handle = new HDevThread(hcppthread_context,
              (void*)HDevExportCpp::_hcppthread_visualize_object_model_3d_ext,15,0);
  // Set thread procedure call arguments 
  hcppthread_handle->SetInputCtrlParamTuple(0,hv_WindowHandle2);
  hcppthread_handle->SetInputCtrlParamTuple(1,(((hv_ObjectModel3DSceneSampled.TupleConcat(hv_ObjectModel3DEdges)).TupleConcat(hv_ObjectModel3DEdgeDirs)).TupleConcat(hv_OM3DCamera)).TupleConcat(hv_OM3DLineSphereToScene));
  hcppthread_handle->SetInputCtrlParamTuple(2,hv_CameraParam);
  hcppthread_handle->SetInputCtrlParamTuple(3,hv_VizposeIn);
  hcppthread_handle->SetInputCtrlParamTuple(4,(((((((HTuple("color_0").Append("color_1")).Append("color_2")).Append("color_3")).Append("color_4")).Append("disp_pose")).Append("disp_normals_1")).Append("disp_normals_2")));
  hcppthread_handle->SetInputCtrlParamTuple(5,(((((((HTuple("gray").Append("green")).Append("red")).Append("gray")).Append("white")).Append("true")).Append("true")).Append("true")));
  hcppthread_handle->SetInputCtrlParamTuple(6,"Inspect Edges");
  hcppthread_handle->SetInputCtrlParamTuple(7,((((HTuple("").Append("")).Append("")).Append("Viewpoint")).Append("")));
  hcppthread_handle->SetInputCtrlParamTuple(8,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(9,hv_MessageQueues2);
  hcppthread_handle->SetInputCtrlParamTuple(10,hv_Buttons);
  hcppthread_handle->SetInputCtrlParamTuple(11,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(12,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(13,"false");
  hcppthread_handle->SetInputCtrlParamTuple(14,HTuple());

  // Start proc line in thread
  hcppthread_handle->ParStart(&hvec_TI[1].T());

  hv_PreviousState2 = HTuple();
  //
  while (0 != (hv_DidFinish1.TupleNot()))
  {
    process_visualize_events_generic(hv_WindowHandle1, hv_MessageQueues1, hv_PreviousState1, 
        &hv_DidFinish1, &hv_PreviousState1, &hv_ButtonPressed, &hv_Pose);
    if (0 != (HTuple(hv_ButtonPressed==0).TupleOr(hv_DidFinish1)))
    {
      //Exit button pressed
      break;
    }
    else if (0 != (hv_ButtonPressed==1))
    {
      //Reset button pressed
      (*hv_Viewpoint).Clear();
      (*hv_Viewpoint)[0] = 0;
      (*hv_Viewpoint)[1] = 0;
      (*hv_Viewpoint)[2] = 0;
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "set_pose");
      SetMessageTuple(hv_MessageHandle, "poses", hv_ViewpointAsPoseIn);
      EnqueueMessage(HTuple(hv_MessageQueues1[1]), hv_MessageHandle, HTuple(), HTuple());
      //Also update the second view below
      hv_Pose = hv_ViewpointAsPoseIn;
    }
    if (0 != (hv_Pose!=HTuple()))
    {
      //The pose of view 1 was updated
      //-> Update the viewpoint in view 2
      PoseToHomMat3d(hv_Pose.TupleSelectRange(0,6), &hv_HomMat3D);
      HomMat3dInvert(hv_HomMat3D, &hv_HomMat3DInvert);
      AffineTransPoint3d(hv_HomMat3DInvert, 0, 0, 0, &hv_Qx, &hv_Qy, &hv_Qz);
      (*hv_Viewpoint).Clear();
      (*hv_Viewpoint).Append(hv_Qx);
      (*hv_Viewpoint).Append(hv_Qy);
      (*hv_Viewpoint).Append(hv_Qz);
      hv_ViewpointStr = (((HTuple((*hv_Viewpoint)[0])+" ")+HTuple((*hv_Viewpoint)[1]))+" ")+HTuple((*hv_Viewpoint)[2]);
      //With this method, the viewpoint would be very far away in view 2, leading to not-so-nice
      //visualization. Adapt the distance to be always <= SceneDiameter.
      hv_Direction = (*hv_Viewpoint)-hv_CenterScene;
      hv_Length = ((hv_Direction*hv_Direction).TupleSum()).TupleSqrt();
      hv_LengthRel = hv_Length/hv_DiameterScene;
      if (0 != (hv_LengthRel>1))
      {
        hv_Direction = hv_Direction/hv_LengthRel;
      }
      hv_ViewpointViz = hv_CenterScene+hv_Direction;
      //
      //Update title of left visualization window
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "change_title");
      SetMessageTuple(hv_MessageHandle, "title", HTuple("Define Viewpoint").TupleConcat(((((("Current Viewpoint: ["+HTuple((*hv_Viewpoint)[0]))+HTuple(","))+HTuple((*hv_Viewpoint)[1]))+HTuple(","))+HTuple((*hv_Viewpoint)[2]))+"]"));
      EnqueueMessage(HTuple(hv_MessageQueues1[1]), hv_MessageHandle, HTuple(), HTuple());
      //
      gen_camera_facing_scene(hv_ViewpointViz, hv_CenterSceneGravity, hv_DiameterModel*2, 
          &hv_OM3DCamera);

      GenObjectModel3dFromPoints(HTuple(hv_ViewpointViz[0]).TupleConcat(HTuple(hv_CenterScene[0])), 
          HTuple(hv_ViewpointViz[1]).TupleConcat(HTuple(hv_CenterScene[1])), HTuple(hv_ViewpointViz[2]).TupleConcat(HTuple(hv_CenterScene[2])), 
          &hv_OM3DLineSphereToScene);
      SetObjectModel3dAttribMod(hv_OM3DLineSphereToScene, "lines", HTuple(), ((HTuple(2).Append(0)).Append(1)));
      EdgesObjectModel3d(hv_ObjectModel3DScene, hv_DefaultAmplitude, (HTuple("max_gap").Append("viewpoint")), 
          hv_DefaultMaxGap.TupleConcat(hv_ViewpointStr), &hv_ObjectModel3DEdges);
      SampleObjectModel3d(hv_ObjectModel3DEdges, "fast_compute_normals", hv_DiameterModel*0.02, 
          HTuple(), HTuple(), &hv_ObjectModel3DEdges);
      //
      GetObjectModel3dParams(hv_ObjectModel3DEdges, HTuple("edge_dir_")+((HTuple("x").Append("y")).Append("z")), 
          &hv_EdgeDirs);
      SetObjectModel3dAttrib(hv_ObjectModel3DEdges, HTuple("point_normal_")+((HTuple("x").Append("y")).Append("z")), 
          HTuple(), hv_EdgeDirs, &hv_ObjectModel3DEdgeDirs);
      //
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "replace_object_model");
      SetMessageTuple(hv_MessageHandle, "index", (((HTuple(1).Append(2)).Append(3)).Append(4)));
      SetMessageTuple(hv_MessageHandle, "model", ((hv_ObjectModel3DEdges.TupleConcat(hv_ObjectModel3DEdgeDirs)).TupleConcat(hv_OM3DCamera)).TupleConcat(hv_OM3DLineSphereToScene));
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
    }

    process_visualize_events_generic(hv_WindowHandle2, hv_MessageQueues2, hv_PreviousState2, 
        &hv_DidFinish2, &hv_PreviousState2, &hv_ButtonPressed, &hv_Poses);
    if (0 != hv_DidFinish2)
    {
      break;
    }
    if (0 != (hv_ButtonPressed==0))
    {
      hv_ShowViewDir = hv_ShowViewDir.TupleNot();
      //Toggle viewing direction
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "toggle_param");
      SetMessageTuple(hv_MessageHandle, "param", "disp_normals_1");
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "change_button_text");
      SetMessageTuple(hv_MessageHandle, "index", 0);
      if (0 != hv_ShowViewDir)
      {
        SetMessageTuple(hv_MessageHandle, "text", "Hide Viewing Direction");
      }
      else
      {
        SetMessageTuple(hv_MessageHandle, "text", "Show Viewing Direction");
      }
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
    }
    else if (0 != (hv_ButtonPressed==1))
    {
      hv_ShowEdgeDir = hv_ShowEdgeDir.TupleNot();
      //Toggle viewing direction
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "toggle_param");
      SetMessageTuple(hv_MessageHandle, "param", "disp_normals_2");
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "change_button_text");
      SetMessageTuple(hv_MessageHandle, "index", 1);
      if (0 != hv_ShowEdgeDir)
      {
        SetMessageTuple(hv_MessageHandle, "text", "Hide Edge Direction");
      }
      else
      {
        SetMessageTuple(hv_MessageHandle, "text", "Show Edge Direction");
      }
      EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
    }
  }

  CreateMessage(&hv_MessageHandle);
  SetMessageTuple(hv_MessageHandle, "type", "exit");
  EnqueueMessage(HTuple(hv_MessageQueues1[1]), hv_MessageHandle, HTuple(), HTuple());
  CreateMessage(&hv_MessageHandle);
  SetMessageTuple(hv_MessageHandle, "type", "exit");
  EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
  //
  hv_TIT = hvec_TI.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_TIT);

  return;
}

void inspect_scene_edge_parameters (HTuple hv_WindowHandle1, HTuple hv_WindowHandle2, 
    HTuple hv_SurfaceModelID, HTuple hv_ObjectModel3DScene, HTuple hv_SurfaceMatchingResultID, 
    HTuple hv_MaxGapIn, HTuple hv_MinAmplitudeAbsIn, HTuple hv_ViewpointIn, HTuple *hv_MaxGap, 
    HTuple *hv_MinAmplitudeAbs)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Diameter, hv_DefaultAmplitude, hv_MinAmplitude;
  HTuple  hv_MaxAmplitude, hv_DefaultMaxGap, hv_MappingSize;
  HTuple  hv_MinMaxGap, hv_MaxMaxGap, hv_ViewpointStr, hv_ObjectModel3DSceneSampled;
  HTuple  hv_ObjectModel3DEdges, hv_Instructions, hv_Buttons;
  HTuple  hv_MessageQueues1, hv_PreviousState1, hv_DidFinish1;
  HTuple  hv_MessageQueues2, hv_MinAmplitudeRel, hv_XXScene;
  HTuple  hv_YYScene, hv_ZZScene, hv_PreviousState2, hv_ButtonPressed;
  HTuple  hv_Poses, hv_DidFinish2, hv_MessageHandle, hv_TIT;
  HTupleVector  hvec_TI(1);

  // +++ Threading variables 
  HDevThread*         hcppthread_handle;
  HDevThreadContext   hcppthread_context; // <-signals begin of procedure

  //Initial, Minimum and Maximum parameter values
  GetSurfaceModelParam(hv_SurfaceModelID, "diameter", &hv_Diameter);
  hv_DefaultAmplitude = hv_MinAmplitudeAbsIn/hv_Diameter;
  hv_MinAmplitude = 0.0001;
  hv_MaxAmplitude = 1;
  hv_DefaultMaxGap = hv_MaxGapIn;
  GetObjectModel3dParams(hv_ObjectModel3DScene, "mapping_size", &hv_MappingSize);
  hv_MinMaxGap = 0;
  hv_MaxMaxGap = hv_MappingSize.TupleMax();
  hv_ViewpointStr = (hv_ViewpointIn+" ").TupleSum();
  //
  GetSurfaceMatchingResult(hv_SurfaceMatchingResultID, "sampled_scene", 0, &hv_ObjectModel3DSceneSampled);
  EdgesObjectModel3d(hv_ObjectModel3DScene, hv_DefaultAmplitude*hv_Diameter, (HTuple("max_gap").Append("viewpoint")), 
      hv_DefaultMaxGap.TupleConcat(hv_ViewpointStr), &hv_ObjectModel3DEdges);
  //
  //Start the 3D visualization window
  hv_Instructions[0] = "Rotate: Left button";
  hv_Instructions[1] = "Zoom:   Shift + left button";
  hv_Instructions[2] = "Move:   Ctrl  + left button";
  //
  hv_Buttons.Clear();
  hv_Buttons[0] = "Continue";
  hv_Buttons[1] = "right";
  hv_Buttons[2] = "bottom";
  hv_Buttons[3] = -1;
  hv_Buttons[4] = -1;
  create_visualization_message_queues(&hv_MessageQueues1);
  // Create a thread instance
  hcppthread_handle = new HDevThread(hcppthread_context,
              (void*)HDevExportCpp::_hcppthread_visualize_object_model_3d_ext,15,0);
  // Set thread procedure call arguments 
  hcppthread_handle->SetInputCtrlParamTuple(0,hv_WindowHandle1);
  hcppthread_handle->SetInputCtrlParamTuple(1,hv_ObjectModel3DSceneSampled.TupleConcat(hv_ObjectModel3DEdges));
  hcppthread_handle->SetInputCtrlParamTuple(2,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(3,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(4,((HTuple("color_0").Append("color_1")).Append("disp_pose")));
  hcppthread_handle->SetInputCtrlParamTuple(5,((HTuple("gray").Append("red")).Append("true")));
  hcppthread_handle->SetInputCtrlParamTuple(6,"Inspection");
  hcppthread_handle->SetInputCtrlParamTuple(7,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(8,hv_Instructions);
  hcppthread_handle->SetInputCtrlParamTuple(9,hv_MessageQueues1);
  hcppthread_handle->SetInputCtrlParamTuple(10,hv_Buttons);
  hcppthread_handle->SetInputCtrlParamTuple(11,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(12,HTuple());
  hcppthread_handle->SetInputCtrlParamTuple(13,"false");
  hcppthread_handle->SetInputCtrlParamTuple(14,HTuple());

  // Start proc line in thread
  hcppthread_handle->ParStart(&hvec_TI[0].T());

  //
  hv_PreviousState1 = HTuple();
  hv_DidFinish1 = 0;
  //
  //Start the 2D Slider window
  create_visualization_message_queues(&hv_MessageQueues2);
  // Create a thread instance
  hcppthread_handle = new HDevThread(hcppthread_context,
              (void*)HDevExportCpp::_hcppthread_set_edge_parameter_sliders,8,2);
  // Set thread procedure call arguments 
  hcppthread_handle->SetInputCtrlParamTuple(0,hv_WindowHandle2);
  hcppthread_handle->SetInputCtrlParamTuple(1,hv_ObjectModel3DScene);
  hcppthread_handle->SetInputCtrlParamTuple(2,hv_MessageQueues2);
  hcppthread_handle->SetInputCtrlParamTuple(3,hv_MessageQueues1);
  hcppthread_handle->SetInputCtrlParamTuple(4,hv_Diameter);
  hcppthread_handle->SetInputCtrlParamTuple(5,(hv_MinAmplitude.TupleConcat(hv_MaxAmplitude)).TupleConcat(hv_DefaultAmplitude));
  hcppthread_handle->SetInputCtrlParamTuple(6,(hv_MinMaxGap.TupleConcat(hv_MaxMaxGap)).TupleConcat(hv_DefaultMaxGap));
  hcppthread_handle->SetInputCtrlParamTuple(7,hv_ViewpointIn);
  hcppthread_handle->BindOutputCtrlParamTuple(0,0,&hv_MinAmplitudeRel);
  hcppthread_handle->BindOutputCtrlParamTuple(1,0,&(*hv_MaxGap));

  // Start proc line in thread
  hcppthread_handle->ParStart(&hvec_TI[1].T());

  //
  GetObjectModel3dParams(hv_ObjectModel3DScene, "point_coord_x", &hv_XXScene);
  GetObjectModel3dParams(hv_ObjectModel3DScene, "point_coord_y", &hv_YYScene);
  GetObjectModel3dParams(hv_ObjectModel3DScene, "point_coord_z", &hv_ZZScene);
  //
  hv_PreviousState2 = HTuple();
  //
  while (0 != (hv_DidFinish1.TupleNot()))
  {
    process_visualize_events_generic(hv_WindowHandle1, hv_MessageQueues1, hv_PreviousState1, 
        &hv_DidFinish1, &hv_PreviousState1, &hv_ButtonPressed, &hv_Poses);

    if (0 != (HTuple(hv_ButtonPressed==0).TupleOr(hv_DidFinish1)))
    {
      //Exit button pressed
      break;
    }

    process_slider_events(hv_WindowHandle2, hv_MessageQueues2, hv_PreviousState2, 
        &hv_PreviousState2, &hv_DidFinish2);
    if (0 != hv_DidFinish2)
    {
      //Window closed
      break;
    }
  }

  CreateMessage(&hv_MessageHandle);
  SetMessageTuple(hv_MessageHandle, "type", "exit");
  EnqueueMessage(HTuple(hv_MessageQueues1[1]), hv_MessageHandle, HTuple(), HTuple());
  CreateMessage(&hv_MessageHandle);
  SetMessageTuple(hv_MessageHandle, "type", "exit");
  EnqueueMessage(HTuple(hv_MessageQueues2[1]), hv_MessageHandle, HTuple(), HTuple());
  //
  hv_TIT = hvec_TI.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_TIT);
  //
  //Convert from relative to absolute
  (*hv_MinAmplitudeAbs) = hv_MinAmplitudeRel*hv_Diameter;
  //
  return;
}

// Chapter: File / Misc
// Short Description: Get all image files under the given path 
void list_image_files (HTuple hv_ImageDirectory, HTuple hv_Extensions, HTuple hv_Options, 
    HTuple *hv_ImageFiles)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ImageDirectoryIndex, hv_ImageFilesTmp;
  HTuple  hv_CurrentImageDirectory, hv_HalconImages, hv_OS;
  HTuple  hv_Directories, hv_Index, hv_Length, hv_NetworkDrive;
  HTuple  hv_Substring, hv_FileExists, hv_AllFiles, hv_i;
  HTuple  hv_Selection;

  //This procedure returns all files in a given directory
  //with one of the suffixes specified in Extensions.
  //
  //Input parameters:
  //ImageDirectory: Directory or a tuple of directories with images.
  //   If a local directory is not found, the directory is searched
  //   under %HALCONIMAGES%/ImageDirectory. If %HALCONIMAGES% is not set,
  //   %HALCONROOT%/images is used instead.
  //Extensions: A string tuple containing the extensions to be found
  //   e.g. ['png','tif',jpg'] or others
  //If Extensions is set to 'default' or the empty string '',
  //   all image suffixes supported by HALCON are used.
  //Options: as in the operator list_files, except that the 'files'
  //   option is always used. Note that the 'directories' option
  //   has no effect but increases runtime, because only files are
  //   returned.
  //
  //Output parameter:
  //ImageFiles: A tuple of all found image file names
  //
  if (0 != (HTuple(HTuple(hv_Extensions==HTuple()).TupleOr(hv_Extensions==HTuple(""))).TupleOr(hv_Extensions==HTuple("default"))))
  {
    hv_Extensions.Clear();
    hv_Extensions[0] = "ima";
    hv_Extensions[1] = "tif";
    hv_Extensions[2] = "tiff";
    hv_Extensions[3] = "gif";
    hv_Extensions[4] = "bmp";
    hv_Extensions[5] = "jpg";
    hv_Extensions[6] = "jpeg";
    hv_Extensions[7] = "jp2";
    hv_Extensions[8] = "jxr";
    hv_Extensions[9] = "png";
    hv_Extensions[10] = "pcx";
    hv_Extensions[11] = "ras";
    hv_Extensions[12] = "xwd";
    hv_Extensions[13] = "pbm";
    hv_Extensions[14] = "pnm";
    hv_Extensions[15] = "pgm";
    hv_Extensions[16] = "ppm";
    //
  }
  (*hv_ImageFiles) = HTuple();
  //Loop through all given image directories.
  {
  HTuple end_val26 = (hv_ImageDirectory.TupleLength())-1;
  HTuple step_val26 = 1;
  for (hv_ImageDirectoryIndex=0; hv_ImageDirectoryIndex.Continue(end_val26, step_val26); hv_ImageDirectoryIndex += step_val26)
  {
    hv_ImageFilesTmp = HTuple();
    hv_CurrentImageDirectory = HTuple(hv_ImageDirectory[hv_ImageDirectoryIndex]);
    if (0 != (hv_CurrentImageDirectory==HTuple("")))
    {
      hv_CurrentImageDirectory = ".";
    }
    GetSystem("image_dir", &hv_HalconImages);
    GetSystem("operating_system", &hv_OS);
    if (0 != ((hv_OS.TupleSubstr(0,2))==HTuple("Win")))
    {
      hv_HalconImages = hv_HalconImages.TupleSplit(";");
    }
    else
    {
      hv_HalconImages = hv_HalconImages.TupleSplit(":");
    }
    hv_Directories = hv_CurrentImageDirectory;
    {
    HTuple end_val40 = (hv_HalconImages.TupleLength())-1;
    HTuple step_val40 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val40, step_val40); hv_Index += step_val40)
    {
      hv_Directories = hv_Directories.TupleConcat((HTuple(hv_HalconImages[hv_Index])+"/")+hv_CurrentImageDirectory);
    }
    }
    TupleStrlen(hv_Directories, &hv_Length);
    TupleGenConst(hv_Length.TupleLength(), 0, &hv_NetworkDrive);
    if (0 != ((hv_OS.TupleSubstr(0,2))==HTuple("Win")))
    {
      {
      HTuple end_val46 = (hv_Length.TupleLength())-1;
      HTuple step_val46 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val46, step_val46); hv_Index += step_val46)
      {
        if (0 != ((HTuple(hv_Directories[hv_Index]).TupleStrlen())>1))
        {
          TupleStrFirstN(HTuple(hv_Directories[hv_Index]), 1, &hv_Substring);
          if (0 != (HTuple(hv_Substring==HTuple("//")).TupleOr(hv_Substring==HTuple("\\\\"))))
          {
            hv_NetworkDrive[hv_Index] = 1;
          }
        }
      }
      }
    }
    hv_ImageFilesTmp = HTuple();
    {
    HTuple end_val56 = (hv_Directories.TupleLength())-1;
    HTuple step_val56 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val56, step_val56); hv_Index += step_val56)
    {
      FileExists(HTuple(hv_Directories[hv_Index]), &hv_FileExists);
      if (0 != hv_FileExists)
      {
        ListFiles(HTuple(hv_Directories[hv_Index]), HTuple("files").TupleConcat(hv_Options), 
            &hv_AllFiles);
        hv_ImageFilesTmp = HTuple();
        {
        HTuple end_val61 = (hv_Extensions.TupleLength())-1;
        HTuple step_val61 = 1;
        for (hv_i=0; hv_i.Continue(end_val61, step_val61); hv_i += step_val61)
        {
          TupleRegexpSelect(hv_AllFiles, ((".*"+HTuple(hv_Extensions[hv_i]))+"$").TupleConcat("ignore_case"), 
              &hv_Selection);
          hv_ImageFilesTmp = hv_ImageFilesTmp.TupleConcat(hv_Selection);
        }
        }
        TupleRegexpReplace(hv_ImageFilesTmp, (HTuple("\\\\").Append("replace_all")), 
            "/", &hv_ImageFilesTmp);
        if (0 != (HTuple(hv_NetworkDrive[hv_Index])))
        {
          TupleRegexpReplace(hv_ImageFilesTmp, (HTuple("//").Append("replace_all")), 
              "/", &hv_ImageFilesTmp);
          hv_ImageFilesTmp = "/"+hv_ImageFilesTmp;
        }
        else
        {
          TupleRegexpReplace(hv_ImageFilesTmp, (HTuple("//").Append("replace_all")), 
              "/", &hv_ImageFilesTmp);
        }
        break;
      }
    }
    }
    //Concatenate the output image paths.
    (*hv_ImageFiles) = (*hv_ImageFiles).TupleConcat(hv_ImageFilesTmp);
  }
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Get string extends of several lines. 
void max_line_width (HTuple hv_WindowHandle, HTuple hv_Lines, HTuple *hv_MaxWidth)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index, hv_Ascent, hv_Descent, hv_LineWidth;
  HTuple  hv_LineHeight;

  (*hv_MaxWidth) = 0;
  {
  HTuple end_val1 = (hv_Lines.TupleLength())-1;
  HTuple step_val1 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val1, step_val1); hv_Index += step_val1)
  {
    GetStringExtents(hv_WindowHandle, HTuple(hv_Lines[hv_Index]), &hv_Ascent, &hv_Descent, 
        &hv_LineWidth, &hv_LineHeight);
    (*hv_MaxWidth) = (hv_LineWidth.TupleConcat((*hv_MaxWidth))).TupleMax();
  }
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Get string extends of several lines. 
void max_line_width_visualize_object_model_3d (HTuple hv_WindowHandle, HTuple hv_Lines, 
    HTuple *hv_MaxWidth)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index, hv_Ascent, hv_Descent, hv_LineWidth;
  HTuple  hv_LineHeight;

  (*hv_MaxWidth) = 0;
  {
  HTuple end_val1 = (hv_Lines.TupleLength())-1;
  HTuple step_val1 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val1, step_val1); hv_Index += step_val1)
  {
    GetStringExtents(hv_WindowHandle, HTuple(hv_Lines[hv_Index]), &hv_Ascent, &hv_Descent, 
        &hv_LineWidth, &hv_LineHeight);
    (*hv_MaxWidth) = (hv_LineWidth.TupleConcat((*hv_MaxWidth))).TupleMax();
  }
  }
  return;
}

// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system. 
void obtain_3d_pose_of_match_moving_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, 
    HTuple *hv_ModelInBasePose)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_ToolInCamPose, hv_PlaneInModelPose;
  HTuple  hv_RectifyImage, hv_ScaleRectification, hv_MatchingPlaneRectifiedPartInCamPose;
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform;
  HTuple  hv_HomMat2DObject, hv_RowObject, hv_ColObject, hv_PXM;
  HTuple  hv_PYM, hv_HomMat3DObject, hv_ModelToMatchInPlanePose;
  HTuple  hv_ModelInPlanePose, hv_ModelInCamPose, hv_ModelToMatchInPlanePartRectPose;
  HTuple  hv_ModelInMatchingPlaneRectifiedPartPose, hv_BaseInToolPose;
  HTuple  hv_BaseInCamPose, hv_CamInBasePose;

  //This procedure obtains the 3D pose from the model to the base of
  //the robot.
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_Poses, "PlaneInModelPose", &hv_PlaneInModelPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (hv_RectifyImage!=HTuple("no_rectification")))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  read_message_tuple(hv_RectificationData, "MatchingPlaneRectifiedPartInCamPose", 
      &hv_MatchingPlaneRectifiedPartInCamPose);
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_ToolInBasePose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_MatchingPlaneRectifiedPartInCamPose, "Rp+T", "gba", "point", 
      &hv_MatchingPlaneRectifiedPartInCamPose);
  ConvertPoseType(hv_PlaneInModelPose, "Rp+T", "gba", "point", &hv_PlaneInModelPose);
  ConvertPoseType(hv_ToolInBasePose, "Rp+T", "gba", "point", &hv_ToolInBasePose);
  ConvertPoseType(hv_ToolInCamPose, "Rp+T", "gba", "point", &hv_ToolInCamPose);
  if (0 != ((hv_Row.TupleLength())==1))
  {
    VectorAngleToRigid(0, 0, 0, hv_Row, hv_Column, hv_Angle, &hv_HomMat2DObject);
    //Col = x, Row = y.
    if (0 != (hv_RectifyImage==HTuple("no_rectification")))
    {
      AffineTransPixel(hv_HomMat2DObject, 0, 0, &hv_RowObject, &hv_ColObject);
      ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneRectifiedPartInCamPose, 
          hv_RowObject, hv_ColObject, "m", &hv_PXM, &hv_PYM);
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PXM);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PYM);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePose);
      PoseCompose(hv_ModelToMatchInPlanePose, hv_PlaneInModelPose, &hv_ModelInPlanePose);
      PoseCompose(hv_MatchingPlaneRectifiedPartInCamPose, hv_ModelInPlanePose, &hv_ModelInCamPose);
    }
    else if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
    {
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[5])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[2])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePartRectPose);
      PoseCompose(hv_ModelToMatchInPlanePartRectPose, hv_PlaneInModelPose, &hv_ModelInMatchingPlaneRectifiedPartPose);
      PoseCompose(hv_MatchingPlaneRectifiedPartInCamPose, hv_ModelInMatchingPlaneRectifiedPartPose, 
          &hv_ModelInCamPose);
    }
    else
    {
      throw HException("Please set the parameter RectifyImage correctly");
    }
    PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
    PoseCompose(hv_ToolInCamPose, hv_BaseInToolPose, &hv_BaseInCamPose);
    PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
    PoseCompose(hv_CamInBasePose, hv_ModelInCamPose, &(*hv_ModelInBasePose));
    //
    ConvertPoseType((*hv_ModelInBasePose), hv_OrderOfTransform, hv_OrderOfRotation, 
        hv_ViewOfTransform, &(*hv_ModelInBasePose));
  }
  else
  {
    throw HException("Exactly one match should be given as input");
  }
  return;
}

// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system in a stationary camera setup. 
void obtain_3d_pose_of_match_stationary_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, HTuple *hv_ModelInBasePose)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_BaseInCamPose, hv_PlaneInModelPose;
  HTuple  hv_MatchingPlaneInCamPose, hv_RectifyImage, hv_ScaleRectification;
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform;
  HTuple  hv_HomMat2DObject, hv_RowObject, hv_ColObject, hv_PXM;
  HTuple  hv_PYM, hv_HomMat3DObject, hv_ModelToMatchInPlanePose;
  HTuple  hv_ModelInPlanePose, hv_ModelInCamPose, hv_ModelToMatchInPlanePartRectPose;
  HTuple  hv_ModelInPlanePartRectPose, hv_CamInBasePose;

  //This procedure obtains the 3D pose from the model to the base of
  //the robot.
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "BaseInCamPose", &hv_BaseInCamPose);
  read_message_tuple(hv_Poses, "PlaneInModelPose", &hv_PlaneInModelPose);
  read_message_tuple(hv_Poses, "MatchingPlaneInCamPose", &hv_MatchingPlaneInCamPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (hv_RectifyImage==HTuple("true")))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_PlaneInModelPose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_MatchingPlaneInCamPose, "Rp+T", "gba", "point", &hv_MatchingPlaneInCamPose);
  ConvertPoseType(hv_PlaneInModelPose, "Rp+T", "gba", "point", &hv_PlaneInModelPose);
  if (0 != (HTuple(HTuple((hv_Row.TupleLength())==1).TupleAnd((hv_Column.TupleLength())==1)).TupleAnd((hv_Angle.TupleLength())==1)))
  {
    VectorAngleToRigid(0, 0, 0, hv_Row, hv_Column, hv_Angle, &hv_HomMat2DObject);
    //col = x, row = y
    if (0 != (hv_RectifyImage==HTuple("false")))
    {
      AffineTransPixel(hv_HomMat2DObject, 0, 0, &hv_RowObject, &hv_ColObject);
      ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_RowObject, 
          hv_ColObject, "m", &hv_PXM, &hv_PYM);
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PXM);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PYM);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePose);
      PoseCompose(hv_ModelToMatchInPlanePose, hv_PlaneInModelPose, &hv_ModelInPlanePose);
      PoseCompose(hv_MatchingPlaneInCamPose, hv_ModelInPlanePose, &hv_ModelInCamPose);
    }
    else if (0 != (hv_RectifyImage==HTuple("true")))
    {
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[5])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[2])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePartRectPose);
      PoseCompose(hv_ModelToMatchInPlanePartRectPose, hv_PlaneInModelPose, &hv_ModelInPlanePartRectPose);
      PoseCompose(hv_MatchingPlaneInCamPose, hv_ModelInPlanePartRectPose, &hv_ModelInCamPose);
    }
    else
    {
      throw HException("Please set the parameter RectifyImage correctly");
    }
    PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
    PoseCompose(hv_CamInBasePose, hv_ModelInCamPose, &(*hv_ModelInBasePose));
    //
    ConvertPoseType((*hv_ModelInBasePose), hv_OrderOfTransform, hv_OrderOfRotation, 
        hv_ViewOfTransform, &(*hv_ModelInBasePose));
  }
  else
  {
    throw HException("Exactly one match should be given as input");
  }
  return;
}

// Chapter: Graphics / Window
// Short Description: Open a new window next to an existing one. 
void open_new_window (HTuple *hv_WindowHandle, HTuple *hv_WindowHandleGraphics)
{

  // Local control variables
  HTuple  hv_Row, hv_Column, hv_Width, hv_Height;

  WaitSeconds(0.1);
  if (HDevWindowStack::IsOpen())
    (*hv_WindowHandle) = HDevWindowStack::GetActive();
  GetWindowExtents((*hv_WindowHandle), &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  dev_open_window_fit_size(0, hv_Width+8, hv_Width, hv_Height, 600, -1, &(*hv_WindowHandleGraphics));
  set_display_font((*hv_WindowHandleGraphics), 14, "mono", "true", "false");
  SetPartStyle((*hv_WindowHandleGraphics), 2);
  return;
}

// Chapter: File / Misc
// Short Description: Parse a filename into directory, base filename, and extension 
void parse_filename (HTuple hv_FileName, HTuple *hv_BaseName, HTuple *hv_Extension, 
    HTuple *hv_Directory)
{

  // Local control variables
  HTuple  hv_DirectoryTmp, hv_Substring;

  //This procedure gets a filename (with full path) as input
  //and returns the directory path, the base filename and the extension
  //in three different strings.
  //
  //In the output path the path separators will be replaced
  //by '/' in all cases.
  //
  //The procedure shows the possibilities of regular expressions in HALCON.
  //
  //Input parameters:
  //FileName: The input filename
  //
  //Output parameters:
  //BaseName: The filename without directory description and file extension
  //Extension: The file extension
  //Directory: The directory path
  //
  //Example:
  //basename('C:/images/part_01.png',...) returns
  //BaseName = 'part_01'
  //Extension = 'png'
  //Directory = 'C:\\images\\' (on Windows systems)
  //
  //Explanation of the regular expressions:
  //
  //'([^\\\\/]*?)(?:\\.[^.]*)?$':
  //To start at the end, the '$' matches the end of the string,
  //so it is best to read the expression from right to left.
  //The part in brackets (?:\\.[^.}*) denotes a non-capturing group.
  //That means, that this part is matched, but not captured
  //in contrast to the first bracketed group ([^\\\\/], see below.)
  //\\.[^.]* matches a dot '.' followed by as many non-dots as possible.
  //So (?:\\.[^.]*)? matches the file extension, if any.
  //The '?' at the end assures, that even if no extension exists,
  //a correct match is returned.
  //The first part in brackets ([^\\\\/]*?) is a capture group,
  //which means, that if a match is found, only the part in
  //brackets is returned as a result.
  //Because both HDevelop strings and regular expressions need a '\\'
  //to describe a backslash, inside regular expressions within HDevelop
  //a backslash has to be written as '\\\\'.
  //[^\\\\/] matches any character but a slash or backslash ('\\' in HDevelop)
  //[^\\\\/]*? matches a string od 0..n characters (except '/' or '\\')
  //where the '?' after the '*' switches the greediness off,
  //that means, that the shortest possible match is returned.
  //This option is necessary to cut off the extension
  //but only if (?:\\.[^.]*)? is able to match one.
  //To summarize, the regular expression matches that part of
  //the input string, that follows after the last '/' or '\\' and
  //cuts off the extension (if any) after the last '.'.
  //
  //'\\.([^.]*)$':
  //This matches everything after the last '.' of the input string.
  //Because ([^.]) is a capturing group,
  //only the part after the dot is returned.
  //
  //'.*[\\\\/]':
  //This matches the longest substring with a '/' or a '\\' at the end.
  //
  TupleRegexpMatch(hv_FileName, ".*[\\\\/]", &hv_DirectoryTmp);
  TupleSubstr(hv_FileName, hv_DirectoryTmp.TupleStrlen(), (hv_FileName.TupleStrlen())-1, 
      &hv_Substring);
  TupleRegexpMatch(hv_Substring, "([^\\\\/]*?)(?:\\.[^.]*)?$", &(*hv_BaseName));
  TupleRegexpMatch(hv_Substring, "\\.([^.]*)$", &(*hv_Extension));
  //
  //
  //Finally all found backslashes ('\\') are converted
  //to a slash to get consistent paths
  TupleRegexpReplace(hv_DirectoryTmp, (HTuple("\\\\").Append("replace_all")), "/", 
      &(*hv_Directory));
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Plot the training error, validation error and learning rate during deep learning classifier training. 
void plot_dl_classifier_training_progress (HTuple hv_TrainingErrors, HTuple hv_ValidationErrors, 
    HTuple hv_LearningRates, HTuple hv_Epochs, HTuple hv_NumEpochs, HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_TrainingErrorPercent, hv_ValidationErrorPercent;
  HTuple  hv_AxesColor, hv_TrainingErrorColor, hv_ValidationErrorColor;
  HTuple  hv_LearningRateColor, hv_TrainingErrorFunction;
  HTuple  hv_ValidationErrorFunction, hv_LearningRateFunction;
  HTuple  hv_GenParamName, hv_GenParamValue, hv_EndYError;
  HTuple  hv_EndYLearningRate, hv_Style, hv_Flush, hv_IndexMinValError;
  HTuple  hv_Text;

  //This procedure plots the tuples training error and
  //validation error with the y-axis on the left side,
  //and the learning rate with the y-axis on the right side,
  //versus the epochs over batches on the x-axis.
  //The maximum number of epochs should be given by NumEpochs,
  //to scale the x-axis appropriately.
  //The plot is displayed in the graphics window given by WindowHandle.
  //
  //The procedure expects the input tuples TrainingErrors, ValidationErrors,
  //LearningRates, and Epochs with their values sorted in chronological order,
  //the current value in each case as last element.
  //
  //Check input parameters.
  if (0 != (hv_NumEpochs==HTuple()))
  {
    hv_NumEpochs = hv_Epochs.TupleMax();
  }
  else if (0 != ((hv_NumEpochs.TupleIsNumber())!=1))
  {
    throw HException("NumEpochs must be a number or an empty tuple.");
  }
  hv_TrainingErrorPercent = hv_TrainingErrors*100;
  hv_ValidationErrorPercent = hv_ValidationErrors*100;
  //
  //Set the colors of the axes, plots and texts.
  hv_AxesColor = "white";
  hv_TrainingErrorColor = "magenta";
  hv_ValidationErrorColor = "gold";
  hv_LearningRateColor = "dark turquoise";
  //
  //Create functions from the input tuples.
  CreateFunct1dPairs(hv_Epochs, hv_TrainingErrorPercent, &hv_TrainingErrorFunction);
  CreateFunct1dPairs(hv_Epochs, hv_ValidationErrorPercent, &hv_ValidationErrorFunction);
  CreateFunct1dPairs(hv_Epochs, hv_LearningRates, &hv_LearningRateFunction);
  //
  //Assemble generic parameters for the plots.
  hv_GenParamName.Clear();
  hv_GenParamName[0] = "axis_location_x";
  hv_GenParamName[1] = "end_x";
  hv_GenParamName[2] = "ticks_x";
  hv_GenParamName[3] = "start_y";
  hv_GenParamName[4] = "margin_top";
  hv_GenParamName[5] = "margin_right";
  hv_GenParamValue.Clear();
  hv_GenParamValue[0] = "origin";
  hv_GenParamValue.Append(hv_NumEpochs);
  hv_GenParamValue.Append((hv_NumEpochs/5)+1);
  hv_GenParamValue.Append(0);
  hv_GenParamValue.Append(70);
  hv_GenParamValue.Append(100);
  hv_EndYError = ((hv_TrainingErrorPercent.TupleConcat(hv_ValidationErrorPercent)).TupleConcat(0.1)).TupleMax();
  //Round the maximum value of the left Y-axis
  //to an integer or a real value with one decimal.
  if (0 != (hv_EndYError>=1.0))
  {
    hv_EndYError = (hv_EndYError.TupleCeil()).TupleInt();
  }
  else
  {
    hv_EndYError = ((hv_EndYError*10.0).TupleCeil())/10.0;
  }
  hv_EndYLearningRate = hv_LearningRates.TupleMax();
  //Display the first values as crosses
  //for better visibility.
  if (0 != ((hv_Epochs.TupleLength())==1))
  {
    hv_Style = "cross";
  }
  else
  {
    hv_Style = "line";
  }
  //
  //Disable flushing the graphics window temporarily
  //to avoid flickering.
  GetWindowParam(hv_WindowHandle, "flush", &hv_Flush);
  SetWindowParam(hv_WindowHandle, "flush", "false");
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  //
  //Display plots.
  plot_funct_1d(hv_WindowHandle, hv_TrainingErrorFunction, HTuple(), "Error [%]", 
      hv_TrainingErrorColor, hv_GenParamName.TupleConcat((((HTuple("axes_color").Append("end_y")).Append("ticks_y")).Append("style"))), 
      (((hv_GenParamValue.TupleConcat(hv_AxesColor)).TupleConcat(hv_EndYError)).TupleConcat(hv_EndYError/5)).TupleConcat(hv_Style));
  plot_funct_1d(hv_WindowHandle, hv_ValidationErrorFunction, HTuple(), HTuple(), 
      hv_ValidationErrorColor, hv_GenParamName.TupleConcat(((HTuple("axes_color").Append("end_y")).Append("style"))), 
      ((hv_GenParamValue.TupleConcat("none")).TupleConcat(hv_EndYError)).TupleConcat(hv_Style));
  plot_funct_1d(hv_WindowHandle, hv_LearningRateFunction, HTuple(), "Learning rate", 
      hv_LearningRateColor, hv_GenParamName.TupleConcat((((((HTuple("axes_color").Append("axis_location_y")).Append("end_y")).Append("ticks_y")).Append("format_y")).Append("style"))), 
      ((((hv_GenParamValue.TupleConcat(hv_AxesColor)).TupleConcat("right")).TupleConcat(hv_EndYLearningRate)).TupleConcat(hv_EndYLearningRate/5)).TupleConcat((HTuple(".1e").Append("step"))));
  //
  //Display current values in appropriate colors.
  hv_IndexMinValError = hv_ValidationErrorPercent.TupleFindLast(hv_ValidationErrorPercent.TupleMin());
  hv_Text = "Best validation error: "+(HTuple(hv_ValidationErrorPercent[hv_IndexMinValError]).TupleString(".1f"));
  hv_Text[1] = "Associated training error: "+(HTuple(hv_TrainingErrorPercent[hv_IndexMinValError]).TupleString(".1f"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text+" %", "window", "top", "left", 
        hv_ValidationErrorColor.TupleConcat(hv_TrainingErrorColor), "box", "false");
  hv_Text = "Learning rate: "+(HTuple(hv_LearningRates[(hv_LearningRates.TupleLength())-1]).TupleString(".1e"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "right", hv_LearningRateColor, 
        "box", "false");
  hv_Text = "Epoch: "+(HTuple(hv_Epochs[(hv_Epochs.TupleLength())-1]).TupleString(".1f"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "center", 
        "white", "box", "false");
  //
  //Flush the buffer and re-enable flushing.
  FlushBuffer(hv_WindowHandle);
  SetWindowParam(hv_WindowHandle, "flush", hv_Flush);
  return;
}

// Chapter: Graphics / Output
// Short Description:  This procedure plots tuples representing functions or curves in a coordinate system. 
void plot_funct_1d (HTuple hv_WindowHandle, HTuple hv_Function, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName, HTuple hv_GenParamValue)
{

  // Local control variables
  HTuple  hv_XValues, hv_YValues;

  //This procedure plots a function in a coordinate system.
  //
  //Input parameters:
  //
  //Function: 1D function
  //
  //XLabel: X-axis label
  //
  //XLabel: Y-axis label
  //
  //Color: Color of the plotted function
  //       If [] is given, the currently set display color is used.
  //       If 'none is given, the function is not plotted, but only
  //       the coordinate axes as specified.
  //
  //GenParamName:  Generic parameters to control the presentation
  //               The parameters are evaluated from left to right.
  //
  //               Possible Values:
  //   'axes_color': coordinate system color
  //                 Default: 'white'
  //                 If 'none' is given, no coordinate system is shown.
  //   'style': Graph style
  //            Possible values: 'line' (default), 'cross', 'step', 'filled'
  //   'clip': Clip graph to coordinate system area
  //           Possible values: 'yes' (default), 'no'
  //   'ticks': Control display of ticks on the axes
  //            If 'min_max_origin' is given (default), ticks are shown
  //            at the minimum and maximum values of the axes and at the
  //            intercept point of x- and y-axis.
  //            If 'none' is given, no ticks are shown.
  //            If any number != 0 is given, it is interpreted as distance
  //            between the ticks.
  //   'ticks_x': Control display of ticks on x-axis only
  //   'ticks_y': Control display of ticks on y-axis only
  //   'format_x': Format of the values next to the ticks of the x-axis
  //               (see tuple_string for more details).
  //   'format_y': Format of the values next to the ticks of the y-axis
  //               (see tuple_string for more details).
  //   'grid': Control display of grid lines within the coordinate system
  //           If 'min_max_origin' is given (default), grid lines are shown
  //           at the minimum and maximum values of the axes.
  //           If 'none' is given, no grid lines are shown.
  //           If any number != 0 is given, it is interpreted as distance
  //           between the grid lines.
  //   'grid_x': Control display of grid lines for the x-axis only
  //   'grid_y': Control display of grid lines for the y-axis only
  //   'grid_color': Color of the grid (default: 'dim gray')
  //   'margin': The distance in pixels of the coordinate system area
  //             to all four window borders.
  //   'margin_left': The distance in pixels of the coordinate system area
  //                  to the left window border.
  //   'margin_right': The distance in pixels of the coordinate system area
  //                   to the right window border.
  //   'margin_top': The distance in pixels of the coordinate system area
  //                 to the upper window border.
  //   'margin_bottom': The distance in pixels of the coordinate system area
  //                    to the lower window border.
  //   'start_x': Lowest x value of the x-axis
  //              Default: min(XValues)
  //   'end_x': Highest x value of the x-axis
  //            Default: max(XValues)
  //   'start_y': Lowest y value of the y-axis
  //              Default: min(YValues)
  //   'end_y': Highest y value of the y-axis
  //            Default: max(YValues)
  //   'axis_location_x': Either 'bottom', 'origin', or 'top'
  //               to position the x-axis conveniently,
  //               or the Y coordinate of the intercept point of x- and y-axis.
  //               Default: 'bottom'
  //               (Used to be called 'origin_y')
  //   'axis_location_y': Either 'left', 'origin', or 'right'
  //               to position the y-axis conveniently,
  //               or the X coordinate of the intercept point of x- and y-axis.
  //               Default: 'left'
  //               (Used to be called 'origin_x')
  //
  //GenParamValue: Values of the generic parameters of GenericParamName
  //
  //
  Funct1dToPairs(hv_Function, &hv_XValues, &hv_YValues);
  plot_tuple(hv_WindowHandle, hv_XValues, hv_YValues, hv_XLabel, hv_YLabel, hv_Color, 
      hv_GenParamName, hv_GenParamValue);
  return;
}

// Chapter: Graphics / Output
// Short Description:  This procedure plots tuples representing functions or curves in a coordinate system. 
void plot_tuple (HTuple hv_WindowHandle, HTuple hv_XValues, HTuple hv_YValues, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName, HTuple hv_GenParamValue)
{

  // Local iconic variables
  HObject  ho_ContourXGrid, ho_ContourYGrid, ho_XArrow;
  HObject  ho_YArrow, ho_ContourXTick, ho_ContourYTick, ho_Contour;
  HObject  ho_Cross, ho_Filled, ho_Stair, ho_StairTmp;

  // Local control variables
  HTuple  hv_PreviousWindowHandle, hv_ClipRegion;
  HTuple  hv_Row, hv_Column, hv_Width, hv_Height, hv_PartRow1;
  HTuple  hv_PartColumn1, hv_PartRow2, hv_PartColumn2, hv_Red;
  HTuple  hv_Green, hv_Blue, hv_DrawMode, hv_OriginStyle;
  HTuple  hv_XAxisEndValue, hv_YAxisEndValue, hv_XAxisStartValue;
  HTuple  hv_YAxisStartValue, hv_XValuesAreStrings, hv_XTickValues;
  HTuple  hv_XTicks, hv_YAxisPosition, hv_XAxisPosition, hv_LeftBorder;
  HTuple  hv_RightBorder, hv_UpperBorder, hv_LowerBorder;
  HTuple  hv_AxesColor, hv_Style, hv_Clip, hv_YTicks, hv_XGrid;
  HTuple  hv_YGrid, hv_GridColor, hv_YPosition, hv_FormatX;
  HTuple  hv_FormatY, hv_NumGenParamNames, hv_NumGenParamValues;
  HTuple  hv_GenParamIndex, hv_XGridTicks, hv_YTickDirection;
  HTuple  hv_XTickDirection, hv_XAxisWidthPx, hv_XAxisWidth;
  HTuple  hv_XScaleFactor, hv_YAxisHeightPx, hv_YAxisHeight;
  HTuple  hv_YScaleFactor, hv_YAxisOffsetPx, hv_XAxisOffsetPx;
  HTuple  hv_DotStyle, hv_XGridValues, hv_XGridStart, hv_XCoord;
  HTuple  hv_IndexGrid, hv_YGridValues, hv_YGridStart, hv_YCoord;
  HTuple  hv_Ascent, hv_Descent, hv_TextWidthXLabel, hv_TextHeightXLabel;
  HTuple  hv_TextWidthYLabel, hv_TextHeightYLabel, hv_XTickStart;
  HTuple  hv_Indices, hv_TypeTicks, hv_IndexTicks, hv_Ascent1;
  HTuple  hv_Descent1, hv_TextWidthXTicks, hv_TextHeightXTicks;
  HTuple  hv_YTickValues, hv_YTickStart, hv_TextWidthYTicks;
  HTuple  hv_TextHeightYTicks, hv_Num, hv_I, hv_YSelected;
  HTuple  hv_Y1Selected, hv_X1Selected, hv_Index, hv_Row1;
  HTuple  hv_Row2, hv_Col1, hv_Col2;

  //This procedure plots tuples representing functions
  //or curves in a coordinate system.
  //
  //Input parameters:
  //
  //XValues: X values of the function to be plotted
  //         If XValues is set to [], it is internally set to 0,1,2,...,|YValues|-1.
  //         If XValues is a tuple of strings, the values are taken as categories.
  //
  //YValues: Y values of the function(s) to be plotted
  //         If YValues is set to [], it is internally set to 0,1,2,...,|XValues|-1.
  //         The number of y values must be equal to the number of x values
  //         or an integral multiple. In the latter case,
  //         multiple functions are plotted, that share the same x values.
  //
  //XLabel: X-axis label
  //
  //XLabel: Y-axis label
  //
  //Color: Color of the plotted function
  //       If [] is given, the currently set display color is used.
  //       If 'none is given, the function is not plotted, but only
  //       the coordinate axes as specified.
  //       If more than one color is given, multiple functions
  //       can be displayed in different colors.
  //
  //GenParamName:  Generic parameters to control the presentation
  //               Possible Values:
  //   'axes_color': coordinate system color
  //                 Default: 'white'
  //                 If 'none' is given, no coordinate system is shown.
  //   'style': Graph style
  //            Possible values: 'line' (default), 'cross', 'stair', 'filled'
  //   'clip': Clip graph to coordinate system area
  //           Possible values: 'yes', 'no' (default)
  //   'ticks': Control display of ticks on the axes
  //            If 'min_max_origin' is given (default), ticks are shown
  //            at the minimum and maximum values of the axes and at the
  //            intercept point of x- and y-axis.
  //            If 'none' is given, no ticks are shown.
  //            If any number != 0 is given, it is interpreted as distance
  //            between the ticks.
  //   'ticks_x': Control display of ticks on x-axis only
  //   'ticks_y': Control display of ticks on y-axis only
  //   'format_x': Format of the values next to the ticks of the x-axis
  //               (see tuple_string for more details).
  //   'format_y': Format of the values next to the ticks of the y-axis
  //               (see tuple_string for more details).
  //   'grid': Control display of grid lines within the coordinate system
  //           If 'min_max_origin' is given (default), grid lines are shown
  //           at the minimum and maximum values of the axes.
  //           If 'none' is given, no grid lines are shown.
  //           If any number != 0 is given, it is interpreted as distance
  //           between the grid lines.
  //   'grid_x': Control display of grid lines for the x-axis only
  //   'grid_y': Control display of grid lines for the y-axis only
  //   'grid_color': Color of the grid (default: 'dim gray')
  //   'margin': The distance in pixels of the coordinate system area
  //             to all four window borders.
  //   'margin_left': The distance in pixels of the coordinate system area
  //                  to the left window border.
  //   'margin_right': The distance in pixels of the coordinate system area
  //                   to the right window border.
  //   'margin_top': The distance in pixels of the coordinate system area
  //                 to the upper window border.
  //   'margin_bottom': The distance in pixels of the coordinate system area
  //                    to the lower window border.
  //   'start_x': Lowest x value of the x-axis
  //              Default: min(XValues)
  //   'end_x': Highest x value of the x-axis
  //            Default: max(XValues)
  //   'start_y': Lowest y value of the y-axis
  //              Default: min(YValues)
  //   'end_y': Highest y value of the y-axis
  //            Default: max(YValues)
  //   'axis_location_x': Either 'bottom', 'origin', or 'top'
  //               to position the x-axis conveniently,
  //               or the Y coordinate of the intercept point of x- and y-axis.
  //               Default: 'bottom'
  //               (Used to be called 'origin_y')
  //   'axis_location_y': Either 'left', 'origin', or 'right'
  //               to position the y-axis conveniently,
  //               or the X coordinate of the intercept point of x- and y-axis.
  //               Default: 'left'
  //               (Used to be called 'origin_x')
  //
  //GenParamValue: Values of the generic parameters of GenericParamName
  //
  //
  //Store current display settings
  if (HDevWindowStack::IsOpen())
    hv_PreviousWindowHandle = HDevWindowStack::GetActive();
  HDevWindowStack::SetActive(hv_WindowHandle);
  GetSystem("clip_region", &hv_ClipRegion);
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  GetPart(hv_WindowHandle, &hv_PartRow1, &hv_PartColumn1, &hv_PartRow2, &hv_PartColumn2);
  GetRgb(hv_WindowHandle, &hv_Red, &hv_Green, &hv_Blue);
  GetDraw(hv_WindowHandle, &hv_DrawMode);
  GetLineStyle(hv_WindowHandle, &hv_OriginStyle);
  //
  //Set display parameters
  SetLineStyle(hv_WindowHandle, HTuple());
  SetSystem("clip_region", "false");
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  //
  //Check input coordinates
  //
  if (0 != (HTuple(hv_XValues==HTuple()).TupleAnd(hv_YValues==HTuple())))
  {
    //Neither XValues nor YValues are given:
    //Set axes to interval [0,1]
    hv_XAxisEndValue = 1;
    hv_YAxisEndValue = 1;
    hv_XAxisStartValue = 0;
    hv_YAxisStartValue = 0;
    hv_XValuesAreStrings = 0;
  }
  else
  {
    if (0 != (hv_XValues==HTuple()))
    {
      //XValues are omitted:
      //Set equidistant XValues
      hv_XValues = HTuple::TupleGenSequence(0,(hv_YValues.TupleLength())-1,1);
      hv_XValuesAreStrings = 0;
    }
    else if (0 != (hv_YValues==HTuple()))
    {
      //YValues are omitted:
      //Set equidistant YValues
      hv_YValues = HTuple::TupleGenSequence(0,(hv_XValues.TupleLength())-1,1);
    }
    if (0 != (((hv_YValues.TupleLength())%(hv_XValues.TupleLength()))!=0))
    {
      //Number of YValues does not match number of XValues
      throw HException("Number of YValues is no multiple of the number of XValues!");
      return;
    }
    hv_XValuesAreStrings = hv_XValues.TupleIsStringElem();
    hv_XValuesAreStrings = (hv_XValuesAreStrings.TupleSum())==(hv_XValuesAreStrings.TupleLength());
    if (0 != hv_XValuesAreStrings)
    {
      //XValues are given as strings:
      //Show XValues as ticks
      hv_XTickValues = hv_XValues;
      hv_XTicks = 1;
      //Set x-axis dimensions
      hv_XValues = HTuple::TupleGenSequence(1,hv_XValues.TupleLength(),1);
    }
    //Set default x-axis dimensions
    if (0 != ((hv_XValues.TupleLength())>1))
    {
      hv_XAxisStartValue = hv_XValues.TupleMin();
      hv_XAxisEndValue = hv_XValues.TupleMax();
    }
    else
    {
      hv_XAxisEndValue = HTuple(hv_XValues[0])+0.5;
      hv_XAxisStartValue = HTuple(hv_XValues[0])-0.5;
    }
  }
  //Set default y-axis dimensions
  if (0 != ((hv_YValues.TupleLength())>1))
  {
    hv_YAxisStartValue = hv_YValues.TupleMin();
    hv_YAxisEndValue = hv_YValues.TupleMax();
  }
  else if (0 != ((hv_YValues.TupleLength())==1))
  {
    hv_YAxisStartValue = HTuple(hv_YValues[0])-0.5;
    hv_YAxisEndValue = HTuple(hv_YValues[0])+0.5;
  }
  else
  {
    hv_YAxisStartValue = 0;
    hv_YAxisEndValue = 1;
  }
  //Set default interception point of x- and y- axis
  hv_YAxisPosition = "default";
  hv_XAxisPosition = "default";
  //
  //Set more defaults
  hv_LeftBorder = hv_Width*0.1;
  hv_RightBorder = hv_Width*0.1;
  hv_UpperBorder = hv_Height*0.1;
  hv_LowerBorder = hv_Height*0.1;
  hv_AxesColor = "white";
  hv_Style = "line";
  hv_Clip = "no";
  hv_XTicks = "min_max_origin";
  hv_YTicks = "min_max_origin";
  hv_XGrid = "none";
  hv_YGrid = "none";
  hv_GridColor = "dim gray";
  hv_YPosition = "left";
  hv_FormatX = "default";
  hv_FormatY = "default";
  //
  //Parse generic parameters
  //
  hv_NumGenParamNames = hv_GenParamName.TupleLength();
  hv_NumGenParamValues = hv_GenParamValue.TupleLength();
  if (0 != (hv_NumGenParamNames!=hv_NumGenParamValues))
  {
    throw HException("Number of generic parameter names does not match generic parameter values!");
    return;
  }
  //
  {
  HTuple end_val190 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val190 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val190, step_val190); hv_GenParamIndex += step_val190)
  {
    //
    //Set 'axes_color'
    if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("axes_color")))
    {
      hv_AxesColor = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'style'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("style")))
    {
      hv_Style = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'clip'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("clip")))
    {
      hv_Clip = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      if (0 != (HTuple(hv_Clip!=HTuple("yes")).TupleAnd(hv_Clip!=HTuple("no"))))
      {
        throw HException(("Unsupported clipping option: '"+hv_Clip)+"'");
      }
      //
      //Set 'ticks'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("ticks")))
    {
      hv_XTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_YTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'ticks_x'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("ticks_x")))
    {
      hv_XTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'ticks_y'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("ticks_y")))
    {
      hv_YTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'grid'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid")))
    {
      hv_XGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_YGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_XGridTicks = hv_XTicks;
      //
      //Set 'grid_x'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid_x")))
    {
      hv_XGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'grid_y'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid_y")))
    {
      hv_YGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'grid_color'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid_color")))
    {
      hv_GridColor = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'start_x'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("start_x")))
    {
      hv_XAxisStartValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'end_x'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("end_x")))
    {
      hv_XAxisEndValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'start_y'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("start_y")))
    {
      hv_YAxisStartValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'end_y'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("end_y")))
    {
      hv_YAxisEndValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'axis_location_y' (old name 'origin_x')
    }
    else if (0 != (HTuple(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("axis_location_y")).TupleOr(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("origin_x"))))
    {
      hv_YAxisPosition = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'axis_location_x' (old name: 'origin_y')
    }
    else if (0 != (HTuple(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("axis_location_x")).TupleOr(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("origin_y"))))
    {
      hv_XAxisPosition = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin")))
    {
      hv_LeftBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_RightBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_UpperBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_LowerBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin_left'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_left")))
    {
      hv_LeftBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin_right'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_right")))
    {
      hv_RightBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin_top'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_top")))
    {
      hv_UpperBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin_bottom'
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_bottom")))
    {
      hv_LowerBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("format_x")))
    {
      hv_FormatX = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("format_y")))
    {
      hv_FormatY = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //Check consistency of start and end values
  //of the axes.
  if (0 != (hv_XAxisStartValue>hv_XAxisEndValue))
  {
    throw HException("Value for 'start_x' is greater than value for 'end_x'");
  }
  if (0 != (hv_YAxisStartValue>hv_YAxisEndValue))
  {
    throw HException("Value for 'start_y' is greater than value for 'end_y'");
  }
  //
  //Set the position of the y-axis.
  if (0 != (hv_YAxisPosition==HTuple("default")))
  {
    hv_YAxisPosition = hv_XAxisStartValue;
  }
  if (0 != ((hv_YAxisPosition.TupleIsString())==1))
  {
    if (0 != (hv_YAxisPosition==HTuple("left")))
    {
      hv_YAxisPosition = hv_XAxisStartValue;
    }
    else if (0 != (hv_YAxisPosition==HTuple("right")))
    {
      hv_YAxisPosition = hv_XAxisEndValue;
    }
    else if (0 != (hv_YAxisPosition==HTuple("origin")))
    {
      hv_YAxisPosition = 0;
    }
    else
    {
      throw HException(("Unsupported axis_location_y: '"+hv_YAxisPosition)+"'");
    }
  }
  //Set the position of the ticks on the y-axis
  //depending of the location of the y-axis.
  if (0 != (((hv_XAxisStartValue.TupleConcat(hv_XAxisEndValue)).TupleMean())>hv_YAxisPosition))
  {
    hv_YTickDirection = "right";
  }
  else
  {
    hv_YTickDirection = "left";
  }
  //
  //Set the position of the x-axis.
  if (0 != (hv_XAxisPosition==HTuple("default")))
  {
    hv_XAxisPosition = hv_YAxisStartValue;
  }
  if (0 != ((hv_XAxisPosition.TupleIsString())==1))
  {
    if (0 != (hv_XAxisPosition==HTuple("bottom")))
    {
      hv_XAxisPosition = hv_YAxisStartValue;
    }
    else if (0 != (hv_XAxisPosition==HTuple("top")))
    {
      hv_XAxisPosition = hv_YAxisEndValue;
    }
    else if (0 != (hv_XAxisPosition==HTuple("origin")))
    {
      hv_XAxisPosition = 0;
    }
    else
    {
      throw HException(("Unsupported axis_location_x: '"+hv_XAxisPosition)+"'");
    }
  }
  //Set the position of the ticks on the y-axis
  //depending of the location of the y-axis.
  if (0 != (((hv_YAxisStartValue.TupleConcat(hv_YAxisEndValue)).TupleMean())>hv_XAxisPosition))
  {
    hv_XTickDirection = "up";
  }
  else
  {
    hv_XTickDirection = "down";
  }
  //
  //Calculate basic pixel coordinates and scale factors
  //
  hv_XAxisWidthPx = (hv_Width-hv_LeftBorder)-hv_RightBorder;
  hv_XAxisWidth = hv_XAxisEndValue-hv_XAxisStartValue;
  if (0 != (hv_XAxisWidth==0))
  {
    hv_XAxisStartValue = hv_XAxisStartValue-0.5;
    hv_XAxisEndValue += 0.5;
    hv_XAxisWidth = 1;
  }
  hv_XScaleFactor = hv_XAxisWidthPx/(hv_XAxisWidth.TupleReal());
  hv_YAxisHeightPx = (hv_Height-hv_LowerBorder)-hv_UpperBorder;
  hv_YAxisHeight = hv_YAxisEndValue-hv_YAxisStartValue;
  if (0 != (hv_YAxisHeight==0))
  {
    hv_YAxisStartValue = hv_YAxisStartValue-0.5;
    hv_YAxisEndValue += 0.5;
    hv_YAxisHeight = 1;
  }
  hv_YScaleFactor = hv_YAxisHeightPx/(hv_YAxisHeight.TupleReal());
  hv_YAxisOffsetPx = (hv_YAxisPosition-hv_XAxisStartValue)*hv_XScaleFactor;
  hv_XAxisOffsetPx = (hv_XAxisPosition-hv_YAxisStartValue)*hv_YScaleFactor;
  //
  //Display grid lines
  //
  if (0 != (hv_GridColor!=HTuple("none")))
  {
    hv_DotStyle.Clear();
    hv_DotStyle[0] = 5;
    hv_DotStyle[1] = 7;
    SetLineStyle(hv_WindowHandle, hv_DotStyle);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_GridColor);
    //
    //Display x grid lines
    if (0 != (hv_XGrid!=HTuple("none")))
    {
      if (0 != (hv_XGrid==HTuple("min_max_origin")))
      {
        //Calculate 'min_max_origin' grid line coordinates
        if (0 != (hv_YAxisPosition==hv_XAxisStartValue))
        {
          hv_XGridValues.Clear();
          hv_XGridValues.Append(hv_XAxisStartValue);
          hv_XGridValues.Append(hv_XAxisEndValue);
        }
        else
        {
          hv_XGridValues.Clear();
          hv_XGridValues.Append(hv_XAxisStartValue);
          hv_XGridValues.Append(hv_YAxisPosition);
          hv_XGridValues.Append(hv_XAxisEndValue);
        }
      }
      else
      {
        //Calculate equidistant grid line coordinates
        hv_XGridStart = ((hv_XAxisStartValue/hv_XGrid).TupleCeil())*hv_XGrid;
        hv_XGridValues = HTuple::TupleGenSequence(hv_XGridStart,hv_XAxisEndValue,hv_XGrid);
      }
      hv_XCoord = (hv_XGridValues-hv_XAxisStartValue)*hv_XScaleFactor;
      //Generate and display grid lines
      {
      HTuple end_val392 = (hv_XGridValues.TupleLength())-1;
      HTuple step_val392 = 1;
      for (hv_IndexGrid=0; hv_IndexGrid.Continue(end_val392, step_val392); hv_IndexGrid += step_val392)
      {
        GenContourPolygonXld(&ho_ContourXGrid, (hv_Height-hv_LowerBorder).TupleConcat(hv_UpperBorder), 
            (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexGrid])).TupleConcat(hv_LeftBorder+HTuple(hv_XCoord[hv_IndexGrid])));
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourXGrid, HDevWindowStack::GetActive());
      }
      }
    }
    //
    //Display y grid lines
    if (0 != (hv_YGrid!=HTuple("none")))
    {
      if (0 != (hv_YGrid==HTuple("min_max_origin")))
      {
        //Calculate 'min_max_origin' grid line coordinates
        if (0 != (hv_XAxisPosition==hv_YAxisStartValue))
        {
          hv_YGridValues.Clear();
          hv_YGridValues.Append(hv_YAxisStartValue);
          hv_YGridValues.Append(hv_YAxisEndValue);
        }
        else
        {
          hv_YGridValues.Clear();
          hv_YGridValues.Append(hv_YAxisStartValue);
          hv_YGridValues.Append(hv_XAxisPosition);
          hv_YGridValues.Append(hv_YAxisEndValue);
        }
      }
      else
      {
        //Calculate equidistant grid line coordinates
        hv_YGridStart = ((hv_YAxisStartValue/hv_YGrid).TupleCeil())*hv_YGrid;
        hv_YGridValues = HTuple::TupleGenSequence(hv_YGridStart,hv_YAxisEndValue,hv_YGrid);
      }
      hv_YCoord = (hv_YGridValues-hv_YAxisStartValue)*hv_YScaleFactor;
      //Generate and display grid lines
      {
      HTuple end_val414 = (hv_YGridValues.TupleLength())-1;
      HTuple step_val414 = 1;
      for (hv_IndexGrid=0; hv_IndexGrid.Continue(end_val414, step_val414); hv_IndexGrid += step_val414)
      {
        GenContourPolygonXld(&ho_ContourYGrid, ((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexGrid])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexGrid])), 
            hv_LeftBorder.TupleConcat(hv_Width-hv_RightBorder));
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourYGrid, HDevWindowStack::GetActive());
      }
      }
    }
  }
  SetLineStyle(hv_WindowHandle, HTuple());
  //
  //
  //Display the coordinate system axes
  if (0 != (hv_AxesColor!=HTuple("none")))
  {
    //Display axes
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_AxesColor);
    gen_arrow_contour_xld(&ho_XArrow, (hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx, 
        hv_LeftBorder, (hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx, hv_Width-hv_RightBorder, 
        0, 0);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_XArrow, HDevWindowStack::GetActive());
    gen_arrow_contour_xld(&ho_YArrow, hv_Height-hv_LowerBorder, hv_LeftBorder+hv_YAxisOffsetPx, 
        hv_UpperBorder, hv_LeftBorder+hv_YAxisOffsetPx, 0, 0);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_YArrow, HDevWindowStack::GetActive());
    //Display labels
    GetStringExtents(hv_WindowHandle, hv_XLabel, &hv_Ascent, &hv_Descent, &hv_TextWidthXLabel, 
        &hv_TextHeightXLabel);
    GetStringExtents(hv_WindowHandle, hv_YLabel, &hv_Ascent, &hv_Descent, &hv_TextWidthYLabel, 
        &hv_TextHeightYLabel);
    if (0 != (hv_YTickDirection==HTuple("right")))
    {
      if (0 != (hv_XTickDirection==HTuple("up")))
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-3, 
              ((hv_Width-hv_RightBorder)-hv_TextWidthXLabel)-3, hv_AxesColor, "box", 
              "false");
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", hv_UpperBorder, 
              (hv_LeftBorder+3)+hv_YAxisOffsetPx, hv_AxesColor, "box", "false");
      }
      else
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)+3)-hv_XAxisOffsetPx, 
              ((hv_Width-hv_RightBorder)-hv_TextWidthXLabel)-3, hv_AxesColor, "box", 
              "false");
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-3, 
              (hv_LeftBorder+3)+hv_YAxisOffsetPx, hv_AxesColor, "box", "false");
      }
    }
    else
    {
      if (0 != (hv_XTickDirection==HTuple("up")))
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)-(2*hv_TextHeightXLabel))+3, 
              hv_LeftBorder-3, hv_AxesColor, "box", "false");
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", hv_UpperBorder, 
              ((hv_Width-hv_RightBorder)-hv_TextWidthYLabel)-13, hv_AxesColor, "box", 
              "false");
      }
      else
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)+3)-hv_XAxisOffsetPx, 
              hv_LeftBorder-3, hv_AxesColor, "box", "false");
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-3, 
              ((hv_Width-hv_RightBorder)-(2*hv_TextWidthYLabel))-3, hv_AxesColor, 
              "box", "false");
      }
    }
  }
  //
  //Display ticks
  //
  if (0 != (hv_AxesColor!=HTuple("none")))
  {
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_AxesColor);
    if (0 != (hv_XTicks!=HTuple("none")))
    {
      //
      //Display x ticks
      if (0 != hv_XValuesAreStrings)
      {
        //Display string XValues as categories
        hv_XTicks = (hv_XValues.TupleLength())/(hv_XTickValues.TupleLength());
        hv_XCoord = (hv_XValues-hv_XAxisStartValue)*hv_XScaleFactor;
      }
      else
      {
        //Display tick values
        if (0 != (hv_XTicks==HTuple("min_max_origin")))
        {
          //Calculate 'min_max_origin' tick coordinates
          if (0 != (hv_YAxisPosition==hv_XAxisStartValue))
          {
            hv_XTickValues.Clear();
            hv_XTickValues.Append(hv_XAxisStartValue);
            hv_XTickValues.Append(hv_XAxisEndValue);
          }
          else
          {
            hv_XTickValues.Clear();
            hv_XTickValues.Append(hv_XAxisStartValue);
            hv_XTickValues.Append(hv_YAxisPosition);
            hv_XTickValues.Append(hv_XAxisEndValue);
          }
        }
        else
        {
          //Calculate equidistant tick coordinates
          hv_XTickStart = ((hv_XAxisStartValue/hv_XTicks).TupleCeil())*hv_XTicks;
          hv_XTickValues = HTuple::TupleGenSequence(hv_XTickStart,hv_XAxisEndValue,hv_XTicks);
        }
        //Remove ticks that are smaller than the x-axis start.
        hv_Indices = (hv_XTickValues.TupleLessElem(hv_XAxisStartValue)).TupleFind(1);
        hv_XCoord = (hv_XTickValues-hv_XAxisStartValue)*hv_XScaleFactor;
        hv_XCoord = hv_XCoord.TupleRemove(hv_Indices);
        hv_XTickValues = hv_XTickValues.TupleRemove(hv_Indices);
        //
        if (0 != (hv_FormatX==HTuple("default")))
        {
          hv_TypeTicks = hv_XTicks.TupleType();
          if (0 != (hv_TypeTicks==4))
          {
            //String ('min_max_origin')
            //Format depends on actual values
            hv_TypeTicks = hv_XTickValues.TupleType();
          }
          if (0 != (hv_TypeTicks==1))
          {
            //Round to integer
            hv_XTickValues = hv_XTickValues.TupleInt();
          }
          else
          {
            //Use floating point numbers
            hv_XTickValues = hv_XTickValues.TupleString(".2f");
          }
        }
        else
        {
          hv_XTickValues = hv_XTickValues.TupleString(hv_FormatX);
        }
      }
      //Generate and display ticks
      {
      HTuple end_val503 = (hv_XTickValues.TupleLength())-1;
      HTuple step_val503 = 1;
      for (hv_IndexTicks=0; hv_IndexTicks.Continue(end_val503, step_val503); hv_IndexTicks += step_val503)
      {
        GetStringExtents(hv_WindowHandle, HTuple(hv_XTickValues[hv_IndexTicks]), 
            &hv_Ascent1, &hv_Descent1, &hv_TextWidthXTicks, &hv_TextHeightXTicks);
        if (0 != (hv_XTickDirection==HTuple("up")))
        {
          GenContourPolygonXld(&ho_ContourXTick, ((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx).TupleConcat(((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx)-5), 
              (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])).TupleConcat(hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])));
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),HTuple(hv_XTickValues[hv_IndexTicks]), 
                "image", ((hv_Height-hv_LowerBorder)+2)-hv_XAxisOffsetPx, hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks]), 
                hv_AxesColor, "box", "false");
        }
        else
        {
          GenContourPolygonXld(&ho_ContourXTick, (((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx)+5).TupleConcat((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx), 
              (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])).TupleConcat(hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])));
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),HTuple(hv_XTickValues[hv_IndexTicks]), 
                "image", ((hv_Height-hv_LowerBorder)-(2*hv_TextHeightXTicks))-hv_XAxisOffsetPx, 
                hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks]), hv_AxesColor, "box", 
                "false");
        }
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourXTick, HDevWindowStack::GetActive());
      }
      }
    }
    //
    if (0 != (hv_YTicks!=HTuple("none")))
    {
      //
      //Display y ticks
      if (0 != (hv_YTicks==HTuple("min_max_origin")))
      {
        //Calculate 'min_max_origin' tick coordinates
        if (0 != (hv_XAxisPosition==hv_YAxisStartValue))
        {
          hv_YTickValues.Clear();
          hv_YTickValues.Append(hv_YAxisStartValue);
          hv_YTickValues.Append(hv_YAxisEndValue);
        }
        else
        {
          hv_YTickValues.Clear();
          hv_YTickValues.Append(hv_YAxisStartValue);
          hv_YTickValues.Append(hv_XAxisPosition);
          hv_YTickValues.Append(hv_YAxisEndValue);
        }
      }
      else
      {
        //Calculate equidistant tick coordinates
        hv_YTickStart = ((hv_YAxisStartValue/hv_YTicks).TupleCeil())*hv_YTicks;
        hv_YTickValues = HTuple::TupleGenSequence(hv_YTickStart,hv_YAxisEndValue,hv_YTicks);
      }
      //Remove ticks that are smaller than the y-axis start.
      hv_Indices = (hv_YTickValues.TupleLessElem(hv_YAxisStartValue)).TupleFind(1);
      hv_YCoord = (hv_YTickValues-hv_YAxisStartValue)*hv_YScaleFactor;
      hv_YCoord = hv_YCoord.TupleRemove(hv_Indices);
      hv_YTickValues = hv_YTickValues.TupleRemove(hv_Indices);
      //
      if (0 != (hv_FormatY==HTuple("default")))
      {
        hv_TypeTicks = hv_YTicks.TupleType();
        if (0 != (hv_TypeTicks==4))
        {
          //String ('min_max_origin')
          //Format depends on actual values
          hv_TypeTicks = hv_YTickValues.TupleType();
        }
        if (0 != (hv_TypeTicks==1))
        {
          //Round to integer
          hv_YTickValues = hv_YTickValues.TupleInt();
        }
        else
        {
          //Use floating point numbers
          hv_YTickValues = hv_YTickValues.TupleString(".2f");
        }
      }
      else
      {
        hv_YTickValues = hv_YTickValues.TupleString(hv_FormatY);
      }
      //Generate and display ticks
      {
      HTuple end_val555 = (hv_YTickValues.TupleLength())-1;
      HTuple step_val555 = 1;
      for (hv_IndexTicks=0; hv_IndexTicks.Continue(end_val555, step_val555); hv_IndexTicks += step_val555)
      {
        GetStringExtents(hv_WindowHandle, HTuple(hv_YTickValues[hv_IndexTicks]), 
            &hv_Ascent1, &hv_Descent1, &hv_TextWidthYTicks, &hv_TextHeightYTicks);
        if (0 != (hv_YTickDirection==HTuple("right")))
        {
          GenContourPolygonXld(&ho_ContourYTick, ((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])), 
              (hv_LeftBorder+hv_YAxisOffsetPx).TupleConcat((hv_LeftBorder+hv_YAxisOffsetPx)+5));
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),HTuple(hv_YTickValues[hv_IndexTicks]), 
                "image", (((hv_Height-hv_LowerBorder)-hv_TextHeightYTicks)+3)-HTuple(hv_YCoord[hv_IndexTicks]), 
                ((hv_LeftBorder-hv_TextWidthYTicks)-2)+hv_YAxisOffsetPx, hv_AxesColor, 
                "box", "false");
        }
        else
        {
          GenContourPolygonXld(&ho_ContourYTick, ((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])), 
              ((hv_LeftBorder+hv_YAxisOffsetPx)-5).TupleConcat(hv_LeftBorder+hv_YAxisOffsetPx));
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),HTuple(hv_YTickValues[hv_IndexTicks]), 
                "image", (((hv_Height-hv_LowerBorder)-hv_TextHeightYTicks)+3)-HTuple(hv_YCoord[hv_IndexTicks]), 
                (hv_LeftBorder+2)+hv_YAxisOffsetPx, hv_AxesColor, "box", "false");
        }
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourYTick, HDevWindowStack::GetActive());
      }
      }
    }
  }
  //
  //Display function plot
  //
  if (0 != (hv_Color!=HTuple("none")))
  {
    if (0 != (HTuple(hv_XValues!=HTuple()).TupleAnd(hv_YValues!=HTuple())))
    {
      hv_Num = (hv_YValues.TupleLength())/(hv_XValues.TupleLength());
      //
      //Iterate over all functions to be displayed
      {
      HTuple end_val576 = hv_Num-1;
      HTuple step_val576 = 1;
      for (hv_I=0; hv_I.Continue(end_val576, step_val576); hv_I += step_val576)
      {
        //Select y values for current function
        hv_YSelected = hv_YValues.TupleSelectRange(hv_I*(hv_XValues.TupleLength()),((hv_I+1)*(hv_XValues.TupleLength()))-1);
        //Set color
        if (0 != (hv_Color==HTuple()))
        {
          SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
        }
        else
        {
          if (HDevWindowStack::IsOpen())
            SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
        }
        //
        //Display in different styles
        //
        if (0 != (HTuple(hv_Style==HTuple("line")).TupleOr(hv_Style==HTuple())))
        {
          //Line
          GenContourPolygonXld(&ho_Contour, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor));
          //Clip, if necessary
          if (0 != (hv_Clip==HTuple("yes")))
          {
            ClipContoursXld(ho_Contour, &ho_Contour, hv_UpperBorder, hv_LeftBorder, 
                hv_Height-hv_LowerBorder, hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Contour, HDevWindowStack::GetActive());
        }
        else if (0 != (hv_Style==HTuple("cross")))
        {
          //Cross
          GenCrossContourXld(&ho_Cross, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor), 
              6, 0.785398);
          //Clip, if necessary
          if (0 != (hv_Clip==HTuple("yes")))
          {
            ClipContoursXld(ho_Cross, &ho_Cross, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder, 
                hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Cross, HDevWindowStack::GetActive());
        }
        else if (0 != (hv_Style==HTuple("filled")))
        {
          //Filled
          hv_Y1Selected.Clear();
          hv_Y1Selected.Append(0+hv_XAxisPosition);
          hv_Y1Selected.Append(hv_YSelected);
          hv_Y1Selected.Append(0+hv_XAxisPosition);
          hv_X1Selected.Clear();
          hv_X1Selected.Append(hv_XValues.TupleMin());
          hv_X1Selected.Append(hv_XValues);
          hv_X1Selected.Append(hv_XValues.TupleMax());
          if (HDevWindowStack::IsOpen())
            SetDraw(HDevWindowStack::GetActive(),"fill");
          GenRegionPolygonFilled(&ho_Filled, ((hv_Height-hv_LowerBorder)-(hv_Y1Selected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_X1Selected*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor));
          //Clip, if necessary
          if (0 != (hv_Clip==HTuple("yes")))
          {
            ClipRegion(ho_Filled, &ho_Filled, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder, 
                hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Filled, HDevWindowStack::GetActive());
        }
        else if (0 != (hv_Style==HTuple("step")))
        {
          GenEmptyObj(&ho_Stair);
          {
          HTuple end_val617 = (hv_XValues.TupleLength())-2;
          HTuple step_val617 = 1;
          for (hv_Index=0; hv_Index.Continue(end_val617, step_val617); hv_Index += step_val617)
          {
            hv_Row1 = ((hv_Height-hv_LowerBorder)-(HTuple(hv_YSelected[hv_Index])*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor);
            hv_Row2 = ((hv_Height-hv_LowerBorder)-(HTuple(hv_YSelected[hv_Index+1])*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor);
            hv_Col1 = ((HTuple(hv_XValues[hv_Index])*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor);
            hv_Col2 = ((HTuple(hv_XValues[hv_Index+1])*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor);
            GenContourPolygonXld(&ho_StairTmp, (hv_Row1.TupleConcat(hv_Row1)).TupleConcat(hv_Row2), 
                (hv_Col1.TupleConcat(hv_Col2)).TupleConcat(hv_Col2));
            ConcatObj(ho_Stair, ho_StairTmp, &ho_Stair);
          }
          }
          UnionAdjacentContoursXld(ho_Stair, &ho_Stair, 0.1, 0.1, "attr_keep");
          if (0 != (hv_Clip==HTuple("yes")))
          {
            ClipRegion(ho_Stair, &ho_Stair, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder, 
                hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Stair, HDevWindowStack::GetActive());
        }
        else
        {
          throw HException("Unsupported style: "+hv_Style);
        }
      }
      }
    }
  }
  //
  //
  //Reset original display settings
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),hv_PartRow1, hv_PartColumn1, hv_PartRow2, 
        hv_PartColumn2);
  HDevWindowStack::SetActive(hv_PreviousWindowHandle);
  SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
  SetLineStyle(hv_WindowHandle, hv_OriginStyle);
  SetSystem("clip_region", hv_ClipRegion);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp. 
void prepare_poses_and_rectification_data_moving_cam (HTuple hv_ToolInBasePose, HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData)
{

  // Local iconic variables
  HObject  ho_RegionGrid, ho_ContCircle, ho_ContCircleWorldPlane;
  HObject  ho_ImageArea, ho_RegionBorder, ho_RectificationMap;

  // Local control variables
  HTuple  hv_CamParam, hv_ToolInCamPose, hv_PlaneInBasePose0;
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform;
  HTuple  hv_BaseInToolPose, hv_BaseInCamPose, hv_PlaneInCamPose0;
  HTuple  hv_PlaneInCamPose0Rot, hv_HomMat3D, hv_Qx, hv_Qy;
  HTuple  hv_CosAngleBetweenZAxis, hv_SwitchZDirection, hv_PlaneInCamPose1;
  HTuple  hv_PlaneInCamPose, hv_CamInBasePose, hv_PlaneInBasePose;
  HTuple  hv_MatchingPlaneInPlanePose, hv_MatchingPlaneInBasePose;
  HTuple  hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInCamPose;
  HTuple  hv_ScaleRectification, hv_Width, hv_Height, hv_Rows;
  HTuple  hv_Columns, hv_Row, hv_Column, hv_Phi, hv_Radius1;
  HTuple  hv_Radius2, hv_StartPhi, hv_EndPhi, hv_PointOrder;
  HTuple  hv_ClipRegion, hv_BorderRows, hv_BorderColumns;
  HTuple  hv_BorderX, hv_BorderY, hv_MatchingPlaneRectifiedPartInMatchingPlanePose;
  HTuple  hv_WidthRect, hv_HeightRect, hv_ModelInPlanePose;
  HTuple  hv_PlaneInModelPose;

  //Prepare the needed poses to match and grasp, and compute the rectification map.
  //
  //RectifyImage Parameter can have one of the following 3 values:
  //'no_rectification', 'align_and_rectify', or 'only_rectify'
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInBasePose0", &hv_PlaneInBasePose0);
  //
  //Check input
  if (0 != (hv_ObjectHeight<0.0))
  {
    throw HException("The parameter ObjectHeight cannot be negative");
  }
  if (0 != (HTuple(hv_CamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_ToolInBasePose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_ToolInBasePose, "Rp+T", "gba", "point", &hv_ToolInBasePose);
  ConvertPoseType(hv_ToolInCamPose, "Rp+T", "gba", "point", &hv_ToolInCamPose);
  ConvertPoseType(hv_PlaneInBasePose0, "Rp+T", "gba", "point", &hv_PlaneInBasePose0);
  //
  //Create the plane for matching and adapt the PlaneInBasePose0 such
  //that the z-axis of the plane points away from the reference camera,
  //and x/y coordinates are aligned with the current image, i.e.
  //PlaneInCamPose0 has Rot_z=0.
  PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
  PoseCompose(hv_ToolInCamPose, hv_BaseInToolPose, &hv_BaseInCamPose);
  PoseCompose(hv_BaseInCamPose, hv_PlaneInBasePose0, &hv_PlaneInCamPose0);
  //The z-axis of the plane should point away from the camera.
  hv_PlaneInCamPose0Rot = hv_PlaneInCamPose0;
  hv_PlaneInCamPose0Rot[HTuple::TupleGenSequence(0,2,1)] = ((HTuple(0).Append(0)).Append(0));
  PoseToHomMat3d(hv_PlaneInCamPose0Rot, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 1, &hv_Qx, &hv_Qy, &hv_CosAngleBetweenZAxis);
  if (0 != (hv_CosAngleBetweenZAxis<0))
  {
    CreatePose(0, 0, 0, 180, 0, 0, "Rp+T", "gba", "point", &hv_SwitchZDirection);
    PoseCompose(hv_PlaneInCamPose0, hv_SwitchZDirection, &hv_PlaneInCamPose1);
    hv_PlaneInCamPose0 = hv_PlaneInCamPose1;
  }
  //Align with the current image.
  hv_PlaneInCamPose = hv_PlaneInCamPose0;
  hv_PlaneInCamPose[5] = 0.0;
  //Adapt the PlaneInBasePose.
  PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
  PoseCompose(hv_CamInBasePose, hv_PlaneInCamPose, &hv_PlaneInBasePose);
  //
  //Create the plane for matching.
  CreatePose(0, 0, -hv_ObjectHeight, 0, 0, 0, "Rp+T", "gba", "point", &hv_MatchingPlaneInPlanePose);
  PoseCompose(hv_PlaneInBasePose, hv_MatchingPlaneInPlanePose, &hv_MatchingPlaneInBasePose);
  PoseCompose(hv_PlaneInCamPose, hv_MatchingPlaneInPlanePose, &hv_MatchingPlaneInCamPose);
  //
  if (0 != (hv_RectifyImage==HTuple("no_rectification")))
  {
    hv_MatchingPlaneRectifiedPartInCamPose = hv_MatchingPlaneInCamPose;
    hv_ScaleRectification = HTuple();
  }
  else if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    //Determine the scale such that the mapped image has at least
    //the same resolution as the current image.
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    GenGridRegion(&ho_RegionGrid, 20, 20, "points", hv_Width, hv_Height);
    GetRegionPoints(ho_RegionGrid, &hv_Rows, &hv_Columns);
    GenCircleContourXld(&ho_ContCircle, hv_Rows, hv_Columns, HTuple(hv_Rows.TupleLength(),1.0), 
        0, 6.28318, "positive", 0.1);
    ContourToWorldPlaneXld(ho_ContCircle, &ho_ContCircleWorldPlane, hv_CamParam, 
        hv_MatchingPlaneInCamPose, "m");
    FitEllipseContourXld(ho_ContCircleWorldPlane, "fitzgibbon", -1, 0, 0, 200, 3, 
        2, &hv_Row, &hv_Column, &hv_Phi, &hv_Radius1, &hv_Radius2, &hv_StartPhi, 
        &hv_EndPhi, &hv_PointOrder);
    hv_ScaleRectification = hv_Radius2.TupleMin();
    //
    //Rectify the current image and create the shape model.
    //
    //The image dimensions should cover the entire original field
    //of view in the current rectification.
    //Look at border of the current image in the world plane.
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_ImageArea, 0, 0, hv_Height-1, hv_Width-1);
    Boundary(ho_ImageArea, &ho_RegionBorder, "outer");
    SetSystem("clip_region", hv_ClipRegion);
    GetRegionPoints(ho_RegionBorder, &hv_BorderRows, &hv_BorderColumns);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_BorderRows, 
        hv_BorderColumns, "m", &hv_BorderX, &hv_BorderY);
    //Adapt parameters.
    CreatePose(hv_BorderX.TupleMin(), hv_BorderY.TupleMin(), 0, 0, 0, 0, "Rp+T", 
        "gba", "point", &hv_MatchingPlaneRectifiedPartInMatchingPlanePose);
    PoseCompose(hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInMatchingPlanePose, 
        &hv_MatchingPlaneRectifiedPartInCamPose);
    hv_WidthRect = ((((hv_BorderX.TupleMax())-(hv_BorderX.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    hv_HeightRect = ((((hv_BorderY.TupleMax())-(hv_BorderY.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    //
    //Create a map for repeated use.
    GenImageToWorldPlaneMap(&ho_RectificationMap, hv_CamParam, hv_MatchingPlaneInCamPose, 
        hv_Width, hv_Height, hv_WidthRect, hv_HeightRect, hv_ScaleRectification, 
        "bilinear");
  }
  else
  {
    throw HException("Please set the parameter RectifyImage correctly");
  }
  //Convert to output pose type.
  ConvertPoseType(hv_PlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_PlaneInCamPose);
  ConvertPoseType(hv_CamInBasePose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_CamInBasePose);
  ConvertPoseType(hv_PlaneInBasePose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_PlaneInBasePose);
  ConvertPoseType(hv_MatchingPlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneInCamPose);
  ConvertPoseType(hv_MatchingPlaneInBasePose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneInBasePose);
  ConvertPoseType(hv_MatchingPlaneRectifiedPartInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneRectifiedPartInCamPose);
  //
  CreatePose(0, 0, hv_ObjectHeight, 180, 0, 0, "Rp+T", "gba", "point", &hv_ModelInPlanePose);
  //Remember the transformation.
  PoseInvert(hv_ModelInPlanePose, &hv_PlaneInModelPose);
  //
  //Create message for Poses.
  CreateMessage(&(*hv_Poses));
  SetMessageTuple((*hv_Poses), "PlaneInCamPose", hv_PlaneInCamPose);
  SetMessageTuple((*hv_Poses), "CamInBasePose", hv_CamInBasePose);
  SetMessageTuple((*hv_Poses), "PlaneInBasePose", hv_PlaneInBasePose);
  SetMessageTuple((*hv_Poses), "MatchingPlaneInCamPose", hv_MatchingPlaneInCamPose);
  SetMessageTuple((*hv_Poses), "MatchingPlaneInBasePose", hv_MatchingPlaneInBasePose);
  SetMessageTuple((*hv_Poses), "PlaneInModelPose", hv_PlaneInModelPose);
  //
  //Create message for rectification data.
  CreateMessage(&(*hv_RectificationData));
  SetMessageTuple((*hv_RectificationData), "RectifyImage", hv_RectifyImage);
  if (0 != (hv_RectifyImage!=HTuple("no_rectification")))
  {
    SetMessageTuple((*hv_RectificationData), "ScaleRectification", hv_ScaleRectification);
    SetMessageObj(ho_RectificationMap, (*hv_RectificationData), "RectificationMap");
  }
  SetMessageTuple((*hv_RectificationData), "MatchingPlaneRectifiedPartInCamPose", 
      hv_MatchingPlaneRectifiedPartInCamPose);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp in a stationary camera setup. 
void prepare_poses_and_rectification_data_stationary_cam (HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData)
{

  // Local iconic variables
  HObject  ho_RegionGrid, ho_ContCircle, ho_ContCircleWorldPlane;
  HObject  ho_ImageArea, ho_RegionBorder, ho_RectificationMap;

  // Local control variables
  HTuple  hv_CamParam, hv_PlaneInCamPose0, hv_OrderOfTransform;
  HTuple  hv_OrderOfRotation, hv_ViewOfTransform, hv_PlaneInCamPose0Rot;
  HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_CosAngleBetweenZAxis;
  HTuple  hv_SwitchZDirection, hv_PlaneInCamPose, hv_MatchingPlaneInPlanePose;
  HTuple  hv_MatchingPlaneInCamPose, hv_ScaleRectification;
  HTuple  hv_Width, hv_Height, hv_Rows, hv_Columns, hv_Row;
  HTuple  hv_Column, hv_Phi, hv_Radius1, hv_Radius2, hv_StartPhi;
  HTuple  hv_EndPhi, hv_PointOrder, hv_ClipRegion, hv_BorderRows;
  HTuple  hv_BorderColumns, hv_BorderX, hv_BorderY, hv_PoseOffset;
  HTuple  hv_WidthRect, hv_HeightRect, hv_ModelInPlanePose;
  HTuple  hv_PlaneInModelPose;

  //Prepare the needed poses to match and grasp, and compute the rectification
  //map in case rectification is set by the user.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInCamPose0", &hv_PlaneInCamPose0);
  //
  //Check input
  if (0 != (hv_ObjectHeight<0.0))
  {
    throw HException("The parameter ObjectHeight cannot be negative");
  }
  if (0 != (HTuple(hv_CamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_PlaneInCamPose0, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_PlaneInCamPose0, "Rp+T", "gba", "point", &hv_PlaneInCamPose0);
  //The z-axis of the plane should point away from the camera.
  hv_PlaneInCamPose0Rot = hv_PlaneInCamPose0;
  hv_PlaneInCamPose0Rot[HTuple::TupleGenSequence(0,2,1)] = ((HTuple(0).Append(0)).Append(0));
  PoseToHomMat3d(hv_PlaneInCamPose0Rot, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 1, &hv_Qx, &hv_Qy, &hv_CosAngleBetweenZAxis);
  if (0 != (hv_CosAngleBetweenZAxis<0))
  {
    CreatePose(0, 0, 0, 180, 0, 0, "Rp+T", "gba", "point", &hv_SwitchZDirection);
    PoseCompose(hv_PlaneInCamPose0, hv_SwitchZDirection, &hv_PlaneInCamPose0);
  }
  //Align with the current image.
  hv_PlaneInCamPose = hv_PlaneInCamPose0;
  hv_PlaneInCamPose[5] = 0.0;
  //
  //Create the plane for matching.
  CreatePose(0, 0, -hv_ObjectHeight, 0, 0, 0, "Rp+T", "gba", "point", &hv_MatchingPlaneInPlanePose);
  PoseCompose(hv_PlaneInCamPose, hv_MatchingPlaneInPlanePose, &hv_MatchingPlaneInCamPose);
  //
  if (0 != (hv_RectifyImage==HTuple("false")))
  {
    hv_ScaleRectification = HTuple();
  }
  else if (0 != (hv_RectifyImage==HTuple("true")))
  {
    //Determine the scale such that the mapped image has at least the same
    //resolution as the current image.
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    GenGridRegion(&ho_RegionGrid, 20, 20, "points", hv_Width, hv_Height);
    GetRegionPoints(ho_RegionGrid, &hv_Rows, &hv_Columns);
    GenCircleContourXld(&ho_ContCircle, hv_Rows, hv_Columns, HTuple(hv_Rows.TupleLength(),1.0), 
        0, 6.28318, "positive", 0.1);
    ContourToWorldPlaneXld(ho_ContCircle, &ho_ContCircleWorldPlane, hv_CamParam, 
        hv_MatchingPlaneInCamPose, "m");
    FitEllipseContourXld(ho_ContCircleWorldPlane, "fitzgibbon", -1, 0, 0, 200, 3, 
        2, &hv_Row, &hv_Column, &hv_Phi, &hv_Radius1, &hv_Radius2, &hv_StartPhi, 
        &hv_EndPhi, &hv_PointOrder);
    hv_ScaleRectification = hv_Radius2.TupleMin();
    //
    //Rectify the current image and create the shape model.
    //
    //The image dimensions should cover the entire original field of view
    //in the current rectification.
    //Look at border of the current image in the world plane.
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_ImageArea, 0, 0, hv_Height-1, hv_Width-1);
    Boundary(ho_ImageArea, &ho_RegionBorder, "outer");
    SetSystem("clip_region", hv_ClipRegion);
    GetRegionPoints(ho_RegionBorder, &hv_BorderRows, &hv_BorderColumns);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_BorderRows, 
        hv_BorderColumns, "m", &hv_BorderX, &hv_BorderY);
    //Adapt parameters.
    CreatePose(hv_BorderX.TupleMin(), hv_BorderY.TupleMin(), 0, 0, 0, 0, "Rp+T", 
        "gba", "point", &hv_PoseOffset);
    PoseCompose(hv_MatchingPlaneInCamPose, hv_PoseOffset, &hv_MatchingPlaneInCamPose);
    hv_WidthRect = ((((hv_BorderX.TupleMax())-(hv_BorderX.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    hv_HeightRect = ((((hv_BorderY.TupleMax())-(hv_BorderY.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    //
    //Create a map for repeated use.
    GenImageToWorldPlaneMap(&ho_RectificationMap, hv_CamParam, hv_MatchingPlaneInCamPose, 
        hv_Width, hv_Height, hv_WidthRect, hv_HeightRect, hv_ScaleRectification, 
        "bilinear");
  }
  else
  {
    throw HException("Please set the parameter RectifyImage correctly");
  }
  //Convert to output pose type.
  ConvertPoseType(hv_PlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_PlaneInCamPose);
  ConvertPoseType(hv_MatchingPlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneInCamPose);
  //
  CreatePose(0, 0, hv_ObjectHeight, 180, 0, 0, "Rp+T", "gba", "point", &hv_ModelInPlanePose);
  //Remember the transformation.
  PoseInvert(hv_ModelInPlanePose, &hv_PlaneInModelPose);
  //
  //Create message for Poses.
  CreateMessage(&(*hv_Poses));
  SetMessageTuple((*hv_Poses), "PlaneInModelPose", hv_PlaneInModelPose);
  SetMessageTuple((*hv_Poses), "MatchingPlaneInCamPose", hv_MatchingPlaneInCamPose);
  SetMessageTuple((*hv_Poses), "PlaneInCamPose", hv_PlaneInCamPose);
  //
  //Create message for rectification data.
  CreateMessage(&(*hv_RectificationData));
  SetMessageTuple((*hv_RectificationData), "RectifyImage", hv_RectifyImage);
  if (0 != (hv_RectifyImage==HTuple("true")))
  {
    SetMessageTuple((*hv_RectificationData), "ScaleRectification", hv_ScaleRectification);
    SetMessageObj(ho_RectificationMap, (*hv_RectificationData), "RectificationMap");
  }
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Preprocess images for deep-learning-based classification training and inference. 
void preprocess_dl_classifier_images (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_DLClassifierHandle)
{

  // Local iconic variables
  HObject  ho_ObjectSelected, ho_ThreeChannelImage;
  HObject  ho_SingleChannelImage;

  // Local control variables
  HTuple  hv_ContrastNormalization, hv_DomainHandling;
  HTuple  hv_GenParamIndex, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_ImageNumChannels;
  HTuple  hv_ImageWidthInput, hv_ImageHeightInput, hv_EqualWidth;
  HTuple  hv_EqualHeight, hv_Type, hv_NumMatches, hv_NumImages;
  HTuple  hv_EqualByte, hv_RescaleRange, hv_ImageIndex, hv_NumChannels;

  //This procedure preprocesses the provided images given by Image
  //so that they can be handled by
  //train_dl_classifier_batch and apply_dl_classifier_batch.
  //Note that depending on the images,
  //additional preprocessing steps might be beneficial.
  //
  //Set defaults.
  hv_ContrastNormalization = "false";
  hv_DomainHandling = "full_domain";
  //Set generic parameters.
  {
  HTuple end_val10 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val10 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val10, step_val10); hv_GenParamIndex += step_val10)
  {
    if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("contrast_normalization")))
    {
      //Set 'contrast_normalization'
      hv_ContrastNormalization = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("domain_handling")))
    {
      //Set 'domain_handling'
      hv_DomainHandling = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //Get the network's image requirements
  //from the handle of the classifier
  //and use them as preprocessing parameters.
  //
  //Expected input image size:
  GetDlClassifierParam(hv_DLClassifierHandle, "image_width", &hv_ImageWidth);
  GetDlClassifierParam(hv_DLClassifierHandle, "image_height", &hv_ImageHeight);
  //Expected gray value range:
  GetDlClassifierParam(hv_DLClassifierHandle, "image_range_min", &hv_ImageRangeMin);
  GetDlClassifierParam(hv_DLClassifierHandle, "image_range_max", &hv_ImageRangeMax);
  //Expected number of channels:
  GetDlClassifierParam(hv_DLClassifierHandle, "image_num_channels", &hv_ImageNumChannels);
  //
  //Preprocess the images.
  //
  if (0 != (hv_DomainHandling==HTuple("full_domain")))
  {
    FullDomain(ho_Images, &ho_Images);
  }
  else if (0 != (hv_DomainHandling==HTuple("crop_domain")))
  {
    CropDomain(ho_Images, &ho_Images);
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  //Zoom images only if they have a different size than the specified size
  GetImageSize(ho_Images, &hv_ImageWidthInput, &hv_ImageHeightInput);
  hv_EqualWidth = hv_ImageWidth.TupleEqualElem(hv_ImageWidthInput);
  hv_EqualHeight = hv_ImageHeight.TupleEqualElem(hv_ImageHeightInput);
  if (0 != (HTuple((hv_EqualWidth.TupleMin())==0).TupleOr((hv_EqualHeight.TupleMin())==0)))
  {
    ZoomImageSize(ho_Images, &ho_Images, hv_ImageWidth, hv_ImageHeight, "constant");
  }
  if (0 != (hv_ContrastNormalization==HTuple("true")))
  {
    //Scale the gray values to [0-255].
    //Note that this converts the image to 'byte'.
    ScaleImageMax(ho_Images, &ho_Images);
  }
  else if (0 != (hv_ContrastNormalization!=HTuple("false")))
  {
    throw HException("Unsupported parameter value for 'contrast_normalization'");
  }
  //Check the type of the input images.
  //If the type is not 'byte',
  //the gray value scaling does not work correctly.
  GetImageType(ho_Images, &hv_Type);
  TupleRegexpTest(hv_Type, "byte|real", &hv_NumMatches);
  CountObj(ho_Images, &hv_NumImages);
  if (0 != (hv_NumMatches!=hv_NumImages))
  {
    throw HException("Please provide only images of type 'byte' or 'real'.");
  }
  hv_EqualByte = hv_Type.TupleEqualElem("byte");
  if (0 != ((hv_EqualByte.TupleMax())==1))
  {
    if (0 != ((hv_EqualByte.TupleMin())==0))
    {
      throw HException("Passing mixed type images is not supported.");
    }
    //Convert the image type from byte to real,
    //because the classifier expects 'real' images.
    ConvertImageType(ho_Images, &ho_Images, "real");
    //Scale/Shift the gray values from [0-255] to the expected range.
    hv_RescaleRange = (hv_ImageRangeMax-hv_ImageRangeMin)/255.0;
    ScaleImage(ho_Images, &ho_Images, hv_RescaleRange, hv_ImageRangeMin);
  }
  else
  {
    //For real images it is assumed that the range is already correct
  }

  //Check the number of channels.
  CountObj(ho_Images, &hv_NumImages);
  {
  HTuple end_val85 = hv_NumImages;
  HTuple step_val85 = 1;
  for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val85, step_val85); hv_ImageIndex += step_val85)
  {
    SelectObj(ho_Images, &ho_ObjectSelected, hv_ImageIndex);
    CountChannels(ho_ObjectSelected, &hv_NumChannels);
    if (0 != (hv_NumChannels!=hv_ImageNumChannels))
    {
      //
      if (0 != (HTuple(hv_NumChannels==1).TupleAnd(hv_ImageNumChannels==3)))
      {
        //If the image is a grayscale image, but the classifier expects a color image:
        //convert it to an image with three channels.
        Compose3(ho_ObjectSelected, ho_ObjectSelected, ho_ObjectSelected, &ho_ThreeChannelImage
            );
        ReplaceObj(ho_Images, ho_ThreeChannelImage, &ho_Images, hv_ImageIndex);
      }
      else if (0 != (HTuple(hv_NumChannels==3).TupleAnd(hv_ImageNumChannels==1)))
      {
        //If the image is a color image, but the classifier expects a grayscale image:
        //convert it to an image with only one channel.
        Rgb1ToGray(ho_ObjectSelected, &ho_SingleChannelImage);
        ReplaceObj(ho_Images, ho_SingleChannelImage, &ho_Images, hv_ImageIndex);
      }
      else
      {
        throw HException("Number of channels not supported. Please provide a grayscale or an RGB image.");
      }
      //
    }
  }
  }
  (*ho_ImagesPreprocessed) = ho_Images;
  return;
}

void process_slider_events (HTuple hv_WindowHandle, HTuple hv_MessageQueues, HTuple hv_PreviousState, 
    HTuple *hv_CurrentState, HTuple *hv_DidFinish)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Row, hv_Column, hv_Button, hv_Current;
  HTuple  hv_MessageHandle, hv_MessageHandleIgnore, hv_Exception;
  HTuple  hv_EventHappened1;

  (*hv_CurrentState) = hv_PreviousState;

  (*hv_DidFinish) = 0;
  try
  {
    get_mouse_info(hv_WindowHandle, HTuple(), HTuple(), &hv_Row, &hv_Column, &hv_Button);
    hv_Current.Clear();
    hv_Current.Append(hv_Row);
    hv_Current.Append(hv_Column);
    hv_Current.Append(hv_Button);
    if (0 != (hv_Current!=hv_PreviousState))
    {
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "mouse_event");
      SetMessageTuple(hv_MessageHandle, "mouse_row", hv_Row);
      SetMessageTuple(hv_MessageHandle, "mouse_col", hv_Column);
      SetMessageTuple(hv_MessageHandle, "mouse_button", hv_Button);
      //Remove any previous mouse message and overwrite it with the new
      //message. If the sub thread is too slow to process the mouse events,
      //we rather skip one and only use the last one. This avoids
      //the "lagging" GUI effect.
      try
      {
        DequeueMessage(HTuple(hv_MessageQueues[0]), "timeout", 0, &hv_MessageHandleIgnore);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
      }
      EnqueueMessage(HTuple(hv_MessageQueues[0]), hv_MessageHandle, HTuple(), HTuple());
      (*hv_CurrentState) = hv_Current;
      hv_EventHappened1 = 1;
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    if (0 != (HTuple(hv_Exception[0])==2891))
    {
      //Message queue overflow
      //-> there is already a mouse event in the queue, do not add another one
      //   to avoid overflowing the queue
      return;
    }
    else if (0 != (HTuple(HTuple(hv_Exception[0])==5).TupleAnd(HTuple(hv_Exception[5])==HTuple("get_mposition_sub_pix"))))
    {
      //Mouse not in window
      //Ignore
      WaitSeconds(0.01);
    }
    else if (0 != (HTuple(HTuple(hv_Exception[0])==2454).TupleOr(HTuple(hv_Exception[0])==5100)))
    {
      //Handle was already cleared -> indicates that the window was closed (by the user)
      //Abort gracefully.
      (*hv_DidFinish) = 1;
      return;
    }
    else
    {
      //Unknown / Unexpected exception
      throw HException(hv_Exception);
    }
  }
  return;

}

// Short Description: Generic processor for events of visualize_object_model_3d_ext 
void process_visualize_events_generic (HTuple hv_WindowHandle, HTuple hv_MessageQueues, 
    HTuple hv_PreviousState, HTuple *hv_DidFinish, HTuple *hv_NewState, HTuple *hv_ButtonPressed, 
    HTuple *hv_Poses)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MessageHandle, hv_Type, hv_ButtonID;
  HTuple  hv_Exception, hv_Row, hv_Column, hv_Button, hv_Current;
  HTuple  hv_MessageHandleIgnore;

  (*hv_NewState) = hv_PreviousState;
  (*hv_ButtonPressed) = HTuple();
  (*hv_Poses) = HTuple();
  (*hv_DidFinish) = 0;
  //
  try
  {
    try
    {
      DequeueMessage(HTuple(hv_MessageQueues[2]), "timeout", 0, &hv_MessageHandle);
      GetMessageTuple(hv_MessageHandle, "type", &hv_Type);
      if (0 != (hv_Type==HTuple("done")))
      {
        //The visualization function has finished and has exited
        (*hv_DidFinish) = 1;
      }
      else if (0 != (hv_Type==HTuple("button_pressed")))
      {
        //The user pressed one of the buttons
        GetMessageTuple(hv_MessageHandle, "button", &hv_ButtonID);
        (*hv_ButtonPressed) = hv_ButtonID;
      }
      else if (0 != (hv_Type==HTuple("redraw")))
      {
        GetMessageTuple(hv_MessageHandle, "poses", &(*hv_Poses));
        //Nothing TBD
      }
      else
      {
        //Unknown / unexpected Message
        // stop(...); only in hdevelop
      }
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      //Ignore timeout (no message in queue)
      if (0 != (HTuple(hv_Exception[0])!=9400))
      {
        throw HException(hv_Exception);
      }
    }

    get_mouse_info(hv_WindowHandle, HTuple(), HTuple(), &hv_Row, &hv_Column, &hv_Button);

    hv_Current.Clear();
    hv_Current.Append(hv_Row);
    hv_Current.Append(hv_Column);
    hv_Current.Append(hv_Button);
    if (0 != (hv_Current!=hv_PreviousState))
    {
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "mouse_event");
      SetMessageTuple(hv_MessageHandle, "mouse_row", hv_Row);
      SetMessageTuple(hv_MessageHandle, "mouse_col", hv_Column);
      SetMessageTuple(hv_MessageHandle, "mouse_button", hv_Button);
      //Remove any previous mouse message and overwrite it with the new
      //message. If the sub thread is too slow to process the mouse events,
      //we rather skip one and only use the last one. This avoids
      //the "lagging" GUI effect.
      try
      {
        DequeueMessage(HTuple(hv_MessageQueues[0]), "timeout", 0, &hv_MessageHandleIgnore);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        //Ignore
      }
      EnqueueMessage(HTuple(hv_MessageQueues[0]), hv_MessageHandle, HTuple(), HTuple());
      (*hv_NewState) = hv_Current;
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    if (0 != (HTuple(hv_Exception[0])==2891))
    {
      //Message Queue overflow (usually of the mouse event queue)
      return;
    }
    else if (0 != (HTuple(HTuple(hv_Exception[0])==5).TupleAnd(HTuple(hv_Exception[5])==HTuple("get_mposition_sub_pix"))))
    {
      //Mouse not in window
      //Ignore
      WaitSeconds(0.01);
    }
    else if (0 != (HTuple(HTuple(hv_Exception[0])==2454).TupleOr(HTuple(hv_Exception[0])==5100)))
    {
      //Handle was already cleared -> indicates that the window was closed (by the user)
      //Abort gracefully.
      (*hv_DidFinish) = 1;
      return;
    }
    else
    {
      //Unknown / Unexpected exception
      throw HException(hv_Exception);
    }
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Project an image point onto the trackball 
void project_point_on_trackball (HTuple hv_X, HTuple hv_Y, HTuple hv_VirtualTrackball, 
    HTuple hv_TrackballSize, HTuple *hv_V)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_R, hv_XP, hv_YP, hv_ZP;

  if (0 != (hv_VirtualTrackball==HTuple("shoemake")))
  {
    //Virtual Trackball according to Shoemake
    hv_R = ((hv_X*hv_X)+(hv_Y*hv_Y)).TupleSqrt();
    if (0 != (hv_R<=hv_TrackballSize))
    {
      hv_XP = hv_X;
      hv_YP = hv_Y;
      hv_ZP = ((hv_TrackballSize*hv_TrackballSize)-(hv_R*hv_R)).TupleSqrt();
    }
    else
    {
      hv_XP = (hv_X*hv_TrackballSize)/hv_R;
      hv_YP = (hv_Y*hv_TrackballSize)/hv_R;
      hv_ZP = 0;
    }
  }
  else
  {
    //Virtual Trackball according to Bell
    hv_R = ((hv_X*hv_X)+(hv_Y*hv_Y)).TupleSqrt();
    if (0 != (hv_R<=(hv_TrackballSize*0.70710678)))
    {
      hv_XP = hv_X;
      hv_YP = hv_Y;
      hv_ZP = ((hv_TrackballSize*hv_TrackballSize)-(hv_R*hv_R)).TupleSqrt();
    }
    else
    {
      hv_XP = hv_X;
      hv_YP = hv_Y;
      hv_ZP = ((0.6*hv_TrackballSize)*hv_TrackballSize)/hv_R;
    }
  }
  (*hv_V).Clear();
  (*hv_V).Append(hv_XP);
  (*hv_V).Append(hv_YP);
  (*hv_V).Append(hv_ZP);
  return;
}

// Chapter: Graphics / Output
// Short Description: Project an image point onto the trackball 
void project_point_on_trackball_visualize_object_model_3d (HTuple hv_X, HTuple hv_Y, 
    HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple *hv_V)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_R, hv_XP, hv_YP, hv_ZP;

  if (0 != (hv_VirtualTrackball==HTuple("shoemake")))
  {
    //Virtual Trackball according to Shoemake
    hv_R = ((hv_X*hv_X)+(hv_Y*hv_Y)).TupleSqrt();
    if (0 != (hv_R<=hv_TrackballSize))
    {
      hv_XP = hv_X;
      hv_YP = hv_Y;
      hv_ZP = ((hv_TrackballSize*hv_TrackballSize)-(hv_R*hv_R)).TupleSqrt();
    }
    else
    {
      hv_XP = (hv_X*hv_TrackballSize)/hv_R;
      hv_YP = (hv_Y*hv_TrackballSize)/hv_R;
      hv_ZP = 0;
    }
  }
  else
  {
    //Virtual Trackball according to Bell
    hv_R = ((hv_X*hv_X)+(hv_Y*hv_Y)).TupleSqrt();
    if (0 != (hv_R<=(hv_TrackballSize*0.70710678)))
    {
      hv_XP = hv_X;
      hv_YP = hv_Y;
      hv_ZP = ((hv_TrackballSize*hv_TrackballSize)-(hv_R*hv_R)).TupleSqrt();
    }
    else
    {
      hv_XP = hv_X;
      hv_YP = hv_Y;
      hv_ZP = ((0.6*hv_TrackballSize)*hv_TrackballSize)/hv_R;
    }
  }
  (*hv_V).Clear();
  (*hv_V).Append(hv_XP);
  (*hv_V).Append(hv_YP);
  (*hv_V).Append(hv_ZP);
  return;
}

// Chapter: Classification / Misc
// Short Description: List all available feature group names. 
void query_feature_group_names (HTuple *hv_GroupNames)
{

  // Local iconic variables
  HObject  ho_Region, ho_Image;

  //
  //Return all available feature groups
  //
  gen_dummy_objects(&ho_Region, &ho_Image);
  get_features(ho_Region, ho_Image, "", "get_groups", &(*hv_GroupNames));
  (*hv_GroupNames) = ((*hv_GroupNames).TupleSort()).TupleUniq();
  (*hv_GroupNames) = (*hv_GroupNames).TupleConcat("all");
  return;
}

// Chapter: Classification / Misc
// Short Description: Returns a table of feature names sorted by groups. 
void query_feature_names_by_group (HTuple hv_GroupNames, HTuple *hv_FeatureNames, 
    HTuple *hv_Groups)
{

  // Local iconic variables
  HObject  ho_Region, ho_Image;

  // Local control variables
  HTuple  hv_I, hv_Names;

  //
  //Return a table (consisting of two tuples)
  //of all features and the groups they belong to.
  //
  (*hv_FeatureNames) = HTuple();
  (*hv_Groups) = HTuple();
  gen_dummy_objects(&ho_Region, &ho_Image);
  {
  HTuple end_val7 = (hv_GroupNames.TupleLength())-1;
  HTuple step_val7 = 1;
  for (hv_I=0; hv_I.Continue(end_val7, step_val7); hv_I += step_val7)
  {
    get_features(ho_Region, ho_Image, HTuple(hv_GroupNames[hv_I]), "get_names", &hv_Names);
    (*hv_FeatureNames) = (*hv_FeatureNames).TupleConcat(hv_Names);
    (*hv_Groups) = (*hv_Groups).TupleConcat(HTuple(hv_Names.TupleLength(),HTuple(hv_GroupNames[hv_I])));
  }
  }
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Read the data set containing the images and their respective ground truth labels.  
void read_dl_classifier_data_set (HTuple hv_ImageDirectory, HTuple hv_LabelSource, 
    HTuple *hv_ImageFiles, HTuple *hv_GroundTruthLabels, HTuple *hv_LabelIndices, 
    HTuple *hv_UniqueClasses)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_LabelsTmp, hv_ClassIndex;

  //This procedures lists all ImageFiles
  //located in ImageDirectory and its subdirectories,
  //and returns the label of each image in GroundTruthLabels.
  //LabelSource determines how the ground truth labels are extracted.
  //Additionally, indices are assigned to the labels,
  //which can be used for the training instead
  //of the string labels, which is more time efficient.
  //The order of indices corresponds with the returned
  //unique Classes.
  //
  //Check the parameter ImageDirectory.
  if (0 != ((hv_ImageDirectory.TupleIsString()).TupleNot()))
  {
    throw HException(("ImageDirectory "+hv_ImageDirectory)+"is not a string.");
  }
  //
  //List all images in the provided directory
  //and its subdirectories ('recursive').
  list_image_files(hv_ImageDirectory, ((((((((((((((HTuple("hobj").Append("ima")).Append("bmp")).Append("jpg")).Append("png")).Append("tiff")).Append("tif")).Append("gif")).Append("jpeg")).Append("pcx")).Append("pgm")).Append("ppm")).Append("pbm")).Append("xwd")).Append("pnm")), 
      (HTuple("recursive").Append("follow_links")), &(*hv_ImageFiles));
  if (0 != (((*hv_ImageFiles).TupleLength())==0))
  {
    throw HException(("Error: Could not find any image files in folder: \""+hv_ImageDirectory)+"\"");
  }
  //
  //Get the ground truth labels.
  //Note that when configuring your own LabelSource mode,
  //you might find the procedure parse_filename helpful.
  if (0 != (hv_LabelSource==HTuple("last_folder")))
  {
    //The last folder name containing the image
    //is used as label.
    TupleRegexpMatch((*hv_ImageFiles), ".*/([^/]+)/[^/]*$", &(*hv_GroundTruthLabels));
  }
  else if (0 != (hv_LabelSource==HTuple("file_name")))
  {
    //The file name of each image is used as label.
    TupleRegexpMatch((*hv_ImageFiles), ".*/([^/]+)[.][^/]*$", &(*hv_GroundTruthLabels));
  }
  else if (0 != (hv_LabelSource==HTuple("file_name_remove_index")))
  {
    //The file name of each image is used as label.
    //All consecutive digits and underscores
    //at the end of the file name are removed.
    TupleRegexpMatch((*hv_ImageFiles), ".*/([^/]+)[.][^/]*$", &hv_LabelsTmp);
    TupleRegexpReplace(hv_LabelsTmp, "[0-9_]*$", "", &(*hv_GroundTruthLabels));
  }
  else if (0 != (hv_LabelSource==HTuple()))
  {
    (*hv_GroundTruthLabels) = HTuple();
  }
  else
  {
    throw HException("LabelSource not supported.");
  }
  //Get the unique elements of Labels,
  //which represent the classes.
  (*hv_UniqueClasses) = ((*hv_GroundTruthLabels).TupleSort()).TupleUniq();
  //Assign indices to the labels.
  (*hv_LabelIndices) = (*hv_GroundTruthLabels);
  {
  HTuple end_val48 = ((*hv_UniqueClasses).TupleLength())-1;
  HTuple step_val48 = 1;
  for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val48, step_val48); hv_ClassIndex += step_val48)
  {
    (*hv_LabelIndices)[(*hv_LabelIndices).TupleFind(HTuple((*hv_UniqueClasses)[hv_ClassIndex]))] = hv_ClassIndex;
  }
  }
  return;
}

// Chapter: System / Multithreading
void read_message_obj (HObject *ho_ObjectData, HTuple hv_MessageHandle, HTuple hv_Key)
{

  // Local control variables
  HTuple  hv_Exception;

  try
  {
    GetMessageObj(&(*ho_ObjectData), hv_MessageHandle, hv_Key);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException((("The key "+hv_Key)+" is missing from the message ")+hv_MessageHandle);
  }
  return;
}

// Chapter: System / Multithreading
void read_message_tuple (HTuple hv_MessageHandle, HTuple hv_Key, HTuple *hv_TupleData)
{

  // Local control variables
  HTuple  hv_Exception;

  try
  {
    GetMessageTuple(hv_MessageHandle, hv_Key, &(*hv_TupleData));
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException((("The key "+hv_Key)+" is missing from the message ")+hv_MessageHandle);
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Prepare the input image for matching and compute the needed pose. 
void rectify_image_and_compute_matching_plane_moving_cam (HObject ho_Image, HObject *ho_ImageRectified, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData)
{

  // Local iconic variables
  HObject  ho_ImageArea, ho_RegionBorder;

  // Local control variables
  HTuple  hv_RectifyImage, hv_OrderOfTransform;
  HTuple  hv_OrderOfRotation, hv_ViewOfTransform, hv_ToolInCamPose;
  HTuple  hv_MatchingPlaneInBasePose, hv_BaseInToolPose, hv_BaseInCamPose;
  HTuple  hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInCamPose;
  HTuple  hv_CamParam, hv_Width, hv_Height, hv_ClipRegion;
  HTuple  hv_BorderRows, hv_BorderColumns, hv_BorderX, hv_BorderY;
  HTuple  hv_MatchingPlaneRectifiedPartInMatchingPlanePose;
  HTuple  hv_ScaleRectification, hv_WidthRect, hv_HeightRect;

  //This procedure finds the pose of the matching part on the plane
  //in the camera coordinate system. Rectification is applied if it
  //is set by the user.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  read_message_tuple(hv_Poses, "MatchingPlaneInBasePose", &hv_MatchingPlaneInBasePose);
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_ToolInBasePose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_ToolInBasePose, "Rp+T", "gba", "point", &hv_ToolInBasePose);
  ConvertPoseType(hv_ToolInCamPose, "Rp+T", "gba", "point", &hv_ToolInCamPose);
  ConvertPoseType(hv_MatchingPlaneInBasePose, "Rp+T", "gba", "point", &hv_MatchingPlaneInBasePose);
  //
  PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
  PoseCompose(hv_ToolInCamPose, hv_BaseInToolPose, &hv_BaseInCamPose);
  PoseCompose(hv_BaseInCamPose, hv_MatchingPlaneInBasePose, &hv_MatchingPlaneInCamPose);
  //
  if (0 != (hv_RectifyImage==HTuple("no_rectification")))
  {
    hv_MatchingPlaneRectifiedPartInCamPose = hv_MatchingPlaneInCamPose;
    CopyObj(ho_Image, &(*ho_ImageRectified), 1, 1);
  }
  else if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    if (0 != (hv_RectifyImage==HTuple("only_rectify")))
    {
      hv_MatchingPlaneInCamPose[5] = 0.0;
    }
    //The image dimensions should cover the entire original
    //field of view in the current rectification. Look at the
    //border of the current image in the world plane.
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_ImageArea, 0, 0, hv_Height-1, hv_Width-1);
    Boundary(ho_ImageArea, &ho_RegionBorder, "outer");
    SetSystem("clip_region", hv_ClipRegion);
    GetRegionPoints(ho_RegionBorder, &hv_BorderRows, &hv_BorderColumns);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_BorderRows, 
        hv_BorderColumns, "m", &hv_BorderX, &hv_BorderY);
    //Adapt parameters.
    CreatePose(hv_BorderX.TupleMin(), hv_BorderY.TupleMin(), 0, 0, 0, 0, "Rp+T", 
        "gba", "point", &hv_MatchingPlaneRectifiedPartInMatchingPlanePose);
    PoseCompose(hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInMatchingPlanePose, 
        &hv_MatchingPlaneRectifiedPartInCamPose);
    hv_WidthRect = ((((hv_BorderX.TupleMax())-(hv_BorderX.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    hv_HeightRect = ((((hv_BorderY.TupleMax())-(hv_BorderY.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    //
    ImageToWorldPlane(ho_Image, &(*ho_ImageRectified), hv_CamParam, hv_MatchingPlaneRectifiedPartInCamPose, 
        hv_WidthRect, hv_HeightRect, hv_ScaleRectification, "bilinear");
  }
  else
  {
    throw HException("Please set the parameter RectifyImage correctly");
  }
  ConvertPoseType(hv_MatchingPlaneRectifiedPartInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneRectifiedPartInCamPose);
  SetMessageTuple(hv_RectificationData, "MatchingPlaneRectifiedPartInCamPose", hv_MatchingPlaneRectifiedPartInCamPose);
  return;
}

// Chapter: File / Misc
// Short Description: This procedure removes a directory recursively. 
void remove_dir_recursively (HTuple hv_DirName)
{

  // Local control variables
  HTuple  hv_Dirs, hv_I, hv_Files;

  //Recursively delete all subdirectories.
  ListFiles(hv_DirName, "directories", &hv_Dirs);
  {
  HTuple end_val2 = (hv_Dirs.TupleLength())-1;
  HTuple step_val2 = 1;
  for (hv_I=0; hv_I.Continue(end_val2, step_val2); hv_I += step_val2)
  {
    remove_dir_recursively(HTuple(hv_Dirs[hv_I]));
  }
  }
  //Delete all files.
  ListFiles(hv_DirName, "files", &hv_Files);
  {
  HTuple end_val7 = (hv_Files.TupleLength())-1;
  HTuple step_val7 = 1;
  for (hv_I=0; hv_I.Continue(end_val7, step_val7); hv_I += step_val7)
  {
    DeleteFile(HTuple(hv_Files[hv_I]));
  }
  }
  //Remove empty directory.
  RemoveDir(hv_DirName);
  return;
}

// Chapter: Filters / Arithmetic
// Short Description: Scale the gray values of an image from the interval [Min,Max] to [0,255] 
void scale_image_range (HObject ho_Image, HObject *ho_ImageScaled, HTuple hv_Min, 
    HTuple hv_Max)
{

  // Local iconic variables
  HObject  ho_ImageSelected, ho_SelectedChannel;
  HObject  ho_LowerRegion, ho_UpperRegion, ho_ImageSelectedScaled;

  // Local control variables
  HTuple  hv_LowerLimit, hv_UpperLimit, hv_Mult;
  HTuple  hv_Add, hv_NumImages, hv_ImageIndex, hv_Channels;
  HTuple  hv_ChannelIndex, hv_MinGray, hv_MaxGray, hv_Range;

  //Convenience procedure to scale the gray values of the
  //input image Image from the interval [Min,Max]
  //to the interval [0,255] (default).
  //Gray values < 0 or > 255 (after scaling) are clipped.
  //
  //If the image shall be scaled to an interval different from [0,255],
  //this can be achieved by passing tuples with 2 values [From, To]
  //as Min and Max.
  //Example:
  //scale_image_range(Image:ImageScaled:[100,50],[200,250])
  //maps the gray values of Image from the interval [100,200] to [50,250].
  //All other gray values will be clipped.
  //
  //input parameters:
  //Image: the input image
  //Min: the minimum gray value which will be mapped to 0
  //     If a tuple with two values is given, the first value will
  //     be mapped to the second value.
  //Max: The maximum gray value which will be mapped to 255
  //     If a tuple with two values is given, the first value will
  //     be mapped to the second value.
  //
  //Output parameter:
  //ImageScale: the resulting scaled image.
  //
  if (0 != ((hv_Min.TupleLength())==2))
  {
    hv_LowerLimit = ((const HTuple&)hv_Min)[1];
    hv_Min = ((const HTuple&)hv_Min)[0];
  }
  else
  {
    hv_LowerLimit = 0.0;
  }
  if (0 != ((hv_Max.TupleLength())==2))
  {
    hv_UpperLimit = ((const HTuple&)hv_Max)[1];
    hv_Max = ((const HTuple&)hv_Max)[0];
  }
  else
  {
    hv_UpperLimit = 255.0;
  }
  //
  //Calculate scaling parameters.
  hv_Mult = ((hv_UpperLimit-hv_LowerLimit).TupleReal())/(hv_Max-hv_Min);
  hv_Add = ((-hv_Mult)*hv_Min)+hv_LowerLimit;
  //
  //Scale image.
  ScaleImage(ho_Image, &ho_Image, hv_Mult, hv_Add);
  //
  //Clip gray values if necessary.
  //This must be done for each image and channel separately.
  GenEmptyObj(&(*ho_ImageScaled));
  CountObj(ho_Image, &hv_NumImages);
  {
  HTuple end_val49 = hv_NumImages;
  HTuple step_val49 = 1;
  for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val49, step_val49); hv_ImageIndex += step_val49)
  {
    SelectObj(ho_Image, &ho_ImageSelected, hv_ImageIndex);
    CountChannels(ho_ImageSelected, &hv_Channels);
    {
    HTuple end_val52 = hv_Channels;
    HTuple step_val52 = 1;
    for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val52, step_val52); hv_ChannelIndex += step_val52)
    {
      AccessChannel(ho_ImageSelected, &ho_SelectedChannel, hv_ChannelIndex);
      MinMaxGray(ho_SelectedChannel, ho_SelectedChannel, 0, &hv_MinGray, &hv_MaxGray, 
          &hv_Range);
      Threshold(ho_SelectedChannel, &ho_LowerRegion, (hv_MinGray.TupleConcat(hv_LowerLimit)).TupleMin(), 
          hv_LowerLimit);
      Threshold(ho_SelectedChannel, &ho_UpperRegion, hv_UpperLimit, (hv_UpperLimit.TupleConcat(hv_MaxGray)).TupleMax());
      PaintRegion(ho_LowerRegion, ho_SelectedChannel, &ho_SelectedChannel, hv_LowerLimit, 
          "fill");
      PaintRegion(ho_UpperRegion, ho_SelectedChannel, &ho_SelectedChannel, hv_UpperLimit, 
          "fill");
      if (0 != (hv_ChannelIndex==1))
      {
        CopyObj(ho_SelectedChannel, &ho_ImageSelectedScaled, 1, 1);
      }
      else
      {
        AppendChannel(ho_ImageSelectedScaled, ho_SelectedChannel, &ho_ImageSelectedScaled
            );
      }
    }
    }
    ConcatObj((*ho_ImageScaled), ho_ImageSelectedScaled, &(*ho_ImageScaled));
  }
  }
  return;
}

void ScanningRuler_ReadBuffer (HObject *ho_ImageCirX, HObject *ho_ImageCirY, HObject *ho_ImageCirZ, 
    HObject *ho_Intensity, HTuple hv_Width, HTuple hv_Height, HTuple hv_File)
{

  // Local iconic variables
  HObject  ho_ImageX, ho_RegionOut, ho_ImageReduced;
  HObject  ho_ImageY, ho_ImageZ, ho_ImageIntensity;

  //Scanning Ruler Cir X, Cir Y, Cir Z ,Intensity
  //-<subcomponent name="X" valuetype="FLOAT">
  //<parameter name="size">3072</parameter>
  //<parameter name="width">768</parameter>
  //</subcomponent>
  //-<subcomponent name="Y" valuetype="FLOAT">
  //<parameter name="size">3072</parameter>
  //<parameter name="width">768</parameter>
  //</subcomponent>
  //-<subcomponent name="Z" valuetype="FLOAT">
  //<parameter name="size">3072</parameter>
  //<parameter name="width">768</parameter>
  //</subcomponent>
  //-<subcomponent name="Intensity" valuetype="BYTE">
  //<parameter name="size">768</parameter>
  //<parameter name="width">768</parameter>
  //******************************************
  //**
  //******************************************
  //Cir X
  ReadSequence(&ho_ImageX, 0, hv_Width, hv_Height, 0, 0, hv_Width, hv_Height, "real", 
      "MSBFirst", "LSBFirst", "long", 1, hv_File);
  Threshold(ho_ImageX, &ho_RegionOut, -5000, 5000);
  ReduceDomain(ho_ImageX, ho_RegionOut, &ho_ImageReduced);
  MirrorImage(ho_ImageReduced, &(*ho_ImageCirX), "column");
  //Cir Y
  ReadSequence(&ho_ImageY, 0, hv_Width, hv_Height*4, hv_Height, 0, hv_Width, hv_Height, 
      "real", "MSBFirst", "LSBFirst", "long", 1, hv_File);
  Threshold(ho_ImageY, &ho_RegionOut, -5000, 5000);
  ReduceDomain(ho_ImageY, ho_RegionOut, &ho_ImageReduced);
  MirrorImage(ho_ImageReduced, &(*ho_ImageCirY), "column");
  //Cir Z
  ReadSequence(&ho_ImageZ, 0, hv_Width, hv_Height*4, hv_Height*2, 0, hv_Width, hv_Height, 
      "real", "MSBFirst", "LSBFirst", "long", 1, hv_File);
  Threshold(ho_ImageZ, &ho_RegionOut, -5000, 5000);
  ReduceDomain(ho_ImageZ, ho_RegionOut, &ho_ImageReduced);
  MirrorImage(ho_ImageReduced, &(*ho_ImageCirZ), "column");
  //Intensity
  ReadSequence(&ho_ImageIntensity, 0, hv_Width, ((hv_Height*3)*4)+hv_Height, (hv_Height*3)*4, 
      0, hv_Width, hv_Height, "byte", "MSBFirst", "LSBFirst", "byte", 1, hv_File);
  //threshold (ImageIntensity, Region, -5000, 5000)
  //reduce_domain (ImageIntensity, Region, ImageReduced)
  MirrorImage(ho_ImageIntensity, &(*ho_Intensity), "column");
  return;
}

void select_case (HObject ho_MenuRegions, HTuple hv_WindowHandleMenu, HTuple hv_MenuTexts, 
    HTuple *hv_SelectedCase)
{

  // Local iconic variables
  HObject  ho_ObjectSelected;

  // Local control variables
  HTuple  hv_Row, hv_Column, hv_Button, hv_Number;
  HTuple  hv_Index, hv_IsInside, hv_Exception;

  while (0 != 1)
  {
    try
    {
      GetMposition(hv_WindowHandleMenu, &hv_Row, &hv_Column, &hv_Button);
      if (0 != (hv_Button==1))
      {
        CountObj(ho_MenuRegions, &hv_Number);
        {
        HTuple end_val5 = hv_Number.TupleMin2(hv_MenuTexts.TupleLength());
        HTuple step_val5 = 1;
        for (hv_Index=1; hv_Index.Continue(end_val5, step_val5); hv_Index += step_val5)
        {
          SelectObj(ho_MenuRegions, &ho_ObjectSelected, hv_Index);
          TestRegionPoint(ho_ObjectSelected, hv_Row, hv_Column, &hv_IsInside);
          if (0 != hv_IsInside)
          {
            (*hv_SelectedCase) = hv_Index-1;
            return;
          }
        }
        }
      }
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      if (0 != (HTuple(HTuple(hv_Exception[0])==2454).TupleOr(HTuple(hv_Exception[0])==5100)))
      {
        //Handle was already cleared -> indicates that the window was closed (by the user)
        //Abort gracefully.
        (*hv_SelectedCase) = -1;
        return;
      }
      else if (0 != (HTuple(hv_Exception[0])==5))
      {
        //Ignore -> mouse outside of window
      }
      else
      {
        //Unknown / Unexpected exception
        //Ignore for now
      }
    }
  }
  return;
}

// Chapter: Object / Manipulation
// Short Description: Select elements from object arrays using a mask. 
void select_mask_obj (HObject ho_Objects, HObject *ho_SelectedObjects, HTuple hv_Mask)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Number, hv_AllNumbers, hv_Indices;

  //select_mask_obj selects one or more single elements of the object array
  //Objects and returns them in SelectedObjects.
  //The elements of Mask determine if the corresponding elements of Objects are selected.
  //If the value is greater than 0, the corresponding element is selected.
  //
  //Check number of elements
  CountObj(ho_Objects, &hv_Number);
  if (0 != (hv_Number!=(hv_Mask.TupleLength())))
  {
    throw HException("Number of elements in Objects and Mask do not match.");
  }
  //
  //Check type of mask elements
  hv_AllNumbers = (((hv_Mask.TupleIsRealElem()).TupleSum())+((hv_Mask.TupleIsIntElem()).TupleSum()))==(hv_Mask.TupleLength());
  if (0 != (HTuple(hv_AllNumbers.TupleNot()).TupleAnd(hv_Mask!=HTuple())))
  {
    throw HException("Invalid type: Elements of Mask must be integer or real numbers.");
  }
  //
  //Use select_mask for tuples to generate a list of object indices.
  hv_Indices = HTuple::TupleGenSequence(1,hv_Mask.TupleLength(),1).TupleSelectMask(hv_Mask);
  SelectObj(ho_Objects, &(*ho_SelectedObjects), hv_Indices);
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Select a percentage of the given data. 
void select_percentage_dl_classifier_data (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_SelectPercentage, HTuple *hv_ImageFilesOut, HTuple *hv_LabelsOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_UniqueClasses, hv_Ratio, hv_ClassIndex;
  HTuple  hv_Label, hv_LabelIndices, hv_ImageFilesLabel, hv_IndexEnd;

  //This procedure selects SelectPercentage percentages
  //of the input data set ImageFiles and GroundTruthLabels and returns
  //the result in ImageFilesOut and LabelsOut.
  //The original ratio of class sizes is kept
  //when applying this percentage.
  //
  //Check the input parameters.
  if (0 != ((hv_ImageFiles.TupleLength())<1))
  {
    throw HException("ImageFiles must not be empty.");
  }
  if (0 != ((hv_ImageFiles.TupleLength())!=(hv_GroundTruthLabels.TupleLength())))
  {
    throw HException("Please provide a label for every image.");
  }
  if (0 != (HTuple(hv_SelectPercentage<0).TupleOr(hv_SelectPercentage>100)))
  {
    throw HException("UsedPercentage must be between 0 and 100.");
  }
  hv_UniqueClasses = (hv_GroundTruthLabels.TupleSort()).TupleUniq();
  //
  //Select the user-defined percentage of every class.
  if (0 != (hv_SelectPercentage==100))
  {
    (*hv_ImageFilesOut) = hv_ImageFiles;
    (*hv_LabelsOut) = hv_GroundTruthLabels;
  }
  else
  {
    hv_Ratio = hv_SelectPercentage*0.01;
    (*hv_ImageFilesOut) = HTuple();
    (*hv_LabelsOut) = HTuple();
    {
    HTuple end_val26 = (hv_UniqueClasses.TupleLength())-1;
    HTuple step_val26 = 1;
    for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val26, step_val26); hv_ClassIndex += step_val26)
    {
      //For each class, find the images with this label.
      hv_Label = HTuple(hv_UniqueClasses[hv_ClassIndex]);
      hv_LabelIndices = hv_GroundTruthLabels.TupleFind(hv_Label);
      hv_ImageFilesLabel = HTuple(hv_ImageFiles[hv_LabelIndices]);
      //Shuffle the images with this label.
      tuple_shuffle(hv_ImageFilesLabel, &hv_ImageFilesLabel);
      //Select images from the class according to the given percentage.
      hv_IndexEnd = HTuple(0).TupleMax2(((((hv_ImageFilesLabel.TupleLength())*hv_Ratio).TupleFloor()).TupleInt())-1);
      (*hv_ImageFilesOut) = (*hv_ImageFilesOut).TupleConcat(hv_ImageFilesLabel.TupleSelectRange(0,hv_IndexEnd));
      (*hv_LabelsOut) = (*hv_LabelsOut).TupleConcat(HTuple(hv_IndexEnd+1,hv_Label));
    }
    }
  }
  return;
}

void send_pose_update (HTuple hv_Parameters, HTuple hv_Poses)
{

  // Local control variables
  HTuple  hv_MessageQueue, hv_MessageHandle;

  GetMessageTuple(hv_Parameters, "MessageQueue", &hv_MessageQueue);
  if (0 != (hv_MessageQueue!=HTuple()))
  {
    CreateMessage(&hv_MessageHandle);
    SetMessageTuple(hv_MessageHandle, "type", "redraw");
    SetMessageTuple(hv_MessageHandle, "poses", hv_Poses);
    EnqueueMessage(HTuple(hv_MessageQueue[2]), hv_MessageHandle, HTuple(), HTuple());
    ClearMessage(hv_MessageHandle);
  }
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Set the value of a specified camera parameter in the camera parameter tuple. 
void set_cam_par_data (HTuple hv_CameraParamIn, HTuple hv_ParamName, HTuple hv_ParamValue, 
    HTuple *hv_CameraParamOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index, hv_ParamNameInd, hv_CameraParamNames;
  HTuple  hv_I, hv_CameraType, hv_IsTelecentric;

  //set_cam_par_data sets the value of the parameter that
  //is given in ParamName in the tuple of camera parameters
  //given in CameraParamIn. The modified camera parameters
  //are returned in CameraParamOut.
  //
  //Check for consistent length of input parameters
  if (0 != ((hv_ParamName.TupleLength())!=(hv_ParamValue.TupleLength())))
  {
    throw HException("Different number of values in ParamName and ParamValue");
  }
  //First, get the parameter names that correspond to the
  //elements in the input camera parameter tuple.
  get_cam_par_names(hv_CameraParamIn, &hv_CameraType, &hv_CameraParamNames);
  //
  //Find the index of the requested camera data and return
  //the corresponding value.
  (*hv_CameraParamOut) = hv_CameraParamIn;
  {
  HTuple end_val16 = (hv_ParamName.TupleLength())-1;
  HTuple step_val16 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val16, step_val16); hv_Index += step_val16)
  {
    hv_ParamNameInd = HTuple(hv_ParamName[hv_Index]);
    hv_I = hv_CameraParamNames.TupleFind(hv_ParamNameInd);
    if (0 != (hv_I!=-1))
    {
      (*hv_CameraParamOut)[hv_I] = HTuple(hv_ParamValue[hv_Index]);
    }
    else
    {
      throw HException("Wrong ParamName "+hv_ParamNameInd);
    }
    //Check the consistency of focus and telecentricity
    if (0 != (hv_ParamNameInd==HTuple("focus")))
    {
      hv_IsTelecentric = HTuple((hv_CameraType.TupleStrstr("telecentric"))!=-1).TupleAnd((hv_CameraType.TupleStrstr("image_side_telecentric"))==-1);
      if (0 != hv_IsTelecentric)
      {
        throw HException(HTuple("Focus for telecentric lenses is always 0, and hence, cannot be changed."));
      }
      if (0 != (HTuple(hv_IsTelecentric.TupleNot()).TupleAnd(HTuple(hv_ParamValue[hv_Index])==0.0)))
      {
        throw HException("Focus for non-telecentric lenses must not be 0.");
      }
    }
  }
  }
  return;
}

// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, HTuple hv_Bold, 
    HTuple hv_Slant)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OS, hv_Fonts, hv_Style, hv_Exception;
  HTuple  hv_AvailableFonts, hv_Fdx, hv_Indices;

  //This procedure sets the text font of the current window with
  //the specified attributes.
  //
  //Input parameters:
  //WindowHandle: The graphics window for which the font will be set
  //Size: The font size. If Size=-1, the default of 16 is used.
  //Bold: If set to 'true', a bold font is used
  //Slant: If set to 'true', a slanted font is used
  //
  GetSystem("operating_system", &hv_OS);
  if (0 != (HTuple(hv_Size==HTuple()).TupleOr(hv_Size==-1)))
  {
    hv_Size = 16;
  }
  if (0 != ((hv_OS.TupleSubstr(0,2))==HTuple("Win")))
  {
    //Restore previous behaviour
    hv_Size = (1.13677*hv_Size).TupleInt();
  }
  else
  {
    hv_Size = hv_Size.TupleInt();
  }
  if (0 != (hv_Font==HTuple("Courier")))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Courier";
    hv_Fonts[1] = "Courier 10 Pitch";
    hv_Fonts[2] = "Courier New";
    hv_Fonts[3] = "CourierNew";
    hv_Fonts[4] = "Liberation Mono";
  }
  else if (0 != (hv_Font==HTuple("mono")))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Consolas";
    hv_Fonts[1] = "Menlo";
    hv_Fonts[2] = "Courier";
    hv_Fonts[3] = "Courier 10 Pitch";
    hv_Fonts[4] = "FreeMono";
    hv_Fonts[5] = "Liberation Mono";
  }
  else if (0 != (hv_Font==HTuple("sans")))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Luxi Sans";
    hv_Fonts[1] = "DejaVu Sans";
    hv_Fonts[2] = "FreeSans";
    hv_Fonts[3] = "Arial";
    hv_Fonts[4] = "Liberation Sans";
  }
  else if (0 != (hv_Font==HTuple("serif")))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Times New Roman";
    hv_Fonts[1] = "Luxi Serif";
    hv_Fonts[2] = "DejaVu Serif";
    hv_Fonts[3] = "FreeSerif";
    hv_Fonts[4] = "Utopia";
    hv_Fonts[5] = "Liberation Serif";
  }
  else
  {
    hv_Fonts = hv_Font;
  }
  hv_Style = "";
  if (0 != (hv_Bold==HTuple("true")))
  {
    hv_Style += HTuple("Bold");
  }
  else if (0 != (hv_Bold!=HTuple("false")))
  {
    hv_Exception = "Wrong value of control parameter Bold";
    throw HException(hv_Exception);
  }
  if (0 != (hv_Slant==HTuple("true")))
  {
    hv_Style += HTuple("Italic");
  }
  else if (0 != (hv_Slant!=HTuple("false")))
  {
    hv_Exception = "Wrong value of control parameter Slant";
    throw HException(hv_Exception);
  }
  if (0 != (hv_Style==HTuple("")))
  {
    hv_Style = "Normal";
  }
  QueryFont(hv_WindowHandle, &hv_AvailableFonts);
  hv_Font = "";
  {
  HTuple end_val48 = (hv_Fonts.TupleLength())-1;
  HTuple step_val48 = 1;
  for (hv_Fdx=0; hv_Fdx.Continue(end_val48, step_val48); hv_Fdx += step_val48)
  {
    hv_Indices = hv_AvailableFonts.TupleFind(HTuple(hv_Fonts[hv_Fdx]));
    if (0 != ((hv_Indices.TupleLength())>0))
    {
      if (0 != (HTuple(hv_Indices[0])>=0))
      {
        hv_Font = HTuple(hv_Fonts[hv_Fdx]);
        break;
      }
    }
  }
  }
  if (0 != (hv_Font==HTuple("")))
  {
    throw HException("Wrong value of control parameter Font");
  }
  hv_Font = (((hv_Font+"-")+hv_Style)+"-")+hv_Size;
  SetFont(hv_WindowHandle, hv_Font);
  return;
}

void set_edge_parameter_sliders (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_MesageQueues, HTuple hv_MessageQueueOut, HTuple hv_ModelDiameter, HTuple hv_AmplitudeRange, 
    HTuple hv_MaxGapRange, HTuple hv_Viewpoint, HTuple *hv_MinAmplitude, HTuple *hv_MaxGap)
{

  // Local iconic variables
  HObject  ho_X, ho_Y, ho_Z, ho_ZZoomed, ho_XEdges;
  HObject  ho_YEdges, ho_ZEdges, ho_EdgesDomain, ho_EdgesDomainZoomed;

  // Local control variables
  HTuple  hv_ViewpointStr, hv_Row, hv_Column, hv_Width;
  HTuple  hv_Height, hv_WindowHandleBuffer, hv_SliderHeight;
  HTuple  hv_RowSlider1, hv_RowSlider2, hv_ColSliderLabel;
  HTuple  hv_ColSliderValue, hv_ColSliderStart, hv_ColSliderEnd;
  HTuple  hv_ImgWidth, hv_ImgHeight, hv_Factor, hv_CurrentSliderActive;
  HTuple  hv_ObjectModel3DEdges, hv_PoseEstimated, hv_MessageHandle;
  HTuple  hv_ValuesUpdated, hv_Slider, hv_MouseRow, hv_MouseColumn;
  HTuple  hv_UpdateSlider, hv_MouseButton, hv_ValueRel, hv_MessageType;
  HTuple  hv_Exception;

  (*hv_MaxGap) = ((const HTuple&)hv_MaxGapRange)[2];
  (*hv_MinAmplitude) = ((const HTuple&)hv_AmplitudeRange)[2];
  hv_ViewpointStr = (hv_Viewpoint+" ").TupleSum();

  //Open (invisible) buffer window to avoid flickering
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  OpenWindow(0, 0, hv_Width, hv_Height, 0, "buffer", "", &hv_WindowHandleBuffer);
  SetPart(hv_WindowHandleBuffer, 0, 0, hv_Height-1, hv_Width-1);

  //Estimate a good visualization pose
  estimate_visualization_pose_simple(hv_ObjectModel3D, hv_WindowHandleBuffer, &hv_PoseEstimated);

  hv_SliderHeight = 25;
  hv_RowSlider1 = (hv_Height-10)-(2*hv_SliderHeight);
  hv_RowSlider2 = (hv_Height-10)-(1*hv_SliderHeight);
  hv_ColSliderLabel = 10;
  hv_ColSliderValue = hv_Width-50;
  hv_ColSliderStart = hv_ColSliderLabel+130;
  hv_ColSliderEnd = hv_ColSliderValue-10;

  set_display_font(hv_WindowHandle, 12, "mono", "true", "false");
  set_display_font(hv_WindowHandleBuffer, 12, "mono", "true", "false");

  ObjectModel3dToXyz(&ho_X, &ho_Y, &ho_Z, hv_ObjectModel3D, "from_xyz_map", HTuple(), 
      HTuple());
  GetImageSize(ho_X, &hv_ImgWidth, &hv_ImgHeight);
  hv_Factor = ((1.0*hv_Width)/hv_ImgWidth).TupleMin2((((1.0*hv_Height)-10)-(2*hv_SliderHeight))/hv_ImgHeight);
  ZoomImageFactor(ho_Z, &ho_ZZoomed, hv_Factor, hv_Factor, "nearest_neighbor");
  DispObj(ho_ZZoomed, hv_WindowHandle);

  hv_CurrentSliderActive = HTuple();

  try
  {
    while (0 != 1)
    {
      EdgesObjectModel3d(hv_ObjectModel3D, (*hv_MinAmplitude)*hv_ModelDiameter, (HTuple("max_gap").Append("viewpoint")), 
          (*hv_MaxGap).TupleConcat(hv_ViewpointStr), &hv_ObjectModel3DEdges);
      //
      //disp_object_model_3d (WindowHandleBuffer, ObjectModel3DEdges, [], PoseEstimated, 'color', 'blue')
      ClearWindow(hv_WindowHandleBuffer);
      DispObj(ho_ZZoomed, hv_WindowHandleBuffer);
      SetColor(hv_WindowHandleBuffer, "red");
      ObjectModel3dToXyz(&ho_XEdges, &ho_YEdges, &ho_ZEdges, hv_ObjectModel3DEdges, 
          "from_xyz_map", HTuple(), HTuple());
      GetDomain(ho_ZEdges, &ho_EdgesDomain);
      ZoomRegion(ho_EdgesDomain, &ho_EdgesDomainZoomed, hv_Factor, hv_Factor);
      DilationCircle(ho_EdgesDomainZoomed, &ho_EdgesDomainZoomed, 1.5);
      DispObj(ho_EdgesDomainZoomed, hv_WindowHandleBuffer);
      //
      //Update the 3D object model with the edges in the 3D visualization window
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "replace_object_model");
      SetMessageTuple(hv_MessageHandle, "index", 1);
      SetMessageTuple(hv_MessageHandle, "model", hv_ObjectModel3DEdges);
      EnqueueMessage(HTuple(hv_MessageQueueOut[1]), hv_MessageHandle, HTuple(), HTuple());
      //
      disp_slider(hv_WindowHandleBuffer, hv_RowSlider1, hv_SliderHeight, hv_ColSliderLabel, 
          hv_ColSliderValue, hv_ColSliderStart, hv_ColSliderEnd, "MinAmplitudeRel: ", 
          HTuple(hv_AmplitudeRange[0]), HTuple(hv_AmplitudeRange[1]), (*hv_MinAmplitude), 
          "2.3f");
      disp_slider(hv_WindowHandleBuffer, hv_RowSlider2, hv_SliderHeight, hv_ColSliderLabel, 
          hv_ColSliderValue, hv_ColSliderStart, hv_ColSliderEnd, "MaxGap: ", HTuple(hv_MaxGapRange[0]), 
          HTuple(hv_MaxGapRange[1]), (*hv_MaxGap), "d");
      //
      CopyRectangle(hv_WindowHandleBuffer, hv_WindowHandle, 0, 0, hv_Height-1, hv_Width-1, 
          0, 0);
      //
      hv_ValuesUpdated = 0;
      while (0 != (hv_ValuesUpdated.TupleNot()))
      {
        get_mouse_info(hv_WindowHandle, hv_MesageQueues, 0.01, &hv_MouseRow, &hv_MouseColumn, 
            &hv_MouseButton);
        //
        //Find the slider the mouse is in
        hv_Slider = HTuple();
        if (0 != (HTuple(HTuple(HTuple(hv_MouseRow>hv_RowSlider1).TupleAnd(hv_MouseRow<(hv_RowSlider1+hv_SliderHeight))).TupleAnd(hv_MouseColumn>=hv_ColSliderStart)).TupleAnd(hv_MouseColumn<=hv_ColSliderEnd)))
        {
          hv_Slider = 1;
        }
        else if (0 != (HTuple(HTuple(HTuple(hv_MouseRow>hv_RowSlider2).TupleAnd(hv_MouseRow<(hv_RowSlider2+hv_SliderHeight))).TupleAnd(hv_MouseColumn>=hv_ColSliderStart)).TupleAnd(hv_MouseColumn<=hv_ColSliderEnd)))
        {
          hv_Slider = 2;
        }
        //
        hv_UpdateSlider = 0;
        if (0 != (hv_MouseButton==1))
        {
          if (0 != (hv_CurrentSliderActive==HTuple()))
          {
            if (0 != (hv_Slider!=HTuple()))
            {
              //Clicked into a slider -> start sliding
              hv_CurrentSliderActive = hv_Slider;
              hv_UpdateSlider = 1;
            }
          }
          else
          {
            //Continue sliding the current slider
            hv_UpdateSlider = 1;
          }
        }
        else if (0 != (hv_MouseButton==0))
        {
          if (0 != (hv_CurrentSliderActive!=HTuple()))
          {
            //mouse button released -> stop sliding
            hv_CurrentSliderActive = HTuple();
          }
        }
        //
        if (0 != hv_UpdateSlider)
        {
          hv_ValueRel = (hv_MouseColumn-hv_ColSliderStart)/(hv_ColSliderEnd-hv_ColSliderStart);
          if (0 != (hv_ValueRel<0))
          {
            hv_ValueRel = 0;
          }
          else if (0 != (hv_ValueRel>1))
          {
            hv_ValueRel = 1;
          }

          if (0 != (1==hv_CurrentSliderActive))
          {
            (*hv_MinAmplitude) = HTuple(hv_AmplitudeRange[0])+(hv_ValueRel*(HTuple(hv_AmplitudeRange[1])-HTuple(hv_AmplitudeRange[0])));
          }
          else if (0 != (2==hv_CurrentSliderActive))
          {
            (*hv_MaxGap) = (HTuple(hv_MaxGapRange[0])+(hv_ValueRel*(HTuple(hv_MaxGapRange[1])-HTuple(hv_MaxGapRange[0])))).TupleInt();
            //rounding might push it out of range
            if (0 != ((*hv_MaxGap)<HTuple(hv_MaxGapRange[0])))
            {
              (*hv_MaxGap) = ((const HTuple&)hv_MaxGapRange)[0];
            }
            else if (0 != ((*hv_MaxGap)>HTuple(hv_MaxGapRange[1])))
            {
              (*hv_MaxGap) = ((const HTuple&)hv_MaxGapRange)[1];
            }
          }
          hv_ValuesUpdated = 1;
        }
        //
        try
        {
          DequeueMessage(HTuple(hv_MesageQueues[1]), "timeout", 0, &hv_MessageHandle);
          GetMessageTuple(hv_MessageHandle, "type", &hv_MessageType);
          if (0 != (hv_MessageType==HTuple("exit")))
          {
            return;
          }
          else
          {
            throw HException((HTuple("Unknown message type").TupleConcat(hv_MessageType)).TupleConcat(hv_MessageHandle));
          }
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          if (0 != (HTuple(hv_Exception[0])!=9400))
          {
            //Ignore timeout (no message in queue)
            throw HException(hv_Exception);
          }
        }
      }
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    if (0 != (HTuple(HTuple(hv_Exception[0])==2454).TupleOr(HTuple(hv_Exception[0])==5100)))
    {
      //Handle was already cleared -> indicates that the window was closed (by the user)
      //Abort gracefully.
      return;
    }
    else
    {
      //Unknown / Unexpected exception
      throw HException(hv_Exception);
    }
  }

  return;
}

// Chapter: Tools / Geometry
// Short Description: Sort tuple pairs. 
void sort_pairs (HTuple hv_T1, HTuple hv_T2, HTuple hv_SortMode, HTuple *hv_Sorted1, 
    HTuple *hv_Sorted2)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Indices1, hv_Indices2;

  //Sort tuple pairs.
  //
  //input parameters:
  //T1: first tuple
  //T2: second tuple
  //SortMode: if set to '1', sort by the first tuple,
  //   if set to '2', sort by the second tuple
  //
  if (0 != (HTuple(hv_SortMode==HTuple("1")).TupleOr(hv_SortMode==1)))
  {
    TupleSortIndex(hv_T1, &hv_Indices1);
    (*hv_Sorted1) = hv_T1.TupleSelect(hv_Indices1);
    (*hv_Sorted2) = hv_T2.TupleSelect(hv_Indices1);
  }
  else if (0 != (HTuple(HTuple(hv_SortMode==HTuple("column")).TupleOr(hv_SortMode==HTuple("2"))).TupleOr(hv_SortMode==2)))
  {
    TupleSortIndex(hv_T2, &hv_Indices2);
    (*hv_Sorted1) = hv_T1.TupleSelect(hv_Indices2);
    (*hv_Sorted2) = hv_T2.TupleSelect(hv_Indices2);
  }
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Split and shuffle the images and ground truth labels into training, validation and test subsets. 
void split_dl_classifier_data_set (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_TrainingPercent, HTuple hv_ValidationPercent, HTuple *hv_TrainingImages, 
    HTuple *hv_TrainingLabels, HTuple *hv_ValidationImages, HTuple *hv_ValidationLabels, 
    HTuple *hv_TestImages, HTuple *hv_TestLabels)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_TrainingRatio, hv_ValidationRatio;
  HTuple  hv_UniqueClasses, hv_ClassIndex, hv_Class, hv_ClassIndices;
  HTuple  hv_ImageFilesClass, hv_LabelsClass, hv_IndexTrainingEnd;
  HTuple  hv_IndexValidationEnd, hv_TrainingSequence, hv_ValidationSequence;
  HTuple  hv_TestSequence;

  //This procedure divides the data set (images and ground truth labels)
  //into three disjoint subsets: training, validation, and test.
  //The number of images and labels in each subset is defined
  //by the given percentages TrainingPercent and ValidationPercent.
  //Each subset contains randomly distributed data,
  //whereby the original ratio of class sizes is kept.
  //
  //Check the input parameters.
  if (0 != ((hv_ImageFiles.TupleLength())!=(hv_GroundTruthLabels.TupleLength())))
  {
    throw HException("Please provide a label for every image file.");
  }
  if (0 != (hv_TrainingPercent<0))
  {
    throw HException("TrainingPercent must not be smaller than zero.");
  }
  if (0 != (hv_ValidationPercent<0))
  {
    throw HException("ValidationPercent must not be smaller than zero.");
  }
  if (0 != ((hv_ImageFiles.TupleLength())<1))
  {
    throw HException("ImageFiles must not be empty.");
  }
  if (0 != ((hv_TrainingPercent+hv_ValidationPercent)>100))
  {
    throw HException("The sum of TrainingPercent and ValidationPercent must not be greater than 100.");
  }
  //
  //Set classes and data ratios.
  hv_TrainingRatio = hv_TrainingPercent*0.01;
  hv_ValidationRatio = hv_ValidationPercent*0.01;
  //
  //Prepare output tuples.
  (*hv_TrainingImages) = HTuple();
  (*hv_TrainingLabels) = HTuple();
  (*hv_ValidationImages) = HTuple();
  (*hv_ValidationLabels) = HTuple();
  (*hv_TestImages) = HTuple();
  (*hv_TestLabels) = HTuple();
  //
  //Loop through all unique classes and add data
  //according to the specified percentages.
  hv_UniqueClasses = (hv_GroundTruthLabels.TupleSort()).TupleUniq();
  {
  HTuple end_val39 = (hv_UniqueClasses.TupleLength())-1;
  HTuple step_val39 = 1;
  for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val39, step_val39); hv_ClassIndex += step_val39)
  {
    //Select all images and ground truth labels with the class.
    hv_Class = HTuple(hv_UniqueClasses[hv_ClassIndex]);
    hv_ClassIndices = hv_GroundTruthLabels.TupleFind(hv_Class);
    hv_ImageFilesClass = HTuple(hv_ImageFiles[hv_ClassIndices]);
    hv_LabelsClass = HTuple(hv_ImageFilesClass.TupleLength(),hv_Class);
    //Shuffle the images in this class.
    tuple_shuffle(hv_ImageFilesClass, &hv_ImageFilesClass);
    //Determine the boundaries of the respective selection.
    hv_IndexTrainingEnd = ((((hv_ImageFilesClass.TupleLength())*hv_TrainingRatio).TupleFloor()).TupleInt())-1;
    hv_IndexValidationEnd = ((((hv_ImageFilesClass.TupleLength())*(hv_ValidationRatio+hv_TrainingRatio)).TupleFloor()).TupleInt())-1;
    //Add the respective images and labels.
    (*hv_TrainingImages) = (*hv_TrainingImages).TupleConcat(hv_ImageFilesClass.TupleSelectRange(0,hv_IndexTrainingEnd));
    (*hv_TrainingLabels) = (*hv_TrainingLabels).TupleConcat(hv_LabelsClass.TupleSelectRange(0,hv_IndexTrainingEnd));
    (*hv_ValidationImages) = (*hv_ValidationImages).TupleConcat(hv_ImageFilesClass.TupleSelectRange(hv_IndexTrainingEnd+1,hv_IndexValidationEnd));
    (*hv_ValidationLabels) = (*hv_ValidationLabels).TupleConcat(hv_LabelsClass.TupleSelectRange(hv_IndexTrainingEnd+1,hv_IndexValidationEnd));
    (*hv_TestImages) = (*hv_TestImages).TupleConcat(hv_ImageFilesClass.TupleSelectRange(hv_IndexValidationEnd+1,(hv_ImageFilesClass.TupleLength())-1));
    (*hv_TestLabels) = (*hv_TestLabels).TupleConcat(hv_LabelsClass.TupleSelectRange(hv_IndexValidationEnd+1,(hv_ImageFilesClass.TupleLength())-1));
  }
  }
  //
  //Shuffle the output.
  tuple_shuffle(HTuple::TupleGenSequence(0,((*hv_TrainingImages).TupleLength())-1,1), 
      &hv_TrainingSequence);
  (*hv_TrainingImages) = HTuple((*hv_TrainingImages)[hv_TrainingSequence]);
  (*hv_TrainingLabels) = HTuple((*hv_TrainingLabels)[hv_TrainingSequence]);
  tuple_shuffle(HTuple::TupleGenSequence(0,((*hv_ValidationImages).TupleLength())-1,1), 
      &hv_ValidationSequence);
  (*hv_ValidationImages) = HTuple((*hv_ValidationImages)[hv_ValidationSequence]);
  (*hv_ValidationLabels) = HTuple((*hv_ValidationLabels)[hv_ValidationSequence]);
  tuple_shuffle(HTuple::TupleGenSequence(0,((*hv_TestImages).TupleLength())-1,1), 
      &hv_TestSequence);
  (*hv_TestImages) = HTuple((*hv_TestImages)[hv_TestSequence]);
  (*hv_TestLabels) = HTuple((*hv_TestLabels)[hv_TestSequence]);
  return;
}

// Chapter: Inspection / Structured Light
// Short Description: Acquire images for the synchronization between the screen and the camera in a structured light setup. 
void structured_light_camera_screen_sync (HObject *ho_CameraImages, HTuple hv_AcqHandle, 
    HTuple hv_WindowHandle, HTuple hv_WindowWidth, HTuple hv_WindowHeight, HTuple hv_WaitSeconds, 
    HTuple *hv_ImagesPerSecond)
{

  // Local iconic variables
  HObject  ho_VerticalStripes, ho_ScreenDomain;
  HObject  ho_HorizontalStripes, ho_Image;

  // Local control variables
  HTuple  hv_NumLoops, hv_ScrRows, hv_ScrColumns;
  HTuple  hv_Begin, hv_Index, hv_End, hv_Time;

  //This procedure helps to establish a synchonization between
  //the screen and the camera in a particular structured light setup.
  //An in-sync setup ensures accurate camera images that are captured
  //at exactly the right time.
  //These camera images show exactly one pattern image
  //each, rather than overlapping pattern images. If on the other
  //hand the camera and screen are not in sync, the captured camera
  //images will show overlap between two pattern images.
  //
  //Define the number of loops for the acquisition.
  hv_NumLoops = 10;
  //Generate test images:
  //Vertical stripe image.
  GenImageConst(&ho_VerticalStripes, "byte", hv_WindowWidth, hv_WindowHeight);
  GetDomain(ho_VerticalStripes, &ho_ScreenDomain);
  GetRegionPoints(ho_ScreenDomain, &hv_ScrRows, &hv_ScrColumns);
  SetGrayval(ho_VerticalStripes, hv_ScrRows, hv_ScrColumns, ((hv_ScrColumns/80)%2)*255);
  //Horizontal stripe image.
  GenImageConst(&ho_HorizontalStripes, "byte", hv_WindowWidth, hv_WindowHeight);
  SetGrayval(ho_HorizontalStripes, hv_ScrRows, hv_ScrColumns, ((hv_ScrRows/80)%2)*255);
  //
  GenEmptyObj(&(*ho_CameraImages));
  CountSeconds(&hv_Begin);
  {
  HTuple end_val23 = hv_NumLoops;
  HTuple step_val23 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val23, step_val23); hv_Index += step_val23)
  {
    //Display the vertical stripes image.
    DispImage(ho_VerticalStripes, hv_WindowHandle);
    //Wait the specified time before acquiring the camera image.
    WaitSeconds(hv_WaitSeconds);
    GrabImage(&ho_Image, hv_AcqHandle);
    //Add the acquired vertical image to the output.
    ConcatObj((*ho_CameraImages), ho_Image, &(*ho_CameraImages));
    //
    //Display the horizontal stripe image.
    DispImage(ho_HorizontalStripes, hv_WindowHandle);
    //Wait the specified time before acquiring the camera image.
    WaitSeconds(hv_WaitSeconds);
    GrabImage(&ho_Image, hv_AcqHandle);
    //Add the acquired horizontal image to the output.
    ConcatObj((*ho_CameraImages), ho_Image, &(*ho_CameraImages));
  }
  }
  CountSeconds(&hv_End);
  //
  //Acquisition time and acquired images per second.
  hv_Time = hv_End-hv_Begin;
  (*hv_ImagesPerSecond) = (2*hv_NumLoops)/hv_Time;
  //
  return;
}

// Chapter: Inspection / Structured Light
// Short Description: Visually inspect the Gray code images of a structured light model. 
void structured_light_inspect_segmentation (HObject ho_CameraImages, HObject ho_BinarizedImages, 
    HTuple hv_WindowHandle)
{

  // Local iconic variables
  HObject  ho_CamImage, ho_BinImage, ho_BrightRegion;

  // Local control variables
  HTuple  hv_NumCamera, hv_NumBinarized, hv_Index;

  //This procedure helps to validate the decoded bright/dark areas
  //in the Gray code images of a structured light model, in comparison
  //to the bright/dark areas in the camera images.
  //
  //The procedure can be thus used to find a suitable value for the
  //parameter min_gray_difference. Please note that being unable to
  //find a suitable value indicates that the actual decoding was wrong
  //since the decision whether a pixel is bright or dark was often
  //incorrect. In that sense, the procedure can also be used to decide
  //whether the surface is partially specular and the pattern_type
  //'single_stripe' should be used.
  //
  HDevWindowStack::SetActive(hv_WindowHandle);
  //Check that CameraImages and BinarizedImages have equal lengths.
  CountObj(ho_CameraImages, &hv_NumCamera);
  CountObj(ho_BinarizedImages, &hv_NumBinarized);
  if (0 != (hv_NumCamera!=hv_NumBinarized))
  {
    throw HException("CameraImages and BinarizedImages do not have equal lengths.");
  }
  //
  //Visualize the decoded bright region(s) on each camera image.
  {
  HTuple end_val21 = hv_NumCamera;
  HTuple step_val21 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
  {
    SelectObj(ho_CameraImages, &ho_CamImage, hv_Index);
    SelectObj(ho_BinarizedImages, &ho_BinImage, hv_Index);
    //The bright region in the binarized image is that with gray
    //value = 255.
    Threshold(ho_BinImage, &ho_BrightRegion, 254, 255);
    if (HDevWindowStack::IsOpen())
      ClearWindow(HDevWindowStack::GetActive());
    if (HDevWindowStack::IsOpen())
      DispObj(ho_CamImage, HDevWindowStack::GetActive());
    if (HDevWindowStack::IsOpen())
      SetDraw(HDevWindowStack::GetActive(),"fill");
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),"#ff000010");
    if (HDevWindowStack::IsOpen())
      DispObj(ho_BrightRegion, HDevWindowStack::GetActive());
    if (HDevWindowStack::IsOpen())
      SetDraw(HDevWindowStack::GetActive(),"margin");
    if (HDevWindowStack::IsOpen())
      SetLineWidth(HDevWindowStack::GetActive(),1);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),"#ff0000");
    if (HDevWindowStack::IsOpen())
      DispObj(ho_BrightRegion, HDevWindowStack::GetActive());
    //If the decoded bright region does not match the visible bright
    //areas on the camera image, try calling the procedure after
    //decoding with a different min_gray_difference value.
    //If no appropriate min_gray_difference value can be found, the
    //actual decode might be incorrect and not the segmentation.
    //In that case, the surface might be partially specular and
    //decoding with the pattern_type 'single_stripe' might correct
    //this effect.
    // stop(...); only in hdevelop
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Test procedure for custom features. 
void test_features (HTuple hv_FeatureNames)
{

  // Local iconic variables
  HObject  ho_Image, ho_Region, ho_TestRegion, ho_TestRegionSelected;
  HObject  ho_ObjectSelected;

  // Local control variables
  HTuple  hv_TestSuccessful, hv_TestString, hv_Test;
  HTuple  hv_NumRegions, hv_AllFeatures, hv_Index, hv_CurName;
  HTuple  hv_Lengths, hv_CurLength, hv_Features, hv_SumLengths;
  HTuple  hv_Total, hv_I, hv_Features2, hv_J, hv_Features1;
  HTuple  hv_CorrectOrder;

  //
  //Test procedure for custom features
  //
  //This procedure can be used to test, if custom features
  //implemented in get_custom_features comply with the
  //specifications of the calculate_feature_set library.
  //
  //In particular, the feature vector Feature, that is
  //calculated with calculate_feature must fulfil
  //following conditions:
  //
  //- For a single input region the result of
  //  get_feature_length has to be equal to the length
  //  of the featue vector: |Feature| == Length
  //
  //- For an empty input region array, the feature
  //  vector has to be empty:
  //  Feature == []
  //
  //- For input region arrays with multiple regions, the
  //  following condition must be met:
  //  |Feature| == NumRegions * Length
  //
  //- Additionally, the feature vector has to be sorted
  //  according to the 'feature_column' order of
  //  add_sample_class_train_data.
  //
  hv_TestSuccessful = 0;
  ReadImage(&ho_Image, "patras");
  Threshold(ho_Image, &ho_Region, 128, 255);
  get_feature_lengths(hv_FeatureNames, &hv_Lengths);
  //
  hv_TestString[0] = "Empty region array test (no region)";
  hv_TestString[1] = "Empty region test";
  hv_TestString[2] = "Single region test";
  for (hv_Test=0; hv_Test<=2; hv_Test+=1)
  {
    switch (hv_Test.I())
    {
    case 0:
      SelectShape(ho_Region, &ho_TestRegion, "area", "and", 0, 0);
      break;
    case 1:
      GenEmptyRegion(&ho_TestRegion);
      break;
    case 2:
      CopyObj(ho_Region, &ho_TestRegion, 1, 1);
      break;
    default:
      ;
    }
    CountObj(ho_TestRegion, &hv_NumRegions);
    hv_AllFeatures = HTuple();
    {
    HTuple end_val50 = (hv_FeatureNames.TupleLength())-1;
    HTuple step_val50 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val50, step_val50); hv_Index += step_val50)
    {
      hv_CurName = HTuple(hv_FeatureNames[hv_Index]);
      hv_CurLength = HTuple(hv_Lengths[hv_Index]);
      calculate_features(ho_TestRegion, ho_Image, hv_CurName, &hv_Features);
      if (0 != ((hv_NumRegions*hv_CurLength)!=(hv_Features.TupleLength())))
      {
        throw HException(((HTuple(hv_TestString[hv_Test])+" failed for feature '")+hv_CurName)+"'");
      }
      hv_AllFeatures = hv_AllFeatures.TupleConcat(hv_Features);
    }
    }
    hv_SumLengths = hv_Lengths.TupleSum();
    hv_Total = hv_SumLengths*hv_NumRegions;
    if (0 != (hv_Total!=(hv_AllFeatures.TupleLength())))
    {
      throw HException((("Test "+hv_Test)+" failed").TupleConcat(HTuple(hv_TestString[hv_Test])));
    }
  }
  //
  //Test multiple input regions
  Connection(ho_Region, &ho_TestRegion);
  SelectObj(ho_TestRegion, &ho_TestRegionSelected, HTuple::TupleGenSequence(1,3,1));
  {
  HTuple end_val69 = (hv_FeatureNames.TupleLength())-1;
  HTuple step_val69 = 1;
  for (hv_I=0; hv_I.Continue(end_val69, step_val69); hv_I += step_val69)
  {
    hv_CurName = HTuple(hv_FeatureNames[hv_I]);
    calculate_features(ho_TestRegionSelected, ho_Image, hv_CurName, &hv_Features1);
    hv_Features2 = HTuple();
    CountObj(ho_TestRegionSelected, &hv_NumRegions);
    {
    HTuple end_val74 = hv_NumRegions;
    HTuple step_val74 = 1;
    for (hv_J=1; hv_J.Continue(end_val74, step_val74); hv_J += step_val74)
    {
      SelectObj(ho_TestRegionSelected, &ho_ObjectSelected, hv_J);
      calculate_features(ho_ObjectSelected, ho_Image, hv_CurName, &hv_Features);
      hv_Features2 = hv_Features2.TupleConcat(hv_Features);
    }
    }
    hv_CorrectOrder = hv_Features1==hv_Features2;
    if (0 != (hv_CorrectOrder.TupleNot()))
    {
      throw HException(("Multiple region test failed for feature '"+hv_CurName)+"'");
    }
  }
  }
  hv_TestSuccessful = 1;
  return;
}

// Chapter: Graphics / Output
// Short Description: Compute the 3D rotation from the mouse movement 
void trackball (HTuple hv_MX1, HTuple hv_MY1, HTuple hv_MX2, HTuple hv_MY2, HTuple hv_VirtualTrackball, 
    HTuple hv_TrackballSize, HTuple hv_SensFactor, HTuple *hv_QuatRotation)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_P1, hv_P2, hv_RotAxis, hv_D, hv_T;
  HTuple  hv_RotAngle, hv_Len;

  //Compute the 3D rotation from the mouse movement
  //
  if (0 != (HTuple(hv_MX1==hv_MX2).TupleAnd(hv_MY1==hv_MY2)))
  {
    (*hv_QuatRotation).Clear();
    (*hv_QuatRotation)[0] = 1;
    (*hv_QuatRotation)[1] = 0;
    (*hv_QuatRotation)[2] = 0;
    (*hv_QuatRotation)[3] = 0;
    return;
  }
  //Project the image point onto the trackball
  project_point_on_trackball(hv_MX1, hv_MY1, hv_VirtualTrackball, hv_TrackballSize, 
      &hv_P1);
  project_point_on_trackball(hv_MX2, hv_MY2, hv_VirtualTrackball, hv_TrackballSize, 
      &hv_P2);
  //The cross product of the projected points defines the rotation axis
  tuple_vector_cross_product(hv_P1, hv_P2, &hv_RotAxis);
  //Compute the rotation angle
  hv_D = hv_P2-hv_P1;
  hv_T = (((hv_D*hv_D).TupleSum()).TupleSqrt())/(2.0*hv_TrackballSize);
  if (0 != (hv_T>1.0))
  {
    hv_T = 1.0;
  }
  if (0 != (hv_T<-1.0))
  {
    hv_T = -1.0;
  }
  hv_RotAngle = (2.0*(hv_T.TupleAsin()))*hv_SensFactor;
  hv_Len = ((hv_RotAxis*hv_RotAxis).TupleSum()).TupleSqrt();
  if (0 != (hv_Len>0.0))
  {
    hv_RotAxis = hv_RotAxis/hv_Len;
  }
  AxisAngleToQuat(HTuple(hv_RotAxis[0]), HTuple(hv_RotAxis[1]), HTuple(hv_RotAxis[2]), 
      hv_RotAngle, &(*hv_QuatRotation));
  return;
}

// Chapter: Graphics / Output
// Short Description: Compute the 3D rotation from the mouse movement 
void trackball_visualize_object_model_3d (HTuple hv_MX1, HTuple hv_MY1, HTuple hv_MX2, 
    HTuple hv_MY2, HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple hv_SensFactor, 
    HTuple *hv_QuatRotation)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_P1, hv_P2, hv_RotAxis, hv_D, hv_T;
  HTuple  hv_RotAngle, hv_Len;

  //Compute the 3D rotation from the mouse movement
  //
  if (0 != (HTuple(hv_MX1==hv_MX2).TupleAnd(hv_MY1==hv_MY2)))
  {
    (*hv_QuatRotation).Clear();
    (*hv_QuatRotation)[0] = 1;
    (*hv_QuatRotation)[1] = 0;
    (*hv_QuatRotation)[2] = 0;
    (*hv_QuatRotation)[3] = 0;
    return;
  }
  //Project the image point onto the trackball
  project_point_on_trackball_visualize_object_model_3d(hv_MX1, hv_MY1, hv_VirtualTrackball, 
      hv_TrackballSize, &hv_P1);
  project_point_on_trackball_visualize_object_model_3d(hv_MX2, hv_MY2, hv_VirtualTrackball, 
      hv_TrackballSize, &hv_P2);
  //The cross product of the projected points defines the rotation axis
  tuple_vector_cross_product_visualize_object_model_3d(hv_P1, hv_P2, &hv_RotAxis);
  //Compute the rotation angle
  hv_D = hv_P2-hv_P1;
  hv_T = (((hv_D*hv_D).TupleSum()).TupleSqrt())/(2.0*hv_TrackballSize);
  if (0 != (hv_T>1.0))
  {
    hv_T = 1.0;
  }
  if (0 != (hv_T<-1.0))
  {
    hv_T = -1.0;
  }
  hv_RotAngle = (2.0*(hv_T.TupleAsin()))*hv_SensFactor;
  hv_Len = ((hv_RotAxis*hv_RotAxis).TupleSum()).TupleSqrt();
  if (0 != (hv_Len>0.0))
  {
    hv_RotAxis = hv_RotAxis/hv_Len;
  }
  AxisAngleToQuat(HTuple(hv_RotAxis[0]), HTuple(hv_RotAxis[1]), HTuple(hv_RotAxis[2]), 
      hv_RotAngle, &(*hv_QuatRotation));
  return;
}

// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ShuffleIndices;

  //This procedure sorts the input tuple randomly.
  //
  if (0 != ((hv_Tuple.TupleLength())>0))
  {
    //Create a tuple of random numbers,
    //sort this tuple, and return the indices
    //of this sorted tuple.
    hv_ShuffleIndices = HTuple::TupleRand(hv_Tuple.TupleLength()).TupleSortIndex();
    //Assign the elements of Tuple
    //to these random positions.
    (*hv_Shuffled) = HTuple(hv_Tuple[hv_ShuffleIndices]);
  }
  else
  {
    //If the input tuple is empty,
    //an empty tuple should be returned.
    (*hv_Shuffled) = HTuple();
  }
  return;
}

// Chapter: Tuple / Arithmetic
// Short Description: Calculates the cross product of two vectors of length 3. 
void tuple_vector_cross_product (HTuple hv_V1, HTuple hv_V2, HTuple *hv_VC)
{

  // Local iconic variables

  //The caller must ensure that the length of both input vectors is 3
  (*hv_VC) = (HTuple(hv_V1[1])*HTuple(hv_V2[2]))-(HTuple(hv_V1[2])*HTuple(hv_V2[1]));
  (*hv_VC) = (*hv_VC).TupleConcat((HTuple(hv_V1[2])*HTuple(hv_V2[0]))-(HTuple(hv_V1[0])*HTuple(hv_V2[2])));
  (*hv_VC) = (*hv_VC).TupleConcat((HTuple(hv_V1[0])*HTuple(hv_V2[1]))-(HTuple(hv_V1[1])*HTuple(hv_V2[0])));
  return;
}

// Chapter: Tuple / Arithmetic
// Short Description: Calculates the cross product of two vectors of length 3. 
void tuple_vector_cross_product_visualize_object_model_3d (HTuple hv_V1, HTuple hv_V2, 
    HTuple *hv_VC)
{

  // Local iconic variables

  //The caller must ensure that the length of both input vectors is 3
  (*hv_VC) = (HTuple(hv_V1[1])*HTuple(hv_V2[2]))-(HTuple(hv_V1[2])*HTuple(hv_V2[1]));
  (*hv_VC) = (*hv_VC).TupleConcat((HTuple(hv_V1[2])*HTuple(hv_V2[0]))-(HTuple(hv_V1[0])*HTuple(hv_V2[2])));
  (*hv_VC) = (*hv_VC).TupleConcat((HTuple(hv_V1[0])*HTuple(hv_V2[1]))-(HTuple(hv_V1[1])*HTuple(hv_V2[0])));
  return;
}

// Chapter: Graphics / 3D Scene
// Short Description: Visualize the poses that were used to calculate the touching point, and the result. 
void visualize_calibrated_touching_point (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OM3DToolTouchingPoint, hv_Instructions;
  HTuple  hv_PoseIn, hv_GenParamName, hv_GenParamValue, hv_Title;
  HTuple  hv_NumOM3D, hv_Label, hv_PoseOut;

  //
  //Create 3D object models.
  gen_tool_to_touching_point_object_model_3d(hvec_ToolInBasePosesTouchingPoint, hv_RobotTouchingPointInToolCoordinates, 
      &hv_OM3DToolTouchingPoint);
  //
  //Prepare parameters for visualize_object_model_3d.
  //Instructions.
  hv_Instructions[0] = "Rotate: Left button";
  hv_Instructions[1] = "Zoom:   Shift + left button";
  hv_Instructions[2] = "Move:   Ctrl  + left button";
  //3D visualization pose.
  CreatePose(0.326, 0.016, 3.137, 83.33, 341.96, 99.32, "Rp+T", "gba", "point", &hv_PoseIn);
  //
  hv_GenParamName.Clear();
  hv_GenParamName[0] = "color_0";
  hv_GenParamName[1] = "color_1";
  hv_GenParamName[2] = "color_2";
  hv_GenParamName[3] = "color_3";
  hv_GenParamName[4] = "color_4";
  hv_GenParamName[5] = "color_5";
  hv_GenParamName[6] = "color_6";
  hv_GenParamName[7] = "color_7";
  hv_GenParamName[8] = "color_8";
  hv_GenParamName[9] = "color_9";
  hv_GenParamName[10] = "color_10";
  hv_GenParamName[11] = "color_11";
  hv_GenParamValue.Clear();
  hv_GenParamValue[0] = "red";
  hv_GenParamValue[1] = "green";
  hv_GenParamValue[2] = "blue";
  hv_GenParamValue[3] = "magenta";
  hv_GenParamValue[4] = "red";
  hv_GenParamValue[5] = "green";
  hv_GenParamValue[6] = "blue";
  hv_GenParamValue[7] = "magenta";
  hv_GenParamValue[8] = "red";
  hv_GenParamValue[9] = "green";
  hv_GenParamValue[10] = "blue";
  hv_GenParamValue[11] = "magenta";
  //
  hv_Title = "Visualization of the read poses. The magenta lines connect the";
  hv_Title[1] = "tool coordinate system with the touching point. They intersect";
  hv_Title[2] = "in the approached point in the plane. Calculated touching point";
  hv_Title[3] = "coordinates with respect to the robot's tool: ";
  hv_Title[4] = ((((("X: "+((HTuple(hv_RobotTouchingPointInToolCoordinates[0])*1000).TupleString(".2f")))+HTuple(" mm, Y: "))+((HTuple(hv_RobotTouchingPointInToolCoordinates[1])*1000).TupleString(".2f")))+HTuple(" mm, Z: "))+((HTuple(hv_RobotTouchingPointInToolCoordinates[2])*1000).TupleString(".2f")))+" mm";
  //Labels for the visualized 3D object models.
  hv_NumOM3D = hv_OM3DToolTouchingPoint.TupleLength();
  TupleGenConst(hv_NumOM3D, "", &hv_Label);
  hv_Label[2] = "ToolInBasePosesTouchingPoint 1";
  hv_Label[6] = "ToolInBasePosesTouchingPoint 2";
  hv_Label[10] = "ToolInBasePosesTouchingPoint 3";
  //
  visualize_object_model_3d(hv_WindowHandle, hv_OM3DToolTouchingPoint, HTuple(), 
      hv_PoseIn, hv_GenParamName, hv_GenParamValue, hv_Title, hv_Label, hv_Instructions, 
      &hv_PoseOut);
  //
  //Clean up.
  ClearObjectModel3d(hv_OM3DToolTouchingPoint);
  return;
}

// Chapter: Graphics / Output
// Short Description: Interactively display 3D object models 
void visualize_object_model_3d (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_PoseIn, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_Title, HTuple hv_Label, HTuple hv_Information, HTuple *hv_PoseOut)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImageDump;

  // Local control variables
  HTuple  ExpTmpLocalVar_gDispObjOffset, ExpTmpLocalVar_gLabelsDecor;
  HTuple  ExpTmpLocalVar_gInfoDecor, ExpTmpLocalVar_gInfoPos;
  HTuple  ExpTmpLocalVar_gTitlePos, ExpTmpLocalVar_gTitleDecor;
  HTuple  ExpTmpLocalVar_gTerminationButtonLabel, ExpTmpLocalVar_gAlphaDeselected;
  HTuple  ExpTmpLocalVar_gIsSinglePose, ExpTmpLocalVar_gUsesOpenGL;
  HTuple  hv_Scene3DTest, hv_Scene3D, hv_WindowHandleBuffer;
  HTuple  hv_TrackballSize, hv_VirtualTrackball, hv_MouseMapping;
  HTuple  hv_WaitForButtonRelease, hv_MaxNumModels, hv_WindowCenteredRotation;
  HTuple  hv_NumModels, hv_SelectedObject, hv_ClipRegion;
  HTuple  hv_CPLength, hv_RowNotUsed, hv_ColumnNotUsed, hv_Width;
  HTuple  hv_Height, hv_WPRow1, hv_WPColumn1, hv_WPRow2, hv_WPColumn2;
  HTuple  hv_CamParamValue, hv_CamWidth, hv_CamHeight, hv_Scale;
  HTuple  hv_Indices, hv_DispBackground, hv_Mask, hv_Center;
  HTuple  hv_Poses, hv_HomMat3Ds, hv_Sequence, hv_PoseEstimated;
  HTuple  hv_Font, hv_Exception, hv_OpenGLInfo, hv_DummyObjectModel3D;
  HTuple  hv_CameraIndexTest, hv_PoseTest, hv_InstanceIndexTest;
  HTuple  hv_MinImageSize, hv_TrackballRadiusPixel, hv_Ascent;
  HTuple  hv_Descent, hv_TextWidth, hv_TextHeight, hv_NumChannels;
  HTuple  hv_ColorImage, hv_CameraIndex, hv_AllInstances;
  HTuple  hv_SetLight, hv_LightParam, hv_LightPosition, hv_LightKind;
  HTuple  hv_LightIndex, hv_PersistenceParamName, hv_PersistenceParamValue;
  HTuple  hv_AlphaOrig, hv_I, hv_ParamName, hv_ParamValue;
  HTuple  hv_ParamNameTrunk, hv_Instance, hv_HomMat3D, hv_Qx;
  HTuple  hv_Qy, hv_Qz, hv_TBCenter, hv_TBSize, hv_ButtonHold;
  HTuple  hv_VisualizeTB, hv_MaxIndex, hv_TrackballCenterRow;
  HTuple  hv_TrackballCenterCol, hv_GraphEvent, hv_Exit, hv_GraphButtonRow;
  HTuple  hv_GraphButtonColumn, hv_GraphButton, hv_ButtonReleased;
  HTuple  hv_e;

  //The procedure visualize_object_model_3d can be used to display
  //one or more 3d object models and to interactively modify
  //the object poses by using the mouse.
  //
  //The pose can be modified by moving the mouse while
  //pressing a mouse button. The default settings are:
  //
  // Rotate: Left mouse button
  // Zoom: Shift + Left mouse button (or Center mouse button)
  // Pan: Ctrl + Left mouse button
  //
  //Furthermore, it is possible to select and deselect objects,
  //to decrease the mouse sensitivity, and to toggle the
  //inspection mode (see the description of the generic parameter
  //'inspection_mode' below):
  //
  // (De-)select object(s): Right mouse button
  // Low mouse sensitivity: Alt + Mouse button
  // Toggle inspection mode: Ctrl + Alt + Left mouse button
  //
  //In GenParamName and GenParamValue all generic Parameters
  //of disp_object_model_3d are supported.
  //
  //**********************************************************
  //Define global variables
  //**********************************************************
  //
  //global def tuple gDispObjOffset
  //global def tuple gLabelsDecor
  //global def tuple gInfoDecor
  //global def tuple gInfoPos
  //global def tuple gTitlePos
  //global def tuple gTitleDecor
  //global def tuple gTerminationButtonLabel
  //global def tuple gAlphaDeselected
  //global def tuple gIsSinglePose
  //global def tuple gUsesOpenGL
  //
  //**********************************************************
  //Initialize Handles to enable correct handling in error case
  //**********************************************************
  hv_Scene3DTest = HTuple();
  hv_Scene3D = HTuple();
  hv_WindowHandleBuffer = HTuple();

  //**********************************************************
  //Some user defines that may be adapted if desired
  //**********************************************************
  //
  //TrackballSize defines the diameter of the trackball in
  //the image with respect to the smaller image dimension.
  hv_TrackballSize = 0.8;
  //
  //VirtualTrackball defines the type of virtual trackball that
  //shall be used ('shoemake' or 'bell').
  hv_VirtualTrackball = "shoemake";
  //VirtualTrackball := 'bell'
  //
  //Functionality of mouse buttons
  //    1: Left Button
  //    2: Middle Button
  //    4: Right Button
  //    5: Left+Right Mousebutton
  //  8+x: Shift + Mousebutton
  // 16+x: Ctrl + Mousebutton
  // 48+x: Ctrl + Alt + Mousebutton
  //in the order [Translate, Rotate, Scale, ScaleAlternative1, ScaleAlternative2, SelectObjects, ToggleSelectionMode]
  hv_MouseMapping.Clear();
  hv_MouseMapping[0] = 17;
  hv_MouseMapping[1] = 1;
  hv_MouseMapping[2] = 2;
  hv_MouseMapping[3] = 5;
  hv_MouseMapping[4] = 9;
  hv_MouseMapping[5] = 4;
  hv_MouseMapping[6] = 49;
  //
  //The labels of the objects appear next to their projected
  //center. With gDispObjOffset a fixed offset is added
  //                  R,  C
  ExpTmpLocalVar_gDispObjOffset.Clear();
  ExpTmpLocalVar_gDispObjOffset[0] = -30;
  ExpTmpLocalVar_gDispObjOffset[1] = 0;
  ExpSetGlobalVar_gDispObjOffset(ExpTmpLocalVar_gDispObjOffset);
  //
  //Customize the decoration of the different text elements
  //              Color,   Box
  ExpTmpLocalVar_gInfoDecor.Clear();
  ExpTmpLocalVar_gInfoDecor[0] = "white";
  ExpTmpLocalVar_gInfoDecor[1] = "false";
  ExpSetGlobalVar_gInfoDecor(ExpTmpLocalVar_gInfoDecor);
  ExpTmpLocalVar_gLabelsDecor.Clear();
  ExpTmpLocalVar_gLabelsDecor[0] = "white";
  ExpTmpLocalVar_gLabelsDecor[1] = "false";
  ExpSetGlobalVar_gLabelsDecor(ExpTmpLocalVar_gLabelsDecor);
  ExpTmpLocalVar_gTitleDecor.Clear();
  ExpTmpLocalVar_gTitleDecor[0] = "black";
  ExpTmpLocalVar_gTitleDecor[1] = "true";
  ExpSetGlobalVar_gTitleDecor(ExpTmpLocalVar_gTitleDecor);
  //
  //Customize the position of some text elements
  //  gInfoPos has one of the values
  //  {'UpperLeft', 'LowerLeft', 'UpperRight'}
  ExpTmpLocalVar_gInfoPos = "LowerLeft";
  ExpSetGlobalVar_gInfoPos(ExpTmpLocalVar_gInfoPos);
  //  gTitlePos has one of the values
  //  {'UpperLeft', 'UpperCenter', 'UpperRight'}
  ExpTmpLocalVar_gTitlePos = "UpperLeft";
  ExpSetGlobalVar_gTitlePos(ExpTmpLocalVar_gTitlePos);
  //Alpha value (=1-transparency) that is used for visualizing
  //the objects that are not selected
  ExpTmpLocalVar_gAlphaDeselected = 0.3;
  ExpSetGlobalVar_gAlphaDeselected(ExpTmpLocalVar_gAlphaDeselected);
  //Customize the label of the continue button
  ExpTmpLocalVar_gTerminationButtonLabel = " Continue ";
  ExpSetGlobalVar_gTerminationButtonLabel(ExpTmpLocalVar_gTerminationButtonLabel);
  //Define if the continue button responds to a single click event or
  //if it responds only if the mouse button is released while being placed
  //over the continue button.
  //'true':  Wait until the continue button has been released.
  //         This should be used to avoid unwanted continuations of
  //         subsequent calls of visualize_object_model_3d, which can
  //         otherwise occur if the mouse button remains pressed while the
  //         next visualization is active.
  //'false': Continue the execution already if the continue button is
  //         pressed. This option allows a fast forwarding through
  //         subsequent calls of visualize_object_model_3d.
  hv_WaitForButtonRelease = "true";
  //Number of 3D Object models that can be selected and handled individually.
  //If there are more models passed then this number, some calculations
  //are performed differently and the individual selection and handling
  //of models is not supported anymore. Note that the value of MaxNumModels
  //can be overwritten with the generic parameter max_num_selectable_models.
  hv_MaxNumModels = 1000;
  //Defines the default for the initial state of the rotation center:
  //(1) The rotation center is fixed in the center of the image and lies
  //    on the surface of the object.
  //(2) The rotation center lies in the center of the object.
  hv_WindowCenteredRotation = 2;
  //
  //**********************************************************
  //
  //Initialize some values
  hv_NumModels = hv_ObjectModel3D.TupleLength();
  hv_SelectedObject = HTuple(hv_NumModels,1);
  //
  //Apply some system settings
  // dev_set_preferences(...); only in hdevelop
  // dev_get_preferences(...); only in hdevelop
  // dev_set_preferences(...); only in hdevelop
  GetSystem("clip_region", &hv_ClipRegion);
  SetSystem("clip_region", "false");
  dev_update_off();
  //
  //Check if GenParamName matches GenParamValue
  if (0 != ((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength())))
  {
    throw HException("Number of generic parameters does not match number of generic parameter values");
  }
  //
  try
  {
    //
    //Refactor camera parameters to fit to window size
    //
    hv_CPLength = hv_CamParam.TupleLength();
    GetWindowExtents(hv_WindowHandle, &hv_RowNotUsed, &hv_ColumnNotUsed, &hv_Width, 
        &hv_Height);
    GetPart(hv_WindowHandle, &hv_WPRow1, &hv_WPColumn1, &hv_WPRow2, &hv_WPColumn2);
    SetPart(hv_WindowHandle, 0, 0, hv_Height-1, hv_Width-1);
    if (0 != (hv_CPLength==0))
    {
      gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
          hv_Width, hv_Height, &hv_CamParam);
    }
    else
    {
      get_cam_par_data(hv_CamParam, (((((HTuple("sx").Append("sy")).Append("cx")).Append("cy")).Append("image_width")).Append("image_height")), 
          &hv_CamParamValue);
      hv_CamWidth = HTuple(hv_CamParamValue[4]).TupleReal();
      hv_CamHeight = HTuple(hv_CamParamValue[5]).TupleReal();
      hv_Scale = ((hv_Width/hv_CamWidth).TupleConcat(hv_Height/hv_CamHeight)).TupleMin();
      set_cam_par_data(hv_CamParam, "sx", HTuple(hv_CamParamValue[0])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "sy", HTuple(hv_CamParamValue[1])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cx", HTuple(hv_CamParamValue[2])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cy", HTuple(hv_CamParamValue[3])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_width", (HTuple(hv_CamParamValue[4])*hv_Scale).TupleInt(), 
          &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_height", (HTuple(hv_CamParamValue[5])*hv_Scale).TupleInt(), 
          &hv_CamParam);
    }
    //
    //Check the generic parameters for max_num_selectable_models
    //(Note that the default is set above to MaxNumModels := 1000)
    hv_Indices = hv_GenParamName.TupleFind("max_num_selectable_models");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]).TupleIsNumber()))
      {
        if (0 != (((HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]).TupleNumber()).TupleInt())<1))
        {
          //Wrong parameter value: Only integer values greater than 0 are allowed
          throw HException("Wrong value for parameter 'max_num_selectable_models' (must be an integer value greater than 0)");
        }
      }
      else
      {
        //Wrong parameter value: Only integer values greater than 0 are allowed
        throw HException("Wrong value for parameter 'max_num_selectable_models' (must be an integer value greater than 0)");
      }
      hv_MaxNumModels = (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]).TupleNumber()).TupleInt();
      hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
      hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
    }
    //
    //Check the generic parameters for window_centered_rotation
    //(Note that the default is set above to WindowCenteredRotation := 2)
    hv_Indices = hv_GenParamName.TupleFind("inspection_mode");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])])==HTuple("surface")))
      {
        hv_WindowCenteredRotation = 1;
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])])==HTuple("standard")))
      {
        hv_WindowCenteredRotation = 2;
      }
      else
      {
        //Wrong parameter value, use default value
      }
      hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
      hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
    }
    //
    //Check the generic parameters for disp_background
    //(The former parameter name 'use_background' is still supported
    // for compatibility reasons)
    hv_DispBackground = "false";
    if (0 != ((hv_GenParamName.TupleLength())>0))
    {
      hv_Mask = (hv_GenParamName.TupleEqualElem("disp_background")).TupleOr(hv_GenParamName.TupleEqualElem("use_background"));
      hv_Indices = hv_Mask.TupleFind(1);
    }
    else
    {
      hv_Indices = -1;
    }
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      hv_DispBackground = HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]);
      if (0 != (HTuple(hv_DispBackground!=HTuple("true")).TupleAnd(hv_DispBackground!=HTuple("false"))))
      {
        //Wrong parameter value: Only 'true' and 'false' are allowed
        throw HException("Wrong value for parameter 'disp_background' (must be either 'true' or 'false')");
      }
      //Note the the background is handled explicitly in this procedure
      //and therefore, the parameter is removed from the list of
      //parameters and disp_background is always set to true (see below)
      hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
      hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
    }
    //
    //Read and check the parameter Label for each object
    if (0 != ((hv_Label.TupleLength())==0))
    {
      hv_Label = 0;
    }
    else if (0 != ((hv_Label.TupleLength())==1))
    {
      hv_Label = HTuple(hv_NumModels,hv_Label);
    }
    else
    {
      if (0 != ((hv_Label.TupleLength())!=hv_NumModels))
      {
        //Number of elements in Label does not match
        //the number of object models.
        throw HException(((HTuple(HTuple("Number of elements in Label (")+(hv_Label.TupleLength()))+") does not match the number of object models(")+hv_NumModels)+").");
      }
    }
    //
    //Read and check the parameter PoseIn for each object
    get_object_models_center_visualize_object_model_3d(hv_ObjectModel3D, &hv_Center);
    if (0 != ((hv_PoseIn.TupleLength())==0))
    {
      //If no pose was specified by the caller, automatically calculate
      //a pose that is appropriate for the visualization.
      //Set the initial model reference pose. The orientation is parallel
      //to the object coordinate system, the position is at the center
      //of gravity of all models.
      CreatePose(-HTuple(hv_Center[0]), -HTuple(hv_Center[1]), -HTuple(hv_Center[2]), 
          0, 0, 0, "Rp+T", "gba", "point", &hv_PoseIn);
      determine_optimum_pose_distance_visualize_object_model_3d(hv_ObjectModel3D, 
          hv_CamParam, 0.9, hv_PoseIn, &hv_PoseEstimated);
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_PoseEstimated[hv_Sequence%7]);
      ExpTmpLocalVar_gIsSinglePose = 1;
      ExpSetGlobalVar_gIsSinglePose(ExpTmpLocalVar_gIsSinglePose);
    }
    else if (0 != ((hv_PoseIn.TupleLength())==7))
    {
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_PoseIn[hv_Sequence%7]);
      ExpTmpLocalVar_gIsSinglePose = 1;
      ExpSetGlobalVar_gIsSinglePose(ExpTmpLocalVar_gIsSinglePose);
    }
    else
    {
      if (0 != ((hv_PoseIn.TupleLength())!=((hv_ObjectModel3D.TupleLength())*7)))
      {
        //Wrong number of values of input control parameter 'PoseIn'
        throw HException("Wrong number of values of input control parameter 'PoseIn'.");
      }
      else
      {
        hv_Poses = hv_PoseIn;
      }
      ExpTmpLocalVar_gIsSinglePose = 0;
      ExpSetGlobalVar_gIsSinglePose(ExpTmpLocalVar_gIsSinglePose);
    }

    //
    //Open (invisible) buffer window to avoid flickering
    OpenWindow(0, 0, hv_Width, hv_Height, 0, "buffer", "", &hv_WindowHandleBuffer);
    SetPart(hv_WindowHandleBuffer, 0, 0, hv_Height-1, hv_Width-1);
    GetFont(hv_WindowHandle, &hv_Font);
    try
    {
      SetFont(hv_WindowHandleBuffer, hv_Font);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    //
    // Is OpenGL available and should it be used?
    ExpTmpLocalVar_gUsesOpenGL = "true";
    ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
    hv_Indices = hv_GenParamName.TupleFind("opengl");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      ExpTmpLocalVar_gUsesOpenGL = HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]);
      ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
      hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
      hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
      if (0 != (HTuple(ExpGetGlobalVar_gUsesOpenGL()!=HTuple("true")).TupleAnd(ExpGetGlobalVar_gUsesOpenGL()!=HTuple("false"))))
      {
        //Wrong parameter value: Only 'true' and 'false' are allowed
        throw HException("Wrong value for parameter 'opengl' (must be either 'true' or 'false')");
      }
    }
    if (0 != (ExpGetGlobalVar_gUsesOpenGL()==HTuple("true")))
    {
      GetSystem("opengl_info", &hv_OpenGLInfo);
      if (0 != (hv_OpenGLInfo==HTuple("No OpenGL support included.")))
      {
        ExpTmpLocalVar_gUsesOpenGL = "false";
        ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
      }
      else
      {
        GenObjectModel3dFromPoints(0, 0, 0, &hv_DummyObjectModel3D);
        CreateScene3d(&hv_Scene3DTest);
        AddScene3dCamera(hv_Scene3DTest, hv_CamParam, &hv_CameraIndexTest);
        determine_optimum_pose_distance_visualize_object_model_3d(hv_DummyObjectModel3D, 
            hv_CamParam, 0.9, ((((((HTuple(0).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)), 
            &hv_PoseTest);
        AddScene3dInstance(hv_Scene3DTest, hv_DummyObjectModel3D, hv_PoseTest, &hv_InstanceIndexTest);
        try
        {
          DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3DTest, hv_InstanceIndexTest);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          ExpTmpLocalVar_gUsesOpenGL = "false";
          ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
        }
        ClearScene3d(hv_Scene3DTest);
        hv_Scene3DTest = HTuple();
        ClearObjectModel3d(hv_DummyObjectModel3D);
      }
    }
    //
    //Compute the trackball
    hv_MinImageSize = (hv_Width.TupleConcat(hv_Height)).TupleMin();
    hv_TrackballRadiusPixel = (hv_TrackballSize*hv_MinImageSize)/2.0;
    //
    //Measure the text extents for the continue button in the
    //graphics window
    GetStringExtents(hv_WindowHandleBuffer, ExpGetGlobalVar_gTerminationButtonLabel()+"  ", 
        &hv_Ascent, &hv_Descent, &hv_TextWidth, &hv_TextHeight);
    //
    //Store background image
    if (0 != (hv_DispBackground==HTuple("false")))
    {
      ClearWindow(hv_WindowHandle);
    }
    DumpWindowImage(&ho_Image, hv_WindowHandle);
    //Special treatment for color background images necessary
    CountChannels(ho_Image, &hv_NumChannels);
    hv_ColorImage = hv_NumChannels==3;
    //
    CreateScene3d(&hv_Scene3D);
    AddScene3dCamera(hv_Scene3D, hv_CamParam, &hv_CameraIndex);
    AddScene3dInstance(hv_Scene3D, hv_ObjectModel3D, hv_Poses, &hv_AllInstances);
    //Always set 'disp_background' to true,  because it is handled explicitly
    //in this procedure (see above)
    SetScene3dParam(hv_Scene3D, "disp_background", "true");
    //Check if we have to set light specific parameters
    hv_SetLight = hv_GenParamName.TupleRegexpTest("light_");
    if (0 != hv_SetLight)
    {
      //set position of light source
      hv_Indices = hv_GenParamName.TupleFind("light_position");
      if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
      {
        //If multiple light positions are given, use the last one
        hv_LightParam = (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])]).TupleSplit(HTuple(", "))).TupleNumber();
        if (0 != ((hv_LightParam.TupleLength())!=4))
        {
          throw HException("light_position must be given as a string that contains four space separated floating point numbers");
        }
        hv_LightPosition = hv_LightParam.TupleSelectRange(0,2);
        hv_LightKind = "point_light";
        if (0 != (HTuple(hv_LightParam[3])==0))
        {
          hv_LightKind = "directional_light";
        }
        //Currently, only one light source is supported
        RemoveScene3dLight(hv_Scene3D, 0);
        AddScene3dLight(hv_Scene3D, hv_LightPosition, hv_LightKind, &hv_LightIndex);
        TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
        TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
      }
      //set ambient part of light source
      hv_Indices = hv_GenParamName.TupleFind("light_ambient");
      if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
      {
        //If the ambient part is set multiple times, use the last setting
        hv_LightParam = (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])]).TupleSplit(HTuple(", "))).TupleNumber();
        if (0 != ((hv_LightParam.TupleLength())<3))
        {
          throw HException("light_ambient must be given as a string that contains three space separated floating point numbers");
        }
        SetScene3dLightParam(hv_Scene3D, 0, "ambient", hv_LightParam.TupleSelectRange(0,2));
        TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
        TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
      }
      //Set diffuse part of light source
      hv_Indices = hv_GenParamName.TupleFind("light_diffuse");
      if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
      {
        //If the diffuse part is set multiple times, use the last setting
        hv_LightParam = (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])]).TupleSplit(HTuple(", "))).TupleNumber();
        if (0 != ((hv_LightParam.TupleLength())<3))
        {
          throw HException("light_diffuse must be given as a string that contains three space separated floating point numbers");
        }
        SetScene3dLightParam(hv_Scene3D, 0, "diffuse", hv_LightParam.TupleSelectRange(0,2));
        TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
        TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
      }
    }
    //
    //Handle persistence parameters separately because persistence will
    //only be activated immediately before leaving the visualization
    //procedure
    hv_PersistenceParamName = HTuple();
    hv_PersistenceParamValue = HTuple();
    //Set position of light source
    hv_Indices = hv_GenParamName.TupleFind("object_index_persistence");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("true")))
      {
        hv_PersistenceParamName = hv_PersistenceParamName.TupleConcat("object_index_persistence");
        hv_PersistenceParamValue = hv_PersistenceParamValue.TupleConcat("true");
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("false")))
      {
      }
      else
      {
        throw HException("Wrong value for parameter 'object_index_persistence' (must be either 'true' or 'false')");
      }
      TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
      TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
    }
    hv_Indices = hv_GenParamName.TupleFind("depth_persistence");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("true")))
      {
        hv_PersistenceParamName = hv_PersistenceParamName.TupleConcat("depth_persistence");
        hv_PersistenceParamValue = hv_PersistenceParamValue.TupleConcat("true");
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("false")))
      {
      }
      else
      {
        throw HException("Wrong value for parameter 'depth_persistence' (must be either 'true' or 'false')");
      }
      TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
      TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
    }
    //
    //Parse the generic parameters
    //- First, all parameters that are understood by set_scene_3d_instance_param
    hv_AlphaOrig = HTuple(hv_NumModels,1);
    {
    HTuple end_val406 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val406 = 1;
    for (hv_I=0; hv_I.Continue(end_val406, step_val406); hv_I += step_val406)
    {
      hv_ParamName = HTuple(hv_GenParamName[hv_I]);
      hv_ParamValue = HTuple(hv_GenParamValue[hv_I]);
      //Check if this parameter is understood by set_scene_3d_param
      if (0 != (hv_ParamName==HTuple("alpha")))
      {
        hv_AlphaOrig = HTuple(hv_NumModels,hv_ParamValue);
      }
      try
      {
        SetScene3dParam(hv_Scene3D, hv_ParamName, hv_ParamValue);
        continue;
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (HTuple(HTuple(hv_Exception[0])==1203).TupleOr(HTuple(hv_Exception[0])==1303)))
        {
          throw HException((("Wrong type or value for parameter "+hv_ParamName)+": ")+hv_ParamValue);
        }
      }
      //Check if it is a parameter that is valid for only one instance
      //and therefore can be set only with set_scene_3d_instance_param
      hv_ParamNameTrunk = hv_ParamName.TupleRegexpReplace("_\\d+$","");
      if (0 != (hv_ParamName==hv_ParamNameTrunk))
      {
        hv_Instance = HTuple::TupleGenSequence(0,hv_NumModels-1,1);
      }
      else
      {
        hv_Instance = (hv_ParamName.TupleRegexpReplace(("^"+hv_ParamNameTrunk)+"_(\\d+)$","$1")).TupleNumber();
        if (0 != (HTuple(hv_Instance<0).TupleOr(hv_Instance>(hv_NumModels-1))))
        {
          throw HException(("Parameter "+hv_ParamName)+" refers to a non existing 3D object model");
        }
      }
      try
      {
        SetScene3dInstanceParam(hv_Scene3D, hv_Instance, hv_ParamNameTrunk, hv_ParamValue);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (HTuple(HTuple(hv_Exception[0])==1204).TupleOr(HTuple(hv_Exception[0])==1304)))
        {
          throw HException((("Wrong type or value for parameter "+hv_ParamName)+": ")+hv_ParamValue);
        }
        else if (0 != (HTuple(HTuple(hv_Exception[0])==1203).TupleOr(HTuple(hv_Exception[0])==1303)))
        {
          throw HException("Wrong parameter name "+hv_ParamName);
        }
        else
        {
          throw HException(hv_Exception);
        }
      }
      if (0 != (hv_ParamNameTrunk==HTuple("alpha")))
      {
        hv_AlphaOrig[hv_Instance] = hv_ParamValue;
      }
    }
    }
    //
    //Start the visualization loop
    PoseToHomMat3d(hv_Poses.TupleSelectRange(0,6), &hv_HomMat3D);
    AffineTransPoint3d(hv_HomMat3D, HTuple(hv_Center[0]), HTuple(hv_Center[1]), HTuple(hv_Center[2]), 
        &hv_Qx, &hv_Qy, &hv_Qz);
    hv_TBCenter.Clear();
    hv_TBCenter.Append(hv_Qx);
    hv_TBCenter.Append(hv_Qy);
    hv_TBCenter.Append(hv_Qz);
    hv_TBSize = (0.5+((0.5*(hv_SelectedObject.TupleSum()))/hv_NumModels))*hv_TrackballRadiusPixel;
    hv_ButtonHold = 0;
    while (0 != 1)
    {
      hv_VisualizeTB = (hv_SelectedObject.TupleMax())!=0;
      hv_MaxIndex = ((HTuple(hv_ObjectModel3D.TupleLength()).TupleConcat(hv_MaxNumModels)).TupleMin())-1;
      //Set trackball fixed in the center of the window
      hv_TrackballCenterRow = hv_Height/2;
      hv_TrackballCenterCol = hv_Width/2;
      if (0 != (hv_WindowCenteredRotation==1))
      {
        try
        {
          get_trackball_center_fixed_visualize_object_model_3d(hv_SelectedObject.TupleSelectRange(0,hv_MaxIndex), 
              hv_TrackballCenterRow, hv_TrackballCenterCol, hv_TrackballRadiusPixel, 
              hv_Scene3D, hv_ObjectModel3D.TupleSelectRange(0,hv_MaxIndex), hv_Poses.TupleSelectRange(0,((hv_MaxIndex+1)*7)-1), 
              hv_WindowHandleBuffer, hv_CamParam, hv_GenParamName, hv_GenParamValue, 
              &hv_TBCenter, &hv_TBSize);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          disp_message(hv_WindowHandle, "Surface inspection mode is not available.", 
              "image", 5, 20, "red", "true");
          hv_WindowCenteredRotation = 2;
          get_trackball_center_visualize_object_model_3d(hv_SelectedObject.TupleSelectRange(0,hv_MaxIndex), 
              hv_TrackballRadiusPixel, hv_ObjectModel3D.TupleSelectRange(0,hv_MaxIndex), 
              hv_Poses.TupleSelectRange(0,((hv_MaxIndex+1)*7)-1), &hv_TBCenter, &hv_TBSize);
          WaitSeconds(1);
        }
      }
      else
      {
        get_trackball_center_visualize_object_model_3d(hv_SelectedObject.TupleSelectRange(0,hv_MaxIndex), 
            hv_TrackballRadiusPixel, hv_ObjectModel3D.TupleSelectRange(0,hv_MaxIndex), 
            hv_Poses.TupleSelectRange(0,((hv_MaxIndex+1)*7)-1), &hv_TBCenter, &hv_TBSize);
      }
      dump_image_output_visualize_object_model_3d(ho_Image, hv_WindowHandleBuffer, 
          hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3D, hv_GenParamName, hv_GenParamValue, 
          hv_CamParam, hv_Poses, hv_ColorImage, hv_Title, hv_Information, hv_Label, 
          hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, hv_TBSize, 
          hv_SelectedObject, hv_WindowCenteredRotation, hv_TBCenter);
      DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
      HDevWindowStack::SetActive(hv_WindowHandle);
      if (HDevWindowStack::IsOpen())
        DispObj(ho_ImageDump, HDevWindowStack::GetActive());
      //
      //Check for mouse events
      hv_GraphEvent = 0;
      hv_Exit = 0;
      while (0 != 1)
      {
        //
        //Check graphic event
        try
        {
          GetMpositionSubPix(hv_WindowHandle, &hv_GraphButtonRow, &hv_GraphButtonColumn, 
              &hv_GraphButton);
          if (0 != (hv_GraphButton!=0))
          {
            if (0 != (HTuple(HTuple(HTuple(hv_GraphButtonRow>((hv_Height-hv_TextHeight)-25)).TupleAnd(hv_GraphButtonRow<hv_Height)).TupleAnd(hv_GraphButtonColumn>((hv_Width-hv_TextWidth)-15))).TupleAnd(hv_GraphButtonColumn<hv_Width)))
            {
              //Wait until the continue button has been released
              if (0 != (hv_WaitForButtonRelease==HTuple("true")))
              {
                while (0 != 1)
                {
                  GetMpositionSubPix(hv_WindowHandle, &hv_GraphButtonRow, &hv_GraphButtonColumn, 
                      &hv_GraphButton);
                  if (0 != (HTuple(hv_GraphButton==0).TupleOr(hv_GraphButton==HTuple())))
                  {
                    if (0 != (HTuple(HTuple(HTuple(hv_GraphButtonRow>((hv_Height-hv_TextHeight)-25)).TupleAnd(hv_GraphButtonRow<hv_Height)).TupleAnd(hv_GraphButtonColumn>((hv_Width-hv_TextWidth)-15))).TupleAnd(hv_GraphButtonColumn<hv_Width)))
                    {
                      hv_ButtonReleased = 1;
                    }
                    else
                    {
                      hv_ButtonReleased = 0;
                    }
                    //
                    break;
                  }
                  //Keep waiting until mouse button is released or moved out of the window
                }
              }
              else
              {
                hv_ButtonReleased = 1;
              }
              //Exit the visualization loop
              if (0 != hv_ButtonReleased)
              {
                hv_Exit = 1;
                break;
              }
            }
            hv_GraphEvent = 1;
            break;
          }
          else
          {
            hv_ButtonHold = 0;
          }
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
      if (0 != hv_GraphEvent)
      {
        analyze_graph_event_visualize_object_model_3d(ho_Image, hv_MouseMapping, 
            hv_GraphButton, hv_GraphButtonRow, hv_GraphButtonColumn, hv_WindowHandle, 
            hv_WindowHandleBuffer, hv_VirtualTrackball, hv_TrackballSize, hv_SelectedObject, 
            hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3D, hv_CamParam, hv_Label, hv_Title, 
            hv_Information, hv_GenParamName, hv_GenParamValue, hv_Poses, hv_ButtonHold, 
            hv_TBCenter, hv_TBSize, hv_WindowCenteredRotation, hv_MaxNumModels, &hv_Poses, 
            &hv_SelectedObject, &hv_ButtonHold, &hv_WindowCenteredRotation);
      }
      if (0 != hv_Exit)
      {
        break;
      }
    }
    //
    //Display final state with persistence, if requested
    //Note that disp_object_model_3d must be used instead of the 3D scene
    if (0 != ((hv_PersistenceParamName.TupleLength())>0))
    {
      DispObjectModel3d(hv_WindowHandle, hv_ObjectModel3D, hv_CamParam, hv_Poses, 
          (HTuple("disp_background").Append("alpha")).TupleConcat(hv_PersistenceParamName), 
          (HTuple("true").Append(0.0)).TupleConcat(hv_PersistenceParamValue));
    }
    //
    //Compute the output pose
    if (0 != ExpGetGlobalVar_gIsSinglePose())
    {
      (*hv_PoseOut) = hv_Poses.TupleSelectRange(0,6);
    }
    else
    {
      (*hv_PoseOut) = hv_Poses;
    }
    //
    //Clean up
    SetSystem("clip_region", hv_ClipRegion);
    // dev_set_preferences(...); only in hdevelop
    // dev_set_preferences(...); only in hdevelop
    dump_image_output_visualize_object_model_3d(ho_Image, hv_WindowHandleBuffer, 
        hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3D, hv_GenParamName, hv_GenParamValue, 
        hv_CamParam, hv_Poses, hv_ColorImage, hv_Title, HTuple(), hv_Label, 0, "false", 
        hv_TrackballCenterRow, hv_TrackballCenterCol, hv_TBSize, hv_SelectedObject, 
        hv_WindowCenteredRotation, hv_TBCenter);
    DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
    HDevWindowStack::SetActive(hv_WindowHandle);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_ImageDump, HDevWindowStack::GetActive());
    CloseWindow(hv_WindowHandleBuffer);
    SetPart(hv_WindowHandle, hv_WPRow1, hv_WPColumn1, hv_WPRow2, hv_WPColumn2);
    ClearScene3d(hv_Scene3D);
    hv_Scene3D = HTuple();
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    try
    {
      if (0 != (0<(hv_Scene3DTest.TupleLength())))
      {
        ClearScene3d(hv_Scene3DTest);
        hv_Scene3DTest = HTuple();
      }
      if (0 != (0<(hv_Scene3D.TupleLength())))
      {
        ClearScene3d(hv_Scene3D);
        hv_Scene3D = HTuple();
      }
      if (0 != (0<(hv_WindowHandleBuffer.TupleLength())))
      {
        CloseWindow(hv_WindowHandleBuffer);
        hv_WindowHandleBuffer = HTuple();
      }
    }
    // catch (e) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_e);
      //suppress all further exceptions to return the original exception
    }

    throw HException(hv_Exception);
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Interactively display 3D object models 
void visualize_object_model_3d_ext (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_PoseIn, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_Title, HTuple hv_Label, HTuple hv_Information, HTuple hv_MessageQueue, 
    HTuple hv_Buttons, HTuple hv_Type, HTuple hv_Message, HTuple hv_DispViewPoint, 
    HTuple hv_ViewPoint)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImageDump;

  // Local control variables
  HTuple  hv_Parameters, hv_Scene3DTest, hv_Scene3D;
  HTuple  hv_WindowHandleBuffer, hv_TrackballSize, hv_VirtualTrackball;
  HTuple  hv_MouseMapping, hv_gDispObjOffset, hv_gInfoDecor;
  HTuple  hv_gLabelsDecor, hv_gTitleDecor, hv_gInfoPos, hv_gTitlePos;
  HTuple  hv_gAlphaDeselected, hv_ExitButton, hv_MaxNumModels;
  HTuple  hv_WindowCenteredRotation, hv_NumModels, hv_SelectedObject;
  HTuple  hv_ButtonPressStatus, hv_ClipRegion, hv_CPLength;
  HTuple  hv_RowNotUsed, hv_ColumnNotUsed, hv_Width, hv_Height;
  HTuple  hv_WPRow1, hv_WPColumn1, hv_WPRow2, hv_WPColumn2;
  HTuple  hv_CamParamValue, hv_CamWidth, hv_CamHeight, hv_Scale;
  HTuple  hv_Indices, hv_DispBackground, hv_Mask, hv_Center;
  HTuple  hv_Poses, hv_HomMat3Ds, hv_Sequence, hv_PoseEstimated;
  HTuple  hv_gIsSinglePose, hv_Font, hv_Exception, hv_gUsesOpenGL;
  HTuple  hv_OpenGLInfo, hv_DummyObjectModel3D, hv_CameraIndexTest;
  HTuple  hv_PoseTest, hv_InstanceIndexTest, hv_MinImageSize;
  HTuple  hv_TrackballRadiusPixel, hv_idx, hv_MaxAscent, hv_MaxDescent;
  HTuple  hv_MaxWidth, hv_MaxHeight, hv_Ascent, hv_Descent;
  HTuple  hv_TextWidth, hv_TextHeight, hv_ButtonWidth, hv_ButtonHeight;
  HTuple  hv_gButtons, hv_NumChannels, hv_ColorImage, hv_OriginalGenParamName;
  HTuple  hv_OriginalGenParamValue, hv_Exit, hv_PreviousSentPose;
  HTuple  hv_CameraIndex, hv_AllInstances, hv_SetLight, hv_LightParam;
  HTuple  hv_LightPosition, hv_LightKind, hv_LightIndex, hv_PersistenceParamName;
  HTuple  hv_PersistenceParamValue, hv_AlphaOrig, hv_I, hv_ParamName;
  HTuple  hv_ParamValue, hv_ParamNameTrunk, hv_Instance, hv_HomMat3D;
  HTuple  hv_Qx, hv_Qy, hv_Qz, hv_TBCenter, hv_TBSize, hv_ButtonHold;
  HTuple  hv_SupressUpdateMessage, hv_VisualizeTB, hv_MaxIndex;
  HTuple  hv_TrackballCenterRow, hv_TrackballCenterCol, hv_GraphEvent;
  HTuple  hv_Redraw, hv_RecreateScene3D, hv_GraphButton, hv_MessageHandle;
  HTuple  hv_MessageType, hv_Pos, hv_Angle, hv_Pose, hv_NewPoses;
  HTuple  hv_Index, hv_Model, hv_ButtonIndex, hv_ButtonText;
  HTuple  hv_ButtonPressed, hv_FoundButton, hv_FoundButton2;
  HTuple  hv_PoseOut, hv_GraphButtonRow, hv_GraphButtonColumn;

  //The procedure visualize_object_model_3d can be used to display
  //one or more 3d object models and to interactively modify
  //the object poses by using the mouse.
  //
  //The pose can be modified by moving the mouse while
  //pressing a mouse button. The default settings are:
  //
  // Rotate: Left mouse button
  // Zoom: Shift + Left mouse button (or Center mouse button)
  // Pan: Ctrl + Left mouse button
  //
  //Furthermore, it is possible to select and deselect objects,
  //to decrease the mouse sensitivity, and to toggle the
  //inspection mode (see the description of the generic parameter
  //'inspection_mode' below):
  //
  // (De-)select object(s): Right mouse button
  // Low mouse sensitivity: Alt + Mouse button
  // Toggle inspection mode: Ctrl + Alt + Left mouse button
  //
  //In GenParamName and GenParamValue all generic Parameters
  //of disp_object_model_3d are supported.
  //
  //**********************************************************
  //Define parameter variables
  //**********************************************************
  //
  CreateMessage(&hv_Parameters);
  SetMessageTuple(hv_Parameters, "MessageQueue", hv_MessageQueue);

  //
  //**********************************************************
  //Initialize Handles to enable correct handling in error case
  //**********************************************************
  hv_Scene3DTest = HTuple();
  hv_Scene3D = HTuple();
  hv_WindowHandleBuffer = HTuple();

  //**********************************************************
  //Some user defines that may be adapted if desired
  //**********************************************************
  //
  //TrackballSize defines the diameter of the trackball in
  //the image with respect to the smaller image dimension.
  hv_TrackballSize = 0.8;
  //
  //VirtualTrackball defines the type of virtual trackball that
  //shall be used ('shoemake' or 'bell').
  hv_VirtualTrackball = "shoemake";
  //VirtualTrackball := 'bell'
  //
  //Functionality of mouse buttons
  //    1: Left Button
  //    2: Middle Button
  //    4: Right Button
  //    5: Left+Right Mousebutton
  //  8+x: Shift + Mousebutton
  // 16+x: Ctrl + Mousebutton
  // 48+x: Ctrl + Alt + Mousebutton
  //in the order [Translate, Rotate, Scale, ScaleAlternative1, ScaleAlternative2, SelectObjects, ToggleSelectionMode]
  hv_MouseMapping.Clear();
  hv_MouseMapping[0] = 17;
  hv_MouseMapping[1] = 1;
  hv_MouseMapping[2] = 2;
  hv_MouseMapping[3] = 5;
  hv_MouseMapping[4] = 9;
  hv_MouseMapping[5] = 4;
  hv_MouseMapping[6] = 49;
  //
  //The labels of the objects appear next to their projected
  //center. With gDispObjOffset a fixed offset is added
  //                  R,  C
  hv_gDispObjOffset.Clear();
  hv_gDispObjOffset[0] = -30;
  hv_gDispObjOffset[1] = 0;
  SetMessageTuple(hv_Parameters, "gDispObjOffset", hv_gDispObjOffset);
  //
  //Customize the decoration of the different text elements
  //              Color,   Box
  hv_gInfoDecor.Clear();
  hv_gInfoDecor[0] = "white";
  hv_gInfoDecor[1] = "false";
  SetMessageTuple(hv_Parameters, "gInfoDecor", hv_gInfoDecor);
  hv_gLabelsDecor.Clear();
  hv_gLabelsDecor[0] = "white";
  hv_gLabelsDecor[1] = "false";
  SetMessageTuple(hv_Parameters, "gLabelsDecor", hv_gLabelsDecor);
  hv_gTitleDecor.Clear();
  hv_gTitleDecor[0] = "black";
  hv_gTitleDecor[1] = "true";
  SetMessageTuple(hv_Parameters, "gTitleDecor", hv_gTitleDecor);
  //
  //Customize the position of some text elements
  //  gInfoPos has one of the values
  //  {'UpperLeft', 'LowerLeft', 'UpperRight'}
  hv_gInfoPos = "LowerLeft";
  SetMessageTuple(hv_Parameters, "gInfoPos", hv_gInfoPos);
  //  gTitlePos has one of the values
  //  {'UpperLeft', 'UpperCenter', 'UpperRight'}
  hv_gTitlePos = "UpperLeft";
  SetMessageTuple(hv_Parameters, "gTitlePos", hv_gTitlePos);
  //Alpha value (=1-transparency) that is used for visualizing
  //the objects that are not selected
  hv_gAlphaDeselected = 0.3;
  SetMessageTuple(hv_Parameters, "gAlphaDeselected", hv_gAlphaDeselected);
  //BUTTONS
  hv_ExitButton = -1;
  if (0 != (hv_Buttons==HTuple()))
  {
    //Customize the label of the continue button
    hv_Buttons[0] = " Continue ";
    //Position of the button
    hv_Buttons[1] = "right";
    hv_Buttons[2] = "bottom";
    hv_Buttons[3] = -1;
    hv_Buttons[4] = -1;
    hv_ExitButton = 0;
  }
  //Number of 3D Object models that can be selected and handled individually.
  //If there are more models passed then this number, some calculations
  //are performed differently and the individual selection and handling
  //of models is not supported anymore. Note that the value of MaxNumModels
  //can be overwritten with the generic parameter max_num_selectable_models.
  hv_MaxNumModels = 1000;
  //Defines the default for the initial state of the rotation center:
  //(1) The rotation center is fixed in the center of the image and lies
  //    on the surface of the object.
  //(2) The rotation center lies in the center of the object.
  hv_WindowCenteredRotation = 2;
  //
  //**********************************************************
  //
  //Initialize some values
  hv_NumModels = hv_ObjectModel3D.TupleLength();
  hv_SelectedObject = HTuple(hv_NumModels,1);
  hv_ButtonPressStatus = 0;
  //
  //Apply some system settings
  // dev_set_preferences(...); only in hdevelop
  // dev_get_preferences(...); only in hdevelop
  // dev_set_preferences(...); only in hdevelop
  GetSystem("clip_region", &hv_ClipRegion);
  SetSystem("clip_region", "false");
  dev_update_off();
  //
  //Check if GenParamName matches GenParamValue
  if (0 != ((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength())))
  {
    throw HException("Number of generic parameters does not match number of generic parameter values");
  }
  //
  //
  //Refactor camera parameters to fit to window size
  //
  hv_CPLength = hv_CamParam.TupleLength();
  GetWindowExtents(hv_WindowHandle, &hv_RowNotUsed, &hv_ColumnNotUsed, &hv_Width, 
      &hv_Height);
  GetPart(hv_WindowHandle, &hv_WPRow1, &hv_WPColumn1, &hv_WPRow2, &hv_WPColumn2);
  SetPart(hv_WindowHandle, 0, 0, hv_Height-1, hv_Width-1);
  if (0 != (hv_CPLength==0))
  {
    gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
        hv_Width, hv_Height, &hv_CamParam);
  }
  else
  {
    get_cam_par_data(hv_CamParam, (((((HTuple("sx").Append("sy")).Append("cx")).Append("cy")).Append("image_width")).Append("image_height")), 
        &hv_CamParamValue);
    hv_CamWidth = HTuple(hv_CamParamValue[4]).TupleReal();
    hv_CamHeight = HTuple(hv_CamParamValue[5]).TupleReal();
    hv_Scale = ((hv_Width/hv_CamWidth).TupleConcat(hv_Height/hv_CamHeight)).TupleMin();
    set_cam_par_data(hv_CamParam, "sx", HTuple(hv_CamParamValue[0])/hv_Scale, &hv_CamParam);
    set_cam_par_data(hv_CamParam, "sy", HTuple(hv_CamParamValue[1])/hv_Scale, &hv_CamParam);
    set_cam_par_data(hv_CamParam, "cx", HTuple(hv_CamParamValue[2])*hv_Scale, &hv_CamParam);
    set_cam_par_data(hv_CamParam, "cy", HTuple(hv_CamParamValue[3])*hv_Scale, &hv_CamParam);
    set_cam_par_data(hv_CamParam, "image_width", (HTuple(hv_CamParamValue[4])*hv_Scale).TupleInt(), 
        &hv_CamParam);
    set_cam_par_data(hv_CamParam, "image_height", (HTuple(hv_CamParamValue[5])*hv_Scale).TupleInt(), 
        &hv_CamParam);
  }
  //
  //Check the generic parameters for max_num_selectable_models
  //(Note that the default is set above to MaxNumModels := 1000)
  hv_Indices = hv_GenParamName.TupleFind("max_num_selectable_models");
  if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
  {
    if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]).TupleIsNumber()))
    {
      if (0 != (((HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]).TupleNumber()).TupleInt())<1))
      {
        //Wrong parameter value: Only integer values greater than 0 are allowed
        throw HException("Wrong value for parameter 'max_num_selectable_models' (must be an integer value greater than 0)");
      }
    }
    else
    {
      //Wrong parameter value: Only integer values greater than 0 are allowed
      throw HException("Wrong value for parameter 'max_num_selectable_models' (must be an integer value greater than 0)");
    }
    hv_MaxNumModels = (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]).TupleNumber()).TupleInt();
    hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
    hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
  }
  //
  //Check the generic parameters for window_centered_rotation
  //(Note that the default is set above to WindowCenteredRotation := 2)
  hv_Indices = hv_GenParamName.TupleFind("inspection_mode");
  if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
  {
    if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])])==HTuple("surface")))
    {
      hv_WindowCenteredRotation = 1;
    }
    else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])])==HTuple("standard")))
    {
      hv_WindowCenteredRotation = 2;
    }
    else
    {
      //Wrong parameter value, use default value
    }
    hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
    hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
  }
  //
  //Check the generic parameters for disp_background
  //(The former parameter name 'use_background' is still supported
  // for compatibility reasons)
  hv_DispBackground = "false";
  if (0 != ((hv_GenParamName.TupleLength())>0))
  {
    hv_Mask = (hv_GenParamName.TupleEqualElem("disp_background")).TupleOr(hv_GenParamName.TupleEqualElem("use_background"));
    hv_Indices = hv_Mask.TupleFind(1);
  }
  else
  {
    hv_Indices = -1;
  }
  if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
  {
    hv_DispBackground = HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]);
    if (0 != (HTuple(hv_DispBackground!=HTuple("true")).TupleAnd(hv_DispBackground!=HTuple("false"))))
    {
      //Wrong parameter value: Only 'true' and 'false' are allowed
      throw HException("Wrong value for parameter 'disp_background' (must be either 'true' or 'false')");
    }
    //Note the the background is handled explicitly in this procedure
    //and therefore, the parameter is removed from the list of
    //parameters and disp_background is always set to true (see below)
    hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
    hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
  }
  //
  //Read and check the parameter Label for each object
  if (0 != ((hv_Label.TupleLength())==0))
  {
    hv_Label = 0;
  }
  else if (0 != ((hv_Label.TupleLength())==1))
  {
    hv_Label = HTuple(hv_NumModels,hv_Label);
  }
  else
  {
    if (0 != ((hv_Label.TupleLength())!=hv_NumModels))
    {
      //Error: Number of elements in Label does not match the
      //number of object models
      // stop(...); only in hdevelop
    }
  }
  //
  //Read and check the parameter PoseIn for each object
  get_object_models_center(hv_ObjectModel3D, &hv_Center);
  if (0 != ((hv_PoseIn.TupleLength())==0))
  {
    //If no pose was specified by the caller, automatically calculate
    //a pose that is appropriate for the visualization.
    //Set the initial model reference pose. The orientation is parallel
    //to the object coordinate system, the position is at the center
    //of gravity of all models.
    CreatePose(-HTuple(hv_Center[0]), -HTuple(hv_Center[1]), -HTuple(hv_Center[2]), 
        0, 0, 0, "Rp+T", "gba", "point", &hv_PoseIn);
    determine_optimum_pose_distance(hv_ObjectModel3D, hv_CamParam, 0.9, hv_PoseIn, 
        &hv_PoseEstimated);
    hv_Poses = HTuple();
    hv_HomMat3Ds = HTuple();
    hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
    hv_Poses = HTuple(hv_PoseEstimated[hv_Sequence%7]);
    hv_gIsSinglePose = 1;
    SetMessageTuple(hv_Parameters, "gIsSinglePose", hv_gIsSinglePose);
  }
  else if (0 != ((hv_PoseIn.TupleLength())==7))
  {
    hv_Poses = HTuple();
    hv_HomMat3Ds = HTuple();
    hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
    hv_Poses = HTuple(hv_PoseIn[hv_Sequence%7]);
    hv_gIsSinglePose = 1;
    SetMessageTuple(hv_Parameters, "gIsSinglePose", hv_gIsSinglePose);
  }
  else
  {
    if (0 != ((hv_PoseIn.TupleLength())!=((hv_ObjectModel3D.TupleLength())*7)))
    {
      //Error: Wrong number of values of input control parameter 'PoseIn'
      // stop(...); only in hdevelop
    }
    else
    {
      hv_Poses = hv_PoseIn;
    }
    hv_gIsSinglePose = 0;
    SetMessageTuple(hv_Parameters, "gIsSinglePose", hv_gIsSinglePose);
  }

  //
  //Open (invisible) buffer window to avoid flickering
  OpenWindow(0, 0, hv_Width, hv_Height, 0, "buffer", "", &hv_WindowHandleBuffer);
  SetPart(hv_WindowHandleBuffer, 0, 0, hv_Height-1, hv_Width-1);
  GetFont(hv_WindowHandle, &hv_Font);
  try
  {
    SetFont(hv_WindowHandleBuffer, hv_Font);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  //
  // Is OpenGL available and should it be used?
  hv_gUsesOpenGL = "true";
  SetMessageTuple(hv_Parameters, "gUsesOpenGL", hv_gUsesOpenGL);
  hv_Indices = hv_GenParamName.TupleFind("opengl");
  if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
  {
    hv_gUsesOpenGL = HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]);
    SetMessageTuple(hv_Parameters, "gUsesOpenGL", hv_gUsesOpenGL);
    hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
    hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
    if (0 != (HTuple(hv_gUsesOpenGL!=HTuple("true")).TupleAnd(hv_gUsesOpenGL!=HTuple("false"))))
    {
      //Wrong parameter value: Only 'true' and 'false' are allowed
      throw HException("Wrong value for parameter 'opengl' (must be either 'true' or 'false')");
    }
  }
  if (0 != (hv_gUsesOpenGL==HTuple("true")))
  {
    GetSystem("opengl_info", &hv_OpenGLInfo);
    if (0 != (hv_OpenGLInfo==HTuple("No OpenGL support included.")))
    {
      hv_gUsesOpenGL = "false";
      SetMessageTuple(hv_Parameters, "gUsesOpenGL", hv_gUsesOpenGL);
    }
    else
    {
      GenObjectModel3dFromPoints(0, 0, 0, &hv_DummyObjectModel3D);
      CreateScene3d(&hv_Scene3DTest);
      AddScene3dCamera(hv_Scene3DTest, hv_CamParam, &hv_CameraIndexTest);
      determine_optimum_pose_distance(hv_DummyObjectModel3D, hv_CamParam, 0.9, ((((((HTuple(0).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)), 
          &hv_PoseTest);
      AddScene3dInstance(hv_Scene3DTest, hv_DummyObjectModel3D, hv_PoseTest, &hv_InstanceIndexTest);
      try
      {
        DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3DTest, hv_InstanceIndexTest);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_gUsesOpenGL = "false";
        SetMessageTuple(hv_Parameters, "gUsesOpenGL", hv_gUsesOpenGL);
      }
      hv_Scene3DTest = HTuple();
      hv_DummyObjectModel3D = HTuple();
    }
  }
  //
  //Compute the trackball
  hv_MinImageSize = (hv_Width.TupleConcat(hv_Height)).TupleMin();
  hv_TrackballRadiusPixel = (hv_TrackballSize*hv_MinImageSize)/2.0;
  //
  //Measure the text extents for the continue button in the
  //graphics window
  //Finalize Buttons
  {
  HTuple end_val312 = (hv_Buttons.TupleLength())-1;
  HTuple step_val312 = 5;
  for (hv_idx=0; hv_idx.Continue(end_val312, step_val312); hv_idx += step_val312)
  {
    GetFontExtents(hv_WindowHandle, &hv_MaxAscent, &hv_MaxDescent, &hv_MaxWidth, 
        &hv_MaxHeight);
    GetStringExtents(hv_WindowHandleBuffer, HTuple(hv_Buttons[hv_idx+0])+"  ", &hv_Ascent, 
        &hv_Descent, &hv_TextWidth, &hv_TextHeight);
    hv_ButtonWidth = HTuple(hv_Buttons[hv_idx+3]);
    if (0 != (hv_ButtonWidth==-1))
    {
      hv_ButtonWidth = hv_TextWidth;
    }
    hv_ButtonHeight = HTuple(hv_Buttons[hv_idx+4]);
    if (0 != (hv_ButtonHeight==-1))
    {
      //Button border is of size 2
      hv_ButtonHeight = hv_MaxHeight;
    }
    //X position
    if (0 != (HTuple(hv_Buttons[hv_idx+1])==HTuple("right")))
    {
      hv_Buttons[hv_idx+1] = (hv_Width-15)-hv_ButtonWidth;
    }
    else if (0 != (HTuple(hv_Buttons[hv_idx+1])==HTuple("left")))
    {
      hv_Buttons[hv_idx+1] = 15;
    }
    else if (0 != (HTuple(hv_Buttons[hv_idx+1])==HTuple("center")))
    {
      hv_Buttons[hv_idx+1] = (hv_Width/2)-(hv_ButtonWidth/2);
    }
    else
    {
      throw HException("Invalid button horizontal position: "+HTuple(hv_Buttons[hv_idx+1]));
    }
    hv_Buttons[hv_idx+3] = HTuple(hv_Buttons[hv_idx+1])+hv_ButtonWidth;
    //Y position
    if (0 != (HTuple(hv_Buttons[hv_idx+2])==HTuple("bottom")))
    {
      hv_Buttons[hv_idx+2] = (hv_Height-25)-hv_ButtonHeight;
    }
    else if (0 != (HTuple(hv_Buttons[hv_idx+2])==HTuple("top")))
    {
      hv_Buttons[hv_idx+2] = 25;
    }
    else if (0 != (HTuple(hv_Buttons[hv_idx+2])==HTuple("center")))
    {
      hv_Buttons[hv_idx+2] = (hv_Height/2)-(hv_ButtonHeight/2);
    }
    else
    {
      throw HException("Invalid button vertical position: "+HTuple(hv_Buttons[hv_idx+2]));
    }
    hv_Buttons[hv_idx+4] = HTuple(hv_Buttons[hv_idx+2])+hv_ButtonHeight;
  }
  }
  hv_gButtons = hv_Buttons;
  SetMessageTuple(hv_Parameters, "gButtons", hv_gButtons);
  //
  //Store background image
  if (0 != (hv_DispBackground==HTuple("false")))
  {
    ClearWindow(hv_WindowHandle);
  }
  DumpWindowImage(&ho_Image, hv_WindowHandle);
  //Special treatment for color background images necessary
  CountChannels(ho_Image, &hv_NumChannels);
  hv_ColorImage = hv_NumChannels==3;
  //
  hv_OriginalGenParamName = hv_GenParamName;
  hv_OriginalGenParamValue = hv_GenParamValue;

  hv_Exit = 0;
  hv_PreviousSentPose = HTuple();
  while (0 != (hv_Exit.TupleNot()))
  {
    hv_GenParamName = hv_OriginalGenParamName;
    hv_GenParamValue = hv_OriginalGenParamValue;

    CreateScene3d(&hv_Scene3D);
    AddScene3dCamera(hv_Scene3D, hv_CamParam, &hv_CameraIndex);
    AddScene3dInstance(hv_Scene3D, hv_ObjectModel3D, hv_Poses, &hv_AllInstances);
    //Always set 'disp_background' to true,  because it is handled explicitly
    //in this procedure (see above)
    SetScene3dParam(hv_Scene3D, "disp_background", "true");
    //Check if we have to set light specific parameters
    hv_SetLight = hv_GenParamName.TupleRegexpTest("light_");
    if (0 != hv_SetLight)
    {
      //set position of light source
      hv_Indices = hv_GenParamName.TupleFind("light_position");
      if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
      {
        //If multiple light positions are given, use the last one
        hv_LightParam = (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])]).TupleSplit(HTuple(", "))).TupleNumber();
        if (0 != ((hv_LightParam.TupleLength())!=4))
        {
          throw HException("light_position must be given as a string that contains four space separated floating point numbers");
        }
        hv_LightPosition = hv_LightParam.TupleSelectRange(0,2);
        hv_LightKind = "point_light";
        if (0 != (HTuple(hv_LightParam[3])==0))
        {
          hv_LightKind = "directional_light";
        }
        //Currently, only one light source is supported
        RemoveScene3dLight(hv_Scene3D, 0);
        AddScene3dLight(hv_Scene3D, hv_LightPosition, hv_LightKind, &hv_LightIndex);
        TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
        TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
      }
      //set ambient part of light source
      hv_Indices = hv_GenParamName.TupleFind("light_ambient");
      if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
      {
        //If the ambient part is set multiple times, use the last setting
        hv_LightParam = (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])]).TupleSplit(HTuple(", "))).TupleNumber();
        if (0 != ((hv_LightParam.TupleLength())<3))
        {
          throw HException("light_ambient must be given as a string that contains three space separated floating point numbers");
        }
        SetScene3dLightParam(hv_Scene3D, 0, "ambient", hv_LightParam.TupleSelectRange(0,2));
        TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
        TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
      }
      //Set diffuse part of light source
      hv_Indices = hv_GenParamName.TupleFind("light_diffuse");
      if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
      {
        //If the diffuse part is set multiple times, use the last setting
        hv_LightParam = (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])]).TupleSplit(HTuple(", "))).TupleNumber();
        if (0 != ((hv_LightParam.TupleLength())<3))
        {
          throw HException("light_diffuse must be given as a string that contains three space separated floating point numbers");
        }
        SetScene3dLightParam(hv_Scene3D, 0, "diffuse", hv_LightParam.TupleSelectRange(0,2));
        TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
        TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
      }
    }
    //
    //Handle persistence parameters separately because persistence will
    //only be activated immediately before leaving the visualization
    //procedure
    hv_PersistenceParamName = HTuple();
    hv_PersistenceParamValue = HTuple();
    //Set position of light source
    hv_Indices = hv_GenParamName.TupleFind("object_index_persistence");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("true")))
      {
        hv_PersistenceParamName = hv_PersistenceParamName.TupleConcat("object_index_persistence");
        hv_PersistenceParamValue = hv_PersistenceParamValue.TupleConcat("true");
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("false")))
      {
      }
      else
      {
        throw HException("Wrong value for parameter 'object_index_persistence' (must be either 'true' or 'false')");
      }
      TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
      TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
    }
    hv_Indices = hv_GenParamName.TupleFind("depth_persistence");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("true")))
      {
        hv_PersistenceParamName = hv_PersistenceParamName.TupleConcat("depth_persistence");
        hv_PersistenceParamValue = hv_PersistenceParamValue.TupleConcat("true");
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("false")))
      {
      }
      else
      {
        throw HException("Wrong value for parameter 'depth_persistence' (must be either 'true' or 'false')");
      }
      TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
      TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
    }
    //
    //Parse the generic parameters
    //- First, all parameters that are understood by set_scene_3d_instance_param
    hv_AlphaOrig = HTuple(hv_NumModels,1);
    {
    HTuple end_val456 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val456 = 1;
    for (hv_I=0; hv_I.Continue(end_val456, step_val456); hv_I += step_val456)
    {
      hv_ParamName = HTuple(hv_GenParamName[hv_I]);
      hv_ParamValue = HTuple(hv_GenParamValue[hv_I]);
      //Check if this parameter is understood by set_scene_3d_param
      if (0 != (hv_ParamName==HTuple("alpha")))
      {
        hv_AlphaOrig = HTuple(hv_NumModels,hv_ParamValue);
      }
      try
      {
        SetScene3dParam(hv_Scene3D, hv_ParamName, hv_ParamValue);
        continue;
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (HTuple(HTuple(hv_Exception[0])==1203).TupleOr(HTuple(hv_Exception[0])==1303)))
        {
          throw HException((("Wrong type or value for parameter "+hv_ParamName)+": ")+hv_ParamValue);
        }
      }
      //Check if it is a parameter that is valid for only one instance
      //and therefore can be set only with set_scene_3d_instance_param
      hv_ParamNameTrunk = hv_ParamName.TupleRegexpReplace("_\\d+$","");
      if (0 != (hv_ParamName==hv_ParamNameTrunk))
      {
        hv_Instance = HTuple::TupleGenSequence(0,hv_NumModels-1,1);
      }
      else
      {
        hv_Instance = (hv_ParamName.TupleRegexpReplace(("^"+hv_ParamNameTrunk)+"_(\\d+)$","$1")).TupleNumber();
        if (0 != (HTuple(hv_Instance<0).TupleOr(hv_Instance>(hv_NumModels-1))))
        {
          throw HException(("Parameter "+hv_ParamName)+" refers to a non existing 3D object model");
        }
      }
      try
      {
        SetScene3dInstanceParam(hv_Scene3D, hv_Instance, hv_ParamNameTrunk, hv_ParamValue);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (HTuple(HTuple(hv_Exception[0])==1204).TupleOr(HTuple(hv_Exception[0])==1304)))
        {
          throw HException((("Wrong type or value for parameter "+hv_ParamName)+": ")+hv_ParamValue);
        }
        else if (0 != (HTuple(HTuple(hv_Exception[0])==1203).TupleOr(HTuple(hv_Exception[0])==1303)))
        {
          throw HException("Wrong parameter name "+hv_ParamName);
        }
        else
        {
          throw HException(hv_Exception);
        }
      }
      if (0 != (hv_ParamNameTrunk==HTuple("alpha")))
      {
        hv_AlphaOrig[hv_Instance] = hv_ParamValue;
      }
    }
    }
    //
    //Start the visualization loop
    PoseToHomMat3d(hv_Poses.TupleSelectRange(0,6), &hv_HomMat3D);
    AffineTransPoint3d(hv_HomMat3D, HTuple(hv_Center[0]), HTuple(hv_Center[1]), HTuple(hv_Center[2]), 
        &hv_Qx, &hv_Qy, &hv_Qz);
    hv_TBCenter.Clear();
    hv_TBCenter.Append(hv_Qx);
    hv_TBCenter.Append(hv_Qy);
    hv_TBCenter.Append(hv_Qz);
    hv_TBSize = (0.5+((0.5*(hv_SelectedObject.TupleSum()))/hv_NumModels))*hv_TrackballRadiusPixel;
    hv_ButtonHold = 0;
    hv_SupressUpdateMessage = 0;
    while (0 != (hv_Exit.TupleNot()))
    {
      hv_VisualizeTB = (hv_SelectedObject.TupleMax())!=0;
      hv_MaxIndex = ((HTuple(hv_ObjectModel3D.TupleLength()).TupleConcat(hv_MaxNumModels)).TupleMin())-1;
      //Set trackball fixed in the center of the window
      hv_TrackballCenterRow = hv_Height/2;
      hv_TrackballCenterCol = hv_Width/2;
      if (0 != (hv_WindowCenteredRotation==1))
      {
        try
        {
          get_trackball_center_fixed(hv_SelectedObject.TupleSelectRange(0,hv_MaxIndex), 
              hv_TrackballCenterRow, hv_TrackballCenterCol, hv_TrackballRadiusPixel, 
              hv_Scene3D, hv_ObjectModel3D.TupleSelectRange(0,hv_MaxIndex), hv_Poses.TupleSelectRange(0,((hv_MaxIndex+1)*7)-1), 
              hv_WindowHandleBuffer, hv_CamParam, hv_GenParamName, hv_GenParamValue, 
              &hv_TBCenter, &hv_TBSize);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          disp_message(hv_WindowHandle, "Surface inspection mode is not available.", 
              "image", 5, 20, "red", "true");
          hv_WindowCenteredRotation = 2;
          get_trackball_center(hv_SelectedObject.TupleSelectRange(0,hv_MaxIndex), 
              hv_TrackballRadiusPixel, hv_ObjectModel3D.TupleSelectRange(0,hv_MaxIndex), 
              hv_Poses.TupleSelectRange(0,((hv_MaxIndex+1)*7)-1), &hv_TBCenter, &hv_TBSize);
          WaitSeconds(1);
        }
      }
      else
      {
        get_trackball_center(hv_SelectedObject.TupleSelectRange(0,hv_MaxIndex), hv_TrackballRadiusPixel, 
            hv_ObjectModel3D.TupleSelectRange(0,hv_MaxIndex), hv_Poses.TupleSelectRange(0,((hv_MaxIndex+1)*7)-1), 
            &hv_TBCenter, &hv_TBSize);
      }
      dump_image_output(ho_Image, hv_Parameters, hv_WindowHandleBuffer, hv_Scene3D, 
          hv_AlphaOrig, hv_ObjectModel3D, hv_GenParamName, hv_GenParamValue, hv_CamParam, 
          hv_Poses, hv_ColorImage, hv_Title, hv_Information, hv_Label, hv_VisualizeTB, 
          "true", hv_TrackballCenterRow, hv_TrackballCenterCol, hv_TBSize, hv_SelectedObject, 
          hv_WindowCenteredRotation, hv_TBCenter, hv_Type, hv_Message, hv_DispViewPoint, 
          hv_ViewPoint);
      DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
      if (0 != 1)
      {
        DispObj(ho_ImageDump, hv_WindowHandle);
      }
      else
      {
        HDevWindowStack::SetActive(hv_WindowHandle);
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ImageDump, HDevWindowStack::GetActive());
      }

      if (0 != (hv_Poses!=hv_PreviousSentPose))
      {
        send_pose_update(hv_Parameters, hv_Poses);
        hv_PreviousSentPose = hv_Poses;
      }
      //
      //
      //Check for mouse events
      hv_GraphEvent = 0;
      hv_Exit = 0;
      hv_Redraw = 0;
      hv_RecreateScene3D = 0;
      while (0 != (hv_Exit.TupleNot()))
      {
        //
        //Check graphic event
        try
        {
          get_mouse_info(hv_WindowHandle, hv_MessageQueue, 0.01, &hv_GraphButtonRow, 
              &hv_GraphButtonColumn, &hv_GraphButton);

          if (0 != (hv_GraphButton==-1))
          {
            //timeout! Check the second message queue
            try
            {
              //Process all messages first, then perform any update
              //This avoids message congestion, where we are too slow with the redrawing.
              while (0 != 1)
              {
                DequeueMessage(HTuple(hv_MessageQueue[1]), "timeout", 0.001, &hv_MessageHandle);
                GetMessageTuple(hv_MessageHandle, "type", &hv_MessageType);
                if (0 != (hv_MessageType==HTuple("exit")))
                {
                  //Graceful exit
                  hv_Exit = 1;
                  break;
                }
                else if (0 != (hv_MessageType==HTuple("exit_fast")))
                {
                  //Fast exit - no cleanup of resources! Use only for debugging.
                  return;
                }
                else if (0 != (hv_MessageType==HTuple("toggle_param")))
                {
                  GetMessageTuple(hv_MessageHandle, "param", &hv_ParamName);
                  hv_Pos = hv_OriginalGenParamName.TupleFind(hv_ParamName);
                  if (0 != (HTuple(hv_Pos!=-1).TupleAnd(hv_Pos!=HTuple())))
                  {
                    if (0 != (HTuple(hv_OriginalGenParamValue[hv_Pos])==HTuple("true")))
                    {
                      hv_OriginalGenParamValue[hv_Pos] = "false";
                    }
                    else
                    {
                      hv_OriginalGenParamValue[hv_Pos] = "true";
                    }
                  }
                  else
                  {
                    hv_OriginalGenParamName = hv_OriginalGenParamName.TupleConcat(hv_ParamName);
                    hv_OriginalGenParamValue = hv_OriginalGenParamValue.TupleConcat("true");
                    hv_Pos = (hv_OriginalGenParamName.TupleLength())-1;
                  }
                  //try
                    //set_scene_3d_param (Scene3D, GenParamName[Pos], GenParamValue[Pos])
                  //catch (Exception)
                    //If the parameter cannot be set directly, recreate the scene
                    //completely
                    hv_RecreateScene3D = 1;
                  //endtry
                  hv_Redraw = 1;
                }
                else if (0 != (hv_MessageType==HTuple("auto_rotate")))
                {
                  GetMessageTuple(hv_MessageHandle, "angle", &hv_Angle);
                  hv_Pose.Clear();
                  hv_Pose[0] = 0;
                  hv_Pose[1] = 0;
                  hv_Pose[2] = 0;
                  hv_Pose[3] = 0;
                  hv_Pose[4] = 0;
                  hv_Pose.Append(hv_Angle);
                  hv_Pose.Append(0);
                  PoseCompose(hv_Poses, hv_Pose, &hv_Poses);
                  SetScene3dInstancePose(hv_Scene3D, hv_AllInstances, hv_Poses);
                  hv_Redraw = 1;
                }
                else if (0 != (hv_MessageType==HTuple("set_pose")))
                {
                  GetMessageTuple(hv_MessageHandle, "poses", &hv_NewPoses);
                  if (0 != ((hv_NewPoses.TupleLength())==(hv_Poses.TupleLength())))
                  {
                    hv_NewPoses = hv_Poses;
                  }
                  else if (0 != ((hv_NewPoses.TupleLength())==7))
                  {
                    hv_Poses = ((const HTuple&)hv_NewPoses)[HTuple::TupleGenSequence(0,(hv_Poses.TupleLength())-1,1)%7];
                  }
                  else
                  {
                    //use only first pose in NewPoses
                    hv_Poses = ((const HTuple&)hv_NewPoses)[HTuple::TupleGenSequence(0,(hv_Poses.TupleLength())-1,1)%7];
                  }
                  SetScene3dInstancePose(hv_Scene3D, hv_AllInstances, hv_Poses);
                  hv_Redraw = 1;
                }
                else if (0 != (hv_MessageType==HTuple("replace_object_model")))
                {
                  GetMessageTuple(hv_MessageHandle, "index", &hv_Index);
                  GetMessageTuple(hv_MessageHandle, "model", &hv_Model);
                  hv_ObjectModel3D[hv_Index] = hv_Model;
                  hv_RecreateScene3D = 1;
                  hv_Redraw = 1;
                }
                else if (0 != (hv_MessageType==HTuple("force_redraw")))
                {
                  hv_Redraw = 1;
                }
                else if (0 != (hv_MessageType==HTuple("change_button_text")))
                {
                  GetMessageTuple(hv_MessageHandle, "index", &hv_ButtonIndex);
                  GetMessageTuple(hv_MessageHandle, "text", &hv_ButtonText);
                  if (0 != (HTuple(hv_ButtonIndex>=0).TupleAnd(hv_ButtonIndex<((hv_gButtons.TupleLength())/5))))
                  {
                    hv_gButtons[5*hv_ButtonIndex] = hv_ButtonText;
                    SetMessageTuple(hv_Parameters, "gButtons", hv_gButtons);
                  }
                  hv_Redraw = 1;
                }
                else if (0 != (hv_MessageType==HTuple("change_title")))
                {
                  GetMessageTuple(hv_MessageHandle, "title", &hv_Title);
                  hv_Redraw = 1;
                }
              }
            }
            // catch (Exception) 
            catch (HException &HDevExpDefaultException)
            {
              HDevExpDefaultException.ToHTuple(&hv_Exception);
              //Timeout in dequeue_message is OK
              if (0 != (HTuple(hv_Exception[0])!=9400))
              {
                throw HException(hv_Exception);
              }
            }
            if (0 != hv_Redraw)
            {
              break;
            }
            continue;
          }

          if (0 != (hv_GraphButton!=0))
          {
            check_mouse_over_button(hv_Parameters, hv_GraphButtonRow, hv_GraphButtonColumn, 
                &hv_FoundButton);
            hv_ButtonPressed = -1;
            if (0 != (hv_FoundButton>=0))
            {
              //Wait until the button has been released
              while (0 != 1)
              {
                get_mouse_info(hv_WindowHandle, hv_MessageQueue, HTuple(), &hv_GraphButtonRow, 
                    &hv_GraphButtonColumn, &hv_GraphButton);
                if (0 != (hv_GraphButton==0))
                {
                  check_mouse_over_button(hv_Parameters, hv_GraphButtonRow, hv_GraphButtonColumn, 
                      &hv_FoundButton2);
                  if (0 != (hv_FoundButton2==hv_FoundButton))
                  {
                    hv_ButtonPressed = hv_FoundButton;
                  }
                  break;
                }
                //Keep waiting until mouse button is released or moved out of the window
              }
              if (0 != (hv_ButtonPressed>=0))
              {
                if (0 != (hv_ButtonPressed==hv_ExitButton))
                {
                  hv_Exit = 1;
                  break;
                }
                else
                {
                  CreateMessage(&hv_MessageHandle);
                  SetMessageTuple(hv_MessageHandle, "type", "button_pressed");
                  SetMessageTuple(hv_MessageHandle, "button", hv_ButtonPressed/5);
                  EnqueueMessage(HTuple(hv_MessageQueue[2]), hv_MessageHandle, HTuple(), 
                      HTuple());
                }
              }
            }
            hv_GraphEvent = 1;
            break;
          }
          else
          {
            hv_ButtonHold = 0;
          }
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
      if (0 != hv_GraphEvent)
      {
        analyze_graph_event(ho_Image, hv_Parameters, hv_MouseMapping, hv_GraphButton, 
            hv_GraphButtonRow, hv_GraphButtonColumn, hv_WindowHandle, hv_WindowHandleBuffer, 
            hv_VirtualTrackball, hv_TrackballSize, hv_SelectedObject, hv_Scene3D, 
            hv_AlphaOrig, hv_ObjectModel3D, hv_CamParam, hv_Label, hv_Title, hv_Information, 
            hv_GenParamName, hv_GenParamValue, hv_Poses, hv_ButtonHold, hv_TBCenter, 
            hv_TBSize, hv_WindowCenteredRotation, hv_MaxNumModels, hv_MessageQueue, 
            &hv_Poses, &hv_SelectedObject, &hv_ButtonHold, &hv_WindowCenteredRotation);
      }
      if (0 != hv_RecreateScene3D)
      {
        break;
      }
    }
  }

  try
  {
    //
    //Display final state with persistence, if requested
    //Note that disp_object_model_3d must be used instead of the 3D scene
    if (0 != ((hv_PersistenceParamName.TupleLength())>0))
    {
      try
      {
        DispObjectModel3d(hv_WindowHandle, hv_ObjectModel3D, hv_CamParam, hv_Poses, 
            (HTuple("disp_background").Append("alpha")).TupleConcat(hv_PersistenceParamName), 
            (HTuple("true").Append(0.0)).TupleConcat(hv_PersistenceParamValue));
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        // stop(...); only in hdevelop
      }
    }
    //
    //Compute the output pose
    GetMessageTuple(hv_Parameters, "gIsSinglePose", &hv_gIsSinglePose);
    if (0 != hv_gIsSinglePose)
    {
      hv_PoseOut = hv_Poses.TupleSelectRange(0,6);
    }
    else
    {
      hv_PoseOut = hv_Poses;
    }
    //
    //Clean up
    SetSystem("clip_region", hv_ClipRegion);
    // dev_set_preferences(...); only in hdevelop
    // dev_set_preferences(...); only in hdevelop
    dump_image_output(ho_Image, hv_Parameters, hv_WindowHandleBuffer, hv_Scene3D, 
        hv_AlphaOrig, hv_ObjectModel3D, hv_GenParamName, hv_GenParamValue, hv_CamParam, 
        hv_Poses, hv_ColorImage, hv_Title, HTuple(), hv_Label, 0, "false", hv_TrackballCenterRow, 
        hv_TrackballCenterCol, hv_TBSize, hv_SelectedObject, hv_WindowCenteredRotation, 
        hv_TBCenter, hv_Type, hv_Message, hv_DispViewPoint, hv_ViewPoint);
    DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
    HDevWindowStack::SetActive(hv_WindowHandle);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_ImageDump, HDevWindowStack::GetActive());
    CloseWindow(hv_WindowHandleBuffer);
    SetPart(hv_WindowHandle, hv_WPRow1, hv_WPColumn1, hv_WPRow2, hv_WPColumn2);

    //Notify listener that we have terminated
    if (0 != (hv_MessageQueue!=HTuple()))
    {
      CreateMessage(&hv_MessageHandle);
      SetMessageTuple(hv_MessageHandle, "type", "done");
      EnqueueMessage(HTuple(hv_MessageQueue[2]), hv_MessageHandle, HTuple(), HTuple());
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    if (0 != (HTuple(HTuple(hv_Exception[0])==2454).TupleOr(HTuple(hv_Exception[0])==5100)))
    {
      //Handle was already cleared -> indicates that the window was closed (by the user)
      //Abort gracefully.
      return;
    }
    else
    {
      //Unknown / Unexpected exception
      throw HException(hv_Exception);
    }
  }

  return;
}

// Short Description: Display continue button and wait for user to click it 
void wait_continue_button (HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Row1, hv_Column1, hv_WinWidth, hv_WinHeight;
  HTuple  hv_Ascent1, hv_Descent1, hv_TextWidth, hv_TextHeight;
  HTuple  hv_ButtonRow, hv_ButtonCol, hv_Row, hv_Column, hv_Button;
  HTuple  hv_Exception;

  //Wait for the user to click the exit button
  GetWindowExtents(hv_WindowHandle, &hv_Row1, &hv_Column1, &hv_WinWidth, &hv_WinHeight);
  GetStringExtents(hv_WindowHandle, "Continue", &hv_Ascent1, &hv_Descent1, &hv_TextWidth, 
      &hv_TextHeight);
  hv_ButtonRow = (hv_WinHeight-hv_TextHeight)-20;
  hv_ButtonCol = (hv_WinWidth-hv_TextWidth)-30;
  disp_text_button(hv_WindowHandle, "Continue", "window", hv_ButtonRow, hv_ButtonCol, 
      "black", "#f28f26");
  while (0 != 1)
  {
    try
    {
      GetMposition(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Button);
      if (0 != (HTuple(HTuple(hv_Button!=0).TupleAnd(hv_Row>=hv_ButtonRow)).TupleAnd(hv_Column>=hv_ButtonCol)))
      {
        break;
      }
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      if (0 != (HTuple(HTuple(hv_Exception[0])==2454).TupleOr(HTuple(hv_Exception[0])==5100)))
      {
        //Handle was already cleared -> indicates that the window was closed (by the user)
        //Abort gracefully.
        return;
      }
      else if (0 != (HTuple(hv_Exception[0])==5))
      {
        //Ignore -> mouse outside of window
      }
      else
      {
        //Unknown / Unexpected exception
        //Ignore for now
      }
    }
    WaitSeconds(0.01);
  }
  return;
}

void write_note (HTuple hv_WindowHandle, HTuple hv_Type, HTuple hv_String)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Strings, hv_Row, hv_Column, hv_WinWidth;
  HTuple  hv_WinHeight, hv_Pos, hv_Ascent, hv_Descent, hv_Width;
  HTuple  hv_Height, hv_SubStrings, hv_Num, hv_CurrTestString;
  HTuple  hv_Index;

  hv_Strings.Clear();
  hv_Strings[0] = "              ";
  hv_Strings[1] = "[INSTRUCTION] ";
  hv_Strings[2] = "[OK         ] ";
  hv_Strings[3] = "[WARNING    ] ";
  hv_Strings[4] = "[INFO       ] ";
  hv_Strings[5] = "[ERROR      ] ";

  if (0 != (hv_Type==HTuple("Title")))
  {

  }
  if (0 != (hv_Type==HTuple("none")))
  {
    WriteString(hv_WindowHandle, HTuple(hv_Strings[0]));
    SetColor(hv_WindowHandle, "white");
  }
  else if (0 != (hv_Type==HTuple("instruction")))
  {
    SetColor(hv_WindowHandle, "cornflower blue");
    WriteString(hv_WindowHandle, HTuple(hv_Strings[1]));
    SetColor(hv_WindowHandle, "light steel blue");
  }
  else if (0 != (hv_Type==HTuple("ok")))
  {
    SetColor(hv_WindowHandle, "green");
    WriteString(hv_WindowHandle, HTuple(hv_Strings[2]));
    SetColor(hv_WindowHandle, "#AAFFAA");
  }
  else if (0 != (hv_Type==HTuple("warning")))
  {
    SetColor(hv_WindowHandle, "yellow");
    WriteString(hv_WindowHandle, HTuple(hv_Strings[3]));
    SetColor(hv_WindowHandle, "#FFFF00");
  }
  else if (0 != (hv_Type==HTuple("info")))
  {
    SetColor(hv_WindowHandle, "white");
    WriteString(hv_WindowHandle, HTuple(hv_Strings[4]));
  }
  else if (0 != (hv_Type==HTuple("error")))
  {
    SetColor(hv_WindowHandle, "red");
    WriteString(hv_WindowHandle, HTuple(hv_Strings[5]));
    SetColor(hv_WindowHandle, "#FFAAAA");
  }
  else
  {
    // stop(...); only in hdevelop
  }

  //Break into lines such that
  //"[SomeInfo]  Text" does not overflow
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_WinWidth, &hv_WinHeight);
  hv_Pos = 0;
  while (0 != (hv_Pos<(hv_String.TupleLength())))
  {
    GetStringExtents(hv_WindowHandle, HTuple(hv_Strings[0])+HTuple(hv_String[hv_Pos]), 
        &hv_Ascent, &hv_Descent, &hv_Width, &hv_Height);
    if (0 != (hv_Width>(hv_WinWidth-20)))
    {
      //Break this line!
      TupleSplit(HTuple(hv_String[hv_Pos]), " ", &hv_SubStrings);
      for (hv_Num=(hv_SubStrings.TupleLength())-1; hv_Num>=1; hv_Num+=-1)
      {
        hv_CurrTestString = ((hv_SubStrings.TupleSelectRange(0,hv_Num-1))+" ").TupleSum();
        GetStringExtents(hv_WindowHandle, HTuple(hv_Strings[0])+hv_CurrTestString, 
            &hv_Ascent, &hv_Descent, &hv_Width, &hv_Height);
        if (0 != (hv_Width>(hv_WinWidth-20)))
        {
          continue;
        }
        else
        {
          //Split the line here
          hv_String[hv_Pos] = ((hv_SubStrings.TupleSelectRange(0,hv_Num-1))+" ").TupleSum();
          TupleInsert(hv_String, hv_Pos+1, ((hv_SubStrings.TupleSelectRange(hv_Num,(hv_SubStrings.TupleLength())-1))+" ").TupleSum(), 
              &hv_String);
          break;
        }
      }
    }
    hv_Pos += 1;
  }

  {
  HTuple end_val56 = (hv_String.TupleLength())-1;
  HTuple step_val56 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val56, step_val56); hv_Index += step_val56)
  {
    if (0 != (hv_Index>0))
    {
      NewLine(hv_WindowHandle);
      WriteString(hv_WindowHandle, HTuple(hv_Strings[0]));
    }
    WriteString(hv_WindowHandle, HTuple(hv_String[hv_Index]));
  }
  }

  NewLine(hv_WindowHandle);
  SetColor(hv_WindowHandle, "white");

  return;
}

// Chapter: 3D Object Model / Transformations
// Short Description: Transform 3D points from images to a 3D object model, and add extended attributes to the points of the object model. 
void xyz_attrib_to_object_model_3d (HObject ho_X, HObject ho_Y, HObject ho_Z, HObject ho_AttribImage, 
    HTuple hv_AttribName, HTuple *hv_ObjectModel3D)
{

  // Local iconic variables
  HObject  ho_DomainX, ho_DomainY, ho_DomainZ, ho_RegionIntersectionTmp;
  HObject  ho_RegionIntersection, ho_Channel;

  // Local control variables
  HTuple  hv_Number, hv_Channels, hv_WidthX, hv_HeightX;
  HTuple  hv_WidthY, hv_HeightY, hv_WidthZ, hv_HeightZ, hv_WidthA;
  HTuple  hv_HeightA, hv_AvailableAttributes, hv_Selection;
  HTuple  hv_Difference, hv_InvalidParameters, hv_Exception;
  HTuple  hv_AttribValues, hv_Index, hv_Rows, hv_Columns;
  HTuple  hv_AttribValuesTmp;

  //
  //Consistency checks:
  CountObj(ho_AttribImage, &hv_Number);
  if (0 != (hv_Number!=1))
  {
    throw HException(HTuple("The attribute image must be an image array with exactly one object. If you want to set multiple attributes, use a multichannel image."));
  }
  //
  CountChannels(ho_AttribImage, &hv_Channels);
  if (0 != (hv_Channels!=(hv_AttribName.TupleLength())))
  {
    throw HException(((("The number of channels of the attribute image ("+hv_Channels)+") must be equal to the number of attribute names (")+(hv_AttribName.TupleLength()))+").");
  }
  //
  GetImageSize(ho_X, &hv_WidthX, &hv_HeightX);
  GetImageSize(ho_Y, &hv_WidthY, &hv_HeightY);
  GetImageSize(ho_Z, &hv_WidthZ, &hv_HeightZ);
  GetImageSize(ho_AttribImage, &hv_WidthA, &hv_HeightA);
  if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(hv_WidthX!=hv_WidthY).TupleOr(hv_HeightX!=hv_HeightY)).TupleOr(hv_WidthX!=hv_WidthZ)).TupleOr(hv_HeightX!=hv_HeightZ)).TupleOr(hv_WidthX!=hv_WidthA)).TupleOr(hv_HeightX!=hv_HeightA)))
  {
    throw HException("Image sizes do not match. The size of all input images must be equal.");
  }
  //
  GetParamInfo("set_object_model_3d_attrib_mod", "AttribName", "value_list", &hv_AvailableAttributes);
  TupleRegexpSelect(hv_AvailableAttributes, "point_.*", &hv_Selection);
  TupleDifference(hv_AttribName, hv_Selection, &hv_Difference);
  TupleRegexpSelect(hv_Difference, "^[^&]", &hv_InvalidParameters);
  if (0 != ((hv_InvalidParameters.TupleLength())>0))
  {
    hv_Exception = ((("The following attribute names are invalid: "+((hv_InvalidParameters+HTuple(", ")).TupleSum()))+HTuple("please use a '&' prefix for extended attributes, e.g., '&"))+HTuple(hv_InvalidParameters[0]))+HTuple("', or a standard point attribute.");
    throw HException(hv_Exception);
  }
  //
  //Get the domain of the images containing the 3D points and get the region all
  //three of them share. This is because xyz_to_object_model_3d only uses points
  //in the intersecting domains of all three images.
  GetDomain(ho_X, &ho_DomainX);
  GetDomain(ho_Y, &ho_DomainY);
  GetDomain(ho_Z, &ho_DomainZ);
  Intersection(ho_DomainX, ho_DomainY, &ho_RegionIntersectionTmp);
  Intersection(ho_RegionIntersectionTmp, ho_DomainZ, &ho_RegionIntersection);
  //
  //Transform the images that contain the X, Y, and Z-coordinates to a 3D object model.
  XyzToObjectModel3d(ho_X, ho_Y, ho_Z, &(*hv_ObjectModel3D));
  //
  //Loop through all channels and collect the cooresponding attribute values
  hv_AttribValues = HTuple();
  {
  HTuple end_val43 = hv_Channels;
  HTuple step_val43 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val43, step_val43); hv_Index += step_val43)
  {
    AccessChannel(ho_AttribImage, &ho_Channel, hv_Index);
    GetRegionPoints(ho_RegionIntersection, &hv_Rows, &hv_Columns);
    GetGrayval(ho_Channel, hv_Rows, hv_Columns, &hv_AttribValuesTmp);
    hv_AttribValues = hv_AttribValues.TupleConcat(hv_AttribValuesTmp);
  }
  }
  //
  //Set the attributes
  SetObjectModel3dAttribMod((*hv_ObjectModel3D), hv_AttribName, "points", hv_AttribValues);
  return;
}

// Generated stubs for parallel procedure calls. Wrapped in name
// space to avoid name conflicts with actual procedure names
namespace HDevExportCpp
{
// Parallel execution wrapper for visualize_object_model_3d_ext(...) 
static void* _hcppthread_visualize_object_model_3d_ext(void *hcthread)
{
  // +++ define thread context for this procedure
  HDevThread*  hcppthread = (HDevThread*) hcthread;
  try
  {
    // Input parameters
    const HTuple        &cbhv_WindowHandle = hcppthread->GetInputCtrlParamTuple(0);
    const HTuple        &cbhv_ObjectModel3D = hcppthread->GetInputCtrlParamTuple(1);
    const HTuple        &cbhv_CamParam = hcppthread->GetInputCtrlParamTuple(2);
    const HTuple        &cbhv_PoseIn = hcppthread->GetInputCtrlParamTuple(3);
    const HTuple        &cbhv_GenParamName = hcppthread->GetInputCtrlParamTuple(4);
    const HTuple        &cbhv_GenParamValue = hcppthread->GetInputCtrlParamTuple(5);
    const HTuple        &cbhv_Title = hcppthread->GetInputCtrlParamTuple(6);
    const HTuple        &cbhv_Label = hcppthread->GetInputCtrlParamTuple(7);
    const HTuple        &cbhv_Information = hcppthread->GetInputCtrlParamTuple(8);
    const HTuple        &cbhv_MessageQueue = hcppthread->GetInputCtrlParamTuple(9);
    const HTuple        &cbhv_Buttons = hcppthread->GetInputCtrlParamTuple(10);
    const HTuple        &cbhv_Type = hcppthread->GetInputCtrlParamTuple(11);
    const HTuple        &cbhv_Message = hcppthread->GetInputCtrlParamTuple(12);
    const HTuple        &cbhv_DispViewPoint = hcppthread->GetInputCtrlParamTuple(13);
    const HTuple        &cbhv_ViewPoint = hcppthread->GetInputCtrlParamTuple(14);

    // Call visualize_object_model_3d_ext
    visualize_object_model_3d_ext(cbhv_WindowHandle, cbhv_ObjectModel3D, cbhv_CamParam, 
        cbhv_PoseIn, cbhv_GenParamName, cbhv_GenParamValue, cbhv_Title, cbhv_Label, 
        cbhv_Information, cbhv_MessageQueue, cbhv_Buttons, cbhv_Type, cbhv_Message, 
        cbhv_DispViewPoint, cbhv_ViewPoint);

    // Reduce reference counter of thread object
    hcppthread->Exit();
    delete hcppthread;

  }
  catch (HException& exc)
  {
    // No exceptions may be raised from stub in parallel case,
    // so we need to store this information prior to cleanup
    bool is_direct_call = hcppthread->IsDirectCall();
    // Attempt to clean up in error case, too
    hcppthread->Exit();
    delete hcppthread;
    // Propagate exception if called directly
    if (is_direct_call)
      throw exc;
  }
  return NULL;
}

// Parallel execution wrapper for set_edge_parameter_sliders(...) 
static void* _hcppthread_set_edge_parameter_sliders(void *hcthread)
{
  // +++ define thread context for this procedure
  HDevThread*  hcppthread = (HDevThread*) hcthread;
  try
  {
    // Input parameters
    const HTuple        &cbhv_WindowHandle = hcppthread->GetInputCtrlParamTuple(0);
    const HTuple        &cbhv_ObjectModel3D = hcppthread->GetInputCtrlParamTuple(1);
    const HTuple        &cbhv_MesageQueues = hcppthread->GetInputCtrlParamTuple(2);
    const HTuple        &cbhv_MessageQueueOut = hcppthread->GetInputCtrlParamTuple(3);
    const HTuple        &cbhv_ModelDiameter = hcppthread->GetInputCtrlParamTuple(4);
    const HTuple        &cbhv_AmplitudeRange = hcppthread->GetInputCtrlParamTuple(5);
    const HTuple        &cbhv_MaxGapRange = hcppthread->GetInputCtrlParamTuple(6);
    const HTuple        &cbhv_Viewpoint = hcppthread->GetInputCtrlParamTuple(7);

    // Output parameters
    HTuple        cbhv_MinAmplitude;
    HTuple        cbhv_MaxGap;

    // Call set_edge_parameter_sliders
    set_edge_parameter_sliders(cbhv_WindowHandle, cbhv_ObjectModel3D, cbhv_MesageQueues, 
        cbhv_MessageQueueOut, cbhv_ModelDiameter, cbhv_AmplitudeRange, cbhv_MaxGapRange, 
        cbhv_Viewpoint, &cbhv_MinAmplitude, &cbhv_MaxGap);

    // Store output parameters in thread object
    hcppthread->StoreOutputCtrlParamTuple(0,cbhv_MinAmplitude);
    hcppthread->StoreOutputCtrlParamTuple(1,cbhv_MaxGap);

    // Reduce reference counter of thread object
    hcppthread->Exit();
    delete hcppthread;

  }
  catch (HException& exc)
  {
    // No exceptions may be raised from stub in parallel case,
    // so we need to store this information prior to cleanup
    bool is_direct_call = hcppthread->IsDirectCall();
    // Attempt to clean up in error case, too
    hcppthread->Exit();
    delete hcppthread;
    // Propagate exception if called directly
    if (is_direct_call)
      throw exc;
  }
  return NULL;
}

}


